{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1326523923315108, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.019044207920948488, "policy_loss": -0.04192038487138537, "vf_loss": 0.046594066825249074, "vf_explained_var": 0.11376952522744735, "kl": 0.017268381334599417, "entropy": 3.8745323623220127, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 8000}, "sampler_results": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}}, "episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 8000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 198.12582491826072, "num_env_steps_trained_throughput_per_sec": 198.12582491826072, "timesteps_total": 4000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 8000, "timers": {"training_iteration_time_ms": 20189.149, "sample_time_ms": 1135.841, "learn_time_ms": 18967.423, "learn_throughput": 210.888, "synch_weights_time_ms": 84.148}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 8000}, "done": false, "episodes_total": 0, "training_iteration": 1, "trial_id": "a9680_00000", "date": "2023-09-24_02-37-18", "timestamp": 1695537438, "time_this_iter_s": 20.199772834777832, "time_total_s": 20.199772834777832, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b3470ee60>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34706a70>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34706b00>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 20.199772834777832, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 4.917241379310345, "ram_util_percent": 15.579310344827588}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4287885648508867, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.004735607409869166, "policy_loss": -0.044217174212584115, "vf_loss": 0.07987315721499423, "vf_explained_var": 0.19589030674348276, "kl": 0.01695651304303643, "entropy": 3.84631396283706, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "sampler_results": {"episode_reward_max": 0.75790625, "episode_reward_min": -1.7253437499999986, "episode_reward_mean": -0.1160656249999997, "episode_len_mean": 155.4, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"blue": 0.82665625, "red": -2.551999999999998}, "policy_reward_max": {"blue": 2.3639375, "red": -1.0809999999999995}, "policy_reward_mean": {"blue": 1.7471343750000004, "red": -1.863199999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994], "episode_lengths": [145, 158, 174, 148, 152], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8139833288999337, "mean_inference_ms": 7.540840177393671, "mean_action_processing_ms": 0.2930543909025429, "mean_env_wait_ms": 0.39811371570795917, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10370016098022461, "StateBufferConnector_ms": 0.004632472991943359, "ViewRequirementAgentConnector_ms": 0.12250900268554688}}, "episode_reward_max": 0.75790625, "episode_reward_min": -1.7253437499999986, "episode_reward_mean": -0.1160656249999997, "episode_len_mean": 155.4, "episodes_this_iter": 5, "policy_reward_min": {"blue": 0.82665625, "red": -2.551999999999998}, "policy_reward_max": {"blue": 2.3639375, "red": -1.0809999999999995}, "policy_reward_mean": {"blue": 1.7471343750000004, "red": -1.863199999999998}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994], "episode_lengths": [145, 158, 174, 148, 152], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8139833288999337, "mean_inference_ms": 7.540840177393671, "mean_action_processing_ms": 0.2930543909025429, "mean_env_wait_ms": 0.39811371570795917, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10370016098022461, "StateBufferConnector_ms": 0.004632472991943359, "ViewRequirementAgentConnector_ms": 0.12250900268554688}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 203.04987957676607, "num_env_steps_trained_throughput_per_sec": 203.04987957676607, "timesteps_total": 8000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 19944.356, "sample_time_ms": 1127.445, "learn_time_ms": 18736.446, "learn_throughput": 213.488, "synch_weights_time_ms": 78.574}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "episodes_total": 5, "training_iteration": 2, "trial_id": "a9680_00000", "date": "2023-09-24_02-37-37", "timestamp": 1695537457, "time_this_iter_s": 19.708006381988525, "time_total_s": 39.90777921676636, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b347601f0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34706200>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34706320>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 39.90777921676636, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 4.814285714285715, "ram_util_percent": 15.69285714285714}, "win_rate": 0.0, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4956616760541996, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.14951485841617493, "policy_loss": -0.03344849053537473, "vf_loss": 0.36724155217719573, "vf_explained_var": 0.1753626625984907, "kl": 0.01581913504866355, "entropy": 3.821253785242637, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 24000, "num_agent_steps_trained": 24000}, "sampler_results": {"episode_reward_max": 1.9033593750000009, "episode_reward_min": -1.7253437499999986, "episode_reward_mean": 0.2813109375000003, "episode_len_mean": 210.9, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"blue": 0.7212343749999999, "red": -2.551999999999998}, "policy_reward_max": {"blue": 2.651906250000004, "red": -0.626}, "policy_reward_mean": {"blue": 1.8680109375000011, "red": -1.5866999999999991}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8081020125652987, "mean_inference_ms": 7.670954458713649, "mean_action_processing_ms": 0.29544510334354296, "mean_env_wait_ms": 0.4064618531354146, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09682416915893555, "StateBufferConnector_ms": 0.004327297210693359, "ViewRequirementAgentConnector_ms": 0.11261940002441406}}, "episode_reward_max": 1.9033593750000009, "episode_reward_min": -1.7253437499999986, "episode_reward_mean": 0.2813109375000003, "episode_len_mean": 210.9, "episodes_this_iter": 5, "policy_reward_min": {"blue": 0.7212343749999999, "red": -2.551999999999998}, "policy_reward_max": {"blue": 2.651906250000004, "red": -0.626}, "policy_reward_mean": {"blue": 1.8680109375000011, "red": -1.5866999999999991}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8081020125652987, "mean_inference_ms": 7.670954458713649, "mean_action_processing_ms": 0.29544510334354296, "mean_env_wait_ms": 0.4064618531354146, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09682416915893555, "StateBufferConnector_ms": 0.004327297210693359, "ViewRequirementAgentConnector_ms": 0.11261940002441406}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 24000, "num_agent_steps_trained": 24000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 197.87612781276934, "num_env_steps_trained_throughput_per_sec": 197.87612781276934, "timesteps_total": 12000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 24000, "timers": {"training_iteration_time_ms": 20034.451, "sample_time_ms": 1135.734, "learn_time_ms": 18821.401, "learn_throughput": 212.524, "synch_weights_time_ms": 75.58}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 24000, "num_agent_steps_trained": 24000}, "done": false, "episodes_total": 10, "training_iteration": 3, "trial_id": "a9680_00000", "date": "2023-09-24_02-37-58", "timestamp": 1695537478, "time_this_iter_s": 20.223249435424805, "time_total_s": 60.13102865219116, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34761900>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b347077f0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34707640>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 60.13102865219116, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 4.768965517241381, "ram_util_percent": 15.69310344827586}, "win_rate": 0.0, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7113581781586011, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.004546983128481467, "policy_loss": -0.04808081264248661, "vf_loss": 0.10590177867173528, "vf_explained_var": 0.2808500049635768, "kl": 0.017340883436069512, "entropy": 3.7912702073653537, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 3360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "sampler_results": {"episode_reward_max": 1.9033593750000009, "episode_reward_min": -1.7253437499999986, "episode_reward_mean": 0.15705208333333356, "episode_len_mean": 234.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"blue": -1.0910000000000002, "red": -2.551999999999998}, "policy_reward_max": {"blue": 2.651906250000004, "red": 0.6755937499999999}, "policy_reward_mean": {"blue": 1.4779192708333342, "red": -1.320867187499999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8009286825535917, "mean_inference_ms": 7.593435293307327, "mean_action_processing_ms": 0.2922550589824399, "mean_env_wait_ms": 0.40108696538302374, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09764730930328369, "StateBufferConnector_ms": 0.0044286251068115234, "ViewRequirementAgentConnector_ms": 0.11317233244578044}}, "episode_reward_max": 1.9033593750000009, "episode_reward_min": -1.7253437499999986, "episode_reward_mean": 0.15705208333333356, "episode_len_mean": 234.0, "episodes_this_iter": 2, "policy_reward_min": {"blue": -1.0910000000000002, "red": -2.551999999999998}, "policy_reward_max": {"blue": 2.651906250000004, "red": 0.6755937499999999}, "policy_reward_mean": {"blue": 1.4779192708333342, "red": -1.320867187499999}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8009286825535917, "mean_inference_ms": 7.593435293307327, "mean_action_processing_ms": 0.2922550589824399, "mean_env_wait_ms": 0.40108696538302374, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09764730930328369, "StateBufferConnector_ms": 0.0044286251068115234, "ViewRequirementAgentConnector_ms": 0.11317233244578044}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 204.70464192089426, "num_env_steps_trained_throughput_per_sec": 204.70464192089426, "timesteps_total": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 19910.919, "sample_time_ms": 1139.508, "learn_time_ms": 18692.079, "learn_throughput": 213.994, "synch_weights_time_ms": 77.54}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "episodes_total": 12, "training_iteration": 4, "trial_id": "a9680_00000", "date": "2023-09-24_02-38-17", "timestamp": 1695537497, "time_this_iter_s": 19.549607038497925, "time_total_s": 79.68063569068909, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34763ac0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34779480>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34779510>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 79.68063569068909, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 4.892857142857143, "ram_util_percent": 15.699999999999998}, "win_rate": 0.08333333333333333, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6507903766507903, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.019669438478255568, "policy_loss": -0.04817962221762476, "vf_loss": 0.05751200569211505, "vf_explained_var": 0.3731679628913601, "kl": 0.017544753394759027, "entropy": 3.754769209275643, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 4320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 40000, "num_agent_steps_trained": 40000}, "sampler_results": {"episode_reward_max": 1.9033593750000009, "episode_reward_min": -1.7253437499999986, "episode_reward_mean": 0.02875841346153922, "episode_len_mean": 247.15384615384616, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"blue": -1.0910000000000002, "red": -2.551999999999998}, "policy_reward_max": {"blue": 2.651906250000004, "red": 0.6755937499999999}, "policy_reward_mean": {"blue": 1.317156250000001, "red": -1.2883978365384603}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7997128127090524, "mean_inference_ms": 7.613005670301713, "mean_action_processing_ms": 0.292763228141038, "mean_env_wait_ms": 0.40022643236900585, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09985153491680439, "StateBufferConnector_ms": 0.004429083604079027, "ViewRequirementAgentConnector_ms": 0.11294713387122521}}, "episode_reward_max": 1.9033593750000009, "episode_reward_min": -1.7253437499999986, "episode_reward_mean": 0.02875841346153922, "episode_len_mean": 247.15384615384616, "episodes_this_iter": 1, "policy_reward_min": {"blue": -1.0910000000000002, "red": -2.551999999999998}, "policy_reward_max": {"blue": 2.651906250000004, "red": 0.6755937499999999}, "policy_reward_mean": {"blue": 1.317156250000001, "red": -1.2883978365384603}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7997128127090524, "mean_inference_ms": 7.613005670301713, "mean_action_processing_ms": 0.292763228141038, "mean_env_wait_ms": 0.40022643236900585, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09985153491680439, "StateBufferConnector_ms": 0.004429083604079027, "ViewRequirementAgentConnector_ms": 0.11294713387122521}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 40000, "num_agent_steps_trained": 40000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.48935429444163, "num_env_steps_trained_throughput_per_sec": 201.48935429444163, "timesteps_total": 20000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 40000, "timers": {"training_iteration_time_ms": 19899.162, "sample_time_ms": 1138.063, "learn_time_ms": 18681.441, "learn_throughput": 214.116, "synch_weights_time_ms": 77.938}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 40000, "num_agent_steps_trained": 40000}, "done": false, "episodes_total": 13, "training_iteration": 5, "trial_id": "a9680_00000", "date": "2023-09-24_02-38-37", "timestamp": 1695537517, "time_this_iter_s": 19.86292314529419, "time_total_s": 99.54355883598328, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b347600a0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34706d40>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34706dd0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 99.54355883598328, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 4.8500000000000005, "ram_util_percent": 15.699999999999998}, "win_rate": 0.15384615384615385, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6979192848006883, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.018204035038373454, "policy_loss": -0.04428348510506718, "vf_loss": 0.05270683516767652, "vf_explained_var": 0.29279940283546846, "kl": 0.01730717381777443, "entropy": 3.7354024464885396, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 5280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "sampler_results": {"episode_reward_max": 1.9033593750000009, "episode_reward_min": -1.7253437499999986, "episode_reward_mean": -0.03052996571428455, "episode_len_mean": 269.7857142857143, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"blue": -1.0910000000000002, "red": -2.551999999999998}, "policy_reward_max": {"blue": 2.651906250000004, "red": 0.6755937499999999}, "policy_reward_mean": {"blue": 1.2750224896428584, "red": -1.305552455357141}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8010321218319346, "mean_inference_ms": 7.647478283925496, "mean_action_processing_ms": 0.29414608635286255, "mean_env_wait_ms": 0.4005087017454975, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10161399841308594, "StateBufferConnector_ms": 0.004476308822631836, "ViewRequirementAgentConnector_ms": 0.11506506374904088}}, "episode_reward_max": 1.9033593750000009, "episode_reward_min": -1.7253437499999986, "episode_reward_mean": -0.03052996571428455, "episode_len_mean": 269.7857142857143, "episodes_this_iter": 1, "policy_reward_min": {"blue": -1.0910000000000002, "red": -2.551999999999998}, "policy_reward_max": {"blue": 2.651906250000004, "red": 0.6755937499999999}, "policy_reward_mean": {"blue": 1.2750224896428584, "red": -1.305552455357141}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8010321218319346, "mean_inference_ms": 7.647478283925496, "mean_action_processing_ms": 0.29414608635286255, "mean_env_wait_ms": 0.4005087017454975, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10161399841308594, "StateBufferConnector_ms": 0.004476308822631836, "ViewRequirementAgentConnector_ms": 0.11506506374904088}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.68292296810498, "num_env_steps_trained_throughput_per_sec": 201.68292296810498, "timesteps_total": 24000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 19888.15, "sample_time_ms": 1133.604, "learn_time_ms": 18674.542, "learn_throughput": 214.195, "synch_weights_time_ms": 78.29}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "episodes_total": 14, "training_iteration": 6, "trial_id": "a9680_00000", "date": "2023-09-24_02-38-57", "timestamp": 1695537537, "time_this_iter_s": 19.842227935791016, "time_total_s": 119.38578677177429, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b345cd720>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3477ac20>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3477acb0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 119.38578677177429, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 4.748275862068966, "ram_util_percent": 15.699999999999996}, "win_rate": 0.14285714285714285, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8164356808488569, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0070308551660370235, "policy_loss": -0.04355349817681902, "vf_loss": 0.07334357476017127, "vf_explained_var": 0.41161912176758053, "kl": 0.017768160605328376, "entropy": 3.7027768142521382, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 6240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 56000, "num_agent_steps_trained": 56000}, "sampler_results": {"episode_reward_max": 1.9033593750000009, "episode_reward_min": -7.122171875000029, "episode_reward_mean": -0.7496294570588269, "episode_len_mean": 317.8235294117647, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {"blue": -1.0910000000000002, "red": -12.989171874999972}, "policy_reward_max": {"blue": 5.866999999999995, "red": 0.6755937499999999}, "policy_reward_mean": {"blue": 1.6088420502941165, "red": -2.358471507352935}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7926844704657173, "mean_inference_ms": 7.542818811085808, "mean_action_processing_ms": 0.29089120883271774, "mean_env_wait_ms": 0.39321052457324573, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10343790054321289, "StateBufferConnector_ms": 0.004522239460664637, "ViewRequirementAgentConnector_ms": 0.11683562222649069}}, "episode_reward_max": 1.9033593750000009, "episode_reward_min": -7.122171875000029, "episode_reward_mean": -0.7496294570588269, "episode_len_mean": 317.8235294117647, "episodes_this_iter": 3, "policy_reward_min": {"blue": -1.0910000000000002, "red": -12.989171874999972}, "policy_reward_max": {"blue": 5.866999999999995, "red": 0.6755937499999999}, "policy_reward_mean": {"blue": 1.6088420502941165, "red": -2.358471507352935}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7926844704657173, "mean_inference_ms": 7.542818811085808, "mean_action_processing_ms": 0.29089120883271774, "mean_env_wait_ms": 0.39321052457324573, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10343790054321289, "StateBufferConnector_ms": 0.004522239460664637, "ViewRequirementAgentConnector_ms": 0.11683562222649069}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 56000, "num_agent_steps_trained": 56000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 206.86810019552155, "num_env_steps_trained_throughput_per_sec": 206.86810019552155, "timesteps_total": 28000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 56000, "timers": {"training_iteration_time_ms": 19809.266, "sample_time_ms": 1136.103, "learn_time_ms": 18593.535, "learn_throughput": 215.129, "synch_weights_time_ms": 77.882}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 56000, "num_agent_steps_trained": 56000}, "done": false, "episodes_total": 17, "training_iteration": 7, "trial_id": "a9680_00000", "date": "2023-09-24_02-39-17", "timestamp": 1695537557, "time_this_iter_s": 19.345648527145386, "time_total_s": 138.73143529891968, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b345ce020>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34779870>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b347797e0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 138.73143529891968, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 5.048148148148147, "ram_util_percent": 15.699999999999998}, "win_rate": 0.17647058823529413, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9313627852747837, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.02873687641476863, "policy_loss": -0.048739711204931764, "vf_loss": 0.03884165355314811, "vf_explained_var": 0.15597242129345734, "kl": 0.02120864819301763, "entropy": 3.659721370289723, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 7200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "sampler_results": {"episode_reward_max": 1.9033593750000009, "episode_reward_min": -7.122171875000029, "episode_reward_mean": -0.7545755457500026, "episode_len_mean": 326.05, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {"blue": -1.6560000000000001, "red": -12.989171874999972}, "policy_reward_max": {"blue": 5.866999999999995, "red": 0.6755937499999999}, "policy_reward_mean": {"blue": 1.4370682042499994, "red": -2.1916437499999946}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7923047802846392, "mean_inference_ms": 7.578050485728975, "mean_action_processing_ms": 0.29125205067408083, "mean_env_wait_ms": 0.39320645455124115, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10369300842285156, "StateBufferConnector_ms": 0.004444122314453125, "ViewRequirementAgentConnector_ms": 0.11612117290496826}}, "episode_reward_max": 1.9033593750000009, "episode_reward_min": -7.122171875000029, "episode_reward_mean": -0.7545755457500026, "episode_len_mean": 326.05, "episodes_this_iter": 3, "policy_reward_min": {"blue": -1.6560000000000001, "red": -12.989171874999972}, "policy_reward_max": {"blue": 5.866999999999995, "red": 0.6755937499999999}, "policy_reward_mean": {"blue": 1.4370682042499994, "red": -2.1916437499999946}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7923047802846392, "mean_inference_ms": 7.578050485728975, "mean_action_processing_ms": 0.29125205067408083, "mean_env_wait_ms": 0.39320645455124115, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10369300842285156, "StateBufferConnector_ms": 0.004444122314453125, "ViewRequirementAgentConnector_ms": 0.11612117290496826}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 207.30925430955077, "num_env_steps_trained_throughput_per_sec": 207.30925430955077, "timesteps_total": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 19744.959, "sample_time_ms": 1146.651, "learn_time_ms": 18518.972, "learn_throughput": 215.995, "synch_weights_time_ms": 77.53}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "episodes_total": 20, "training_iteration": 8, "trial_id": "a9680_00000", "date": "2023-09-24_02-39-36", "timestamp": 1695537576, "time_this_iter_s": 19.30367398262024, "time_total_s": 158.03510928153992, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34760370>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3477b6d0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3477b760>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 158.03510928153992, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 5.057142857142857, "ram_util_percent": 15.699999999999998}, "win_rate": 0.2, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8736106000840664, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.013080593162158038, "policy_loss": -0.04669611203232004, "vf_loss": 0.06352706939602891, "vf_explained_var": 0.29558190622677405, "kl": 0.018218610654374363, "entropy": 3.6135996165374915, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 8160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 72000, "num_agent_steps_trained": 72000}, "sampler_results": {"episode_reward_max": 1.9033593750000009, "episode_reward_min": -7.122171875000029, "episode_reward_mean": -0.6589942352526097, "episode_len_mean": 360.3636363636364, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"blue": -1.6880000000000002, "red": -12.989171874999972}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.4214189894425986}, "policy_reward_mean": {"blue": 1.216652912954545, "red": -1.8756471482071495}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7911830615158849, "mean_inference_ms": 7.598285709571525, "mean_action_processing_ms": 0.2916501460328448, "mean_env_wait_ms": 0.3934343271907483, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10134794495322487, "StateBufferConnector_ms": 0.004350055347789417, "ViewRequirementAgentConnector_ms": 0.11381777850064365}}, "episode_reward_max": 1.9033593750000009, "episode_reward_min": -7.122171875000029, "episode_reward_mean": -0.6589942352526097, "episode_len_mean": 360.3636363636364, "episodes_this_iter": 2, "policy_reward_min": {"blue": -1.6880000000000002, "red": -12.989171874999972}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.4214189894425986}, "policy_reward_mean": {"blue": 1.216652912954545, "red": -1.8756471482071495}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7911830615158849, "mean_inference_ms": 7.598285709571525, "mean_action_processing_ms": 0.2916501460328448, "mean_env_wait_ms": 0.3934343271907483, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10134794495322487, "StateBufferConnector_ms": 0.004350055347789417, "ViewRequirementAgentConnector_ms": 0.11381777850064365}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 72000, "num_agent_steps_trained": 72000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.27582724807021, "num_env_steps_trained_throughput_per_sec": 200.27582724807021, "timesteps_total": 36000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 72000, "timers": {"training_iteration_time_ms": 19770.233, "sample_time_ms": 1147.632, "learn_time_ms": 18543.175, "learn_throughput": 215.713, "synch_weights_time_ms": 77.617}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 72000, "num_agent_steps_trained": 72000}, "done": false, "episodes_total": 22, "training_iteration": 9, "trial_id": "a9680_00000", "date": "2023-09-24_02-39-56", "timestamp": 1695537596, "time_this_iter_s": 19.98143434524536, "time_total_s": 178.01654362678528, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34610490>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b347a4700>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b347a4790>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 178.01654362678528, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 4.8571428571428585, "ram_util_percent": 15.785714285714288}, "win_rate": 0.2727272727272727, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7943999878441295, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.04361502585828324, "policy_loss": -0.038459127113067856, "vf_loss": 0.16305427724534335, "vf_explained_var": 0.2576292905335625, "kl": 0.013889214515520302, "entropy": 3.6197503310938677, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 9120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "sampler_results": {"episode_reward_max": 1.9033593750000009, "episode_reward_min": -7.122171875000029, "episode_reward_mean": -0.49553040076138405, "episode_len_mean": 414.2962962962963, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"blue": -1.6880000000000002, "red": -12.989171874999972}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.6824687500000017}, "policy_reward_mean": {"blue": 0.7509394105555564, "red": -1.2464698113169357}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7917087193957367, "mean_inference_ms": 7.6629609387044235, "mean_action_processing_ms": 0.29369449940608455, "mean_env_wait_ms": 0.3933970230482907, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10055700937906902, "StateBufferConnector_ms": 0.004323765083595559, "ViewRequirementAgentConnector_ms": 0.11329385969373915}}, "episode_reward_max": 1.9033593750000009, "episode_reward_min": -7.122171875000029, "episode_reward_mean": -0.49553040076138405, "episode_len_mean": 414.2962962962963, "episodes_this_iter": 5, "policy_reward_min": {"blue": -1.6880000000000002, "red": -12.989171874999972}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.6824687500000017}, "policy_reward_mean": {"blue": 0.7509394105555564, "red": -1.2464698113169357}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7917087193957367, "mean_inference_ms": 7.6629609387044235, "mean_action_processing_ms": 0.29369449940608455, "mean_env_wait_ms": 0.3933970230482907, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10055700937906902, "StateBufferConnector_ms": 0.004323765083595559, "ViewRequirementAgentConnector_ms": 0.11329385969373915}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 204.09531806234543, "num_env_steps_trained_throughput_per_sec": 204.09531806234543, "timesteps_total": 40000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 19753.075, "sample_time_ms": 1146.751, "learn_time_ms": 18526.426, "learn_throughput": 215.908, "synch_weights_time_ms": 78.089}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "episodes_total": 27, "training_iteration": 10, "trial_id": "a9680_00000", "date": "2023-09-24_02-40-16", "timestamp": 1695537616, "time_this_iter_s": 19.60677409172058, "time_total_s": 197.62331771850586, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b345cec50>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3477add0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3477aa70>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 197.62331771850586, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 4.835714285714286, "ram_util_percent": 15.74642857142857}, "win_rate": 0.4074074074074074, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7465214687710007, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.007914154549022593, "policy_loss": -0.045276424421657184, "vf_loss": 0.07165130530678046, "vf_explained_var": 0.4192745193839073, "kl": 0.01710872355633531, "entropy": 3.5959994450211523, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 10080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 88000, "num_agent_steps_trained": 88000}, "sampler_results": {"episode_reward_max": 2.1761175427729507, "episode_reward_min": -7.480531250000043, "episode_reward_mean": -0.526531571805764, "episode_len_mean": 458.21875, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"blue": -1.6880000000000002, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.6824687500000017}, "policy_reward_mean": {"blue": 0.7576867682812507, "red": -1.2842183400870084}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7900286026266902, "mean_inference_ms": 7.659690604932061, "mean_action_processing_ms": 0.2937046886666896, "mean_env_wait_ms": 0.39080235311757766, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10244511067867279, "StateBufferConnector_ms": 0.004376843571662903, "ViewRequirementAgentConnector_ms": 0.1158103346824646}}, "episode_reward_max": 2.1761175427729507, "episode_reward_min": -7.480531250000043, "episode_reward_mean": -0.526531571805764, "episode_len_mean": 458.21875, "episodes_this_iter": 5, "policy_reward_min": {"blue": -1.6880000000000002, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.6824687500000017}, "policy_reward_mean": {"blue": 0.7576867682812507, "red": -1.2842183400870084}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7900286026266902, "mean_inference_ms": 7.659690604932061, "mean_action_processing_ms": 0.2937046886666896, "mean_env_wait_ms": 0.39080235311757766, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10244511067867279, "StateBufferConnector_ms": 0.004376843571662903, "ViewRequirementAgentConnector_ms": 0.1158103346824646}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 88000, "num_agent_steps_trained": 88000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 198.60712579745027, "num_env_steps_trained_throughput_per_sec": 198.60712579745027, "timesteps_total": 44000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 88000, "timers": {"training_iteration_time_ms": 19748.182, "sample_time_ms": 1144.244, "learn_time_ms": 18524.06, "learn_throughput": 215.935, "synch_weights_time_ms": 78.009}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 88000, "num_agent_steps_trained": 88000}, "done": false, "episodes_total": 32, "training_iteration": 11, "trial_id": "a9680_00000", "date": "2023-09-24_02-40-36", "timestamp": 1695537636, "time_this_iter_s": 20.149333000183105, "time_total_s": 217.77265071868896, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34612e60>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b347a5f30>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b347a5fc0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 217.77265071868896, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 4.737931034482759, "ram_util_percent": 15.793103448275865}, "win_rate": 0.40625, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9980431479712328, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.028804213535477175, "policy_loss": -0.050923075652584276, "vf_loss": 0.04101882537943311, "vf_explained_var": 0.5875700433428089, "kl": 0.017253479667602174, "entropy": 3.5665947097043196, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 11040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "sampler_results": {"episode_reward_max": 2.1761175427729507, "episode_reward_min": -7.480531250000043, "episode_reward_mean": -0.531380046902559, "episode_len_mean": 447.54545454545456, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"blue": -1.6880000000000002, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.6824687500000017}, "policy_reward_mean": {"blue": 0.6884538359090916, "red": -1.2198338828116446}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7897709292862485, "mean_inference_ms": 7.65336420073551, "mean_action_processing_ms": 0.2934721173834435, "mean_env_wait_ms": 0.3901933712522101, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10197487744418057, "StateBufferConnector_ms": 0.004351861549146248, "ViewRequirementAgentConnector_ms": 0.11543143879283559}}, "episode_reward_max": 2.1761175427729507, "episode_reward_min": -7.480531250000043, "episode_reward_mean": -0.531380046902559, "episode_len_mean": 447.54545454545456, "episodes_this_iter": 1, "policy_reward_min": {"blue": -1.6880000000000002, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.6824687500000017}, "policy_reward_mean": {"blue": 0.6884538359090916, "red": -1.2198338828116446}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7897709292862485, "mean_inference_ms": 7.65336420073551, "mean_action_processing_ms": 0.2934721173834435, "mean_env_wait_ms": 0.3901933712522101, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10197487744418057, "StateBufferConnector_ms": 0.004351861549146248, "ViewRequirementAgentConnector_ms": 0.11543143879283559}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 202.80346033829701, "num_env_steps_trained_throughput_per_sec": 202.80346033829701, "timesteps_total": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 19750.576, "sample_time_ms": 1144.869, "learn_time_ms": 18525.472, "learn_throughput": 215.919, "synch_weights_time_ms": 78.373}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "episodes_total": 33, "training_iteration": 12, "trial_id": "a9680_00000", "date": "2023-09-24_02-40-56", "timestamp": 1695537656, "time_this_iter_s": 19.73260998725891, "time_total_s": 237.50526070594788, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34613640>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b347a41f0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b347a4ee0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 237.50526070594788, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 4.8571428571428585, "ram_util_percent": 15.792857142857144}, "win_rate": 0.42424242424242425, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.196368454520901, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.04226901431296331, "policy_loss": -0.054068147986254186, "vf_loss": 0.020041734936239664, "vf_explained_var": 0.72147999946028, "kl": 0.01766074851228344, "entropy": 3.5199589019020396, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 104000, "num_agent_steps_trained": 104000}, "sampler_results": {"episode_reward_max": 2.641976842816244, "episode_reward_min": -7.480531250000043, "episode_reward_mean": -0.17611725205042988, "episode_len_mean": 743.9622641509434, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"blue": -1.6880000000000002, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.6824687500000017}, "policy_reward_mean": {"blue": 0.20458981490566708, "red": -0.38070706695608175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7846722669069038, "mean_inference_ms": 7.6580999495785065, "mean_action_processing_ms": 0.2920516076531394, "mean_env_wait_ms": 0.3870383442867471, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09670662430097472, "StateBufferConnector_ms": 0.004121267570639556, "ViewRequirementAgentConnector_ms": 0.11059450653364074}}, "episode_reward_max": 2.641976842816244, "episode_reward_min": -7.480531250000043, "episode_reward_mean": -0.17611725205042988, "episode_len_mean": 743.9622641509434, "episodes_this_iter": 20, "policy_reward_min": {"blue": -1.6880000000000002, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.6824687500000017}, "policy_reward_mean": {"blue": 0.20458981490566708, "red": -0.38070706695608175}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7846722669069038, "mean_inference_ms": 7.6580999495785065, "mean_action_processing_ms": 0.2920516076531394, "mean_env_wait_ms": 0.3870383442867471, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09670662430097472, "StateBufferConnector_ms": 0.004121267570639556, "ViewRequirementAgentConnector_ms": 0.11059450653364074}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 104000, "num_agent_steps_trained": 104000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 198.29070577321448, "num_env_steps_trained_throughput_per_sec": 198.29070577321448, "timesteps_total": 52000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 104000, "timers": {"training_iteration_time_ms": 19746.349, "sample_time_ms": 1143.618, "learn_time_ms": 18520.274, "learn_throughput": 215.98, "synch_weights_time_ms": 80.502}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 104000, "num_agent_steps_trained": 104000}, "done": false, "episodes_total": 53, "training_iteration": 13, "trial_id": "a9680_00000", "date": "2023-09-24_02-41-16", "timestamp": 1695537676, "time_this_iter_s": 20.181734800338745, "time_total_s": 257.6869955062866, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34611ff0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34778f70>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3477a950>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 257.6869955062866, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 4.744827586206896, "ram_util_percent": 15.793103448275865}, "win_rate": 0.5849056603773585, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2346906418601673, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0015244011318524522, "policy_loss": -0.057526260868568595, "vf_loss": 0.10727227536262944, "vf_explained_var": 0.3379761818796396, "kl": 0.01932407837790985, "entropy": 3.4315014332532883, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "sampler_results": {"episode_reward_max": 2.7178625000000074, "episode_reward_min": -7.480531250000043, "episode_reward_mean": -0.07587810756866634, "episode_len_mean": 713.1754385964912, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {"blue": -1.6880000000000002, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.7792869878161888}, "policy_reward_mean": {"blue": 0.1905215603508837, "red": -0.26639966791953607}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7838235676676067, "mean_inference_ms": 7.657631112544459, "mean_action_processing_ms": 0.29183096252557994, "mean_env_wait_ms": 0.3874309744007131, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09579658508300781, "StateBufferConnector_ms": 0.0040899243271141725, "ViewRequirementAgentConnector_ms": 0.10983797541835852}}, "episode_reward_max": 2.7178625000000074, "episode_reward_min": -7.480531250000043, "episode_reward_mean": -0.07587810756866634, "episode_len_mean": 713.1754385964912, "episodes_this_iter": 4, "policy_reward_min": {"blue": -1.6880000000000002, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.7792869878161888}, "policy_reward_mean": {"blue": 0.1905215603508837, "red": -0.26639966791953607}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7838235676676067, "mean_inference_ms": 7.657631112544459, "mean_action_processing_ms": 0.29183096252557994, "mean_env_wait_ms": 0.3874309744007131, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09579658508300781, "StateBufferConnector_ms": 0.0040899243271141725, "ViewRequirementAgentConnector_ms": 0.10983797541835852}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.87755136813269, "num_env_steps_trained_throughput_per_sec": 201.87755136813269, "timesteps_total": 56000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 19773.712, "sample_time_ms": 1145.1, "learn_time_ms": 18546.767, "learn_throughput": 215.671, "synch_weights_time_ms": 79.882}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "episodes_total": 57, "training_iteration": 14, "trial_id": "a9680_00000", "date": "2023-09-24_02-41-36", "timestamp": 1695537696, "time_this_iter_s": 19.823201417922974, "time_total_s": 277.5101969242096, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b3465dfc0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b347a5d80>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b347a7010>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 277.5101969242096, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 4.913793103448277, "ram_util_percent": 15.793103448275865}, "win_rate": 0.5789473684210527, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3603044817845027, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.01621058378732414, "policy_loss": -0.05297748602849121, "vf_loss": 0.13422120979133373, "vf_explained_var": 0.3330669580027461, "kl": 0.018287408209948806, "entropy": 3.4087576821446417, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 13920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000}, "sampler_results": {"episode_reward_max": 2.7178625000000074, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.05953563709134378, "episode_len_mean": 710.6212121212121, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.789046875000003}, "policy_reward_mean": {"blue": 0.11615095931818921, "red": -0.056615322226830855}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.784323913749138, "mean_inference_ms": 7.673513512120603, "mean_action_processing_ms": 0.2919894986512985, "mean_env_wait_ms": 0.38738581242143966, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0978740778836337, "StateBufferConnector_ms": 0.004168893351699367, "ViewRequirementAgentConnector_ms": 0.11280522202000473}}, "episode_reward_max": 2.7178625000000074, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.05953563709134378, "episode_len_mean": 710.6212121212121, "episodes_this_iter": 9, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.789046875000003}, "policy_reward_mean": {"blue": 0.11615095931818921, "red": -0.056615322226830855}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.784323913749138, "mean_inference_ms": 7.673513512120603, "mean_action_processing_ms": 0.2919894986512985, "mean_env_wait_ms": 0.38738581242143966, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0978740778836337, "StateBufferConnector_ms": 0.004168893351699367, "ViewRequirementAgentConnector_ms": 0.11280522202000473}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 198.77557151358215, "num_env_steps_trained_throughput_per_sec": 198.77557151358215, "timesteps_total": 60000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 120000, "timers": {"training_iteration_time_ms": 19800.815, "sample_time_ms": 1149.875, "learn_time_ms": 18570.43, "learn_throughput": 215.396, "synch_weights_time_ms": 78.546}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000}, "done": false, "episodes_total": 66, "training_iteration": 15, "trial_id": "a9680_00000", "date": "2023-09-24_02-41-56", "timestamp": 1695537716, "time_this_iter_s": 20.132349491119385, "time_total_s": 297.642546415329, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b3465e4d0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b347a6680>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b347a6b90>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 297.642546415329, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 4.935714285714286, "ram_util_percent": 15.796428571428574}, "win_rate": 0.5909090909090909, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3308423973619936, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.008055427734022184, "policy_loss": -0.06055587521890023, "vf_loss": 0.13143975157290697, "vf_explained_var": 0.40236614098151524, "kl": 0.020930734084614263, "entropy": 3.387792922059695, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 14880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "sampler_results": {"episode_reward_max": 2.7178625000000074, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.1993465869199854, "episode_len_mean": 674.6315789473684, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.789046875000003}, "policy_reward_mean": {"blue": 0.23671994302632304, "red": -0.03737335610632391}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7840692399493512, "mean_inference_ms": 7.671130989570866, "mean_action_processing_ms": 0.2915842766498702, "mean_env_wait_ms": 0.3871981634246927, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09804509187999524, "StateBufferConnector_ms": 0.004161972748605828, "ViewRequirementAgentConnector_ms": 0.11283943527623226}}, "episode_reward_max": 2.7178625000000074, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.1993465869199854, "episode_len_mean": 674.6315789473684, "episodes_this_iter": 10, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.789046875000003}, "policy_reward_mean": {"blue": 0.23671994302632304, "red": -0.03737335610632391}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7840692399493512, "mean_inference_ms": 7.671130989570866, "mean_action_processing_ms": 0.2915842766498702, "mean_env_wait_ms": 0.3871981634246927, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09804509187999524, "StateBufferConnector_ms": 0.004161972748605828, "ViewRequirementAgentConnector_ms": 0.11283943527623226}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.75414292355103, "num_env_steps_trained_throughput_per_sec": 201.75414292355103, "timesteps_total": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 19800.115, "sample_time_ms": 1153.214, "learn_time_ms": 18566.375, "learn_throughput": 215.443, "synch_weights_time_ms": 78.569}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "episodes_total": 76, "training_iteration": 16, "trial_id": "a9680_00000", "date": "2023-09-24_02-42-16", "timestamp": 1695537736, "time_this_iter_s": 19.834975242614746, "time_total_s": 317.4775216579437, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b3465f850>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b347a7d90>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b347a7d00>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 317.4775216579437, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 4.83448275862069, "ram_util_percent": 15.793103448275865}, "win_rate": 0.5789473684210527, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.290526760369539, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.019566324930686583, "policy_loss": -0.05728131043288158, "vf_loss": 0.06807776219405544, "vf_explained_var": 0.4098044010500113, "kl": 0.01575927290987238, "entropy": 3.415567829956611, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 15840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 136000, "num_agent_steps_trained": 136000}, "sampler_results": {"episode_reward_max": 2.7178625000000074, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.20600557383768, "episode_len_mean": 686.5949367088608, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.789046875000003}, "policy_reward_mean": {"blue": 0.21695759853725588, "red": -0.010952024699561146}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7841884286646866, "mean_inference_ms": 7.6774520055275755, "mean_action_processing_ms": 0.29161857636019345, "mean_env_wait_ms": 0.3871509924790444, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09872098512287382, "StateBufferConnector_ms": 0.004192998137655137, "ViewRequirementAgentConnector_ms": 0.11380699616444262}}, "episode_reward_max": 2.7178625000000074, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.20600557383768, "episode_len_mean": 686.5949367088608, "episodes_this_iter": 3, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.789046875000003}, "policy_reward_mean": {"blue": 0.21695759853725588, "red": -0.010952024699561146}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7841884286646866, "mean_inference_ms": 7.6774520055275755, "mean_action_processing_ms": 0.29161857636019345, "mean_env_wait_ms": 0.3871509924790444, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09872098512287382, "StateBufferConnector_ms": 0.004192998137655137, "ViewRequirementAgentConnector_ms": 0.11380699616444262}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 136000, "num_agent_steps_trained": 136000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.3236839751025, "num_env_steps_trained_throughput_per_sec": 199.3236839751025, "timesteps_total": 68000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 136000, "timers": {"training_iteration_time_ms": 19873.301, "sample_time_ms": 1157.412, "learn_time_ms": 18634.877, "learn_throughput": 214.651, "synch_weights_time_ms": 79.028}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 136000, "num_agent_steps_trained": 136000}, "done": false, "episodes_total": 79, "training_iteration": 17, "trial_id": "a9680_00000", "date": "2023-09-24_02-42-36", "timestamp": 1695537756, "time_this_iter_s": 20.078509092330933, "time_total_s": 337.55603075027466, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b346a08e0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3477b130>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3477b640>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 337.55603075027466, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 4.907142857142858, "ram_util_percent": 15.796428571428574}, "win_rate": 0.5822784810126582, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1473961632698773, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.02833500135554156, "policy_loss": -0.046091195665455116, "vf_loss": 0.14093877641716973, "vf_explained_var": 0.3985477017238736, "kl": 0.01632968707215999, "entropy": 3.3915495264033475, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 16800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "sampler_results": {"episode_reward_max": 2.7178625000000074, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.2582001514723877, "episode_len_mean": 666.2093023255813, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.789046875000003}, "policy_reward_mean": {"blue": 0.18973757598189805, "red": 0.06846257549050291}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7847450230029819, "mean_inference_ms": 7.694749460088666, "mean_action_processing_ms": 0.291883300825601, "mean_env_wait_ms": 0.3873336298403839, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09955417278201081, "StateBufferConnector_ms": 0.004215850386508676, "ViewRequirementAgentConnector_ms": 0.11441042256909748}}, "episode_reward_max": 2.7178625000000074, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.2582001514723877, "episode_len_mean": 666.2093023255813, "episodes_this_iter": 7, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 2.789046875000003}, "policy_reward_mean": {"blue": 0.18973757598189805, "red": 0.06846257549050291}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7847450230029819, "mean_inference_ms": 7.694749460088666, "mean_action_processing_ms": 0.291883300825601, "mean_env_wait_ms": 0.3873336298403839, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09955417278201081, "StateBufferConnector_ms": 0.004215850386508676, "ViewRequirementAgentConnector_ms": 0.11441042256909748}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 203.73806012824514, "num_env_steps_trained_throughput_per_sec": 203.73806012824514, "timesteps_total": 72000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 19907.122, "sample_time_ms": 1151.021, "learn_time_ms": 18674.741, "learn_throughput": 214.193, "synch_weights_time_ms": 79.433}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "episodes_total": 86, "training_iteration": 18, "trial_id": "a9680_00000", "date": "2023-09-24_02-42-56", "timestamp": 1695537776, "time_this_iter_s": 19.642476797103882, "time_total_s": 357.19850754737854, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b3465fcd0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b347a71c0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b347a70a0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 357.19850754737854, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 5.025000000000001, "ram_util_percent": 15.792857142857144}, "win_rate": 0.5813953488372093, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4138775801906984, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.011866327652630087, "policy_loss": -0.05923187850664059, "vf_loss": 0.08533616716934679, "vf_explained_var": 0.4720101167758306, "kl": 0.01786764590230639, "entropy": 3.3429733199377853, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 17760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 152000, "num_agent_steps_trained": 152000}, "sampler_results": {"episode_reward_max": 2.7178625000000074, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.3126786026568482, "episode_len_mean": 648.4239130434783, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 3.298377355000002}, "policy_reward_mean": {"blue": 0.16016365798307886, "red": 0.152514944673782}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7853232335766208, "mean_inference_ms": 7.706209357319741, "mean_action_processing_ms": 0.2921918418566336, "mean_env_wait_ms": 0.3874959343529806, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09956165500309157, "StateBufferConnector_ms": 0.004220138425412385, "ViewRequirementAgentConnector_ms": 0.11456025683361551}}, "episode_reward_max": 2.7178625000000074, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.3126786026568482, "episode_len_mean": 648.4239130434783, "episodes_this_iter": 6, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 3.298377355000002}, "policy_reward_mean": {"blue": 0.16016365798307886, "red": 0.152514944673782}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7853232335766208, "mean_inference_ms": 7.706209357319741, "mean_action_processing_ms": 0.2921918418566336, "mean_env_wait_ms": 0.3874959343529806, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09956165500309157, "StateBufferConnector_ms": 0.004220138425412385, "ViewRequirementAgentConnector_ms": 0.11456025683361551}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 152000, "num_agent_steps_trained": 152000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 197.0338548119823, "num_env_steps_trained_throughput_per_sec": 197.0338548119823, "timesteps_total": 76000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 152000, "timers": {"training_iteration_time_ms": 19939.984, "sample_time_ms": 1150.999, "learn_time_ms": 18707.969, "learn_throughput": 213.813, "synch_weights_time_ms": 79.037}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 152000, "num_agent_steps_trained": 152000}, "done": false, "episodes_total": 92, "training_iteration": 19, "trial_id": "a9680_00000", "date": "2023-09-24_02-43-17", "timestamp": 1695537797, "time_this_iter_s": 20.31164240837097, "time_total_s": 377.5101499557495, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b346a2f50>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34691240>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b346912d0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 377.5101499557495, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 4.762068965517242, "ram_util_percent": 15.793103448275865}, "win_rate": 0.5869565217391305, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.610853184511264, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.016116022735028917, "policy_loss": -0.05196875334271075, "vf_loss": 0.06407353605997439, "vf_explained_var": 0.7040526237338781, "kl": 0.015792701871396274, "entropy": 3.290752168248097, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 18720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "sampler_results": {"episode_reward_max": 2.7178625000000074, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.32027419013168, "episode_len_mean": 649.1075268817204, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 3.298377355000002}, "policy_reward_mean": {"blue": 0.15594684445637913, "red": 0.16432734567531304}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7853730616745099, "mean_inference_ms": 7.707736699526417, "mean_action_processing_ms": 0.2922194854058565, "mean_env_wait_ms": 0.3874776650239273, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09953039948658277, "StateBufferConnector_ms": 0.004216676117271506, "ViewRequirementAgentConnector_ms": 0.11455666634344286}}, "episode_reward_max": 2.7178625000000074, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.32027419013168, "episode_len_mean": 649.1075268817204, "episodes_this_iter": 1, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 3.298377355000002}, "policy_reward_mean": {"blue": 0.15594684445637913, "red": 0.16432734567531304}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7853730616745099, "mean_inference_ms": 7.707736699526417, "mean_action_processing_ms": 0.2922194854058565, "mean_env_wait_ms": 0.3874776650239273, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09953039948658277, "StateBufferConnector_ms": 0.004216676117271506, "ViewRequirementAgentConnector_ms": 0.11455666634344286}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 204.44714399535002, "num_env_steps_trained_throughput_per_sec": 204.44714399535002, "timesteps_total": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 19936.611, "sample_time_ms": 1154.172, "learn_time_ms": 18701.896, "learn_throughput": 213.882, "synch_weights_time_ms": 78.523}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "episodes_total": 93, "training_iteration": 20, "trial_id": "a9680_00000", "date": "2023-09-24_02-43-36", "timestamp": 1695537816, "time_this_iter_s": 19.57425546646118, "time_total_s": 397.0844054222107, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b346a3760>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34690940>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34690d30>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 397.0844054222107, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 4.964285714285715, "ram_util_percent": 15.792857142857144}, "win_rate": 0.5913978494623656, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4769521238903205, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.026020343019808934, "policy_loss": -0.05391813662232987, "vf_loss": 0.04840050041384529, "vf_explained_var": 0.555033752322197, "kl": 0.015453680920669892, "entropy": 3.2566125385463236, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 19680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000}, "sampler_results": {"episode_reward_max": 2.7178625000000074, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.24149979650062495, "episode_len_mean": 639.02, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 3.298377355000002}, "policy_reward_mean": {"blue": 0.12052556534443307, "red": 0.12097423115620302}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7853513290975974, "mean_inference_ms": 7.711437000219573, "mean_action_processing_ms": 0.2921311618845752, "mean_env_wait_ms": 0.38745553049433745, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09874594211578369, "StateBufferConnector_ms": 0.004184722900390625, "ViewRequirementAgentConnector_ms": 0.113777756690979}}, "episode_reward_max": 2.7178625000000074, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.24149979650062495, "episode_len_mean": 639.02, "episodes_this_iter": 7, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 3.298377355000002}, "policy_reward_mean": {"blue": 0.12052556534443307, "red": 0.12097423115620302}, "hist_stats": {"episode_reward": [-0.19295312500000006, 0.75790625, -1.7253437499999986, 0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286], "episode_lengths": [145, 158, 174, 148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280], "policy_blue_reward": [1.8540468749999999, 1.83890625, 0.82665625, 2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7853513290975974, "mean_inference_ms": 7.711437000219573, "mean_action_processing_ms": 0.2921311618845752, "mean_env_wait_ms": 0.38745553049433745, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09874594211578369, "StateBufferConnector_ms": 0.004184722900390625, "ViewRequirementAgentConnector_ms": 0.113777756690979}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.69223582047422, "num_env_steps_trained_throughput_per_sec": 201.69223582047422, "timesteps_total": 84000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 168000, "timers": {"training_iteration_time_ms": 19905.806, "sample_time_ms": 1159.106, "learn_time_ms": 18666.12, "learn_throughput": 214.292, "synch_weights_time_ms": 78.62}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000}, "done": false, "episodes_total": 100, "training_iteration": 21, "trial_id": "a9680_00000", "date": "2023-09-24_02-43-56", "timestamp": 1695537836, "time_this_iter_s": 19.84151864051819, "time_total_s": 416.9259240627289, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b346a2e30>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b348ba440>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b348ba8c0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 416.9259240627289, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 4.8310344827586205, "ram_util_percent": 15.793103448275865}, "win_rate": 0.6, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4193084958940743, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03696139937261857, "policy_loss": -0.05481894331460353, "vf_loss": 0.028342380624477907, "vf_explained_var": 0.603664210687081, "kl": 0.015433522522994281, "entropy": 3.2587312211592994, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 20640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "sampler_results": {"episode_reward_max": 3.651476842815242, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.31468252764238025, "episode_len_mean": 653.42, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 3.298377355000002}, "policy_reward_mean": {"blue": 0.09308840139443314, "red": 0.22159412624795777}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242], "episode_lengths": [148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544], "policy_blue_reward": [2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7865700269511915, "mean_inference_ms": 7.745599047586982, "mean_action_processing_ms": 0.2929887228560831, "mean_env_wait_ms": 0.3883798327644758, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09929132461547852, "StateBufferConnector_ms": 0.0042035579681396484, "ViewRequirementAgentConnector_ms": 0.11432218551635742}}, "episode_reward_max": 3.651476842815242, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.31468252764238025, "episode_len_mean": 653.42, "episodes_this_iter": 3, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 3.298377355000002}, "policy_reward_mean": {"blue": 0.09308840139443314, "red": 0.22159412624795777}, "hist_stats": {"episode_reward": [0.3219375000000002, 0.25812499999999994, 1.9033593750000009, 1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242], "episode_lengths": [148, 152, 237, 286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544], "policy_blue_reward": [2.3639375, 1.852125, 2.6103593750000043, 2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7865700269511915, "mean_inference_ms": 7.745599047586982, "mean_action_processing_ms": 0.2929887228560831, "mean_env_wait_ms": 0.3883798327644758, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09929132461547852, "StateBufferConnector_ms": 0.0042035579681396484, "ViewRequirementAgentConnector_ms": 0.11432218551635742}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 206.028677368673, "num_env_steps_trained_throughput_per_sec": 206.028677368673, "timesteps_total": 88000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 19874.93, "sample_time_ms": 1165.273, "learn_time_ms": 18628.548, "learn_throughput": 214.724, "synch_weights_time_ms": 79.136}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "episodes_total": 103, "training_iteration": 22, "trial_id": "a9680_00000", "date": "2023-09-24_02-44-16", "timestamp": 1695537856, "time_this_iter_s": 19.4252667427063, "time_total_s": 436.3511908054352, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b344dde70>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34690e50>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b346915a0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 436.3511908054352, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 5.040740740740741, "ram_util_percent": 15.792592592592595}, "win_rate": 0.61, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0133234803875286, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.03374657010960315, "policy_loss": -0.04251960679733505, "vf_loss": 0.14753331803367473, "vf_explained_var": 0.5006235495209694, "kl": 0.012715854045859318, "entropy": 3.2226166968544323, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 21600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 184000, "num_agent_steps_trained": 184000}, "sampler_results": {"episode_reward_max": 3.651476842815242, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.3021584166982717, "episode_len_mean": 674.21, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 3.298377355000002}, "policy_reward_mean": {"blue": -0.017455817355566297, "red": 0.3196142340538498}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208], "episode_lengths": [286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280], "policy_blue_reward": [2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7838706645943593, "mean_inference_ms": 7.721781678558725, "mean_action_processing_ms": 0.29199390644062967, "mean_env_wait_ms": 0.38674377646489255, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09837782382965088, "StateBufferConnector_ms": 0.0041582584381103516, "ViewRequirementAgentConnector_ms": 0.11344718933105469}}, "episode_reward_max": 3.651476842815242, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.3021584166982717, "episode_len_mean": 674.21, "episodes_this_iter": 3, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 3.298377355000002}, "policy_reward_mean": {"blue": -0.017455817355566297, "red": 0.3196142340538498}, "hist_stats": {"episode_reward": [1.0829062499999997, 0.1712656250000002, 0.09523437500000087, 0.14067187499999978, -0.4154062500000002, -0.513078125, -1.5107656249999928, -0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208], "episode_lengths": [286, 267, 277, 265, 322, 377, 405, 564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280], "policy_blue_reward": [2.651906250000004, 2.241265625, 0.7212343749999999, 1.719671875, -1.0910000000000002, 0.14592187499999998, -0.6120000000000001, 0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7838706645943593, "mean_inference_ms": 7.721781678558725, "mean_action_processing_ms": 0.29199390644062967, "mean_env_wait_ms": 0.38674377646489255, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09837782382965088, "StateBufferConnector_ms": 0.0041582584381103516, "ViewRequirementAgentConnector_ms": 0.11344718933105469}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 184000, "num_agent_steps_trained": 184000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.8190547117833, "num_env_steps_trained_throughput_per_sec": 201.8190547117833, "timesteps_total": 92000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 184000, "timers": {"training_iteration_time_ms": 19839.663, "sample_time_ms": 1164.422, "learn_time_ms": 18595.152, "learn_throughput": 215.11, "synch_weights_time_ms": 78.13}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 184000, "num_agent_steps_trained": 184000}, "done": false, "episodes_total": 106, "training_iteration": 23, "trial_id": "a9680_00000", "date": "2023-09-24_02-44-36", "timestamp": 1695537876, "time_this_iter_s": 19.82846975326538, "time_total_s": 456.17966055870056, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b344dea10>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34690dc0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34690c10>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 456.17966055870056, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 4.796551724137931, "ram_util_percent": 15.793103448275865}, "win_rate": 0.64, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5464337542653084, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009204109152051387, "policy_loss": -0.05946946707990719, "vf_loss": 0.09181094643039008, "vf_explained_var": 0.5230522389834126, "kl": 0.016743987429388978, "entropy": 3.174908620119095, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 22560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "sampler_results": {"episode_reward_max": 3.651476842815242, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.38503336659003673, "episode_len_mean": 705.66, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 3.783861730000003}, "policy_reward_mean": {"blue": -0.11835128610556556, "red": 0.503384652695615}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349], "episode_lengths": [564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280], "policy_blue_reward": [0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7844895056029167, "mean_inference_ms": 7.739258356551175, "mean_action_processing_ms": 0.2924247610885662, "mean_env_wait_ms": 0.3860135726583337, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09853661060333252, "StateBufferConnector_ms": 0.00415194034576416, "ViewRequirementAgentConnector_ms": 0.11418414115905762}}, "episode_reward_max": 3.651476842815242, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.38503336659003673, "episode_len_mean": 705.66, "episodes_this_iter": 7, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.866999999999995, "red": 3.783861730000003}, "policy_reward_mean": {"blue": -0.11835128610556556, "red": 0.503384652695615}, "hist_stats": {"episode_reward": [-0.8012788949999936, -7.122171875000029, 0.3077968750000115, -5.501906250000057, 0.4730492300000009, -1.1672187500000004, -1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349], "episode_lengths": [564, 471, 481, 674, 235, 518, 365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280], "policy_blue_reward": [0.7272836050000073, 5.866999999999995, -0.1809999999999985, 3.8139999999999707, 2.6720492300000025, -1.6560000000000001, 0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7844895056029167, "mean_inference_ms": 7.739258356551175, "mean_action_processing_ms": 0.2924247610885662, "mean_env_wait_ms": 0.3860135726583337, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09853661060333252, "StateBufferConnector_ms": 0.00415194034576416, "ViewRequirementAgentConnector_ms": 0.11418414115905762}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.78743516963328, "num_env_steps_trained_throughput_per_sec": 200.78743516963328, "timesteps_total": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 19850.42, "sample_time_ms": 1160.896, "learn_time_ms": 18608.417, "learn_throughput": 214.956, "synch_weights_time_ms": 79.107}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "episodes_total": 113, "training_iteration": 24, "trial_id": "a9680_00000", "date": "2023-09-24_02-44-56", "timestamp": 1695537896, "time_this_iter_s": 19.933977365493774, "time_total_s": 476.11363792419434, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b344de5f0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34693640>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34693910>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 476.11363792419434, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 4.860714285714287, "ram_util_percent": 15.792857142857144}, "win_rate": 0.67, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.419500335181753, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.009820542660114976, "policy_loss": -0.0487180290617592, "vf_loss": 0.10949395949525448, "vf_explained_var": 0.5111353746925791, "kl": 0.01537383175510317, "entropy": 3.1266318408151466, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 23520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 200000, "num_agent_steps_trained": 200000}, "sampler_results": {"episode_reward_max": 3.651476842815242, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.5419703901745231, "episode_len_mean": 707.88, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.629999999999985, "red": 3.783861730000003}, "policy_reward_mean": {"blue": -0.23040414570556475, "red": 0.7723745358801001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002], "episode_lengths": [365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81], "policy_blue_reward": [0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.785234015806603, "mean_inference_ms": 7.7580095045809205, "mean_action_processing_ms": 0.29267146323889953, "mean_env_wait_ms": 0.38639675396272777, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09925377368927002, "StateBufferConnector_ms": 0.004175782203674316, "ViewRequirementAgentConnector_ms": 0.1149148941040039}}, "episode_reward_max": 3.651476842815242, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.5419703901745231, "episode_len_mean": 707.88, "episodes_this_iter": 6, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.629999999999985, "red": 3.783861730000003}, "policy_reward_mean": {"blue": -0.23040414570556475, "red": 0.7723745358801001}, "hist_stats": {"episode_reward": [-1.6536406249999966, -0.13978124999997577, 0.7334189894426133, 1.628468750000002, -1.728953124999967, 0.3141750000000114, 1.1507054799999996, -0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002], "episode_lengths": [365, 826, 581, 170, 913, 280, 985, 910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81], "policy_blue_reward": [0.3750000000000009, -0.2869999999999979, -1.6880000000000002, -1.0539999999999996, -1.2900000000000003, -1.5889999999999955, -1.2789999999999755, -1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.785234015806603, "mean_inference_ms": 7.7580095045809205, "mean_action_processing_ms": 0.29267146323889953, "mean_env_wait_ms": 0.38639675396272777, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09925377368927002, "StateBufferConnector_ms": 0.004175782203674316, "ViewRequirementAgentConnector_ms": 0.1149148941040039}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 200000, "num_agent_steps_trained": 200000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 197.83657284536082, "num_env_steps_trained_throughput_per_sec": 197.83657284536082, "timesteps_total": 100000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 200000, "timers": {"training_iteration_time_ms": 19859.97, "sample_time_ms": 1165.107, "learn_time_ms": 18611.427, "learn_throughput": 214.922, "synch_weights_time_ms": 81.393}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 200000, "num_agent_steps_trained": 200000}, "done": false, "episodes_total": 119, "training_iteration": 25, "trial_id": "a9680_00000", "date": "2023-09-24_02-45-16", "timestamp": 1695537916, "time_this_iter_s": 20.227284908294678, "time_total_s": 496.340922832489, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b3465f4c0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34691900>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34692a70>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 496.340922832489, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 5.006666666666667, "ram_util_percent": 15.896666666666663}, "win_rate": 0.69, "league_size": 4}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.480129179979364, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.027718808880308643, "policy_loss": -0.05829632746608695, "vf_loss": 0.05162847523558109, "vf_explained_var": 0.5643412925923864, "kl": 0.017540525210294314, "entropy": 3.1299542312820754, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 24480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "sampler_results": {"episode_reward_max": 3.651476842815242, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.6369530233934948, "episode_len_mean": 722.48, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.629999999999985, "red": 3.97097448781617}, "policy_reward_mean": {"blue": -0.23548414570556464, "red": 0.8724371690990717}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173], "episode_lengths": [910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176], "policy_blue_reward": [-1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7839817945703998, "mean_inference_ms": 7.729238080272934, "mean_action_processing_ms": 0.2914144683286062, "mean_env_wait_ms": 0.38436859538876145, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09908413887023926, "StateBufferConnector_ms": 0.004154682159423828, "ViewRequirementAgentConnector_ms": 0.11458349227905273}}, "episode_reward_max": 3.651476842815242, "episode_reward_min": -7.480531250000043, "episode_reward_mean": 0.6369530233934948, "episode_len_mean": 722.48, "episodes_this_iter": 7, "policy_reward_min": {"blue": -2.0429999999999975, "red": -13.110531249999974}, "policy_reward_max": {"blue": 5.629999999999985, "red": 3.97097448781617}, "policy_reward_mean": {"blue": -0.23548414570556464, "red": 0.8724371690990717}, "hist_stats": {"episode_reward": [-0.24584374999999858, 1.4528617300000128, 2.1761175427729507, 0.4296125000000006, -0.04775000000000029, -7.480531250000043, -0.6865312499999998, 0.6910000000000333, 0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173], "episode_lengths": [910, 743, 392, 204, 1072, 1066, 106, 1280, 341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176], "policy_blue_reward": [-1.2790000000000004, -1.2229999999999792, 0.08005000000000062, 0.7985625000000001, -1.3150000000000002, 5.629999999999985, -1.5270000000000001, -0.39400000000000013, -0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7839817945703998, "mean_inference_ms": 7.729238080272934, "mean_action_processing_ms": 0.2914144683286062, "mean_env_wait_ms": 0.38436859538876145, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09908413887023926, "StateBufferConnector_ms": 0.004154682159423828, "ViewRequirementAgentConnector_ms": 0.11458349227905273}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 210.27428251921916, "num_env_steps_trained_throughput_per_sec": 210.27428251921916, "timesteps_total": 104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 19779.636, "sample_time_ms": 1165.491, "learn_time_ms": 18531.346, "learn_throughput": 215.85, "synch_weights_time_ms": 80.725}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "episodes_total": 126, "training_iteration": 26, "trial_id": "a9680_00000", "date": "2023-09-24_02-45-36", "timestamp": 1695537936, "time_this_iter_s": 19.033747911453247, "time_total_s": 515.3746707439423, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b344dff70>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b346929e0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b346905e0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 515.3746707439423, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 5.192592592592593, "ram_util_percent": 16.092592592592595}, "win_rate": 0.69, "league_size": 5}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.528781952833136, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0013018698099282724, "policy_loss": -0.055133890618647756, "vf_loss": 0.1039295935149615, "vf_explained_var": 0.5582333642368515, "kl": 0.01689667348896364, "entropy": 3.132539131740729, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 25440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 216000, "num_agent_steps_trained": 216000}, "sampler_results": {"episode_reward_max": 3.651476842815242, "episode_reward_min": -4.395000000000002, "episode_reward_mean": 0.7630300922838625, "episode_len_mean": 708.96, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"blue": -2.0429999999999975, "red": -9.49999999999997, "red_v2": -2.0219999999999985}, "policy_reward_max": {"blue": 5.104999999999983, "red": 3.97097448781617, "red_v2": -0.594}, "policy_reward_mean": {"blue": -0.25347078005669776, "red": 1.037591456739439, "red_v2": -1.3079999999999992}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774], "episode_lengths": [341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160], "policy_blue_reward": [-0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766], "policy_red_v2_reward": [-2.0219999999999985, -0.594]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7848196214832975, "mean_inference_ms": 7.750139800337796, "mean_action_processing_ms": 0.2916930989961919, "mean_env_wait_ms": 0.38512162744468464, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0978853702545166, "StateBufferConnector_ms": 0.004113554954528809, "ViewRequirementAgentConnector_ms": 0.11347079277038574}}, "episode_reward_max": 3.651476842815242, "episode_reward_min": -4.395000000000002, "episode_reward_mean": 0.7630300922838625, "episode_len_mean": 708.96, "episodes_this_iter": 8, "policy_reward_min": {"blue": -2.0429999999999975, "red": -9.49999999999997, "red_v2": -2.0219999999999985}, "policy_reward_max": {"blue": 5.104999999999983, "red": 3.97097448781617, "red_v2": -0.594}, "policy_reward_mean": {"blue": -0.25347078005669776, "red": 1.037591456739439, "red_v2": -1.3079999999999992}, "hist_stats": {"episode_reward": [0.5472343750000002, 0.7131030335440542, -0.26300000000000046, -0.2740000000000006, 2.641976842816244, 1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774], "episode_lengths": [341, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160], "policy_blue_reward": [-0.596, -1.3969999999999694, -1.3549999999999682, -1.4029999999999674, 0.5212836050000047, -0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766], "policy_red_v2_reward": [-2.0219999999999985, -0.594]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7848196214832975, "mean_inference_ms": 7.750139800337796, "mean_action_processing_ms": 0.2916930989961919, "mean_env_wait_ms": 0.38512162744468464, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0978853702545166, "StateBufferConnector_ms": 0.004113554954528809, "ViewRequirementAgentConnector_ms": 0.11347079277038574}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 216000, "num_agent_steps_trained": 216000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 202.77607349524584, "num_env_steps_trained_throughput_per_sec": 202.77607349524584, "timesteps_total": 108000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 216000, "timers": {"training_iteration_time_ms": 19745.47, "sample_time_ms": 1158.942, "learn_time_ms": 18504.135, "learn_throughput": 216.168, "synch_weights_time_ms": 80.366}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 216000, "num_agent_steps_trained": 216000}, "done": false, "episodes_total": 134, "training_iteration": 27, "trial_id": "a9680_00000", "date": "2023-09-24_02-45-56", "timestamp": 1695537956, "time_this_iter_s": 19.73711347579956, "time_total_s": 535.1117842197418, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34511840>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b347a4700>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b347a4940>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 535.1117842197418, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 4.941379310344829, "ram_util_percent": 16.19310344827586}, "win_rate": 0.7, "league_size": 6}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6899611932535965, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.014086190811091607, "policy_loss": -0.056727146885047354, "vf_loss": 0.07416646692727227, "vf_explained_var": 0.5332645329336325, "kl": 0.01921876315445843, "entropy": 3.0907207081715264, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 26400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "sampler_results": {"episode_reward_max": 3.651476842815242, "episode_reward_min": -4.395000000000002, "episode_reward_mean": 0.7600165127892309, "episode_len_mean": 692.44, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"blue": -2.0429999999999975, "red": -9.49999999999997, "red_v2": -2.0219999999999985}, "policy_reward_max": {"blue": 5.104999999999983, "red": 3.97097448781617, "red_v2": 0.9806932378161716}, "policy_reward_mean": {"blue": -0.20094279691295255, "red": 0.9712840934166451, "red_v2": -0.5451022540612755}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345], "episode_lengths": [1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110], "policy_blue_reward": [-0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7854804073847766, "mean_inference_ms": 7.7511446534941, "mean_action_processing_ms": 0.29174720746581134, "mean_env_wait_ms": 0.38522231937196294, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09735536575317383, "StateBufferConnector_ms": 0.00408780574798584, "ViewRequirementAgentConnector_ms": 0.1128767728805542}}, "episode_reward_max": 3.651476842815242, "episode_reward_min": -4.395000000000002, "episode_reward_mean": 0.7600165127892309, "episode_len_mean": 692.44, "episodes_this_iter": 5, "policy_reward_min": {"blue": -2.0429999999999975, "red": -9.49999999999997, "red_v2": -2.0219999999999985}, "policy_reward_max": {"blue": 5.104999999999983, "red": 3.97097448781617, "red_v2": 0.9806932378161716}, "policy_reward_mean": {"blue": -0.20094279691295255, "red": 0.9712840934166451, "red_v2": -0.5451022540612755}, "hist_stats": {"episode_reward": [1.2671030335440856, 0.4420499999999994, -4.395000000000002, 0.7669346144425917, 0.7401030335440574, 0.7246932378152283, 0.12999999999999945, 1.678693237816231, 0.6086925427729457, -0.2770000000000005, 0.4170499999999998, 0.6410000000000159, 0.5910000000000085, 0.8096932378161745, 2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345], "episode_lengths": [1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110], "policy_blue_reward": [-0.8490000000000003, -1.354999999999966, 5.104999999999983, -1.3539999999999723, -1.3719999999999726, -1.382999999999968, -1.3429999999999758, -0.4450000000000002, 1.5350000000000241, -1.3639999999999741, -1.3829999999999691, -0.8570000000000003, -0.8560000000000003, -1.330999999999973, 0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7854804073847766, "mean_inference_ms": 7.7511446534941, "mean_action_processing_ms": 0.29174720746581134, "mean_env_wait_ms": 0.38522231937196294, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09735536575317383, "StateBufferConnector_ms": 0.00408780574798584, "ViewRequirementAgentConnector_ms": 0.1128767728805542}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 196.44129117253473, "num_env_steps_trained_throughput_per_sec": 196.44129117253473, "timesteps_total": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 19818.396, "sample_time_ms": 1155.292, "learn_time_ms": 18580.503, "learn_throughput": 215.279, "synch_weights_time_ms": 80.459}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "episodes_total": 139, "training_iteration": 28, "trial_id": "a9680_00000", "date": "2023-09-24_02-46-17", "timestamp": 1695537977, "time_this_iter_s": 20.372148990631104, "time_total_s": 555.4839332103729, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b346dd180>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b347a64d0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b347a7010>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 555.4839332103729, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 5.613333333333334, "ram_util_percent": 16.38333333333333}, "win_rate": 0.68, "league_size": 7}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6504394318908453, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.015478400085946002, "policy_loss": -0.06171090978411182, "vf_loss": 0.08355851365098109, "vf_explained_var": 0.6946390410885215, "kl": 0.01665778757424633, "entropy": 3.0427515829602876, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 27360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 232000, "num_agent_steps_trained": 232000}, "sampler_results": {"episode_reward_max": 3.651476842815242, "episode_reward_min": -4.2132500000000075, "episode_reward_mean": 0.8476186022851013, "episode_len_mean": 629.24, "episode_media": {}, "episodes_this_iter": 14, "policy_reward_min": {"blue": -2.0429999999999975, "red": -7.263000000000032, "red_v2": -2.0219999999999985, "red_v3": 3.310802612816173, "red_v1": 0.41305000000000236}, "policy_reward_max": {"blue": 4.7067656250000045, "red": 3.97097448781617, "red_v2": 0.9806932378161716, "red_v3": 3.310802612816173, "red_v1": 0.41305000000000236}, "policy_reward_mean": {"blue": -0.2466866494740044, "red": 1.0737185942843528, "red_v2": -0.7863266905459566, "red_v3": 3.310802612816173, "red_v1": 0.41305000000000236}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985], "episode_lengths": [316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280], "policy_blue_reward": [0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716, -1.5099999999999998], "policy_red_v3_reward": [3.310802612816173], "policy_red_v1_reward": [0.41305000000000236]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7871796626091685, "mean_inference_ms": 7.771798892242637, "mean_action_processing_ms": 0.2918862885792242, "mean_env_wait_ms": 0.3858402223883377, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09794020652770996, "StateBufferConnector_ms": 0.004132866859436035, "ViewRequirementAgentConnector_ms": 0.11404931545257568}}, "episode_reward_max": 3.651476842815242, "episode_reward_min": -4.2132500000000075, "episode_reward_mean": 0.8476186022851013, "episode_len_mean": 629.24, "episodes_this_iter": 14, "policy_reward_min": {"blue": -2.0429999999999975, "red": -7.263000000000032, "red_v2": -2.0219999999999985, "red_v3": 3.310802612816173, "red_v1": 0.41305000000000236}, "policy_reward_max": {"blue": 4.7067656250000045, "red": 3.97097448781617, "red_v2": 0.9806932378161716, "red_v3": 3.310802612816173, "red_v1": 0.41305000000000236}, "policy_reward_mean": {"blue": -0.2466866494740044, "red": 1.0737185942843528, "red_v2": -0.7863266905459566, "red_v3": 3.310802612816173, "red_v1": 0.41305000000000236}, "hist_stats": {"episode_reward": [2.7178625000000074, 1.5792869878161981, -0.6253906249999988, 1.3374033644425949, 1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985], "episode_lengths": [316, 706, 93, 106, 207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280], "policy_blue_reward": [0.35699999999999993, -1.1999999999999889, -1.024, 1.88346875, 2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716, -1.5099999999999998], "policy_red_v3_reward": [3.310802612816173], "policy_red_v1_reward": [0.41305000000000236]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7871796626091685, "mean_inference_ms": 7.771798892242637, "mean_action_processing_ms": 0.2918862885792242, "mean_env_wait_ms": 0.3858402223883377, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09794020652770996, "StateBufferConnector_ms": 0.004132866859436035, "ViewRequirementAgentConnector_ms": 0.11404931545257568}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 232000, "num_agent_steps_trained": 232000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.8955729589634, "num_env_steps_trained_throughput_per_sec": 200.8955729589634, "timesteps_total": 116000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 232000, "timers": {"training_iteration_time_ms": 19779.371, "sample_time_ms": 1156.878, "learn_time_ms": 18540.04, "learn_throughput": 215.749, "synch_weights_time_ms": 80.333}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 232000, "num_agent_steps_trained": 232000}, "done": false, "episodes_total": 153, "training_iteration": 29, "trial_id": "a9680_00000", "date": "2023-09-24_02-46-38", "timestamp": 1695537998, "time_this_iter_s": 19.91922092437744, "time_total_s": 575.4031541347504, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b3483dba0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b347a6b90>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b347a7880>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 575.4031541347504, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 5.117241379310346, "ram_util_percent": 16.489655172413794}, "win_rate": 0.67, "league_size": 8}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7538493763655425, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01189327974182864, "policy_loss": -0.05423722125269705, "vf_loss": 0.07503278205404058, "vf_explained_var": 0.6444188515966137, "kl": 0.017470287203168837, "entropy": 3.034078428397576, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 28320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "sampler_results": {"episode_reward_max": 3.651476842815242, "episode_reward_min": -4.2132500000000075, "episode_reward_mean": 0.8034001859406749, "episode_len_mean": 622.33, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {"blue": -2.0429999999999975, "red": -7.263000000000032, "red_v2": -2.0219999999999985, "red_v3": -1.5659999999999987, "red_v1": 0.41305000000000236, "red_v4": -1.532}, "policy_reward_max": {"blue": 4.7067656250000045, "red": 3.97097448781617, "red_v2": 0.9806932378161716, "red_v3": 3.310802612816173, "red_v1": 0.41305000000000236, "red_v4": -1.532}, "policy_reward_mean": {"blue": -0.28555449783213505, "red": 1.0913048654399267, "red_v2": -0.7863266905459566, "red_v3": 0.8724013064080872, "red_v1": 0.41305000000000236, "red_v4": -1.532}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994], "episode_lengths": [207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90], "policy_blue_reward": [2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716, -1.5099999999999998], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987], "policy_red_v1_reward": [0.41305000000000236], "policy_red_v4_reward": [-1.532]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7879557568734488, "mean_inference_ms": 7.77662401760168, "mean_action_processing_ms": 0.29189575989225697, "mean_env_wait_ms": 0.38545525501827393, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0989457368850708, "StateBufferConnector_ms": 0.004160165786743164, "ViewRequirementAgentConnector_ms": 0.1149139404296875}}, "episode_reward_max": 3.651476842815242, "episode_reward_min": -4.2132500000000075, "episode_reward_mean": 0.8034001859406749, "episode_len_mean": 622.33, "episodes_this_iter": 4, "policy_reward_min": {"blue": -2.0429999999999975, "red": -7.263000000000032, "red_v2": -2.0219999999999985, "red_v3": -1.5659999999999987, "red_v1": 0.41305000000000236, "red_v4": -1.532}, "policy_reward_max": {"blue": 4.7067656250000045, "red": 3.97097448781617, "red_v2": 0.9806932378161716, "red_v3": 3.310802612816173, "red_v1": 0.41305000000000236, "red_v4": -1.532}, "policy_reward_mean": {"blue": -0.28555449783213505, "red": 1.0913048654399267, "red_v2": -0.7863266905459566, "red_v3": 0.8724013064080872, "red_v1": 0.41305000000000236, "red_v4": -1.532}, "hist_stats": {"episode_reward": [1.1664531250000003, 0.813934614442614, 2.4453000000000067, 1.2511273550000244, 0.9493773550000207, -0.2201687499999948, 0.4200499999999996, 0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994], "episode_lengths": [207, 1280, 176, 434, 1122, 326, 1280, 1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90], "policy_blue_reward": [2.296453125, -1.3459999999999726, 0.944, -0.6680000000000001, -1.3169999999999715, 1.6757812500000009, -1.384999999999966, -1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716, -1.5099999999999998], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987], "policy_red_v1_reward": [0.41305000000000236], "policy_red_v4_reward": [-1.532]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7879557568734488, "mean_inference_ms": 7.77662401760168, "mean_action_processing_ms": 0.29189575989225697, "mean_env_wait_ms": 0.38545525501827393, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0989457368850708, "StateBufferConnector_ms": 0.004160165786743164, "ViewRequirementAgentConnector_ms": 0.1149139404296875}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 195.0321259473052, "num_env_steps_trained_throughput_per_sec": 195.0321259473052, "timesteps_total": 120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 19873.82, "sample_time_ms": 1158.856, "learn_time_ms": 18631.011, "learn_throughput": 214.696, "synch_weights_time_ms": 81.855}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "episodes_total": 157, "training_iteration": 30, "trial_id": "a9680_00000", "date": "2023-09-24_02-46-59", "timestamp": 1695538019, "time_this_iter_s": 20.51879906654358, "time_total_s": 595.921953201294, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b345cd780>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3477a710>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b347797e0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 595.921953201294, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 5.0200000000000005, "ram_util_percent": 16.686666666666664}, "win_rate": 0.69, "league_size": 9}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.784000110626221, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0359043186896694, "policy_loss": -0.06503866496447396, "vf_loss": 0.04836388552115144, "vf_explained_var": 0.7499438491960366, "kl": 0.017623048394697586, "entropy": 2.97796785980463, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 29280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 248000, "num_agent_steps_trained": 248000}, "sampler_results": {"episode_reward_max": 3.651476842815242, "episode_reward_min": -4.2132500000000075, "episode_reward_mean": 0.8193800770088956, "episode_len_mean": 594.22, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"blue": -2.0429999999999975, "red": -7.263000000000032, "red_v2": -2.0219999999999985, "red_v3": -1.5659999999999987, "red_v1": -1.616, "red_v4": -1.532}, "policy_reward_max": {"blue": 4.7067656250000045, "red": 3.97097448781617, "red_v2": 0.9806932378161716, "red_v3": 3.310802612816173, "red_v1": 0.479, "red_v4": -1.532}, "policy_reward_mean": {"blue": -0.3388891838131422, "red": 1.176647100258147, "red_v2": -0.7863266905459566, "red_v3": 0.06026753760539146, "red_v1": -0.35198749999999945, "red_v4": -1.532}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001], "episode_lengths": [1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74], "policy_blue_reward": [-1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716, -1.5099999999999998], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987, -1.564], "policy_red_v1_reward": [0.41305000000000236, -0.6839999999999999, -1.616, 0.479], "policy_red_v4_reward": [-1.532]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7883553927559628, "mean_inference_ms": 7.778008412110721, "mean_action_processing_ms": 0.29180917112188587, "mean_env_wait_ms": 0.38544057263307346, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09807419776916504, "StateBufferConnector_ms": 0.0041391849517822266, "ViewRequirementAgentConnector_ms": 0.11386096477508545}}, "episode_reward_max": 3.651476842815242, "episode_reward_min": -4.2132500000000075, "episode_reward_mean": 0.8193800770088956, "episode_len_mean": 594.22, "episodes_this_iter": 7, "policy_reward_min": {"blue": -2.0429999999999975, "red": -7.263000000000032, "red_v2": -2.0219999999999985, "red_v3": -1.5659999999999987, "red_v1": -1.616, "red_v4": -1.532}, "policy_reward_max": {"blue": 4.7067656250000045, "red": 3.97097448781617, "red_v2": 0.9806932378161716, "red_v3": 3.310802612816173, "red_v1": 0.479, "red_v4": -1.532}, "policy_reward_mean": {"blue": -0.3388891838131422, "red": 1.176647100258147, "red_v2": -0.7863266905459566, "red_v3": 0.06026753760539146, "red_v1": -0.35198749999999945, "red_v4": -1.532}, "hist_stats": {"episode_reward": [0.6822836049999996, 0.7460468749999999, 0.737693237815226, 2.3234502394425967, 1.3262088628161708, 2.6289276128161823, 0.33464062500000025, 0.41404999999999936, -1.9342343749999917, 2.3919867300000064, 1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001], "episode_lengths": [1280, 145, 1280, 123, 123, 277, 83, 1280, 299, 319, 306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74], "policy_blue_reward": [-1.3509999999999704, -2.0429999999999975, -1.377999999999971, -0.03400000000000003, 1.877515625, -0.08000000000000006, 1.410640625, -1.3609999999999738, 4.7067656250000045, 3.5699867300000028, 2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716, -1.5099999999999998], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987, -1.564], "policy_red_v1_reward": [0.41305000000000236, -0.6839999999999999, -1.616, 0.479], "policy_red_v4_reward": [-1.532]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7883553927559628, "mean_inference_ms": 7.778008412110721, "mean_action_processing_ms": 0.29180917112188587, "mean_env_wait_ms": 0.38544057263307346, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09807419776916504, "StateBufferConnector_ms": 0.0041391849517822266, "ViewRequirementAgentConnector_ms": 0.11386096477508545}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 248000, "num_agent_steps_trained": 248000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.37488024778185, "num_env_steps_trained_throughput_per_sec": 200.37488024778185, "timesteps_total": 124000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 248000, "timers": {"training_iteration_time_ms": 19886.857, "sample_time_ms": 1160.764, "learn_time_ms": 18642.105, "learn_throughput": 214.568, "synch_weights_time_ms": 81.751}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 248000, "num_agent_steps_trained": 248000}, "done": false, "episodes_total": 164, "training_iteration": 31, "trial_id": "a9680_00000", "date": "2023-09-24_02-47-20", "timestamp": 1695538040, "time_this_iter_s": 19.974218368530273, "time_total_s": 615.8961715698242, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34761a20>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3477af80>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3477ad40>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 615.8961715698242, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 4.986666666666666, "ram_util_percent": 16.78666666666667}, "win_rate": 0.71, "league_size": 10}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8746209016690654, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.021187612727226225, "policy_loss": -0.06110552988781516, "vf_loss": 0.06932858098686362, "vf_explained_var": 0.7186524492998918, "kl": 0.01806132979466176, "entropy": 2.8739716470241548, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 30240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "sampler_results": {"episode_reward_max": 3.651476842815242, "episode_reward_min": -4.2132500000000075, "episode_reward_mean": 0.8352900947407302, "episode_len_mean": 611.23, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"blue": -2.025999999999998, "red": -7.263000000000032, "red_v2": -2.0219999999999985, "red_v3": -1.5659999999999987, "red_v1": -1.616, "red_v4": -1.532}, "policy_reward_max": {"blue": 3.4155000000000086, "red": 3.97097448781617, "red_v2": 0.9806932378161716, "red_v3": 3.310802612816173, "red_v1": 0.479, "red_v4": -0.5419999999999999}, "policy_reward_mean": {"blue": -0.49219614594772326, "red": 1.3353513602899811, "red_v2": -0.7716613524367653, "red_v3": 0.06026753760539146, "red_v1": -0.35198749999999945, "red_v4": -1.0279999999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843], "episode_lengths": [306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280], "policy_blue_reward": [2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716, -1.5099999999999998, -0.713], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987, -1.564], "policy_red_v1_reward": [0.41305000000000236, -0.6839999999999999, -1.616, 0.479], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7889288559858688, "mean_inference_ms": 7.787258454458826, "mean_action_processing_ms": 0.2918994652904788, "mean_env_wait_ms": 0.385174222122127, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09720611572265625, "StateBufferConnector_ms": 0.0041266679763793945, "ViewRequirementAgentConnector_ms": 0.11346125602722168}}, "episode_reward_max": 3.651476842815242, "episode_reward_min": -4.2132500000000075, "episode_reward_mean": 0.8352900947407302, "episode_len_mean": 611.23, "episodes_this_iter": 10, "policy_reward_min": {"blue": -2.025999999999998, "red": -7.263000000000032, "red_v2": -2.0219999999999985, "red_v3": -1.5659999999999987, "red_v1": -1.616, "red_v4": -1.532}, "policy_reward_max": {"blue": 3.4155000000000086, "red": 3.97097448781617, "red_v2": 0.9806932378161716, "red_v3": 3.310802612816173, "red_v1": 0.479, "red_v4": -0.5419999999999999}, "policy_reward_mean": {"blue": -0.49219614594772326, "red": 1.3353513602899811, "red_v2": -0.7716613524367653, "red_v3": 0.06026753760539146, "red_v1": -0.35198749999999945, "red_v4": -1.0279999999999998}, "hist_stats": {"episode_reward": [1.0038437499999997, 1.9944218750000102, 0.7436932378152145, 0.01845336444261425, 0.36195312499999965, 0.8810804800000172, 0.9596875, 0.8084588628161882, 1.3305031250000026, 0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843], "episode_lengths": [306, 281, 1280, 874, 815, 417, 356, 491, 271, 155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280], "policy_blue_reward": [2.1898437499999996, -0.5770000000000001, -1.3689999999999671, 1.7489346144426108, -1.2309999999999797, -1.1009999999999969, -1.1099999999999892, 0.5207656249999999, -0.5740000000000001, 1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716, -1.5099999999999998, -0.713], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987, -1.564], "policy_red_v1_reward": [0.41305000000000236, -0.6839999999999999, -1.616, 0.479], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7889288559858688, "mean_inference_ms": 7.787258454458826, "mean_action_processing_ms": 0.2918994652904788, "mean_env_wait_ms": 0.385174222122127, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09720611572265625, "StateBufferConnector_ms": 0.0041266679763793945, "ViewRequirementAgentConnector_ms": 0.11346125602722168}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.73330784706016, "num_env_steps_trained_throughput_per_sec": 200.73330784706016, "timesteps_total": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 19938.074, "sample_time_ms": 1155.782, "learn_time_ms": 18698.285, "learn_throughput": 213.923, "synch_weights_time_ms": 81.751}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "episodes_total": 174, "training_iteration": 32, "trial_id": "a9680_00000", "date": "2023-09-24_02-47-41", "timestamp": 1695538061, "time_this_iter_s": 19.93666934967041, "time_total_s": 635.8328409194946, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b346126e0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b346935b0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b346932e0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 635.8328409194946, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 4.940000000000001, "ram_util_percent": 16.98}, "win_rate": 0.74, "league_size": 11}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.76728181168437, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.007566055496378492, "policy_loss": -0.06291023442463484, "vf_loss": 0.10017255468216414, "vf_explained_var": 0.5803941664596398, "kl": 0.01815466148909574, "entropy": 2.911695670088132, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 31200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 264000, "num_agent_steps_trained": 264000}, "sampler_results": {"episode_reward_max": 3.651476842815242, "episode_reward_min": -4.2132500000000075, "episode_reward_mean": 0.9098731544507146, "episode_len_mean": 579.3, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {"blue": -2.025999999999998, "red": -7.263000000000032, "red_v2": -2.0219999999999985, "red_v3": -1.5659999999999987, "red_v1": -1.616, "red_v4": -1.532, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126}, "policy_reward_max": {"blue": 3.4155000000000086, "red": 3.97097448781617, "red_v2": 0.9806932378161716, "red_v3": 3.310802612816173, "red_v1": 3.2230961050000024, "red_v4": -0.5419999999999999, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126}, "policy_reward_mean": {"blue": -0.5442495635714177, "red": 1.4129335289662392, "red_v2": -0.7716613524367653, "red_v3": -0.1803662311973043, "red_v1": 0.21197322380253472, "red_v4": -1.0279999999999998, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726], "episode_lengths": [155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114], "policy_blue_reward": [1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716, -1.5099999999999998, -0.713], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987, -1.564, -1.076, 0.488, -0.6750000000000002], "policy_red_v1_reward": [0.41305000000000236, -0.6839999999999999, -1.616, 0.479, 3.2230961050000024, -0.5433067621847962], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996], "policy_red_v9_reward": [-2.0109999999999992], "policy_red_v6_reward": [-0.023000000000000013], "policy_red_v7_reward": [0.38784375000000126]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7891355619283259, "mean_inference_ms": 7.784467720539457, "mean_action_processing_ms": 0.2918321266081123, "mean_env_wait_ms": 0.38506441550924725, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0980147123336792, "StateBufferConnector_ms": 0.0041741132736206055, "ViewRequirementAgentConnector_ms": 0.11497807502746582}}, "episode_reward_max": 3.651476842815242, "episode_reward_min": -4.2132500000000075, "episode_reward_mean": 0.9098731544507146, "episode_len_mean": 579.3, "episodes_this_iter": 9, "policy_reward_min": {"blue": -2.025999999999998, "red": -7.263000000000032, "red_v2": -2.0219999999999985, "red_v3": -1.5659999999999987, "red_v1": -1.616, "red_v4": -1.532, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126}, "policy_reward_max": {"blue": 3.4155000000000086, "red": 3.97097448781617, "red_v2": 0.9806932378161716, "red_v3": 3.310802612816173, "red_v1": 3.2230961050000024, "red_v4": -0.5419999999999999, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126}, "policy_reward_mean": {"blue": -0.5442495635714177, "red": 1.4129335289662392, "red_v2": -0.7716613524367653, "red_v3": -0.1803662311973043, "red_v1": 0.21197322380253472, "red_v4": -1.0279999999999998, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126}, "hist_stats": {"episode_reward": [0.2940156250000001, -0.11569738718381672, 1.7727244878162287, -1.3895966355573965, 1.5989218749999998, 1.7718807378161778, 1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726], "episode_lengths": [155, 477, 886, 618, 185, 580, 312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114], "policy_blue_reward": [1.847015625, 0.3650000000000069, -0.7700000000000001, 0.3380000000000043, -1.056999999999996, -1.1379999999999872, -1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716, -1.5099999999999998, -0.713], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987, -1.564, -1.076, 0.488, -0.6750000000000002], "policy_red_v1_reward": [0.41305000000000236, -0.6839999999999999, -1.616, 0.479, 3.2230961050000024, -0.5433067621847962], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996], "policy_red_v9_reward": [-2.0109999999999992], "policy_red_v6_reward": [-0.023000000000000013], "policy_red_v7_reward": [0.38784375000000126]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7891355619283259, "mean_inference_ms": 7.784467720539457, "mean_action_processing_ms": 0.2918321266081123, "mean_env_wait_ms": 0.38506441550924725, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0980147123336792, "StateBufferConnector_ms": 0.0041741132736206055, "ViewRequirementAgentConnector_ms": 0.11497807502746582}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 264000, "num_agent_steps_trained": 264000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 198.67191718075142, "num_env_steps_trained_throughput_per_sec": 198.67191718075142, "timesteps_total": 132000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 264000, "timers": {"training_iteration_time_ms": 19969.469, "sample_time_ms": 1163.699, "learn_time_ms": 18722.02, "learn_throughput": 213.652, "synch_weights_time_ms": 81.417}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 264000, "num_agent_steps_trained": 264000}, "done": false, "episodes_total": 183, "training_iteration": 33, "trial_id": "a9680_00000", "date": "2023-09-24_02-48-02", "timestamp": 1695538082, "time_this_iter_s": 20.143255710601807, "time_total_s": 655.9760966300964, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34512d10>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34641cf0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34641d80>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 655.9760966300964, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 5.283333333333334, "ram_util_percent": 17.090000000000007}, "win_rate": 0.74, "league_size": 12}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7568922460079195, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.02275950906187063, "policy_loss": -0.06093063692872723, "vf_loss": 0.06520883104046031, "vf_explained_var": 0.5121445058534543, "kl": 0.01878712266684488, "entropy": 2.8874922004838783, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 32160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "sampler_results": {"episode_reward_max": 3.651476842815242, "episode_reward_min": -4.2132500000000075, "episode_reward_mean": 0.9723930664907745, "episode_len_mean": 592.22, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"blue": -2.025999999999998, "red": -7.263000000000032, "red_v2": -2.0219999999999985, "red_v3": -1.5659999999999987, "red_v1": -1.616, "red_v4": -1.532, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126}, "policy_reward_max": {"blue": 3.4155000000000086, "red": 3.97097448781617, "red_v2": 3.7872713628161723, "red_v3": 3.310802612816173, "red_v1": 3.2230961050000024, "red_v4": -0.5419999999999999, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126}, "policy_reward_mean": {"blue": -0.5830242502702582, "red": 1.4683265086281372, "red_v2": -0.011839233227942373, "red_v3": -0.1803662311973043, "red_v1": 0.0008341918307468126, "red_v4": -0.9139999999999999, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204], "episode_lengths": [312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280], "policy_blue_reward": [-1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716, -1.5099999999999998, -0.713, 3.7872713628161723], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987, -1.564, -1.076, 0.488, -0.6750000000000002], "policy_red_v1_reward": [0.41305000000000236, -0.6839999999999999, -1.616, 0.479, 3.2230961050000024, -0.5433067621847962, -1.2659999999999807], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996, -0.5720000000000001], "policy_red_v9_reward": [-2.0109999999999992], "policy_red_v6_reward": [-0.023000000000000013], "policy_red_v7_reward": [0.38784375000000126]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7883914966746471, "mean_inference_ms": 7.767227546273796, "mean_action_processing_ms": 0.2911300413124401, "mean_env_wait_ms": 0.384510038633047, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09920918941497803, "StateBufferConnector_ms": 0.0042116641998291016, "ViewRequirementAgentConnector_ms": 0.11554908752441406}}, "episode_reward_max": 3.651476842815242, "episode_reward_min": -4.2132500000000075, "episode_reward_mean": 0.9723930664907745, "episode_len_mean": 592.22, "episodes_this_iter": 6, "policy_reward_min": {"blue": -2.025999999999998, "red": -7.263000000000032, "red_v2": -2.0219999999999985, "red_v3": -1.5659999999999987, "red_v1": -1.616, "red_v4": -1.532, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126}, "policy_reward_max": {"blue": 3.4155000000000086, "red": 3.97097448781617, "red_v2": 3.7872713628161723, "red_v3": 3.310802612816173, "red_v1": 3.2230961050000024, "red_v4": -0.5419999999999999, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126}, "policy_reward_mean": {"blue": -0.5830242502702582, "red": 1.4683265086281372, "red_v2": -0.011839233227942373, "red_v3": -0.1803662311973043, "red_v1": 0.0008341918307468126, "red_v4": -0.9139999999999999, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126}, "hist_stats": {"episode_reward": [1.1203175427729501, 2.2713773550000003, 1.1883175427729662, 1.0190682378162066, 0.12242761281616987, -3.847499999999972, 0.7300187500000109, -2.666453124999987, -0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204], "episode_lengths": [312, 98, 568, 712, 309, 544, 330, 369, 636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280], "policy_blue_reward": [-1.092, -1.0269999999999986, 2.393625, -0.23199999999999332, -0.5930000000000001, 3.4155000000000086, -1.595, 1.383000000000004, -1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716, -1.5099999999999998, -0.713, 3.7872713628161723], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987, -1.564, -1.076, 0.488, -0.6750000000000002], "policy_red_v1_reward": [0.41305000000000236, -0.6839999999999999, -1.616, 0.479, 3.2230961050000024, -0.5433067621847962, -1.2659999999999807], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996, -0.5720000000000001], "policy_red_v9_reward": [-2.0109999999999992], "policy_red_v6_reward": [-0.023000000000000013], "policy_red_v7_reward": [0.38784375000000126]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7883914966746471, "mean_inference_ms": 7.767227546273796, "mean_action_processing_ms": 0.2911300413124401, "mean_env_wait_ms": 0.384510038633047, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09920918941497803, "StateBufferConnector_ms": 0.0042116641998291016, "ViewRequirementAgentConnector_ms": 0.11554908752441406}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 197.8721043930391, "num_env_steps_trained_throughput_per_sec": 197.8721043930391, "timesteps_total": 136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 19998.82, "sample_time_ms": 1167.536, "learn_time_ms": 18748.89, "learn_throughput": 213.346, "synch_weights_time_ms": 80.036}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "episodes_total": 189, "training_iteration": 34, "trial_id": "a9680_00000", "date": "2023-09-24_02-48-23", "timestamp": 1695538103, "time_this_iter_s": 20.22450041770935, "time_total_s": 676.2005970478058, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b345136a0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34640430>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b346400d0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 676.2005970478058, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 5.053333333333333, "ram_util_percent": 17.19333333333333}, "win_rate": 0.75, "league_size": 13}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7373560082167385, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.02646844988388087, "policy_loss": -0.06345211011939682, "vf_loss": 0.06451093514818543, "vf_explained_var": 0.4261320869748791, "kl": 0.016886122009744767, "entropy": 2.8705615679423016, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 33120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 280000, "num_agent_steps_trained": 280000}, "sampler_results": {"episode_reward_max": 3.651476842815242, "episode_reward_min": -4.2132500000000075, "episode_reward_mean": 1.1078923249368051, "episode_len_mean": 600.8, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"blue": -2.025999999999998, "red": -7.090249999999987, "red_v2": -2.0219999999999985, "red_v3": -1.5659999999999987, "red_v1": -1.616, "red_v4": -1.532, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126}, "policy_reward_max": {"blue": 3.244140625, "red": 3.97097448781617, "red_v2": 3.7872713628161723, "red_v3": 3.310802612816173, "red_v1": 3.2230961050000024, "red_v4": 1.888296875, "red_v9": -1.6169999999999998, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126}, "policy_reward_mean": {"blue": -0.6789275439211087, "red": 1.6452535848797427, "red_v2": 0.03963649445404377, "red_v3": -0.1803662311973043, "red_v1": 0.0008341918307468126, "red_v4": -0.47795052083333217, "red_v9": -1.8139999999999996, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112], "episode_lengths": [636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626], "policy_blue_reward": [-1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716, -1.5099999999999998, -0.713, 3.7872713628161723, 0.13828360500000325, 0.24984375000000103], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987, -1.564, -1.076, 0.488, -0.6750000000000002], "policy_red_v1_reward": [0.41305000000000236, -0.6839999999999999, -1.616, 0.479, 3.2230961050000024, -0.5433067621847962, -1.2659999999999807], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996, -0.5720000000000001, -1.0999999999999936, 1.888296875], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998], "policy_red_v6_reward": [-0.023000000000000013], "policy_red_v7_reward": [0.38784375000000126]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7886229236060047, "mean_inference_ms": 7.759578487722906, "mean_action_processing_ms": 0.29079140450058544, "mean_env_wait_ms": 0.3838775787315574, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10012125968933105, "StateBufferConnector_ms": 0.004250645637512207, "ViewRequirementAgentConnector_ms": 0.11669290065765381}}, "episode_reward_max": 3.651476842815242, "episode_reward_min": -4.2132500000000075, "episode_reward_mean": 1.1078923249368051, "episode_len_mean": 600.8, "episodes_this_iter": 8, "policy_reward_min": {"blue": -2.025999999999998, "red": -7.090249999999987, "red_v2": -2.0219999999999985, "red_v3": -1.5659999999999987, "red_v1": -1.616, "red_v4": -1.532, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126}, "policy_reward_max": {"blue": 3.244140625, "red": 3.97097448781617, "red_v2": 3.7872713628161723, "red_v3": 3.310802612816173, "red_v1": 3.2230961050000024, "red_v4": 1.888296875, "red_v9": -1.6169999999999998, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126}, "policy_reward_mean": {"blue": -0.6789275439211087, "red": 1.6452535848797427, "red_v2": 0.03963649445404377, "red_v3": -0.1803662311973043, "red_v1": 0.0008341918307468126, "red_v4": -0.47795052083333217, "red_v9": -1.8139999999999996, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126}, "hist_stats": {"episode_reward": [-0.4421875000000002, -0.1411093750000001, 0.6092836050000286, 1.1251030335441163, 1.3813026128161696, 3.651476842815242, -0.22296875000000005, 0.7892862927729462, 0.664693237816208, -0.13670312500000026, -0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112], "episode_lengths": [636, 67, 1280, 1280, 93, 544, 118, 1218, 1280, 897, 1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626], "policy_blue_reward": [-1.698, -2.0189999999999992, -1.343999999999968, -0.8940000000000003, 1.9116093749999998, 0.7582836050000079, -1.5299999999999998, -1.34799999999997, -1.3499999999999688, -0.7490000000000002, -1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716, -1.5099999999999998, -0.713, 3.7872713628161723, 0.13828360500000325, 0.24984375000000103], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987, -1.564, -1.076, 0.488, -0.6750000000000002], "policy_red_v1_reward": [0.41305000000000236, -0.6839999999999999, -1.616, 0.479, 3.2230961050000024, -0.5433067621847962, -1.2659999999999807], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996, -0.5720000000000001, -1.0999999999999936, 1.888296875], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998], "policy_red_v6_reward": [-0.023000000000000013], "policy_red_v7_reward": [0.38784375000000126]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7886229236060047, "mean_inference_ms": 7.759578487722906, "mean_action_processing_ms": 0.29079140450058544, "mean_env_wait_ms": 0.3838775787315574, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10012125968933105, "StateBufferConnector_ms": 0.004250645637512207, "ViewRequirementAgentConnector_ms": 0.11669290065765381}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 280000, "num_agent_steps_trained": 280000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 196.30926943656723, "num_env_steps_trained_throughput_per_sec": 196.30926943656723, "timesteps_total": 140000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 280000, "timers": {"training_iteration_time_ms": 20014.549, "sample_time_ms": 1158.958, "learn_time_ms": 18772.995, "learn_throughput": 213.072, "synch_weights_time_ms": 80.071}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 280000, "num_agent_steps_trained": 280000}, "done": false, "episodes_total": 197, "training_iteration": 35, "trial_id": "a9680_00000", "date": "2023-09-24_02-48-45", "timestamp": 1695538125, "time_this_iter_s": 20.38465428352356, "time_total_s": 696.5852513313293, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34510a30>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34706a70>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34707880>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 696.5852513313293, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 4.973333333333334, "ram_util_percent": 17.48}, "win_rate": 0.74, "league_size": 14}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8427116885781287, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.017699518210186702, "policy_loss": -0.06025291684394082, "vf_loss": 0.07552445841332277, "vf_explained_var": 0.5467604514832298, "kl": 0.016979125910969135, "entropy": 2.849437446395556, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 34080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "sampler_results": {"episode_reward_max": 3.5975549678161833, "episode_reward_min": -4.2132500000000075, "episode_reward_mean": 1.2045902979443195, "episode_len_mean": 546.86, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"blue": -2.025999999999998, "red": -7.090249999999987, "red_v2": -2.0219999999999985, "red_v3": -1.5659999999999987, "red_v1": -1.616, "red_v4": -1.532, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126, "red_v5": 1.9013564894425938}, "policy_reward_max": {"blue": 3.244140625, "red": 3.983118658544055, "red_v2": 3.7872713628161723, "red_v3": 3.310802612816173, "red_v1": 3.2230961050000024, "red_v4": 1.888296875, "red_v9": -1.6169999999999998, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126, "red_v5": 1.9145625}, "policy_reward_mean": {"blue": -0.634394275162409, "red": 1.6650017091646683, "red_v2": 0.03963649445404377, "red_v3": -0.1803662311973043, "red_v1": -0.19171860215206527, "red_v4": -0.47795052083333217, "red_v9": -1.8139999999999996, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126, "red_v5": 1.9079594947212968}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884], "episode_lengths": [1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339], "policy_blue_reward": [-1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034, -1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716, -1.5099999999999998, -0.713, 3.7872713628161723, 0.13828360500000325, 0.24984375000000103], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987, -1.564, -1.076, 0.488, -0.6750000000000002], "policy_red_v1_reward": [0.41305000000000236, -0.6839999999999999, -1.616, 0.479, 3.2230961050000024, -0.5433067621847962, -1.2659999999999807, -0.16930676218381768, -1.5619999999999972], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996, -0.5720000000000001, -1.0999999999999936, 1.888296875], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998], "policy_red_v6_reward": [-0.023000000000000013], "policy_red_v7_reward": [0.38784375000000126], "policy_red_v5_reward": [1.9145625, 1.9013564894425938]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.788421496775694, "mean_inference_ms": 7.749132749460597, "mean_action_processing_ms": 0.29029947102190357, "mean_env_wait_ms": 0.3829863307967517, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10105502605438232, "StateBufferConnector_ms": 0.00427854061126709, "ViewRequirementAgentConnector_ms": 0.11742520332336426}}, "episode_reward_max": 3.5975549678161833, "episode_reward_min": -4.2132500000000075, "episode_reward_mean": 1.2045902979443195, "episode_len_mean": 546.86, "episodes_this_iter": 10, "policy_reward_min": {"blue": -2.025999999999998, "red": -7.090249999999987, "red_v2": -2.0219999999999985, "red_v3": -1.5659999999999987, "red_v1": -1.616, "red_v4": -1.532, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126, "red_v5": 1.9013564894425938}, "policy_reward_max": {"blue": 3.244140625, "red": 3.983118658544055, "red_v2": 3.7872713628161723, "red_v3": 3.310802612816173, "red_v1": 3.2230961050000024, "red_v4": 1.888296875, "red_v9": -1.6169999999999998, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126, "red_v5": 1.9145625}, "policy_reward_mean": {"blue": -0.634394275162409, "red": 1.6650017091646683, "red_v2": 0.03963649445404377, "red_v3": -0.1803662311973043, "red_v1": -0.19171860215206527, "red_v4": -0.47795052083333217, "red_v9": -1.8139999999999996, "red_v6": -0.023000000000000013, "red_v7": 0.38784375000000126, "red_v5": 1.9079594947212968}, "hist_stats": {"episode_reward": [-0.04400000000000057, 1.7588617300000036, 3.0369744878162, 0.6475561585440599, 0.9449406250000079, 1.1306932378162349, -4.2132500000000075, 1.7460526128161906, 1.0714119878161714, 1.5923651128161962, 1.7813461050000168, -0.0959531250000002, 1.6446932378162145, 1.1989658644426004, 1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884], "episode_lengths": [1280, 103, 614, 271, 899, 1280, 400, 557, 1050, 649, 428, 81, 1280, 246, 1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339], "policy_blue_reward": [-1.3609999999999676, -2.0249999999999986, 1.6980000000000093, 0.23145312500000348, -1.263999999999977, -0.8430000000000003, 2.877000000000005, -1.1569999999999871, -1.2939999999999743, -1.1779999999999848, -1.1339999999999915, 1.9240468749999997, 0.47900000000000176, -1.562, -0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034, -1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716, -1.5099999999999998, -0.713, 3.7872713628161723, 0.13828360500000325, 0.24984375000000103], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987, -1.564, -1.076, 0.488, -0.6750000000000002], "policy_red_v1_reward": [0.41305000000000236, -0.6839999999999999, -1.616, 0.479, 3.2230961050000024, -0.5433067621847962, -1.2659999999999807, -0.16930676218381768, -1.5619999999999972], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996, -0.5720000000000001, -1.0999999999999936, 1.888296875], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998], "policy_red_v6_reward": [-0.023000000000000013], "policy_red_v7_reward": [0.38784375000000126], "policy_red_v5_reward": [1.9145625, 1.9013564894425938]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.788421496775694, "mean_inference_ms": 7.749132749460597, "mean_action_processing_ms": 0.29029947102190357, "mean_env_wait_ms": 0.3829863307967517, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10105502605438232, "StateBufferConnector_ms": 0.00427854061126709, "ViewRequirementAgentConnector_ms": 0.11742520332336426}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.5610424784182, "num_env_steps_trained_throughput_per_sec": 200.5610424784182, "timesteps_total": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 20106.676, "sample_time_ms": 1156.759, "learn_time_ms": 18865.974, "learn_throughput": 212.022, "synch_weights_time_ms": 81.272}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "episodes_total": 207, "training_iteration": 36, "trial_id": "a9680_00000", "date": "2023-09-24_02-49-06", "timestamp": 1695538146, "time_this_iter_s": 19.952577590942383, "time_total_s": 716.5378289222717, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34571c60>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34643520>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b346435b0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 716.5378289222717, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 5.046666666666668, "ram_util_percent": 17.580000000000005}, "win_rate": 0.72, "league_size": 15}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8947612663110096, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.016319189586647555, "policy_loss": -0.06281265063298633, "vf_loss": 0.08235511829455694, "vf_explained_var": 0.6176043371359508, "kl": 0.01790960482195762, "entropy": 2.7434203741451104, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 35040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 296000, "num_agent_steps_trained": 296000}, "sampler_results": {"episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.261088533527849, "episode_len_mean": 536.19, "episode_media": {}, "episodes_this_iter": 14, "policy_reward_min": {"blue": -2.025999999999998, "red": -8.196306762183793, "red_v2": -2.0219999999999985, "red_v3": -1.5659999999999987, "red_v1": -1.616, "red_v4": -1.532, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": -1.5179999999999998, "red_v5": -2.0139999999999993, "red_v11": 0.4526932378161701, "red_v12": 1.935}, "policy_reward_max": {"blue": 5.327049999999944, "red": 3.983118658544055, "red_v2": 3.7872713628161723, "red_v3": 3.310802612816173, "red_v1": 3.2230961050000024, "red_v4": 1.888296875, "red_v9": -1.6169999999999998, "red_v6": 2.819406250000001, "red_v7": 0.38784375000000126, "red_v5": 1.9145625, "red_v11": 0.4526932378161701, "red_v12": 1.935}, "policy_reward_mean": {"blue": -0.5369509118199429, "red": 1.6290141998700367, "red_v2": -0.0933231160408485, "red_v3": -0.1803662311973043, "red_v1": -0.3087467419368556, "red_v4": -0.47795052083333217, "red_v9": -1.8139999999999996, "red_v6": 1.3982031250000004, "red_v7": -0.5650781249999992, "red_v5": 0.6006396631475314, "red_v11": 0.4526932378161701, "red_v12": 1.935}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719], "episode_lengths": [1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64], "policy_blue_reward": [-0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034, -1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716, -1.5099999999999998, -0.713, 3.7872713628161723, 0.13828360500000325, 0.24984375000000103, -1.1569999999999867], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987, -1.564, -1.076, 0.488, -0.6750000000000002], "policy_red_v1_reward": [0.41305000000000236, -0.6839999999999999, -1.616, 0.479, 3.2230961050000024, -0.5433067621847962, -1.2659999999999807, -0.16930676218381768, -1.5619999999999972, -1.3619999999999683], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996, -0.5720000000000001, -1.0999999999999936, 1.888296875], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998], "policy_red_v6_reward": [-0.023000000000000013, 2.819406250000001], "policy_red_v7_reward": [0.38784375000000126, -1.5179999999999998], "policy_red_v5_reward": [1.9145625, 1.9013564894425938, -2.0139999999999993], "policy_red_v11_reward": [0.4526932378161701], "policy_red_v12_reward": [1.935]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7898450172617985, "mean_inference_ms": 7.762059395846264, "mean_action_processing_ms": 0.29047374077319116, "mean_env_wait_ms": 0.3835973384901908, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10022974014282227, "StateBufferConnector_ms": 0.004269957542419434, "ViewRequirementAgentConnector_ms": 0.11713850498199463}}, "episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.261088533527849, "episode_len_mean": 536.19, "episodes_this_iter": 14, "policy_reward_min": {"blue": -2.025999999999998, "red": -8.196306762183793, "red_v2": -2.0219999999999985, "red_v3": -1.5659999999999987, "red_v1": -1.616, "red_v4": -1.532, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": -1.5179999999999998, "red_v5": -2.0139999999999993, "red_v11": 0.4526932378161701, "red_v12": 1.935}, "policy_reward_max": {"blue": 5.327049999999944, "red": 3.983118658544055, "red_v2": 3.7872713628161723, "red_v3": 3.310802612816173, "red_v1": 3.2230961050000024, "red_v4": 1.888296875, "red_v9": -1.6169999999999998, "red_v6": 2.819406250000001, "red_v7": 0.38784375000000126, "red_v5": 1.9145625, "red_v11": 0.4526932378161701, "red_v12": 1.935}, "policy_reward_mean": {"blue": -0.5369509118199429, "red": 1.6290141998700367, "red_v2": -0.0933231160408485, "red_v3": -0.1803662311973043, "red_v1": -0.3087467419368556, "red_v4": -0.47795052083333217, "red_v9": -1.8139999999999996, "red_v6": 1.3982031250000004, "red_v7": -0.5650781249999992, "red_v5": 0.6006396631475314, "red_v11": 0.4526932378161701, "red_v12": 1.935}, "hist_stats": {"episode_reward": [1.016693237816255, 1.9589744878161708, 0.6196932378162064, 1.0876932378162447, 2.275943237816173, -0.9018593749999999, 0.7575937500000002, 0.8507713628162038, 0.8974432378161723, 2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719], "episode_lengths": [1280, 38, 1280, 1280, 176, 243, 66, 1159, 80, 353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64], "policy_blue_reward": [-0.9050000000000002, -2.0119999999999996, -1.3589999999999733, -0.9080000000000004, -1.0529999999999953, 3.244140625, -1.360999999999969, 0.41674999999999995, -0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034, -1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998], "policy_red_v2_reward": [-2.0219999999999985, -0.594, 0.9806932378161716, -1.5099999999999998, -0.713, 3.7872713628161723, 0.13828360500000325, 0.24984375000000103, -1.1569999999999867], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987, -1.564, -1.076, 0.488, -0.6750000000000002], "policy_red_v1_reward": [0.41305000000000236, -0.6839999999999999, -1.616, 0.479, 3.2230961050000024, -0.5433067621847962, -1.2659999999999807, -0.16930676218381768, -1.5619999999999972, -1.3619999999999683], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996, -0.5720000000000001, -1.0999999999999936, 1.888296875], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998], "policy_red_v6_reward": [-0.023000000000000013, 2.819406250000001], "policy_red_v7_reward": [0.38784375000000126, -1.5179999999999998], "policy_red_v5_reward": [1.9145625, 1.9013564894425938, -2.0139999999999993], "policy_red_v11_reward": [0.4526932378161701], "policy_red_v12_reward": [1.935]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7898450172617985, "mean_inference_ms": 7.762059395846264, "mean_action_processing_ms": 0.29047374077319116, "mean_env_wait_ms": 0.3835973384901908, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10022974014282227, "StateBufferConnector_ms": 0.004269957542419434, "ViewRequirementAgentConnector_ms": 0.11713850498199463}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 296000, "num_agent_steps_trained": 296000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 202.28687449509565, "num_env_steps_trained_throughput_per_sec": 202.28687449509565, "timesteps_total": 148000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 296000, "timers": {"training_iteration_time_ms": 20111.445, "sample_time_ms": 1159.312, "learn_time_ms": 18866.797, "learn_throughput": 212.013, "synch_weights_time_ms": 82.504}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 296000, "num_agent_steps_trained": 296000}, "done": false, "episodes_total": 221, "training_iteration": 37, "trial_id": "a9680_00000", "date": "2023-09-24_02-49-27", "timestamp": 1695538167, "time_this_iter_s": 19.784147262573242, "time_total_s": 736.321976184845, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34572a10>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34642dd0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34643760>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 736.321976184845, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 5.053333333333333, "ram_util_percent": 17.683333333333334}, "win_rate": 0.71, "league_size": 16}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9584446109831335, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.00037803049005257584, "policy_loss": -0.0591061234260754, "vf_loss": 0.1092527828431533, "vf_explained_var": 0.4957602603981892, "kl": 0.01675807266118075, "entropy": 2.6833695294956366, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "sampler_results": {"episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.2992431607385375, "episode_len_mean": 500.18, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {"blue": -2.0259999999999985, "red": -8.196306762183793, "red_v2": -1.5099999999999998, "red_v3": -1.5659999999999987, "red_v1": -1.616, "red_v4": -1.532, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": -1.5179999999999998, "red_v5": -2.0139999999999993, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 0.3322031250000006, "red_v8": -0.14330676218382843}, "policy_reward_max": {"blue": 5.327049999999944, "red": 3.983118658544055, "red_v2": 3.7872713628161723, "red_v3": 3.310802612816173, "red_v1": 3.2230961050000024, "red_v4": 1.888296875, "red_v9": -1.6169999999999998, "red_v6": 2.819406250000001, "red_v7": 0.38784375000000126, "red_v5": 1.9145625, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.904974487816172, "red_v8": -0.14330676218382843}, "policy_reward_mean": {"blue": -0.6391956346464863, "red": 1.6763561887744012, "red_v2": 0.017787995070262432, "red_v3": -0.1803662311973043, "red_v1": -0.3087467419368556, "red_v4": -0.47795052083333217, "red_v9": -1.8139999999999996, "red_v6": 1.3982031250000004, "red_v7": -0.5650781249999992, "red_v5": 0.6006396631475314, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.1185888064080864, "red_v8": -0.14330676218382843}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034], "episode_lengths": [353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862], "policy_blue_reward": [-0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034, -1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916], "policy_red_v2_reward": [-0.594, 0.9806932378161716, -1.5099999999999998, -0.713, 3.7872713628161723, 0.13828360500000325, 0.24984375000000103, -1.1569999999999867, -1.0219999999999998], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987, -1.564, -1.076, 0.488, -0.6750000000000002], "policy_red_v1_reward": [0.41305000000000236, -0.6839999999999999, -1.616, 0.479, 3.2230961050000024, -0.5433067621847962, -1.2659999999999807, -0.16930676218381768, -1.5619999999999972, -1.3619999999999683], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996, -0.5720000000000001, -1.0999999999999936, 1.888296875], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998], "policy_red_v6_reward": [-0.023000000000000013, 2.819406250000001], "policy_red_v7_reward": [0.38784375000000126, -1.5179999999999998], "policy_red_v5_reward": [1.9145625, 1.9013564894425938, -2.0139999999999993], "policy_red_v11_reward": [0.4526932378161701], "policy_red_v12_reward": [1.935], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172], "policy_red_v8_reward": [-0.14330676218382843]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7901468712205209, "mean_inference_ms": 7.755420941664316, "mean_action_processing_ms": 0.29014665596240674, "mean_env_wait_ms": 0.3837443347495137, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10145819187164307, "StateBufferConnector_ms": 0.004310250282287598, "ViewRequirementAgentConnector_ms": 0.11797547340393066}}, "episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.2992431607385375, "episode_len_mean": 500.18, "episodes_this_iter": 9, "policy_reward_min": {"blue": -2.0259999999999985, "red": -8.196306762183793, "red_v2": -1.5099999999999998, "red_v3": -1.5659999999999987, "red_v1": -1.616, "red_v4": -1.532, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": -1.5179999999999998, "red_v5": -2.0139999999999993, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 0.3322031250000006, "red_v8": -0.14330676218382843}, "policy_reward_max": {"blue": 5.327049999999944, "red": 3.983118658544055, "red_v2": 3.7872713628161723, "red_v3": 3.310802612816173, "red_v1": 3.2230961050000024, "red_v4": 1.888296875, "red_v9": -1.6169999999999998, "red_v6": 2.819406250000001, "red_v7": 0.38784375000000126, "red_v5": 1.9145625, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.904974487816172, "red_v8": -0.14330676218382843}, "policy_reward_mean": {"blue": -0.6391956346464863, "red": 1.6763561887744012, "red_v2": 0.017787995070262432, "red_v3": -0.1803662311973043, "red_v1": -0.3087467419368556, "red_v4": -0.47795052083333217, "red_v9": -1.8139999999999996, "red_v6": 1.3982031250000004, "red_v7": -0.5650781249999992, "red_v5": 0.6006396631475314, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.1185888064080864, "red_v8": -0.14330676218382843}, "hist_stats": {"episode_reward": [2.960490112815222, 0.5996925427729835, 0.9873175427729763, 2.7451932378161774, -2.3801348871838046, 0.8396619878161773, 0.5786932378161947, 0.642693237816211, 3.383042725632345, -0.8091938414559455, 0.5886932378161924, 1.457443237816213, 0.4766932378162059, 1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034], "episode_lengths": [353, 1280, 1080, 160, 681, 458, 1280, 1280, 110, 1087, 1280, 1104, 1280, 49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862], "policy_blue_reward": [-0.15800000000000003, -1.3659999999999652, -1.2969999999999766, 1.306000000000012, 2.5589687500000036, -1.3649999999999676, -1.3809999999999658, -0.3079999999999905, -1.36299999999997, -0.8230000000000003, -1.3839999999999648, -2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034, -1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916], "policy_red_v2_reward": [-0.594, 0.9806932378161716, -1.5099999999999998, -0.713, 3.7872713628161723, 0.13828360500000325, 0.24984375000000103, -1.1569999999999867, -1.0219999999999998], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987, -1.564, -1.076, 0.488, -0.6750000000000002], "policy_red_v1_reward": [0.41305000000000236, -0.6839999999999999, -1.616, 0.479, 3.2230961050000024, -0.5433067621847962, -1.2659999999999807, -0.16930676218381768, -1.5619999999999972, -1.3619999999999683], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996, -0.5720000000000001, -1.0999999999999936, 1.888296875], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998], "policy_red_v6_reward": [-0.023000000000000013, 2.819406250000001], "policy_red_v7_reward": [0.38784375000000126, -1.5179999999999998], "policy_red_v5_reward": [1.9145625, 1.9013564894425938, -2.0139999999999993], "policy_red_v11_reward": [0.4526932378161701], "policy_red_v12_reward": [1.935], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172], "policy_red_v8_reward": [-0.14330676218382843]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7901468712205209, "mean_inference_ms": 7.755420941664316, "mean_action_processing_ms": 0.29014665596240674, "mean_env_wait_ms": 0.3837443347495137, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10145819187164307, "StateBufferConnector_ms": 0.004310250282287598, "ViewRequirementAgentConnector_ms": 0.11797547340393066}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.0026703237386, "num_env_steps_trained_throughput_per_sec": 200.0026703237386, "timesteps_total": 152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 20075.187, "sample_time_ms": 1164.977, "learn_time_ms": 18825.074, "learn_throughput": 212.483, "synch_weights_time_ms": 82.352}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "episodes_total": 230, "training_iteration": 38, "trial_id": "a9680_00000", "date": "2023-09-24_02-49-48", "timestamp": 1695538188, "time_this_iter_s": 20.00908064842224, "time_total_s": 756.3310568332672, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b345701c0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34640f70>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b346411b0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 756.3310568332672, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 5.120000000000001, "ram_util_percent": 17.78666666666667}, "win_rate": 0.71, "league_size": 17}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.000558711712559, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009741909656198307, "policy_loss": -0.0590923126039949, "vf_loss": 0.08954926545266062, "vf_explained_var": 0.6712349579979976, "kl": 0.016184544330011857, "entropy": 2.707274011025826, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 312000, "num_agent_steps_trained": 312000}, "sampler_results": {"episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.3254851907357488, "episode_len_mean": 426.07, "episode_media": {}, "episodes_this_iter": 13, "policy_reward_min": {"blue": -2.0259999999999985, "red": -8.196306762183793, "red_v2": -1.5099999999999998, "red_v3": -1.5659999999999987, "red_v1": -2.012999999999999, "red_v4": -1.532, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": -1.5179999999999998, "red_v5": -2.0139999999999993, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 0.3322031250000006, "red_v8": -0.14330676218382843, "red_v10": -1.5859999999999999}, "policy_reward_max": {"blue": 5.327049999999944, "red": 3.983118658544055, "red_v2": 3.7872713628161723, "red_v3": 3.310802612816173, "red_v1": 3.2230961050000024, "red_v4": 2.256578125, "red_v9": -1.6169999999999998, "red_v6": 2.819406250000001, "red_v7": 0.38784375000000126, "red_v5": 1.9145625, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.904974487816172, "red_v8": 2.233140625, "red_v10": -1.5859999999999999}, "policy_reward_mean": {"blue": -0.7181261587868767, "red": 1.7179232761497731, "red_v2": -0.15173347579820115, "red_v3": -0.3327424838834037, "red_v1": -0.4636788563062322, "red_v4": -0.028654296874999097, "red_v9": -1.8139999999999996, "red_v6": 1.3982031250000004, "red_v7": -0.5650781249999992, "red_v5": 0.6006396631475314, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.1185888064080864, "red_v8": 1.0449169314080857, "red_v10": -1.5859999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172], "episode_lengths": [49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179], "policy_blue_reward": [-2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034, -1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002], "policy_red_v2_reward": [-1.5099999999999998, -0.713, 3.7872713628161723, 0.13828360500000325, 0.24984375000000103, -1.1569999999999867, -1.0219999999999998, -0.3380000000000003, -0.8010000000000002], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987, -1.564, -1.076, 0.488, -0.6750000000000002, -1.2470000000000003], "policy_red_v1_reward": [0.41305000000000236, -0.6839999999999999, -1.616, 0.479, 3.2230961050000024, -0.5433067621847962, -1.2659999999999807, -0.16930676218381768, -1.5619999999999972, -1.3619999999999683, -2.012999999999999], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996, -0.5720000000000001, -1.0999999999999936, 1.888296875, 0.3818906250000007, 2.256578125], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998], "policy_red_v6_reward": [-0.023000000000000013, 2.819406250000001], "policy_red_v7_reward": [0.38784375000000126, -1.5179999999999998], "policy_red_v5_reward": [1.9145625, 1.9013564894425938, -2.0139999999999993], "policy_red_v11_reward": [0.4526932378161701], "policy_red_v12_reward": [1.935], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625], "policy_red_v10_reward": [-1.5859999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7895042067162293, "mean_inference_ms": 7.720068321126662, "mean_action_processing_ms": 0.2888600868987201, "mean_env_wait_ms": 0.3821526233379287, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10219383239746094, "StateBufferConnector_ms": 0.004316568374633789, "ViewRequirementAgentConnector_ms": 0.11837375164031982}}, "episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.3254851907357488, "episode_len_mean": 426.07, "episodes_this_iter": 13, "policy_reward_min": {"blue": -2.0259999999999985, "red": -8.196306762183793, "red_v2": -1.5099999999999998, "red_v3": -1.5659999999999987, "red_v1": -2.012999999999999, "red_v4": -1.532, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": -1.5179999999999998, "red_v5": -2.0139999999999993, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 0.3322031250000006, "red_v8": -0.14330676218382843, "red_v10": -1.5859999999999999}, "policy_reward_max": {"blue": 5.327049999999944, "red": 3.983118658544055, "red_v2": 3.7872713628161723, "red_v3": 3.310802612816173, "red_v1": 3.2230961050000024, "red_v4": 2.256578125, "red_v9": -1.6169999999999998, "red_v6": 2.819406250000001, "red_v7": 0.38784375000000126, "red_v5": 1.9145625, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.904974487816172, "red_v8": 2.233140625, "red_v10": -1.5859999999999999}, "policy_reward_mean": {"blue": -0.7181261587868767, "red": 1.7179232761497731, "red_v2": -0.15173347579820115, "red_v3": -0.3327424838834037, "red_v1": -0.4636788563062322, "red_v4": -0.028654296874999097, "red_v9": -1.8139999999999996, "red_v6": 1.3982031250000004, "red_v7": -0.5650781249999992, "red_v5": 0.6006396631475314, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.1185888064080864, "red_v8": 1.0449169314080857, "red_v10": -1.5859999999999999}, "hist_stats": {"episode_reward": [1.9422401128161704, 0.44568749999999946, -0.13589062499999993, 1.457349487816199, 0.6006932378161689, -1.045400512183816, 3.232495850632354, 0.6776932378162132, 3.3820244878162202, 0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172], "episode_lengths": [49, 996, 61, 750, 1280, 478, 189, 1280, 486, 1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179], "policy_blue_reward": [-2.0149999999999997, -1.307999999999976, -1.21699999999998, -1.374999999999965, 1.5469062500000021, -1.3369999999999689, -1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034, -1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002], "policy_red_v2_reward": [-1.5099999999999998, -0.713, 3.7872713628161723, 0.13828360500000325, 0.24984375000000103, -1.1569999999999867, -1.0219999999999998, -0.3380000000000003, -0.8010000000000002], "policy_red_v3_reward": [3.310802612816173, -1.5659999999999987, -1.564, -1.076, 0.488, -0.6750000000000002, -1.2470000000000003], "policy_red_v1_reward": [0.41305000000000236, -0.6839999999999999, -1.616, 0.479, 3.2230961050000024, -0.5433067621847962, -1.2659999999999807, -0.16930676218381768, -1.5619999999999972, -1.3619999999999683, -2.012999999999999], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996, -0.5720000000000001, -1.0999999999999936, 1.888296875, 0.3818906250000007, 2.256578125], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998], "policy_red_v6_reward": [-0.023000000000000013, 2.819406250000001], "policy_red_v7_reward": [0.38784375000000126, -1.5179999999999998], "policy_red_v5_reward": [1.9145625, 1.9013564894425938, -2.0139999999999993], "policy_red_v11_reward": [0.4526932378161701], "policy_red_v12_reward": [1.935], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625], "policy_red_v10_reward": [-1.5859999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7895042067162293, "mean_inference_ms": 7.720068321126662, "mean_action_processing_ms": 0.2888600868987201, "mean_env_wait_ms": 0.3821526233379287, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10219383239746094, "StateBufferConnector_ms": 0.004316568374633789, "ViewRequirementAgentConnector_ms": 0.11837375164031982}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 312000, "num_agent_steps_trained": 312000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 202.695911527376, "num_env_steps_trained_throughput_per_sec": 202.695911527376, "timesteps_total": 156000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 312000, "timers": {"training_iteration_time_ms": 20057.502, "sample_time_ms": 1157.004, "learn_time_ms": 18815.265, "learn_throughput": 212.593, "synch_weights_time_ms": 82.429}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 312000, "num_agent_steps_trained": 312000}, "done": false, "episodes_total": 243, "training_iteration": 39, "trial_id": "a9680_00000", "date": "2023-09-24_02-50-09", "timestamp": 1695538209, "time_this_iter_s": 19.74618625640869, "time_total_s": 776.0772430896759, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34599cf0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3459d480>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3459d510>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 776.0772430896759, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 5.053333333333333, "ram_util_percent": 17.889999999999993}, "win_rate": 0.7, "league_size": 18}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0421850569546223, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0025937915097529185, "policy_loss": -0.052853018094416865, "vf_loss": 0.09177207619068213, "vf_explained_var": 0.6591016157219808, "kl": 0.015697515624462862, "entropy": 2.690693235148986, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 37920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "sampler_results": {"episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.3409718493294238, "episode_len_mean": 417.87, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {"blue": -2.0259999999999985, "red": -8.196306762183793, "red_v3": -1.5659999999999987, "red_v4": -1.532, "red_v1": -2.012999999999999, "red_v2": -1.1569999999999867, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": -1.5179999999999998, "red_v5": -2.0139999999999993, "red_v11": 0.20290625000000728, "red_v12": 1.935, "red_v13": -2.0299999999999994, "red_v8": -0.14330676218382843, "red_v10": -1.5859999999999999, "red_v15": -2.017}, "policy_reward_max": {"blue": 5.327049999999944, "red": 3.983118658544055, "red_v3": 0.488, "red_v4": 2.256578125, "red_v1": 3.2230961050000024, "red_v2": 3.7872713628161723, "red_v9": -1.6169999999999998, "red_v6": 2.819406250000001, "red_v7": 0.38784375000000126, "red_v5": 3.294971105000003, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.904974487816172, "red_v8": 2.233140625, "red_v10": -1.5859999999999999, "red_v15": -2.017}, "policy_reward_mean": {"blue": -0.741746553841639, "red": 1.77007874982161, "red_v3": -0.9400000000000001, "red_v4": -0.028654296874999097, "red_v1": -0.6130470381244121, "red_v2": 0.018049839727023675, "red_v9": -1.8139999999999996, "red_v6": 1.3982031250000004, "red_v7": -0.5650781249999992, "red_v5": 1.2742225236106492, "red_v11": 0.3277997439080887, "red_v12": 1.935, "red_v13": 0.06905920427205785, "red_v8": 1.0449169314080857, "red_v10": -1.5859999999999999, "red_v15": -2.017}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137], "episode_lengths": [1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417], "policy_blue_reward": [-1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034, -1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902], "policy_red_v3_reward": [-1.5659999999999987, -1.564, -1.076, 0.488, -0.6750000000000002, -1.2470000000000003], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996, -0.5720000000000001, -1.0999999999999936, 1.888296875, 0.3818906250000007, 2.256578125], "policy_red_v1_reward": [-0.6839999999999999, -1.616, 0.479, 3.2230961050000024, -0.5433067621847962, -1.2659999999999807, -0.16930676218381768, -1.5619999999999972, -1.3619999999999683, -2.012999999999999, -1.2299999999999771], "policy_red_v2_reward": [-0.713, 3.7872713628161723, 0.13828360500000325, 0.24984375000000103, -1.1569999999999867, -1.0219999999999998, -0.3380000000000003, -0.8010000000000002], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998], "policy_red_v6_reward": [-0.023000000000000013, 2.819406250000001], "policy_red_v7_reward": [0.38784375000000126, -1.5179999999999998], "policy_red_v5_reward": [1.9145625, 1.9013564894425938, -2.0139999999999993, 3.294971105000003], "policy_red_v11_reward": [0.4526932378161701, 0.20290625000000728], "policy_red_v12_reward": [1.935], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172, -2.0299999999999994], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625], "policy_red_v10_reward": [-1.5859999999999999], "policy_red_v15_reward": [-2.017]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7902969156942722, "mean_inference_ms": 7.720693837449385, "mean_action_processing_ms": 0.2891583008087615, "mean_env_wait_ms": 0.3821338278939518, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10396862030029297, "StateBufferConnector_ms": 0.004384040832519531, "ViewRequirementAgentConnector_ms": 0.12009572982788086}}, "episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.3409718493294238, "episode_len_mean": 417.87, "episodes_this_iter": 9, "policy_reward_min": {"blue": -2.0259999999999985, "red": -8.196306762183793, "red_v3": -1.5659999999999987, "red_v4": -1.532, "red_v1": -2.012999999999999, "red_v2": -1.1569999999999867, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": -1.5179999999999998, "red_v5": -2.0139999999999993, "red_v11": 0.20290625000000728, "red_v12": 1.935, "red_v13": -2.0299999999999994, "red_v8": -0.14330676218382843, "red_v10": -1.5859999999999999, "red_v15": -2.017}, "policy_reward_max": {"blue": 5.327049999999944, "red": 3.983118658544055, "red_v3": 0.488, "red_v4": 2.256578125, "red_v1": 3.2230961050000024, "red_v2": 3.7872713628161723, "red_v9": -1.6169999999999998, "red_v6": 2.819406250000001, "red_v7": 0.38784375000000126, "red_v5": 3.294971105000003, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.904974487816172, "red_v8": 2.233140625, "red_v10": -1.5859999999999999, "red_v15": -2.017}, "policy_reward_mean": {"blue": -0.741746553841639, "red": 1.77007874982161, "red_v3": -0.9400000000000001, "red_v4": -0.028654296874999097, "red_v1": -0.6130470381244121, "red_v2": 0.018049839727023675, "red_v9": -1.8139999999999996, "red_v6": 1.3982031250000004, "red_v7": -0.5650781249999992, "red_v5": 1.2742225236106492, "red_v11": 0.3277997439080887, "red_v12": 1.935, "red_v13": 0.06905920427205785, "red_v8": 1.0449169314080857, "red_v10": -1.5859999999999999, "red_v15": -2.017}, "hist_stats": {"episode_reward": [0.6346932378161985, 0.2528807378161697, -0.15073437499999986, 0.6614554800000005, -0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137], "episode_lengths": [1280, 196, 75, 169, 90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417], "policy_blue_reward": [-1.3659999999999672, -1.525, -1.541, -1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034, -1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902], "policy_red_v3_reward": [-1.5659999999999987, -1.564, -1.076, 0.488, -0.6750000000000002, -1.2470000000000003], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996, -0.5720000000000001, -1.0999999999999936, 1.888296875, 0.3818906250000007, 2.256578125], "policy_red_v1_reward": [-0.6839999999999999, -1.616, 0.479, 3.2230961050000024, -0.5433067621847962, -1.2659999999999807, -0.16930676218381768, -1.5619999999999972, -1.3619999999999683, -2.012999999999999, -1.2299999999999771], "policy_red_v2_reward": [-0.713, 3.7872713628161723, 0.13828360500000325, 0.24984375000000103, -1.1569999999999867, -1.0219999999999998, -0.3380000000000003, -0.8010000000000002], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998], "policy_red_v6_reward": [-0.023000000000000013, 2.819406250000001], "policy_red_v7_reward": [0.38784375000000126, -1.5179999999999998], "policy_red_v5_reward": [1.9145625, 1.9013564894425938, -2.0139999999999993, 3.294971105000003], "policy_red_v11_reward": [0.4526932378161701, 0.20290625000000728], "policy_red_v12_reward": [1.935], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172, -2.0299999999999994], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625], "policy_red_v10_reward": [-1.5859999999999999], "policy_red_v15_reward": [-2.017]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7902969156942722, "mean_inference_ms": 7.720693837449385, "mean_action_processing_ms": 0.2891583008087615, "mean_env_wait_ms": 0.3821338278939518, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10396862030029297, "StateBufferConnector_ms": 0.004384040832519531, "ViewRequirementAgentConnector_ms": 0.12009572982788086}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.11283720984315, "num_env_steps_trained_throughput_per_sec": 201.11283720984315, "timesteps_total": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 19995.491, "sample_time_ms": 1160.817, "learn_time_ms": 18750.069, "learn_throughput": 213.333, "synch_weights_time_ms": 81.689}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "episodes_total": 252, "training_iteration": 40, "trial_id": "a9680_00000", "date": "2023-09-24_02-50-30", "timestamp": 1695538230, "time_this_iter_s": 19.901862621307373, "time_total_s": 795.9791057109833, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b3459a5c0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3459cd30>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3459cc10>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 795.9791057109833, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 5.083333333333334, "ram_util_percent": 18.083333333333336}, "win_rate": 0.71, "league_size": 19}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.932892661044995, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.020552058091561777, "policy_loss": -0.0516439375312378, "vf_loss": 0.05292933872551657, "vf_explained_var": 0.7135494531442722, "kl": 0.01616956041088997, "entropy": 2.6490921042859554, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 38880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 328000, "num_agent_steps_trained": 328000}, "sampler_results": {"episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.4022098230520017, "episode_len_mean": 414.82, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {"red_v4": -1.532, "red": -8.196306762183793, "blue": -2.0259999999999985, "red_v3": -1.564, "red_v1": -2.012999999999999, "red_v2": -1.1569999999999867, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": -1.5179999999999998, "red_v5": -2.0139999999999993, "red_v11": 0.20290625000000728, "red_v12": 1.935, "red_v13": -2.0299999999999994, "red_v8": -0.14330676218382843, "red_v10": -1.5859999999999999, "red_v15": -2.017}, "policy_reward_max": {"red_v4": 2.256578125, "red": 3.9943338628152043, "blue": 5.327049999999944, "red_v3": 0.488, "red_v1": 3.2230961050000024, "red_v2": 3.7872713628161723, "red_v9": -1.6169999999999998, "red_v6": 2.819406250000001, "red_v7": 0.38784375000000126, "red_v5": 3.294971105000003, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.904974487816172, "red_v8": 2.233140625, "red_v10": -1.5859999999999999, "red_v15": -2.017}, "policy_reward_mean": {"red_v4": -0.010581597222221443, "red": 1.8053867235441876, "blue": -0.7227465538416394, "red_v3": -0.8148000000000002, "red_v1": -0.6130470381244121, "red_v2": 0.018049839727023675, "red_v9": -1.8139999999999996, "red_v6": 1.3982031250000004, "red_v7": -0.5650781249999992, "red_v5": 1.2742225236106492, "red_v11": 0.3277997439080887, "red_v12": 1.935, "red_v13": 0.06905920427205785, "red_v8": 1.0449169314080857, "red_v10": -1.5859999999999999, "red_v15": -2.017}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957], "episode_lengths": [90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996, -0.5720000000000001, -1.0999999999999936, 1.888296875, 0.3818906250000007, 2.256578125, 0.13399999999999979], "policy_blue_reward": [-1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034, -1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475], "policy_red_v3_reward": [-1.564, -1.076, 0.488, -0.6750000000000002, -1.2470000000000003], "policy_red_v1_reward": [-0.6839999999999999, -1.616, 0.479, 3.2230961050000024, -0.5433067621847962, -1.2659999999999807, -0.16930676218381768, -1.5619999999999972, -1.3619999999999683, -2.012999999999999, -1.2299999999999771], "policy_red_v2_reward": [-0.713, 3.7872713628161723, 0.13828360500000325, 0.24984375000000103, -1.1569999999999867, -1.0219999999999998, -0.3380000000000003, -0.8010000000000002], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998], "policy_red_v6_reward": [-0.023000000000000013, 2.819406250000001], "policy_red_v7_reward": [0.38784375000000126, -1.5179999999999998], "policy_red_v5_reward": [1.9145625, 1.9013564894425938, -2.0139999999999993, 3.294971105000003], "policy_red_v11_reward": [0.4526932378161701, 0.20290625000000728], "policy_red_v12_reward": [1.935], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172, -2.0299999999999994], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625], "policy_red_v10_reward": [-1.5859999999999999], "policy_red_v15_reward": [-2.017]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7909851070631703, "mean_inference_ms": 7.725563096422881, "mean_action_processing_ms": 0.28962087204329473, "mean_env_wait_ms": 0.3824952250535776, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10483551025390625, "StateBufferConnector_ms": 0.004414677619934082, "ViewRequirementAgentConnector_ms": 0.12110888957977295}}, "episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.4022098230520017, "episode_len_mean": 414.82, "episodes_this_iter": 4, "policy_reward_min": {"red_v4": -1.532, "red": -8.196306762183793, "blue": -2.0259999999999985, "red_v3": -1.564, "red_v1": -2.012999999999999, "red_v2": -1.1569999999999867, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": -1.5179999999999998, "red_v5": -2.0139999999999993, "red_v11": 0.20290625000000728, "red_v12": 1.935, "red_v13": -2.0299999999999994, "red_v8": -0.14330676218382843, "red_v10": -1.5859999999999999, "red_v15": -2.017}, "policy_reward_max": {"red_v4": 2.256578125, "red": 3.9943338628152043, "blue": 5.327049999999944, "red_v3": 0.488, "red_v1": 3.2230961050000024, "red_v2": 3.7872713628161723, "red_v9": -1.6169999999999998, "red_v6": 2.819406250000001, "red_v7": 0.38784375000000126, "red_v5": 3.294971105000003, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.904974487816172, "red_v8": 2.233140625, "red_v10": -1.5859999999999999, "red_v15": -2.017}, "policy_reward_mean": {"red_v4": -0.010581597222221443, "red": 1.8053867235441876, "blue": -0.7227465538416394, "red_v3": -0.8148000000000002, "red_v1": -0.6130470381244121, "red_v2": 0.018049839727023675, "red_v9": -1.8139999999999996, "red_v6": 1.3982031250000004, "red_v7": -0.5650781249999992, "red_v5": 1.2742225236106492, "red_v11": 0.3277997439080887, "red_v12": 1.935, "red_v13": 0.06905920427205785, "red_v8": 1.0449169314080857, "red_v10": -1.5859999999999999, "red_v15": -2.017}, "hist_stats": {"episode_reward": [-0.17628124999999994, 1.670833862816181, 1.096927612816207, 0.7820057378161703, 1.352846875000004, 0.7807869878161708, 0.6576429800000054, 2.083018750000001, 0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957], "episode_lengths": [90, 243, 597, 156, 161, 610, 173, 74, 1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85], "policy_red_v4_reward": [-1.532, -0.5419999999999999, -1.0099999999999996, -0.5720000000000001, -1.0999999999999936, 1.888296875, 0.3818906250000007, 2.256578125, 0.13399999999999979], "policy_blue_reward": [-1.571, -0.21999999999999686, -1.5599999999999967, -1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034, -1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475], "policy_red_v3_reward": [-1.564, -1.076, 0.488, -0.6750000000000002, -1.2470000000000003], "policy_red_v1_reward": [-0.6839999999999999, -1.616, 0.479, 3.2230961050000024, -0.5433067621847962, -1.2659999999999807, -0.16930676218381768, -1.5619999999999972, -1.3619999999999683, -2.012999999999999, -1.2299999999999771], "policy_red_v2_reward": [-0.713, 3.7872713628161723, 0.13828360500000325, 0.24984375000000103, -1.1569999999999867, -1.0219999999999998, -0.3380000000000003, -0.8010000000000002], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998], "policy_red_v6_reward": [-0.023000000000000013, 2.819406250000001], "policy_red_v7_reward": [0.38784375000000126, -1.5179999999999998], "policy_red_v5_reward": [1.9145625, 1.9013564894425938, -2.0139999999999993, 3.294971105000003], "policy_red_v11_reward": [0.4526932378161701, 0.20290625000000728], "policy_red_v12_reward": [1.935], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172, -2.0299999999999994], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625], "policy_red_v10_reward": [-1.5859999999999999], "policy_red_v15_reward": [-2.017]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7909851070631703, "mean_inference_ms": 7.725563096422881, "mean_action_processing_ms": 0.28962087204329473, "mean_env_wait_ms": 0.3824952250535776, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10483551025390625, "StateBufferConnector_ms": 0.004414677619934082, "ViewRequirementAgentConnector_ms": 0.12110888957977295}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 328000, "num_agent_steps_trained": 328000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 209.3547800445448, "num_env_steps_trained_throughput_per_sec": 209.3547800445448, "timesteps_total": 164000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 328000, "timers": {"training_iteration_time_ms": 19909.865, "sample_time_ms": 1157.392, "learn_time_ms": 18667.484, "learn_throughput": 214.276, "synch_weights_time_ms": 82.174}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 328000, "num_agent_steps_trained": 328000}, "done": false, "episodes_total": 256, "training_iteration": 41, "trial_id": "a9680_00000", "date": "2023-09-24_02-50-51", "timestamp": 1695538251, "time_this_iter_s": 19.116201162338257, "time_total_s": 815.0953068733215, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34572e60>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3459e050>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3459dfc0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 815.0953068733215, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 5.206666666666667, "ram_util_percent": 18.279999999999998}, "win_rate": 0.69, "league_size": 20}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8115379257748523, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.024408542986323785, "policy_loss": -0.051414554268315746, "vf_loss": 0.04444396460506444, "vf_explained_var": 0.735902147491773, "kl": 0.016414409548466815, "entropy": 2.6024556969602903, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 39840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "sampler_results": {"episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.418475846921487, "episode_len_mean": 425.53, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"blue": -2.0259999999999985, "red": -8.196306762183793, "red_v4": -1.0999999999999936, "red_v2": -1.164999999999984, "red_v1": -2.012999999999999, "red_v3": -1.2470000000000003, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": -1.5179999999999998, "red_v5": -2.0139999999999993, "red_v11": 0.20290625000000728, "red_v12": 0.17228360500001294, "red_v13": -2.0299999999999994, "red_v8": -0.14330676218382843, "red_v10": -1.5859999999999999, "red_v15": -2.017}, "policy_reward_max": {"blue": 5.327049999999944, "red": 3.9943338628152043, "red_v4": 2.256578125, "red_v2": 3.7872713628161723, "red_v1": 3.2230961050000024, "red_v3": 0.488, "red_v9": 0.14728360500001836, "red_v6": 2.819406250000001, "red_v7": 0.38784375000000126, "red_v5": 3.294971105000003, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.904974487816172, "red_v8": 2.233140625, "red_v10": -1.5859999999999999, "red_v15": 1.7353304800000051}, "policy_reward_mean": {"blue": -0.7026421334491055, "red": 1.7611611142636716, "red_v4": 0.17959570312500084, "red_v2": -0.11340014246486607, "red_v1": -0.6153146774210668, "red_v3": -0.6275000000000002, "red_v9": -1.1602387983333269, "red_v6": 1.3982031250000004, "red_v7": -0.5650781249999992, "red_v5": 1.2742225236106492, "red_v11": 0.3277997439080887, "red_v12": 1.0536418025000065, "red_v13": 0.06905920427205785, "red_v8": 1.0449169314080857, "red_v10": -1.5859999999999999, "red_v15": -0.1408347599999974}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957, 2.201023717816181, 0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093], "episode_lengths": [1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85, 145, 1280, 36, 49, 317, 630, 270, 448], "policy_blue_reward": [-1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034, -1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475, -2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995], "policy_red_v4_reward": [-0.5419999999999999, -1.0099999999999996, -0.5720000000000001, -1.0999999999999936, 1.888296875, 0.3818906250000007, 2.256578125, 0.13399999999999979], "policy_red_v2_reward": [-0.713, 3.7872713628161723, 0.13828360500000325, 0.24984375000000103, -1.1569999999999867, -1.0219999999999998, -0.3380000000000003, -0.8010000000000002, -1.164999999999984], "policy_red_v1_reward": [3.2230961050000024, -0.5433067621847962, -1.2659999999999807, -0.16930676218381768, -1.5619999999999972, -1.3619999999999683, -2.012999999999999, -1.2299999999999771], "policy_red_v3_reward": [-1.076, 0.488, -0.6750000000000002, -1.2470000000000003], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998, 0.14728360500001836], "policy_red_v6_reward": [-0.023000000000000013, 2.819406250000001], "policy_red_v7_reward": [0.38784375000000126, -1.5179999999999998], "policy_red_v5_reward": [1.9145625, 1.9013564894425938, -2.0139999999999993, 3.294971105000003], "policy_red_v11_reward": [0.4526932378161701, 0.20290625000000728], "policy_red_v12_reward": [1.935, 0.17228360500001294], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172, -2.0299999999999994], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625], "policy_red_v10_reward": [-1.5859999999999999], "policy_red_v15_reward": [-2.017, 1.7353304800000051]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7915649216043471, "mean_inference_ms": 7.722056802711831, "mean_action_processing_ms": 0.28959889568391267, "mean_env_wait_ms": 0.38219738408921183, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10558950901031494, "StateBufferConnector_ms": 0.004411578178405762, "ViewRequirementAgentConnector_ms": 0.12141096591949463}}, "episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.418475846921487, "episode_len_mean": 425.53, "episodes_this_iter": 8, "policy_reward_min": {"blue": -2.0259999999999985, "red": -8.196306762183793, "red_v4": -1.0999999999999936, "red_v2": -1.164999999999984, "red_v1": -2.012999999999999, "red_v3": -1.2470000000000003, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": -1.5179999999999998, "red_v5": -2.0139999999999993, "red_v11": 0.20290625000000728, "red_v12": 0.17228360500001294, "red_v13": -2.0299999999999994, "red_v8": -0.14330676218382843, "red_v10": -1.5859999999999999, "red_v15": -2.017}, "policy_reward_max": {"blue": 5.327049999999944, "red": 3.9943338628152043, "red_v4": 2.256578125, "red_v2": 3.7872713628161723, "red_v1": 3.2230961050000024, "red_v3": 0.488, "red_v9": 0.14728360500001836, "red_v6": 2.819406250000001, "red_v7": 0.38784375000000126, "red_v5": 3.294971105000003, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.904974487816172, "red_v8": 2.233140625, "red_v10": -1.5859999999999999, "red_v15": 1.7353304800000051}, "policy_reward_mean": {"blue": -0.7026421334491055, "red": 1.7611611142636716, "red_v4": 0.17959570312500084, "red_v2": -0.11340014246486607, "red_v1": -0.6153146774210668, "red_v3": -0.6275000000000002, "red_v9": -1.1602387983333269, "red_v6": 1.3982031250000004, "red_v7": -0.5650781249999992, "red_v5": 1.2742225236106492, "red_v11": 0.3277997439080887, "red_v12": 1.0536418025000065, "red_v13": 0.06905920427205785, "red_v8": 1.0449169314080857, "red_v10": -1.5859999999999999, "red_v15": -0.1408347599999974}, "hist_stats": {"episode_reward": [0.5816932378162066, 1.3488842835440598, 0.7370838628161736, 0.6836932378162087, 0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957, 2.201023717816181, 0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093], "episode_lengths": [1280, 134, 227, 1280, 95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85, 145, 1280, 36, 49, 317, 630, 270, 448], "policy_blue_reward": [-1.3729999999999656, -2.025999999999998, -1.056, -1.3279999999999714, 1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034, -1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475, -2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995], "policy_red_v4_reward": [-0.5419999999999999, -1.0099999999999996, -0.5720000000000001, -1.0999999999999936, 1.888296875, 0.3818906250000007, 2.256578125, 0.13399999999999979], "policy_red_v2_reward": [-0.713, 3.7872713628161723, 0.13828360500000325, 0.24984375000000103, -1.1569999999999867, -1.0219999999999998, -0.3380000000000003, -0.8010000000000002, -1.164999999999984], "policy_red_v1_reward": [3.2230961050000024, -0.5433067621847962, -1.2659999999999807, -0.16930676218381768, -1.5619999999999972, -1.3619999999999683, -2.012999999999999, -1.2299999999999771], "policy_red_v3_reward": [-1.076, 0.488, -0.6750000000000002, -1.2470000000000003], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998, 0.14728360500001836], "policy_red_v6_reward": [-0.023000000000000013, 2.819406250000001], "policy_red_v7_reward": [0.38784375000000126, -1.5179999999999998], "policy_red_v5_reward": [1.9145625, 1.9013564894425938, -2.0139999999999993, 3.294971105000003], "policy_red_v11_reward": [0.4526932378161701, 0.20290625000000728], "policy_red_v12_reward": [1.935, 0.17228360500001294], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172, -2.0299999999999994], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625], "policy_red_v10_reward": [-1.5859999999999999], "policy_red_v15_reward": [-2.017, 1.7353304800000051]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7915649216043471, "mean_inference_ms": 7.722056802711831, "mean_action_processing_ms": 0.28959889568391267, "mean_env_wait_ms": 0.38219738408921183, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10558950901031494, "StateBufferConnector_ms": 0.004411578178405762, "ViewRequirementAgentConnector_ms": 0.12141096591949463}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 203.107508503542, "num_env_steps_trained_throughput_per_sec": 203.107508503542, "timesteps_total": 168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 19886.572, "sample_time_ms": 1160.781, "learn_time_ms": 18640.348, "learn_throughput": 214.588, "synch_weights_time_ms": 82.638}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "episodes_total": 264, "training_iteration": 42, "trial_id": "a9680_00000", "date": "2023-09-24_02-51-13", "timestamp": 1695538273, "time_this_iter_s": 19.70459008216858, "time_total_s": 834.7998969554901, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b343c5510>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3459f400>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3459f490>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 834.7998969554901, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 5.220000000000001, "ram_util_percent": 18.389999999999993}, "win_rate": 0.65, "league_size": 20}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8776067813237507, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.04036244480569925, "policy_loss": -0.05912471577854982, "vf_loss": 0.02714442053596334, "vf_explained_var": 0.6282194492717584, "kl": 0.01737907575961041, "entropy": 2.6305227195223173, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 40800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 344000, "num_agent_steps_trained": 344000}, "sampler_results": {"episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.4673804574705311, "episode_len_mean": 417.26, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {"red_v4": -1.0999999999999936, "red": -8.196306762183793, "blue": -2.0259999999999985, "red_v2": -1.164999999999984, "red_v1": -2.012999999999999, "red_v3": -1.2470000000000003, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": -1.5179999999999998, "red_v5": -2.0139999999999993, "red_v11": 0.20290625000000728, "red_v12": 0.17228360500001294, "red_v13": -2.0299999999999994, "red_v8": -0.14330676218382843, "red_v10": -1.5859999999999999, "red_v15": -2.017, "red_v18": -0.017306762183829316}, "policy_reward_max": {"red_v4": 2.256578125, "red": 3.9943338628152043, "blue": 5.327049999999944, "red_v2": 3.7872713628161723, "red_v1": 3.2230961050000024, "red_v3": 0.488, "red_v9": 0.14728360500001836, "red_v6": 2.819406250000001, "red_v7": 0.38784375000000126, "red_v5": 3.294971105000003, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.904974487816172, "red_v8": 2.233140625, "red_v10": -1.5859999999999999, "red_v15": 1.7353304800000051, "red_v18": -0.017306762183829316}, "policy_reward_mean": {"red_v4": 0.22871765142401992, "red": 1.753121860056392, "blue": -0.6225396175121113, "red_v2": -0.11340014246486607, "red_v1": -0.6153146774210668, "red_v3": -0.6275000000000002, "red_v9": -1.1602387983333269, "red_v6": 1.3982031250000004, "red_v7": -0.5650781249999992, "red_v5": 1.2742225236106492, "red_v11": 0.3277997439080887, "red_v12": 1.0536418025000065, "red_v13": 0.06905920427205785, "red_v8": 1.0449169314080857, "red_v10": -1.5859999999999999, "red_v15": -0.1408347599999974, "red_v18": -0.017306762183829316}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957, 2.201023717816181, 0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093, 2.325370850632347, 2.212599487816182, 1.727386475632418, 1.9764588628161854], "episode_lengths": [95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85, 145, 1280, 36, 49, 317, 630, 270, 448, 165, 222, 1280, 427], "policy_red_v4_reward": [-0.5419999999999999, -1.0099999999999996, -0.5720000000000001, -1.0999999999999936, 1.888296875, 0.3818906250000007, 2.256578125, 0.13399999999999979, 0.6216932378161725], "policy_blue_reward": [1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034, -1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475, -2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995, 0.43399999999999994, -1.1269999999999887], "policy_red_v2_reward": [-0.713, 3.7872713628161723, 0.13828360500000325, 0.24984375000000103, -1.1569999999999867, -1.0219999999999998, -0.3380000000000003, -0.8010000000000002, -1.164999999999984], "policy_red_v1_reward": [3.2230961050000024, -0.5433067621847962, -1.2659999999999807, -0.16930676218381768, -1.5619999999999972, -1.3619999999999683, -2.012999999999999, -1.2299999999999771], "policy_red_v3_reward": [-1.076, 0.488, -0.6750000000000002, -1.2470000000000003], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998, 0.14728360500001836], "policy_red_v6_reward": [-0.023000000000000013, 2.819406250000001], "policy_red_v7_reward": [0.38784375000000126, -1.5179999999999998], "policy_red_v5_reward": [1.9145625, 1.9013564894425938, -2.0139999999999993, 3.294971105000003], "policy_red_v11_reward": [0.4526932378161701, 0.20290625000000728], "policy_red_v12_reward": [1.935, 0.17228360500001294], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172, -2.0299999999999994], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625], "policy_red_v10_reward": [-1.5859999999999999], "policy_red_v15_reward": [-2.017, 1.7353304800000051], "policy_red_v18_reward": [-0.017306762183829316]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7917688213672281, "mean_inference_ms": 7.719481856788717, "mean_action_processing_ms": 0.28966729646024236, "mean_env_wait_ms": 0.3822433412466446, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10590851306915283, "StateBufferConnector_ms": 0.004416823387145996, "ViewRequirementAgentConnector_ms": 0.12175393104553223}}, "episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.4673804574705311, "episode_len_mean": 417.26, "episodes_this_iter": 4, "policy_reward_min": {"red_v4": -1.0999999999999936, "red": -8.196306762183793, "blue": -2.0259999999999985, "red_v2": -1.164999999999984, "red_v1": -2.012999999999999, "red_v3": -1.2470000000000003, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v7": -1.5179999999999998, "red_v5": -2.0139999999999993, "red_v11": 0.20290625000000728, "red_v12": 0.17228360500001294, "red_v13": -2.0299999999999994, "red_v8": -0.14330676218382843, "red_v10": -1.5859999999999999, "red_v15": -2.017, "red_v18": -0.017306762183829316}, "policy_reward_max": {"red_v4": 2.256578125, "red": 3.9943338628152043, "blue": 5.327049999999944, "red_v2": 3.7872713628161723, "red_v1": 3.2230961050000024, "red_v3": 0.488, "red_v9": 0.14728360500001836, "red_v6": 2.819406250000001, "red_v7": 0.38784375000000126, "red_v5": 3.294971105000003, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.904974487816172, "red_v8": 2.233140625, "red_v10": -1.5859999999999999, "red_v15": 1.7353304800000051, "red_v18": -0.017306762183829316}, "policy_reward_mean": {"red_v4": 0.22871765142401992, "red": 1.753121860056392, "blue": -0.6225396175121113, "red_v2": -0.11340014246486607, "red_v1": -0.6153146774210668, "red_v3": -0.6275000000000002, "red_v9": -1.1602387983333269, "red_v6": 1.3982031250000004, "red_v7": -0.5650781249999992, "red_v5": 1.2742225236106492, "red_v11": 0.3277997439080887, "red_v12": 1.0536418025000065, "red_v13": 0.06905920427205785, "red_v8": 1.0449169314080857, "red_v10": -1.5859999999999999, "red_v15": -0.1408347599999974, "red_v18": -0.017306762183829316}, "hist_stats": {"episode_reward": [0.3552031250000002, 1.5761776128162133, 2.164630737816206, 2.471302612816171, 0.6746932378162129, 0.6486932378161843, 1.6730961050000053, 0.6671776128161696, 0.4162244878161696, 2.438806158544057, 2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957, 2.201023717816181, 0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093, 2.325370850632347, 2.212599487816182, 1.727386475632418, 1.9764588628161854], "episode_lengths": [95, 709, 596, 29, 1280, 1280, 188, 261, 534, 63, 421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85, 145, 1280, 36, 49, 317, 630, 270, 448, 165, 222, 1280, 427], "policy_red_v4_reward": [-0.5419999999999999, -1.0099999999999996, -0.5720000000000001, -1.0999999999999936, 1.888296875, 0.3818906250000007, 2.256578125, 0.13399999999999979, 0.6216932378161725], "policy_blue_reward": [1.808484375, -1.3569999999999687, -1.3649999999999678, -1.573, -1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034, -1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475, -2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995, 0.43399999999999994, -1.1269999999999887], "policy_red_v2_reward": [-0.713, 3.7872713628161723, 0.13828360500000325, 0.24984375000000103, -1.1569999999999867, -1.0219999999999998, -0.3380000000000003, -0.8010000000000002, -1.164999999999984], "policy_red_v1_reward": [3.2230961050000024, -0.5433067621847962, -1.2659999999999807, -0.16930676218381768, -1.5619999999999972, -1.3619999999999683, -2.012999999999999, -1.2299999999999771], "policy_red_v3_reward": [-1.076, 0.488, -0.6750000000000002, -1.2470000000000003], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998, 0.14728360500001836], "policy_red_v6_reward": [-0.023000000000000013, 2.819406250000001], "policy_red_v7_reward": [0.38784375000000126, -1.5179999999999998], "policy_red_v5_reward": [1.9145625, 1.9013564894425938, -2.0139999999999993, 3.294971105000003], "policy_red_v11_reward": [0.4526932378161701, 0.20290625000000728], "policy_red_v12_reward": [1.935, 0.17228360500001294], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172, -2.0299999999999994], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625], "policy_red_v10_reward": [-1.5859999999999999], "policy_red_v15_reward": [-2.017, 1.7353304800000051], "policy_red_v18_reward": [-0.017306762183829316]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7917688213672281, "mean_inference_ms": 7.719481856788717, "mean_action_processing_ms": 0.28966729646024236, "mean_env_wait_ms": 0.3822433412466446, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10590851306915283, "StateBufferConnector_ms": 0.004416823387145996, "ViewRequirementAgentConnector_ms": 0.12175393104553223}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 344000, "num_agent_steps_trained": 344000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.02322705095654, "num_env_steps_trained_throughput_per_sec": 200.02322705095654, "timesteps_total": 172000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 344000, "timers": {"training_iteration_time_ms": 19872.971, "sample_time_ms": 1155.332, "learn_time_ms": 18631.831, "learn_throughput": 214.686, "synch_weights_time_ms": 83.096}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 344000, "num_agent_steps_trained": 344000}, "done": false, "episodes_total": 268, "training_iteration": 43, "trial_id": "a9680_00000", "date": "2023-09-24_02-51-33", "timestamp": 1695538293, "time_this_iter_s": 20.008379459381104, "time_total_s": 854.8082764148712, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b343c5ea0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3459f910>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3459f9a0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 854.8082764148712, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 4.8275862068965525, "ram_util_percent": 18.49310344827586}, "win_rate": 0.63, "league_size": 20}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.901041403164466, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01763925284515911, "policy_loss": -0.05465482777993505, "vf_loss": 0.06520355325386239, "vf_explained_var": 0.7068357581893603, "kl": 0.01561581968938602, "entropy": 2.61332072665294, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 41760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "sampler_results": {"episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.4824953281139923, "episode_len_mean": 423.15, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"red_v3": -1.2470000000000003, "red": -8.196306762183793, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v1": -2.012999999999999, "red_v7": -1.5179999999999998, "blue": -2.0259999999999985, "red_v4": -1.0999999999999936, "red_v2": -1.164999999999984, "red_v5": -2.0139999999999993, "red_v11": 0.20290625000000728, "red_v12": 0.17228360500001294, "red_v13": -2.0299999999999994, "red_v8": -0.14330676218382843, "red_v10": -1.5859999999999999, "red_v15": -2.017, "red_v18": -0.017306762183829316}, "policy_reward_max": {"red_v3": -0.5630653855574075, "red": 3.9943338628152043, "red_v9": 0.14728360500001836, "red_v6": 2.819406250000001, "red_v1": -0.16930676218381768, "red_v7": 1.8905468749999998, "blue": 5.327049999999944, "red_v4": 2.256578125, "red_v2": 3.7872713628161723, "red_v5": 3.294971105000003, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.904974487816172, "red_v8": 2.233140625, "red_v10": -1.5859999999999999, "red_v15": 1.7353304800000051, "red_v18": -0.017306762183829316}, "policy_reward_mean": {"red_v3": -0.828355128519136, "red": 1.826149439355427, "red_v9": -1.1602387983333269, "red_v6": 1.3982031250000004, "red_v1": -1.2039516905460619, "red_v7": 0.2534635416666671, "blue": -0.6956766386574401, "red_v4": 0.5157798375451684, "red_v2": -0.03845016027297432, "red_v5": 0.9179780188885193, "red_v11": 0.3277997439080887, "red_v12": 1.0536418025000065, "red_v13": 0.06905920427205785, "red_v8": 1.0449169314080857, "red_v10": -1.5859999999999999, "red_v15": -0.1408347599999974, "red_v18": -0.017306762183829316}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957, 2.201023717816181, 0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093, 2.325370850632347, 2.212599487816182, 1.727386475632418, 1.9764588628161854, 0.4226932378161854, 1.931693237816172, 2.1513182378161813, 0.5966932378161889, 1.9386151128161928, 1.8792401128161726, 0.7786932378162135, 2.749377852258771, 1.437646362815205, 0.7115213628161947], "episode_lengths": [421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85, 145, 1280, 36, 49, 317, 630, 270, 448, 165, 222, 1280, 427, 1280, 64, 312, 1280, 441, 113, 1280, 208, 47, 599], "policy_red_v3_reward": [-0.6750000000000002, -1.2470000000000003, -0.5630653855574075], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998, 0.14728360500001836], "policy_red_v6_reward": [-0.023000000000000013, 2.819406250000001], "policy_red_v1_reward": [-0.5433067621847962, -1.2659999999999807, -0.16930676218381768, -1.5619999999999972, -1.3619999999999683, -2.012999999999999, -1.2299999999999771, -1.4859999999999594], "policy_red_v7_reward": [0.38784375000000126, -1.5179999999999998, 1.8905468749999998], "policy_blue_reward": [-1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034, -1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475, -2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995, 0.43399999999999994, -1.1269999999999887, -2.0219999999999994, -1.0759999999999947, -1.3859999999999661, -1.1339999999999881, -2.016, 0.39182812499999986], "policy_red_v4_reward": [-0.5720000000000001, -1.0999999999999936, 1.888296875, 0.3818906250000007, 2.256578125, 0.13399999999999979, 0.6216932378161725], "policy_red_v2_reward": [3.7872713628161723, 0.13828360500000325, 0.24984375000000103, -1.1569999999999867, -1.0219999999999998, -0.3380000000000003, -0.8010000000000002, -1.164999999999984], "policy_red_v5_reward": [1.9145625, 1.9013564894425938, -2.0139999999999993, 3.294971105000003, -0.5070000000000005], "policy_red_v11_reward": [0.4526932378161701, 0.20290625000000728], "policy_red_v12_reward": [1.935, 0.17228360500001294], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172, -2.0299999999999994], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625], "policy_red_v10_reward": [-1.5859999999999999], "policy_red_v15_reward": [-2.017, 1.7353304800000051], "policy_red_v18_reward": [-0.017306762183829316]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7921494021779983, "mean_inference_ms": 7.709318972528709, "mean_action_processing_ms": 0.289440888504493, "mean_env_wait_ms": 0.3819950987512981, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10658800601959229, "StateBufferConnector_ms": 0.004414200782775879, "ViewRequirementAgentConnector_ms": 0.12153911590576172}}, "episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.4824953281139923, "episode_len_mean": 423.15, "episodes_this_iter": 10, "policy_reward_min": {"red_v3": -1.2470000000000003, "red": -8.196306762183793, "red_v9": -2.0109999999999992, "red_v6": -0.023000000000000013, "red_v1": -2.012999999999999, "red_v7": -1.5179999999999998, "blue": -2.0259999999999985, "red_v4": -1.0999999999999936, "red_v2": -1.164999999999984, "red_v5": -2.0139999999999993, "red_v11": 0.20290625000000728, "red_v12": 0.17228360500001294, "red_v13": -2.0299999999999994, "red_v8": -0.14330676218382843, "red_v10": -1.5859999999999999, "red_v15": -2.017, "red_v18": -0.017306762183829316}, "policy_reward_max": {"red_v3": -0.5630653855574075, "red": 3.9943338628152043, "red_v9": 0.14728360500001836, "red_v6": 2.819406250000001, "red_v1": -0.16930676218381768, "red_v7": 1.8905468749999998, "blue": 5.327049999999944, "red_v4": 2.256578125, "red_v2": 3.7872713628161723, "red_v5": 3.294971105000003, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.904974487816172, "red_v8": 2.233140625, "red_v10": -1.5859999999999999, "red_v15": 1.7353304800000051, "red_v18": -0.017306762183829316}, "policy_reward_mean": {"red_v3": -0.828355128519136, "red": 1.826149439355427, "red_v9": -1.1602387983333269, "red_v6": 1.3982031250000004, "red_v1": -1.2039516905460619, "red_v7": 0.2534635416666671, "blue": -0.6956766386574401, "red_v4": 0.5157798375451684, "red_v2": -0.03845016027297432, "red_v5": 0.9179780188885193, "red_v11": 0.3277997439080887, "red_v12": 1.0536418025000065, "red_v13": 0.06905920427205785, "red_v8": 1.0449169314080857, "red_v10": -1.5859999999999999, "red_v15": -0.1408347599999974, "red_v18": -0.017306762183829316}, "hist_stats": {"episode_reward": [2.370677612816196, 0.9362401128161699, 2.882646362816174, 3.3049958506313826, 0.8705369878161726, 1.5332088628162022, 0.8927088628162093, 2.822943237816175, 3.5975549678161833, 0.7131307378162217, 0.624693237816204, 0.615693237816206, 2.5856377394426233, 0.9646776128152048, 1.9074432378161847, 2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957, 2.201023717816181, 0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093, 2.325370850632347, 2.212599487816182, 1.727386475632418, 1.9764588628161854, 0.4226932378161854, 1.931693237816172, 2.1513182378161813, 0.5966932378161889, 1.9386151128161928, 1.8792401128161726, 0.7786932378162135, 2.749377852258771, 1.437646362815205, 0.7115213628161947], "episode_lengths": [421, 49, 111, 157, 114, 635, 1115, 112, 231, 820, 1280, 1280, 575, 37, 464, 133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85, 145, 1280, 36, 49, 317, 630, 270, 448, 165, 222, 1280, 427, 1280, 64, 312, 1280, 441, 113, 1280, 208, 47, 599], "policy_red_v3_reward": [-0.6750000000000002, -1.2470000000000003, -0.5630653855574075], "policy_red_v9_reward": [-2.0109999999999992, -1.6169999999999998, 0.14728360500001836], "policy_red_v6_reward": [-0.023000000000000013, 2.819406250000001], "policy_red_v1_reward": [-0.5433067621847962, -1.2659999999999807, -0.16930676218381768, -1.5619999999999972, -1.3619999999999683, -2.012999999999999, -1.2299999999999771, -1.4859999999999594], "policy_red_v7_reward": [0.38784375000000126, -1.5179999999999998, 1.8905468749999998], "policy_blue_reward": [-1.3559999999999681, 1.0654375000000162, -1.360999999999969, -1.3539999999999666, -0.15906538555740568, 0.46398437500000034, -1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475, -2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995, 0.43399999999999994, -1.1269999999999887, -2.0219999999999994, -1.0759999999999947, -1.3859999999999661, -1.1339999999999881, -2.016, 0.39182812499999986], "policy_red_v4_reward": [-0.5720000000000001, -1.0999999999999936, 1.888296875, 0.3818906250000007, 2.256578125, 0.13399999999999979, 0.6216932378161725], "policy_red_v2_reward": [3.7872713628161723, 0.13828360500000325, 0.24984375000000103, -1.1569999999999867, -1.0219999999999998, -0.3380000000000003, -0.8010000000000002, -1.164999999999984], "policy_red_v5_reward": [1.9145625, 1.9013564894425938, -2.0139999999999993, 3.294971105000003, -0.5070000000000005], "policy_red_v11_reward": [0.4526932378161701, 0.20290625000000728], "policy_red_v12_reward": [1.935, 0.17228360500001294], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172, -2.0299999999999994], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625], "policy_red_v10_reward": [-1.5859999999999999], "policy_red_v15_reward": [-2.017, 1.7353304800000051], "policy_red_v18_reward": [-0.017306762183829316]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7921494021779983, "mean_inference_ms": 7.709318972528709, "mean_action_processing_ms": 0.289440888504493, "mean_env_wait_ms": 0.3819950987512981, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10658800601959229, "StateBufferConnector_ms": 0.004414200782775879, "ViewRequirementAgentConnector_ms": 0.12153911590576172}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 195.61418975015363, "num_env_steps_trained_throughput_per_sec": 195.61418975015363, "timesteps_total": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 19896.307, "sample_time_ms": 1160.719, "learn_time_ms": 18650.157, "learn_throughput": 214.475, "synch_weights_time_ms": 82.775}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "episodes_total": 278, "training_iteration": 44, "trial_id": "a9680_00000", "date": "2023-09-24_02-51-53", "timestamp": 1695538313, "time_this_iter_s": 20.45854115486145, "time_total_s": 875.2668175697327, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b343c53f0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3459df30>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3459d990>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 875.2668175697327, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 5.531034482758621, "ram_util_percent": 18.49310344827586}, "win_rate": 0.64, "league_size": 20}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0186119016259907, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.002864861997416786, "policy_loss": -0.051738790442080546, "vf_loss": 0.10117718970868736, "vf_explained_var": 0.6369828627134363, "kl": 0.014701386880794113, "entropy": 2.600565915554762, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 42720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 360000, "num_agent_steps_trained": 360000}, "sampler_results": {"episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.4630242678434464, "episode_len_mean": 428.78, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"red_v9": -1.6169999999999998, "red": -8.196306762183793, "red_v4": 0.13399999999999979, "red_v2": -1.164999999999984, "blue": -2.0259999999999985, "red_v5": -2.0139999999999993, "red_v1": -2.012999999999999, "red_v7": -1.5179999999999998, "red_v6": 2.819406250000001, "red_v11": 0.20290625000000728, "red_v12": 0.17228360500001294, "red_v13": -2.0299999999999994, "red_v8": -0.14330676218382843, "red_v10": -1.5859999999999999, "red_v3": -1.2470000000000003, "red_v15": -2.017, "red_v18": -0.017306762183829316, "red_v17": -0.573307457227058}, "policy_reward_max": {"red_v9": 0.14728360500001836, "red": 3.9943338628152043, "red_v4": 2.256578125, "red_v2": 0.24984375000000103, "blue": 5.327049999999944, "red_v5": 3.294971105000003, "red_v1": -0.16930676218381768, "red_v7": 1.8905468749999998, "red_v6": 2.819406250000001, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.904974487816172, "red_v8": 2.233140625, "red_v10": -0.06689696645591336, "red_v3": -0.5630653855574075, "red_v15": 1.7353304800000051, "red_v18": -0.017306762183829316, "red_v17": -0.573307457227058}, "policy_reward_mean": {"red_v9": -0.5653410523946011, "red": 1.8915132643442885, "red_v4": 1.0564917725632346, "red_v2": -0.5849818064285667, "blue": -0.7905405216037684, "red_v5": 0.9179780188885193, "red_v1": -1.3037177936972864, "red_v7": 0.18627343750000003, "red_v6": 2.819406250000001, "red_v11": 0.3277997439080887, "red_v12": 1.0536418025000065, "red_v13": 0.06905920427205785, "red_v8": 1.0449169314080857, "red_v10": -0.8264484832279566, "red_v3": -0.9786884618524652, "red_v15": -0.1408347599999974, "red_v18": -0.017306762183829316, "red_v17": -0.573307457227058}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957, 2.201023717816181, 0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093, 2.325370850632347, 2.212599487816182, 1.727386475632418, 1.9764588628161854, 0.4226932378161854, 1.931693237816172, 2.1513182378161813, 0.5966932378161889, 1.9386151128161928, 1.8792401128161726, 0.7786932378162135, 2.749377852258771, 1.437646362815205, 0.7115213628161947, 0.8216932378161718, 1.2100682378162138, 0.9263721144425925, 1.1514432378161823, 2.3144276128161763, 1.1808807378162096, 2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312], "episode_lengths": [133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85, 145, 1280, 36, 49, 317, 630, 270, 448, 165, 222, 1280, 427, 1280, 64, 312, 1280, 441, 113, 1280, 208, 47, 599, 1280, 968, 52, 336, 181, 964, 727, 31, 72, 83, 282, 836, 40, 1280, 832], "policy_red_v9_reward": [-1.6169999999999998, 0.14728360500001836, -0.22630676218382195], "policy_red_v4_reward": [1.888296875, 0.3818906250000007, 2.256578125, 0.13399999999999979, 0.6216932378161725], "policy_red_v2_reward": [0.13828360500000325, 0.24984375000000103, -1.1569999999999867, -1.0219999999999998, -0.3380000000000003, -0.8010000000000002, -1.164999999999984], "policy_blue_reward": [-1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475, -2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995, 0.43399999999999994, -1.1269999999999887, -2.0219999999999994, -1.0759999999999947, -1.3859999999999661, -1.1339999999999881, -2.016, 0.39182812499999986, -1.300999999999974, 0.4484375000000004, 0.6647499999999998, -1.0409999999999966, -1.2819999999999736, -2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657], "policy_red_v5_reward": [1.9145625, 1.9013564894425938, -2.0139999999999993, 3.294971105000003, -0.5070000000000005], "policy_red_v1_reward": [-0.16930676218381768, -1.5619999999999972, -1.3619999999999683, -2.012999999999999, -1.2299999999999771, -1.4859999999999594], "policy_red_v7_reward": [-1.5179999999999998, 1.8905468749999998], "policy_red_v6_reward": [2.819406250000001], "policy_red_v11_reward": [0.4526932378161701, 0.20290625000000728], "policy_red_v12_reward": [1.935, 0.17228360500001294], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172, -2.0299999999999994], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625], "policy_red_v10_reward": [-1.5859999999999999, -0.06689696645591336], "policy_red_v3_reward": [-1.2470000000000003, -0.5630653855574075, -1.1259999999999877], "policy_red_v15_reward": [-2.017, 1.7353304800000051], "policy_red_v18_reward": [-0.017306762183829316], "policy_red_v17_reward": [-0.573307457227058]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7937864922676, "mean_inference_ms": 7.715254020493976, "mean_action_processing_ms": 0.28979569436064617, "mean_env_wait_ms": 0.3820913197062095, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10527563095092773, "StateBufferConnector_ms": 0.004342436790466309, "ViewRequirementAgentConnector_ms": 0.12014901638031006}}, "episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.4630242678434464, "episode_len_mean": 428.78, "episodes_this_iter": 15, "policy_reward_min": {"red_v9": -1.6169999999999998, "red": -8.196306762183793, "red_v4": 0.13399999999999979, "red_v2": -1.164999999999984, "blue": -2.0259999999999985, "red_v5": -2.0139999999999993, "red_v1": -2.012999999999999, "red_v7": -1.5179999999999998, "red_v6": 2.819406250000001, "red_v11": 0.20290625000000728, "red_v12": 0.17228360500001294, "red_v13": -2.0299999999999994, "red_v8": -0.14330676218382843, "red_v10": -1.5859999999999999, "red_v3": -1.2470000000000003, "red_v15": -2.017, "red_v18": -0.017306762183829316, "red_v17": -0.573307457227058}, "policy_reward_max": {"red_v9": 0.14728360500001836, "red": 3.9943338628152043, "red_v4": 2.256578125, "red_v2": 0.24984375000000103, "blue": 5.327049999999944, "red_v5": 3.294971105000003, "red_v1": -0.16930676218381768, "red_v7": 1.8905468749999998, "red_v6": 2.819406250000001, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.904974487816172, "red_v8": 2.233140625, "red_v10": -0.06689696645591336, "red_v3": -0.5630653855574075, "red_v15": 1.7353304800000051, "red_v18": -0.017306762183829316, "red_v17": -0.573307457227058}, "policy_reward_mean": {"red_v9": -0.5653410523946011, "red": 1.8915132643442885, "red_v4": 1.0564917725632346, "red_v2": -0.5849818064285667, "blue": -0.7905405216037684, "red_v5": 0.9179780188885193, "red_v1": -1.3037177936972864, "red_v7": 0.18627343750000003, "red_v6": 2.819406250000001, "red_v11": 0.3277997439080887, "red_v12": 1.0536418025000065, "red_v13": 0.06905920427205785, "red_v8": 1.0449169314080857, "red_v10": -0.8264484832279566, "red_v3": -0.9786884618524652, "red_v15": -0.1408347599999974, "red_v18": -0.017306762183829316, "red_v17": -0.573307457227058}, "hist_stats": {"episode_reward": [2.2621776128161786, 1.8549901128161745, 2.6391018428162383, 0.6577783644426112, 2.130740112816187, 0.7215625000000001, 0.7297968750000001, 1.978118658544055, 2.3950497272587663, 2.250911987816173, 1.586161987816181, 2.295636475632379, 0.7966619878161775, 2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957, 2.201023717816181, 0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093, 2.325370850632347, 2.212599487816182, 1.727386475632418, 1.9764588628161854, 0.4226932378161854, 1.931693237816172, 2.1513182378161813, 0.5966932378161889, 1.9386151128161928, 1.8792401128161726, 0.7786932378162135, 2.749377852258771, 1.437646362815205, 0.7115213628161947, 0.8216932378161718, 1.2100682378162138, 0.9263721144425925, 1.1514432378161823, 2.3144276128161763, 1.1808807378162096, 2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312], "episode_lengths": [133, 129, 856, 626, 273, 76, 97, 27, 89, 186, 298, 496, 138, 339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85, 145, 1280, 36, 49, 317, 630, 270, 448, 165, 222, 1280, 427, 1280, 64, 312, 1280, 441, 113, 1280, 208, 47, 599, 1280, 968, 52, 336, 181, 964, 727, 31, 72, 83, 282, 836, 40, 1280, 832], "policy_red_v9_reward": [-1.6169999999999998, 0.14728360500001836, -0.22630676218382195], "policy_red_v4_reward": [1.888296875, 0.3818906250000007, 2.256578125, 0.13399999999999979, 0.6216932378161725], "policy_red_v2_reward": [0.13828360500000325, 0.24984375000000103, -1.1569999999999867, -1.0219999999999998, -0.3380000000000003, -0.8010000000000002, -1.164999999999984], "policy_blue_reward": [-1.0659999999999947, 1.405796875, -2.005, -1.0489999999999982, 1.15246875, -1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475, -2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995, 0.43399999999999994, -1.1269999999999887, -2.0219999999999994, -1.0759999999999947, -1.3859999999999661, -1.1339999999999881, -2.016, 0.39182812499999986, -1.300999999999974, 0.4484375000000004, 0.6647499999999998, -1.0409999999999966, -1.2819999999999736, -2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657], "policy_red_v5_reward": [1.9145625, 1.9013564894425938, -2.0139999999999993, 3.294971105000003, -0.5070000000000005], "policy_red_v1_reward": [-0.16930676218381768, -1.5619999999999972, -1.3619999999999683, -2.012999999999999, -1.2299999999999771, -1.4859999999999594], "policy_red_v7_reward": [-1.5179999999999998, 1.8905468749999998], "policy_red_v6_reward": [2.819406250000001], "policy_red_v11_reward": [0.4526932378161701, 0.20290625000000728], "policy_red_v12_reward": [1.935, 0.17228360500001294], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172, -2.0299999999999994], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625], "policy_red_v10_reward": [-1.5859999999999999, -0.06689696645591336], "policy_red_v3_reward": [-1.2470000000000003, -0.5630653855574075, -1.1259999999999877], "policy_red_v15_reward": [-2.017, 1.7353304800000051], "policy_red_v18_reward": [-0.017306762183829316], "policy_red_v17_reward": [-0.573307457227058]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7937864922676, "mean_inference_ms": 7.715254020493976, "mean_action_processing_ms": 0.28979569436064617, "mean_env_wait_ms": 0.3820913197062095, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10527563095092773, "StateBufferConnector_ms": 0.004342436790466309, "ViewRequirementAgentConnector_ms": 0.12014901638031006}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 360000, "num_agent_steps_trained": 360000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 207.56629982741055, "num_env_steps_trained_throughput_per_sec": 207.56629982741055, "timesteps_total": 180000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 360000, "timers": {"training_iteration_time_ms": 19785.802, "sample_time_ms": 1163.488, "learn_time_ms": 18537.239, "learn_throughput": 215.782, "synch_weights_time_ms": 82.502}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 360000, "num_agent_steps_trained": 360000}, "done": false, "episodes_total": 293, "training_iteration": 45, "trial_id": "a9680_00000", "date": "2023-09-24_02-52-13", "timestamp": 1695538333, "time_this_iter_s": 19.280189037322998, "time_total_s": 894.5470066070557, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34450670>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34419480>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34419510>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 894.5470066070557, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 4.967857142857143, "ram_util_percent": 18.49285714285714}, "win_rate": 0.66, "league_size": 21}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.07800999643902, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.010194615154371907, "policy_loss": -0.0548315876891138, "vf_loss": 0.11922485259516785, "vf_explained_var": 0.6239702628925443, "kl": 0.01777644971798555, "entropy": 2.585625644524892, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 43680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "sampler_results": {"episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.4388286007681972, "episode_len_mean": 449.88, "episode_media": {}, "episodes_this_iter": 13, "policy_reward_min": {"blue": -2.0259999999999985, "red": -8.196306762183793, "red_v7": -1.5179999999999998, "red_v2": -1.164999999999984, "red_v6": 2.819406250000001, "red_v5": -2.0139999999999993, "red_v1": -2.012999999999999, "red_v11": 0.20290625000000728, "red_v12": 0.17228360500001294, "red_v13": -2.0299999999999994, "red_v8": -0.18000000000000016, "red_v4": -1.5439999999999998, "red_v10": -1.5859999999999999, "red_v3": -1.2470000000000003, "red_v15": -2.017, "red_v9": -1.5379999999999998, "red_v18": -0.017306762183829316, "red_v17": -0.573307457227058}, "policy_reward_max": {"blue": 5.327049999999944, "red": 3.9943338628152043, "red_v7": 1.8905468749999998, "red_v2": -0.3380000000000003, "red_v6": 2.819406250000001, "red_v5": 3.294971105000003, "red_v1": -1.2299999999999771, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.904974487816172, "red_v8": 2.233140625, "red_v4": 2.256578125, "red_v10": 0.9186932378161892, "red_v3": -0.5630653855574075, "red_v15": 1.7353304800000051, "red_v9": 0.14728360500001836, "red_v18": -0.017306762183829316, "red_v17": -0.573307457227058}, "policy_reward_mean": {"blue": -0.9093975139999946, "red": 2.0104526857134655, "red_v7": 0.18627343750000003, "red_v2": -0.8965999999999943, "red_v6": 2.819406250000001, "red_v5": -0.1870072237499992, "red_v1": -1.5227499999999758, "red_v11": 0.3277997439080887, "red_v12": 1.0536418025000065, "red_v13": 0.06905920427205785, "red_v8": 0.5809709657040439, "red_v4": 0.3700323975632346, "red_v10": -0.24473457621324135, "red_v3": -0.9786884618524652, "red_v15": -0.1408347599999974, "red_v9": -0.5390077190612678, "red_v18": -0.017306762183829316, "red_v17": -0.573307457227058}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957, 2.201023717816181, 0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093, 2.325370850632347, 2.212599487816182, 1.727386475632418, 1.9764588628161854, 0.4226932378161854, 1.931693237816172, 2.1513182378161813, 0.5966932378161889, 1.9386151128161928, 1.8792401128161726, 0.7786932378162135, 2.749377852258771, 1.437646362815205, 0.7115213628161947, 0.8216932378161718, 1.2100682378162138, 0.9263721144425925, 1.1514432378161823, 2.3144276128161763, 1.1808807378162096, 2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312, 1.3085526128161722, 1.7067432378162177, 2.072386475632441, 1.4493494878161708, 1.6959463628161788, 1.331740112816175, 1.4289901128161726, 1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836], "episode_lengths": [339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85, 145, 1280, 36, 49, 317, 630, 270, 448, 165, 222, 1280, 427, 1280, 64, 312, 1280, 441, 113, 1280, 208, 47, 599, 1280, 968, 52, 336, 181, 964, 727, 31, 72, 83, 282, 836, 40, 1280, 832, 141, 1280, 1280, 46, 415, 145, 65, 49, 72, 1280, 152, 272, 337], "policy_blue_reward": [-1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475, -2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995, 0.43399999999999994, -1.1269999999999887, -2.0219999999999994, -1.0759999999999947, -1.3859999999999661, -1.1339999999999881, -2.016, 0.39182812499999986, -1.300999999999974, 0.4484375000000004, 0.6647499999999998, -1.0409999999999966, -1.2819999999999736, -2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657, -2.0139999999999993, -0.4399499999999984, -1.030999999999999, -2.017999999999999, -2.0119999999999996, -1.0719999999999936, -1.0929999999999929], "policy_red_v7_reward": [-1.5179999999999998, 1.8905468749999998], "policy_red_v2_reward": [-1.1569999999999867, -1.0219999999999998, -0.3380000000000003, -0.8010000000000002, -1.164999999999984], "policy_red_v6_reward": [2.819406250000001], "policy_red_v5_reward": [-2.0139999999999993, 3.294971105000003, -0.5070000000000005, -1.5219999999999998], "policy_red_v1_reward": [-1.3619999999999683, -2.012999999999999, -1.2299999999999771, -1.4859999999999594], "policy_red_v11_reward": [0.4526932378161701, 0.20290625000000728], "policy_red_v12_reward": [1.935, 0.17228360500001294], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172, -2.0299999999999994], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625, 0.41405000000000436, -0.18000000000000016], "policy_red_v4_reward": [0.3818906250000007, 2.256578125, 0.13399999999999979, 0.6216932378161725, -1.5439999999999998], "policy_red_v10_reward": [-1.5859999999999999, -0.06689696645591336, 0.9186932378161892], "policy_red_v3_reward": [-1.2470000000000003, -0.5630653855574075, -1.1259999999999877], "policy_red_v15_reward": [-2.017, 1.7353304800000051], "policy_red_v9_reward": [0.14728360500001836, -0.22630676218382195, -1.5379999999999998], "policy_red_v18_reward": [-0.017306762183829316], "policy_red_v17_reward": [-0.573307457227058]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7958161489204366, "mean_inference_ms": 7.7380126631550725, "mean_action_processing_ms": 0.2907668124238449, "mean_env_wait_ms": 0.3828042890319602, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10541212558746338, "StateBufferConnector_ms": 0.004338860511779785, "ViewRequirementAgentConnector_ms": 0.12012803554534912}}, "episode_reward_max": 3.745464600632351, "episode_reward_min": -2.8692567621837926, "episode_reward_mean": 1.4388286007681972, "episode_len_mean": 449.88, "episodes_this_iter": 13, "policy_reward_min": {"blue": -2.0259999999999985, "red": -8.196306762183793, "red_v7": -1.5179999999999998, "red_v2": -1.164999999999984, "red_v6": 2.819406250000001, "red_v5": -2.0139999999999993, "red_v1": -2.012999999999999, "red_v11": 0.20290625000000728, "red_v12": 0.17228360500001294, "red_v13": -2.0299999999999994, "red_v8": -0.18000000000000016, "red_v4": -1.5439999999999998, "red_v10": -1.5859999999999999, "red_v3": -1.2470000000000003, "red_v15": -2.017, "red_v9": -1.5379999999999998, "red_v18": -0.017306762183829316, "red_v17": -0.573307457227058}, "policy_reward_max": {"blue": 5.327049999999944, "red": 3.9943338628152043, "red_v7": 1.8905468749999998, "red_v2": -0.3380000000000003, "red_v6": 2.819406250000001, "red_v5": 3.294971105000003, "red_v1": -1.2299999999999771, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v13": 1.904974487816172, "red_v8": 2.233140625, "red_v4": 2.256578125, "red_v10": 0.9186932378161892, "red_v3": -0.5630653855574075, "red_v15": 1.7353304800000051, "red_v9": 0.14728360500001836, "red_v18": -0.017306762183829316, "red_v17": -0.573307457227058}, "policy_reward_mean": {"blue": -0.9093975139999946, "red": 2.0104526857134655, "red_v7": 0.18627343750000003, "red_v2": -0.8965999999999943, "red_v6": 2.819406250000001, "red_v5": -0.1870072237499992, "red_v1": -1.5227499999999758, "red_v11": 0.3277997439080887, "red_v12": 1.0536418025000065, "red_v13": 0.06905920427205785, "red_v8": 0.5809709657040439, "red_v4": 0.3700323975632346, "red_v10": -0.24473457621324135, "red_v3": -0.9786884618524652, "red_v15": -0.1408347599999974, "red_v9": -0.5390077190612678, "red_v18": -0.017306762183829316, "red_v17": -0.573307457227058}, "hist_stats": {"episode_reward": [2.0633338628161884, 2.812756250000009, 0.8426689894425938, 0.6176932378161719, 1.9429119878161711, 1.4413494878162036, 2.7930994878161775, -2.8692567621837926, 1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957, 2.201023717816181, 0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093, 2.325370850632347, 2.212599487816182, 1.727386475632418, 1.9764588628161854, 0.4226932378161854, 1.931693237816172, 2.1513182378161813, 0.5966932378161889, 1.9386151128161928, 1.8792401128161726, 0.7786932378162135, 2.749377852258771, 1.437646362815205, 0.7115213628161947, 0.8216932378161718, 1.2100682378162138, 0.9263721144425925, 1.1514432378161823, 2.3144276128161763, 1.1808807378162096, 2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312, 1.3085526128161722, 1.7067432378162177, 2.072386475632441, 1.4493494878161708, 1.6959463628161788, 1.331740112816175, 1.4289901128161726, 1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836], "episode_lengths": [339, 430, 117, 1280, 58, 814, 126, 1280, 59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85, 145, 1280, 36, 49, 317, 630, 270, 448, 165, 222, 1280, 427, 1280, 64, 312, 1280, 441, 113, 1280, 208, 47, 599, 1280, 968, 52, 336, 181, 964, 727, 31, 72, 83, 282, 836, 40, 1280, 832, 141, 1280, 1280, 46, 415, 145, 65, 49, 72, 1280, 152, 272, 337], "policy_blue_reward": [-1.0899999999999928, 3.2607062500000037, -1.352999999999969, 1.9462187499999999, 5.327049999999944, -1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475, -2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995, 0.43399999999999994, -1.1269999999999887, -2.0219999999999994, -1.0759999999999947, -1.3859999999999661, -1.1339999999999881, -2.016, 0.39182812499999986, -1.300999999999974, 0.4484375000000004, 0.6647499999999998, -1.0409999999999966, -1.2819999999999736, -2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657, -2.0139999999999993, -0.4399499999999984, -1.030999999999999, -2.017999999999999, -2.0119999999999996, -1.0719999999999936, -1.0929999999999929], "policy_red_v7_reward": [-1.5179999999999998, 1.8905468749999998], "policy_red_v2_reward": [-1.1569999999999867, -1.0219999999999998, -0.3380000000000003, -0.8010000000000002, -1.164999999999984], "policy_red_v6_reward": [2.819406250000001], "policy_red_v5_reward": [-2.0139999999999993, 3.294971105000003, -0.5070000000000005, -1.5219999999999998], "policy_red_v1_reward": [-1.3619999999999683, -2.012999999999999, -1.2299999999999771, -1.4859999999999594], "policy_red_v11_reward": [0.4526932378161701, 0.20290625000000728], "policy_red_v12_reward": [1.935, 0.17228360500001294], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172, -2.0299999999999994], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625, 0.41405000000000436, -0.18000000000000016], "policy_red_v4_reward": [0.3818906250000007, 2.256578125, 0.13399999999999979, 0.6216932378161725, -1.5439999999999998], "policy_red_v10_reward": [-1.5859999999999999, -0.06689696645591336, 0.9186932378161892], "policy_red_v3_reward": [-1.2470000000000003, -0.5630653855574075, -1.1259999999999877], "policy_red_v15_reward": [-2.017, 1.7353304800000051], "policy_red_v9_reward": [0.14728360500001836, -0.22630676218382195, -1.5379999999999998], "policy_red_v18_reward": [-0.017306762183829316], "policy_red_v17_reward": [-0.573307457227058]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7958161489204366, "mean_inference_ms": 7.7380126631550725, "mean_action_processing_ms": 0.2907668124238449, "mean_env_wait_ms": 0.3828042890319602, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10541212558746338, "StateBufferConnector_ms": 0.004338860511779785, "ViewRequirementAgentConnector_ms": 0.12012803554534912}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 213.0788304557499, "num_env_steps_trained_throughput_per_sec": 213.0788304557499, "timesteps_total": 184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 19668.637, "sample_time_ms": 1161.621, "learn_time_ms": 18422.053, "learn_throughput": 217.131, "synch_weights_time_ms": 82.513}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "episodes_total": 306, "training_iteration": 46, "trial_id": "a9680_00000", "date": "2023-09-24_02-52-33", "timestamp": 1695538353, "time_this_iter_s": 18.783220052719116, "time_total_s": 913.3302266597748, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b346dcd30>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34643760>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34642dd0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 913.3302266597748, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 5.420689655172414, "ram_util_percent": 18.67241379310345}, "win_rate": 0.71, "league_size": 22}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1123468425124883, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.00825600835281269, "policy_loss": -0.06245922326828198, "vf_loss": 0.09610652157959218, "vf_explained_var": 0.5717242155224085, "kl": 0.01940709016388382, "entropy": 2.5832360682388145, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 44640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 376000, "num_agent_steps_trained": 376000}, "sampler_results": {"episode_reward_max": 4.063290112816174, "episode_reward_min": -1.2259999999999773, "episode_reward_mean": 1.4522466294400351, "episode_len_mean": 425.2, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"red_v5": -2.0139999999999993, "red": -1.5229999999999997, "red_v1": -2.012999999999999, "blue": -2.0259999999999985, "red_v11": 0.20290625000000728, "red_v12": 0.17228360500001294, "red_v2": -1.164999999999984, "red_v13": -2.0299999999999994, "red_v8": -0.18000000000000016, "red_v4": -1.5439999999999998, "red_v10": -1.5859999999999999, "red_v3": -1.2470000000000003, "red_v15": -2.017, "red_v9": -1.5379999999999998, "red_v18": -0.017306762183829316, "red_v7": 1.8905468749999998, "red_v17": -0.573307457227058, "red_v16": 0.37189062500000025, "red_v6": -1.52}, "policy_reward_max": {"red_v5": 3.294971105000003, "red": 3.9943338628152043, "red_v1": -1.2299999999999771, "blue": 1.955546875, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v2": -0.3380000000000003, "red_v13": 1.904974487816172, "red_v8": 2.233140625, "red_v4": 2.256578125, "red_v10": 0.9186932378161892, "red_v3": -0.5630653855574075, "red_v15": 1.7353304800000051, "red_v9": 0.3532656249999999, "red_v18": -0.017306762183829316, "red_v7": 1.8905468749999998, "red_v17": -0.573307457227058, "red_v16": 0.37189062500000025, "red_v6": -1.52}, "policy_reward_mean": {"red_v5": -0.1870072237499992, "red": 2.106624339385303, "red_v1": -1.5227499999999758, "blue": -1.1435536205769172, "red_v11": 0.3277997439080887, "red_v12": 1.0536418025000065, "red_v2": -0.8314999999999961, "red_v13": 0.06905920427205785, "red_v8": 0.5809709657040439, "red_v4": 0.7384249268308819, "red_v10": -0.24473457621324135, "red_v3": -0.9786884618524652, "red_v15": -0.1408347599999974, "red_v9": -0.49415150643675665, "red_v18": -0.017306762183829316, "red_v7": 1.8905468749999998, "red_v17": -0.573307457227058, "red_v16": 0.37189062500000025, "red_v6": -1.52}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957, 2.201023717816181, 0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093, 2.325370850632347, 2.212599487816182, 1.727386475632418, 1.9764588628161854, 0.4226932378161854, 1.931693237816172, 2.1513182378161813, 0.5966932378161889, 1.9386151128161928, 1.8792401128161726, 0.7786932378162135, 2.749377852258771, 1.437646362815205, 0.7115213628161947, 0.8216932378161718, 1.2100682378162138, 0.9263721144425925, 1.1514432378161823, 2.3144276128161763, 1.1808807378162096, 2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312, 1.3085526128161722, 1.7067432378162177, 2.072386475632441, 1.4493494878161708, 1.6959463628161788, 1.331740112816175, 1.4289901128161726, 1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836, 0.8046932378162143, 1.9653807378161698, 1.386568237816173, 0.39693750000000017, 4.063290112816174, 0.8139588628161758, 0.6751742300000054, 0.8803564894425933], "episode_lengths": [59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85, 145, 1280, 36, 49, 317, 630, 270, 448, 165, 222, 1280, 427, 1280, 64, 312, 1280, 441, 113, 1280, 208, 47, 599, 1280, 968, 52, 336, 181, 964, 727, 31, 72, 83, 282, 836, 40, 1280, 832, 141, 1280, 1280, 46, 415, 145, 65, 49, 72, 1280, 152, 272, 337, 1280, 36, 104, 84, 113, 139, 131, 89], "policy_red_v5_reward": [-2.0139999999999993, 3.294971105000003, -0.5070000000000005, -1.5219999999999998], "policy_red_v1_reward": [-1.3619999999999683, -2.012999999999999, -1.2299999999999771, -1.4859999999999594], "policy_blue_reward": [-1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475, -2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995, 0.43399999999999994, -1.1269999999999887, -2.0219999999999994, -1.0759999999999947, -1.3859999999999661, -1.1339999999999881, -2.016, 0.39182812499999986, -1.300999999999974, 0.4484375000000004, 0.6647499999999998, -1.0409999999999966, -1.2819999999999736, -2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657, -2.0139999999999993, -0.4399499999999984, -1.030999999999999, -2.017999999999999, -2.0119999999999996, -1.0719999999999936, -1.0929999999999929, -2.01, 0.6530500000000008], "policy_red_v11_reward": [0.4526932378161701, 0.20290625000000728], "policy_red_v12_reward": [1.935, 0.17228360500001294], "policy_red_v2_reward": [-1.0219999999999998, -0.3380000000000003, -0.8010000000000002, -1.164999999999984], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172, -2.0299999999999994], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625, 0.41405000000000436, -0.18000000000000016], "policy_red_v4_reward": [0.3818906250000007, 2.256578125, 0.13399999999999979, 0.6216932378161725, -1.5439999999999998, 1.3988749999999999, 1.9199375], "policy_red_v10_reward": [-1.5859999999999999, -0.06689696645591336, 0.9186932378161892], "policy_red_v3_reward": [-1.2470000000000003, -0.5630653855574075, -1.1259999999999877], "policy_red_v15_reward": [-2.017, 1.7353304800000051], "policy_red_v9_reward": [0.14728360500001836, -0.22630676218382195, -1.5379999999999998, -1.2069999999999796, 0.3532656249999999], "policy_red_v18_reward": [-0.017306762183829316], "policy_red_v7_reward": [1.8905468749999998], "policy_red_v17_reward": [-0.573307457227058], "policy_red_v16_reward": [0.37189062500000025], "policy_red_v6_reward": [-1.52]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7964327722622869, "mean_inference_ms": 7.733945542695259, "mean_action_processing_ms": 0.2908274187274824, "mean_env_wait_ms": 0.3828556265012395, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1063683032989502, "StateBufferConnector_ms": 0.004361271858215332, "ViewRequirementAgentConnector_ms": 0.12118875980377197}}, "episode_reward_max": 4.063290112816174, "episode_reward_min": -1.2259999999999773, "episode_reward_mean": 1.4522466294400351, "episode_len_mean": 425.2, "episodes_this_iter": 8, "policy_reward_min": {"red_v5": -2.0139999999999993, "red": -1.5229999999999997, "red_v1": -2.012999999999999, "blue": -2.0259999999999985, "red_v11": 0.20290625000000728, "red_v12": 0.17228360500001294, "red_v2": -1.164999999999984, "red_v13": -2.0299999999999994, "red_v8": -0.18000000000000016, "red_v4": -1.5439999999999998, "red_v10": -1.5859999999999999, "red_v3": -1.2470000000000003, "red_v15": -2.017, "red_v9": -1.5379999999999998, "red_v18": -0.017306762183829316, "red_v7": 1.8905468749999998, "red_v17": -0.573307457227058, "red_v16": 0.37189062500000025, "red_v6": -1.52}, "policy_reward_max": {"red_v5": 3.294971105000003, "red": 3.9943338628152043, "red_v1": -1.2299999999999771, "blue": 1.955546875, "red_v11": 0.4526932378161701, "red_v12": 1.935, "red_v2": -0.3380000000000003, "red_v13": 1.904974487816172, "red_v8": 2.233140625, "red_v4": 2.256578125, "red_v10": 0.9186932378161892, "red_v3": -0.5630653855574075, "red_v15": 1.7353304800000051, "red_v9": 0.3532656249999999, "red_v18": -0.017306762183829316, "red_v7": 1.8905468749999998, "red_v17": -0.573307457227058, "red_v16": 0.37189062500000025, "red_v6": -1.52}, "policy_reward_mean": {"red_v5": -0.1870072237499992, "red": 2.106624339385303, "red_v1": -1.5227499999999758, "blue": -1.1435536205769172, "red_v11": 0.3277997439080887, "red_v12": 1.0536418025000065, "red_v2": -0.8314999999999961, "red_v13": 0.06905920427205785, "red_v8": 0.5809709657040439, "red_v4": 0.7384249268308819, "red_v10": -0.24473457621324135, "red_v3": -0.9786884618524652, "red_v15": -0.1408347599999974, "red_v9": -0.49415150643675665, "red_v18": -0.017306762183829316, "red_v7": 1.8905468749999998, "red_v17": -0.573307457227058, "red_v16": 0.37189062500000025, "red_v6": -1.52}, "hist_stats": {"episode_reward": [1.4452088628161712, 0.779302612816214, 0.35628125000000654, 0.588693237816216, 3.745464600632351, 1.4236151128161918, 1.9306932378161719, 1.3960057378161739, 1.9406151128161708, 1.3968252394425944, -0.30851562499999996, 0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957, 2.201023717816181, 0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093, 2.325370850632347, 2.212599487816182, 1.727386475632418, 1.9764588628161854, 0.4226932378161854, 1.931693237816172, 2.1513182378161813, 0.5966932378161889, 1.9386151128161928, 1.8792401128161726, 0.7786932378162135, 2.749377852258771, 1.437646362815205, 0.7115213628161947, 0.8216932378161718, 1.2100682378162138, 0.9263721144425925, 1.1514432378161823, 2.3144276128161763, 1.1808807378162096, 2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312, 1.3085526128161722, 1.7067432378162177, 2.072386475632441, 1.4493494878161708, 1.6959463628161788, 1.331740112816175, 1.4289901128161726, 1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836, 0.8046932378162143, 1.9653807378161698, 1.386568237816173, 0.39693750000000017, 4.063290112816174, 0.8139588628161758, 0.6751742300000054, 0.8803564894425933], "episode_lengths": [59, 1181, 422, 1280, 199, 761, 64, 92, 57, 67, 197, 159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85, 145, 1280, 36, 49, 317, 630, 270, 448, 165, 222, 1280, 427, 1280, 64, 312, 1280, 441, 113, 1280, 208, 47, 599, 1280, 968, 52, 336, 181, 964, 727, 31, 72, 83, 282, 836, 40, 1280, 832, 141, 1280, 1280, 46, 415, 145, 65, 49, 72, 1280, 152, 272, 337, 1280, 36, 104, 84, 113, 139, 131, 89], "policy_red_v5_reward": [-2.0139999999999993, 3.294971105000003, -0.5070000000000005, -1.5219999999999998], "policy_red_v1_reward": [-1.3619999999999683, -2.012999999999999, -1.2299999999999771, -1.4859999999999594], "policy_blue_reward": [-1.116, -1.3629999999999665, -1.21799999999998, -2.0259999999999985, -2.016999999999999, -1.562, -2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475, -2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995, 0.43399999999999994, -1.1269999999999887, -2.0219999999999994, -1.0759999999999947, -1.3859999999999661, -1.1339999999999881, -2.016, 0.39182812499999986, -1.300999999999974, 0.4484375000000004, 0.6647499999999998, -1.0409999999999966, -1.2819999999999736, -2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657, -2.0139999999999993, -0.4399499999999984, -1.030999999999999, -2.017999999999999, -2.0119999999999996, -1.0719999999999936, -1.0929999999999929, -2.01, 0.6530500000000008], "policy_red_v11_reward": [0.4526932378161701, 0.20290625000000728], "policy_red_v12_reward": [1.935, 0.17228360500001294], "policy_red_v2_reward": [-1.0219999999999998, -0.3380000000000003, -0.8010000000000002, -1.164999999999984], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172, -2.0299999999999994], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625, 0.41405000000000436, -0.18000000000000016], "policy_red_v4_reward": [0.3818906250000007, 2.256578125, 0.13399999999999979, 0.6216932378161725, -1.5439999999999998, 1.3988749999999999, 1.9199375], "policy_red_v10_reward": [-1.5859999999999999, -0.06689696645591336, 0.9186932378161892], "policy_red_v3_reward": [-1.2470000000000003, -0.5630653855574075, -1.1259999999999877], "policy_red_v15_reward": [-2.017, 1.7353304800000051], "policy_red_v9_reward": [0.14728360500001836, -0.22630676218382195, -1.5379999999999998, -1.2069999999999796, 0.3532656249999999], "policy_red_v18_reward": [-0.017306762183829316], "policy_red_v7_reward": [1.8905468749999998], "policy_red_v17_reward": [-0.573307457227058], "policy_red_v16_reward": [0.37189062500000025], "policy_red_v6_reward": [-1.52]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7964327722622869, "mean_inference_ms": 7.733945542695259, "mean_action_processing_ms": 0.2908274187274824, "mean_env_wait_ms": 0.3828556265012395, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1063683032989502, "StateBufferConnector_ms": 0.004361271858215332, "ViewRequirementAgentConnector_ms": 0.12118875980377197}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 376000, "num_agent_steps_trained": 376000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.02445519939096, "num_env_steps_trained_throughput_per_sec": 200.02445519939096, "timesteps_total": 188000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 376000, "timers": {"training_iteration_time_ms": 19691.004, "sample_time_ms": 1160.706, "learn_time_ms": 18445.161, "learn_throughput": 216.859, "synch_weights_time_ms": 82.781}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 376000, "num_agent_steps_trained": 376000}, "done": false, "episodes_total": 314, "training_iteration": 47, "trial_id": "a9680_00000", "date": "2023-09-24_02-52-55", "timestamp": 1695538375, "time_this_iter_s": 20.00683832168579, "time_total_s": 933.3370649814606, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34572bf0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b347a6560>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b347a7eb0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 933.3370649814606, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 5.2266666666666675, "ram_util_percent": 18.786666666666665}, "win_rate": 0.7, "league_size": 23}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0801350792249043, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.021645031949932066, "policy_loss": -0.06034642621137512, "vf_loss": 0.0666929079083881, "vf_explained_var": 0.7270100088169177, "kl": 0.01748469670300589, "entropy": 2.513172578563293, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 45600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "sampler_results": {"episode_reward_max": 4.063290112816174, "episode_reward_min": -1.2259999999999773, "episode_reward_mean": 1.4473057609796625, "episode_len_mean": 428.02, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {"red_v13": -2.0299999999999994, "red": -5.069307457227051, "blue": -2.022999999999999, "red_v8": -0.18000000000000016, "red_v4": -1.5439999999999998, "red_v10": -1.5859999999999999, "red_v1": -2.012999999999999, "red_v3": -1.2470000000000003, "red_v2": -1.164999999999984, "red_v15": -2.017, "red_v5": -1.5219999999999998, "red_v11": 0.20290625000000728, "red_v9": -1.5379999999999998, "red_v12": 0.17228360500001294, "red_v18": -0.017306762183829316, "red_v7": -1.7189999999999472, "red_v17": -0.573307457227058, "red_v16": 0.37189062500000025, "red_v6": -1.52, "red_v19": -2.034999999999999}, "policy_reward_max": {"red_v13": 1.904974487816172, "red": 3.9943338628152043, "blue": 4.292203125000004, "red_v8": 2.233140625, "red_v4": 2.256578125, "red_v10": 0.9186932378161892, "red_v1": -1.2299999999999771, "red_v3": 0.19439062500000281, "red_v2": -0.3380000000000003, "red_v15": 1.7353304800000051, "red_v5": 3.294971105000003, "red_v11": 1.2271906250000004, "red_v9": 0.3532656249999999, "red_v12": 0.17228360500001294, "red_v18": -0.017306762183829316, "red_v7": 1.8905468749999998, "red_v17": -0.573307457227058, "red_v16": 0.37189062500000025, "red_v6": 2.644375000000002, "red_v19": -2.034999999999999}, "policy_reward_mean": {"red_v13": 0.06905920427205785, "red": 1.9581231271749298, "blue": -0.9717459978571378, "red_v8": 0.5809709657040439, "red_v4": 0.7384249268308819, "red_v10": -0.06837762270588849, "red_v1": -1.5763333333333118, "red_v3": -0.6854186901393482, "red_v2": -0.7679999999999948, "red_v15": -0.1408347599999974, "red_v5": 0.42199036833333414, "red_v11": 0.7150484375000039, "red_v9": -0.49415150643675665, "red_v12": 0.17228360500001294, "red_v18": -0.017306762183829316, "red_v7": 0.0857734375000263, "red_v17": -0.573307457227058, "red_v16": 0.37189062500000025, "red_v6": 0.21205468750000517, "red_v19": -2.034999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957, 2.201023717816181, 0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093, 2.325370850632347, 2.212599487816182, 1.727386475632418, 1.9764588628161854, 0.4226932378161854, 1.931693237816172, 2.1513182378161813, 0.5966932378161889, 1.9386151128161928, 1.8792401128161726, 0.7786932378162135, 2.749377852258771, 1.437646362815205, 0.7115213628161947, 0.8216932378161718, 1.2100682378162138, 0.9263721144425925, 1.1514432378161823, 2.3144276128161763, 1.1808807378162096, 2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312, 1.3085526128161722, 1.7067432378162177, 2.072386475632441, 1.4493494878161708, 1.6959463628161788, 1.331740112816175, 1.4289901128161726, 1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836, 0.8046932378162143, 1.9653807378161698, 1.386568237816173, 0.39693750000000017, 4.063290112816174, 0.8139588628161758, 0.6751742300000054, 0.8803564894425933, 2.6000682378161866, 0.37969323781620246, 1.690883862816193, 0.5620838628161788, 0.7007244878161765, 3.865792725632345, -0.7771043322270501, 1.0912401128162172, 0.7085369878161885, 1.9676776128161704, 1.4105057378161714], "episode_lengths": [159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85, 145, 1280, 36, 49, 317, 630, 270, 448, 165, 222, 1280, 427, 1280, 64, 312, 1280, 441, 113, 1280, 208, 47, 599, 1280, 968, 52, 336, 181, 964, 727, 31, 72, 83, 282, 836, 40, 1280, 832, 141, 1280, 1280, 46, 415, 145, 65, 49, 72, 1280, 152, 272, 337, 1280, 36, 104, 84, 113, 139, 131, 89, 264, 1280, 371, 355, 246, 126, 223, 1137, 562, 37, 60], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172, -2.0299999999999994], "policy_blue_reward": [-2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475, -2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995, 0.43399999999999994, -1.1269999999999887, -2.0219999999999994, -1.0759999999999947, -1.3859999999999661, -1.1339999999999881, -2.016, 0.39182812499999986, -1.300999999999974, 0.4484375000000004, 0.6647499999999998, -1.0409999999999966, -1.2819999999999736, -2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657, -2.0139999999999993, -0.4399499999999984, -1.030999999999999, -2.017999999999999, -2.0119999999999996, -1.0719999999999936, -1.0929999999999929, -2.01, 0.6530500000000008, 0.26603125000000016, 4.292203125000004, -2.0109999999999997], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625, 0.41405000000000436, -0.18000000000000016], "policy_red_v4_reward": [0.3818906250000007, 2.256578125, 0.13399999999999979, 0.6216932378161725, -1.5439999999999998, 1.3988749999999999, 1.9199375], "policy_red_v10_reward": [-1.5859999999999999, -0.06689696645591336, 0.9186932378161892, 0.4606932378161701], "policy_red_v1_reward": [-2.012999999999999, -1.2299999999999771, -1.4859999999999594], "policy_red_v3_reward": [-1.2470000000000003, -0.5630653855574075, -1.1259999999999877, 0.19439062500000281], "policy_red_v2_reward": [-0.3380000000000003, -0.8010000000000002, -1.164999999999984], "policy_red_v15_reward": [-2.017, 1.7353304800000051], "policy_red_v5_reward": [3.294971105000003, -0.5070000000000005, -1.5219999999999998], "policy_red_v11_reward": [0.20290625000000728, 1.2271906250000004], "policy_red_v9_reward": [0.14728360500001836, -0.22630676218382195, -1.5379999999999998, -1.2069999999999796, 0.3532656249999999], "policy_red_v12_reward": [0.17228360500001294], "policy_red_v18_reward": [-0.017306762183829316], "policy_red_v7_reward": [1.8905468749999998, -1.7189999999999472], "policy_red_v17_reward": [-0.573307457227058], "policy_red_v16_reward": [0.37189062500000025], "policy_red_v6_reward": [-1.52, 2.644375000000002, -1.194999999999981, 0.9188437499999997], "policy_red_v19_reward": [-2.034999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7975031521972565, "mean_inference_ms": 7.742378304171023, "mean_action_processing_ms": 0.2913852594983467, "mean_env_wait_ms": 0.3833481852309365, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10560166835784912, "StateBufferConnector_ms": 0.00434112548828125, "ViewRequirementAgentConnector_ms": 0.12061905860900879}}, "episode_reward_max": 4.063290112816174, "episode_reward_min": -1.2259999999999773, "episode_reward_mean": 1.4473057609796625, "episode_len_mean": 428.02, "episodes_this_iter": 11, "policy_reward_min": {"red_v13": -2.0299999999999994, "red": -5.069307457227051, "blue": -2.022999999999999, "red_v8": -0.18000000000000016, "red_v4": -1.5439999999999998, "red_v10": -1.5859999999999999, "red_v1": -2.012999999999999, "red_v3": -1.2470000000000003, "red_v2": -1.164999999999984, "red_v15": -2.017, "red_v5": -1.5219999999999998, "red_v11": 0.20290625000000728, "red_v9": -1.5379999999999998, "red_v12": 0.17228360500001294, "red_v18": -0.017306762183829316, "red_v7": -1.7189999999999472, "red_v17": -0.573307457227058, "red_v16": 0.37189062500000025, "red_v6": -1.52, "red_v19": -2.034999999999999}, "policy_reward_max": {"red_v13": 1.904974487816172, "red": 3.9943338628152043, "blue": 4.292203125000004, "red_v8": 2.233140625, "red_v4": 2.256578125, "red_v10": 0.9186932378161892, "red_v1": -1.2299999999999771, "red_v3": 0.19439062500000281, "red_v2": -0.3380000000000003, "red_v15": 1.7353304800000051, "red_v5": 3.294971105000003, "red_v11": 1.2271906250000004, "red_v9": 0.3532656249999999, "red_v12": 0.17228360500001294, "red_v18": -0.017306762183829316, "red_v7": 1.8905468749999998, "red_v17": -0.573307457227058, "red_v16": 0.37189062500000025, "red_v6": 2.644375000000002, "red_v19": -2.034999999999999}, "policy_reward_mean": {"red_v13": 0.06905920427205785, "red": 1.9581231271749298, "blue": -0.9717459978571378, "red_v8": 0.5809709657040439, "red_v4": 0.7384249268308819, "red_v10": -0.06837762270588849, "red_v1": -1.5763333333333118, "red_v3": -0.6854186901393482, "red_v2": -0.7679999999999948, "red_v15": -0.1408347599999974, "red_v5": 0.42199036833333414, "red_v11": 0.7150484375000039, "red_v9": -0.49415150643675665, "red_v12": 0.17228360500001294, "red_v18": -0.017306762183829316, "red_v7": 0.0857734375000263, "red_v17": -0.573307457227058, "red_v16": 0.37189062500000025, "red_v6": 0.21205468750000517, "red_v19": -2.034999999999999}, "hist_stats": {"episode_reward": [0.12820312500000064, 1.555024487816174, 1.930668989442594, 2.9136989756323732, 1.4258830928162034, 0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957, 2.201023717816181, 0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093, 2.325370850632347, 2.212599487816182, 1.727386475632418, 1.9764588628161854, 0.4226932378161854, 1.931693237816172, 2.1513182378161813, 0.5966932378161889, 1.9386151128161928, 1.8792401128161726, 0.7786932378162135, 2.749377852258771, 1.437646362815205, 0.7115213628161947, 0.8216932378161718, 1.2100682378162138, 0.9263721144425925, 1.1514432378161823, 2.3144276128161763, 1.1808807378162096, 2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312, 1.3085526128161722, 1.7067432378162177, 2.072386475632441, 1.4493494878161708, 1.6959463628161788, 1.331740112816175, 1.4289901128161726, 1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836, 0.8046932378162143, 1.9653807378161698, 1.386568237816173, 0.39693750000000017, 4.063290112816174, 0.8139588628161758, 0.6751742300000054, 0.8803564894425933, 2.6000682378161866, 0.37969323781620246, 1.690883862816193, 0.5620838628161788, 0.7007244878161765, 3.865792725632345, -0.7771043322270501, 1.0912401128162172, 0.7085369878161885, 1.9676776128161704, 1.4105057378161714], "episode_lengths": [159, 102, 53, 412, 862, 131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85, 145, 1280, 36, 49, 317, 630, 270, 448, 165, 222, 1280, 427, 1280, 64, 312, 1280, 441, 113, 1280, 208, 47, 599, 1280, 968, 52, 336, 181, 964, 727, 31, 72, 83, 282, 836, 40, 1280, 832, 141, 1280, 1280, 46, 415, 145, 65, 49, 72, 1280, 152, 272, 337, 1280, 36, 104, 84, 113, 139, 131, 89, 264, 1280, 371, 355, 246, 126, 223, 1137, 562, 37, 60], "policy_red_v13_reward": [0.3322031250000006, 1.904974487816172, -2.0299999999999994], "policy_blue_reward": [-2.012999999999999, -0.33171639499999916, -1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475, -2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995, 0.43399999999999994, -1.1269999999999887, -2.0219999999999994, -1.0759999999999947, -1.3859999999999661, -1.1339999999999881, -2.016, 0.39182812499999986, -1.300999999999974, 0.4484375000000004, 0.6647499999999998, -1.0409999999999966, -1.2819999999999736, -2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657, -2.0139999999999993, -0.4399499999999984, -1.030999999999999, -2.017999999999999, -2.0119999999999996, -1.0719999999999936, -1.0929999999999929, -2.01, 0.6530500000000008, 0.26603125000000016, 4.292203125000004, -2.0109999999999997], "policy_red_v8_reward": [-0.14330676218382843, 2.233140625, 0.41405000000000436, -0.18000000000000016], "policy_red_v4_reward": [0.3818906250000007, 2.256578125, 0.13399999999999979, 0.6216932378161725, -1.5439999999999998, 1.3988749999999999, 1.9199375], "policy_red_v10_reward": [-1.5859999999999999, -0.06689696645591336, 0.9186932378161892, 0.4606932378161701], "policy_red_v1_reward": [-2.012999999999999, -1.2299999999999771, -1.4859999999999594], "policy_red_v3_reward": [-1.2470000000000003, -0.5630653855574075, -1.1259999999999877, 0.19439062500000281], "policy_red_v2_reward": [-0.3380000000000003, -0.8010000000000002, -1.164999999999984], "policy_red_v15_reward": [-2.017, 1.7353304800000051], "policy_red_v5_reward": [3.294971105000003, -0.5070000000000005, -1.5219999999999998], "policy_red_v11_reward": [0.20290625000000728, 1.2271906250000004], "policy_red_v9_reward": [0.14728360500001836, -0.22630676218382195, -1.5379999999999998, -1.2069999999999796, 0.3532656249999999], "policy_red_v12_reward": [0.17228360500001294], "policy_red_v18_reward": [-0.017306762183829316], "policy_red_v7_reward": [1.8905468749999998, -1.7189999999999472], "policy_red_v17_reward": [-0.573307457227058], "policy_red_v16_reward": [0.37189062500000025], "policy_red_v6_reward": [-1.52, 2.644375000000002, -1.194999999999981, 0.9188437499999997], "policy_red_v19_reward": [-2.034999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7975031521972565, "mean_inference_ms": 7.742378304171023, "mean_action_processing_ms": 0.2913852594983467, "mean_env_wait_ms": 0.3833481852309365, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10560166835784912, "StateBufferConnector_ms": 0.00434112548828125, "ViewRequirementAgentConnector_ms": 0.12061905860900879}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.7889477874422, "num_env_steps_trained_throughput_per_sec": 201.7889477874422, "timesteps_total": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 19673.299, "sample_time_ms": 1157.182, "learn_time_ms": 18430.903, "learn_throughput": 217.027, "synch_weights_time_ms": 82.86}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "episodes_total": 325, "training_iteration": 48, "trial_id": "a9680_00000", "date": "2023-09-24_02-53-16", "timestamp": 1695538396, "time_this_iter_s": 19.831945657730103, "time_total_s": 953.1690106391907, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b343c46a0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3459f910>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3459f880>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 953.1690106391907, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 5.022580645161292, "ram_util_percent": 18.9741935483871}, "win_rate": 0.65, "league_size": 23}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0341533878197273, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03564870596504382, "policy_loss": -0.06163147447659867, "vf_loss": 0.04073430366891747, "vf_explained_var": 0.4184958143780629, "kl": 0.018335980111503097, "entropy": 2.635574210683505, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 46560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 392000, "num_agent_steps_trained": 392000}, "sampler_results": {"episode_reward_max": 4.063290112816174, "episode_reward_min": -1.2259999999999773, "episode_reward_mean": 1.4837682247915602, "episode_len_mean": 431.93, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"red_v4": -1.5439999999999998, "red": -5.069307457227051, "red_v10": -1.5859999999999999, "blue": -2.022999999999999, "red_v1": -2.012999999999999, "red_v3": -1.2470000000000003, "red_v2": -1.164999999999984, "red_v8": -0.18000000000000016, "red_v13": -2.0299999999999994, "red_v15": -2.017, "red_v5": -1.5219999999999998, "red_v11": 0.20290625000000728, "red_v9": -1.5379999999999998, "red_v12": 0.17228360500001294, "red_v18": -0.017306762183829316, "red_v7": -1.7189999999999472, "red_v17": -1.0859999999999952, "red_v16": 0.37189062500000025, "red_v6": -1.52, "red_v19": -2.034999999999999}, "policy_reward_max": {"red_v4": 2.256578125, "red": 3.9943338628152043, "red_v10": 0.9186932378161892, "blue": 4.292203125000004, "red_v1": -1.2299999999999771, "red_v3": 0.19439062500000281, "red_v2": -0.3380000000000003, "red_v8": 2.233140625, "red_v13": -2.0299999999999994, "red_v15": 1.7353304800000051, "red_v5": 3.294971105000003, "red_v11": 1.2271906250000004, "red_v9": 0.3532656249999999, "red_v12": 0.17228360500001294, "red_v18": -0.017306762183829316, "red_v7": 1.8905468749999998, "red_v17": -0.573307457227058, "red_v16": 0.37189062500000025, "red_v6": 2.644375000000002, "red_v19": -2.034999999999999}, "policy_reward_mean": {"red_v4": 0.7384249268308819, "red": 1.9986239219149888, "red_v10": -0.06837762270588849, "blue": -0.9748507812499948, "red_v1": -1.5763333333333118, "red_v3": -0.6854186901393482, "red_v2": -0.7679999999999948, "red_v8": 1.0133654969540444, "red_v13": -2.0299999999999994, "red_v15": -0.1408347599999974, "red_v5": 0.42199036833333414, "red_v11": 0.7150484375000039, "red_v9": -0.49415150643675665, "red_v12": 0.17228360500001294, "red_v18": -0.017306762183829316, "red_v7": 0.016865625000018803, "red_v17": -0.8296537286135266, "red_v16": 0.37189062500000025, "red_v6": 0.2672437500000041, "red_v19": -2.034999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957, 2.201023717816181, 0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093, 2.325370850632347, 2.212599487816182, 1.727386475632418, 1.9764588628161854, 0.4226932378161854, 1.931693237816172, 2.1513182378161813, 0.5966932378161889, 1.9386151128161928, 1.8792401128161726, 0.7786932378162135, 2.749377852258771, 1.437646362815205, 0.7115213628161947, 0.8216932378161718, 1.2100682378162138, 0.9263721144425925, 1.1514432378161823, 2.3144276128161763, 1.1808807378162096, 2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312, 1.3085526128161722, 1.7067432378162177, 2.072386475632441, 1.4493494878161708, 1.6959463628161788, 1.331740112816175, 1.4289901128161726, 1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836, 0.8046932378162143, 1.9653807378161698, 1.386568237816173, 0.39693750000000017, 4.063290112816174, 0.8139588628161758, 0.6751742300000054, 0.8803564894425933, 2.6000682378161866, 0.37969323781620246, 1.690883862816193, 0.5620838628161788, 0.7007244878161765, 3.865792725632345, -0.7771043322270501, 1.0912401128162172, 0.7085369878161885, 1.9676776128161704, 1.4105057378161714, 1.8867432378162499, 2.27966198781618, 2.078964600632354, 1.9036307378161736, 3.450724487816171], "episode_lengths": [131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85, 145, 1280, 36, 49, 317, 630, 270, 448, 165, 222, 1280, 427, 1280, 64, 312, 1280, 441, 113, 1280, 208, 47, 599, 1280, 968, 52, 336, 181, 964, 727, 31, 72, 83, 282, 836, 40, 1280, 832, 141, 1280, 1280, 46, 415, 145, 65, 49, 72, 1280, 152, 272, 337, 1280, 36, 104, 84, 113, 139, 131, 89, 264, 1280, 371, 355, 246, 126, 223, 1137, 562, 37, 60, 1280, 138, 423, 84, 54], "policy_red_v4_reward": [0.3818906250000007, 2.256578125, 0.13399999999999979, 0.6216932378161725, -1.5439999999999998, 1.3988749999999999, 1.9199375], "policy_red_v10_reward": [-1.5859999999999999, -0.06689696645591336, 0.9186932378161892, 0.4606932378161701], "policy_blue_reward": [-1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475, -2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995, 0.43399999999999994, -1.1269999999999887, -2.0219999999999994, -1.0759999999999947, -1.3859999999999661, -1.1339999999999881, -2.016, 0.39182812499999986, -1.300999999999974, 0.4484375000000004, 0.6647499999999998, -1.0409999999999966, -1.2819999999999736, -2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657, -2.0139999999999993, -0.4399499999999984, -1.030999999999999, -2.017999999999999, -2.0119999999999996, -1.0719999999999936, -1.0929999999999929, -2.01, 0.6530500000000008, 0.26603125000000016, 4.292203125000004, -2.0109999999999997, -1.5219999999999998], "policy_red_v1_reward": [-2.012999999999999, -1.2299999999999771, -1.4859999999999594], "policy_red_v3_reward": [-1.2470000000000003, -0.5630653855574075, -1.1259999999999877, 0.19439062500000281], "policy_red_v2_reward": [-0.3380000000000003, -0.8010000000000002, -1.164999999999984], "policy_red_v8_reward": [2.233140625, 0.41405000000000436, -0.18000000000000016, 1.586271362816173], "policy_red_v13_reward": [-2.0299999999999994], "policy_red_v15_reward": [-2.017, 1.7353304800000051], "policy_red_v5_reward": [3.294971105000003, -0.5070000000000005, -1.5219999999999998], "policy_red_v11_reward": [0.20290625000000728, 1.2271906250000004], "policy_red_v9_reward": [0.14728360500001836, -0.22630676218382195, -1.5379999999999998, -1.2069999999999796, 0.3532656249999999], "policy_red_v12_reward": [0.17228360500001294], "policy_red_v18_reward": [-0.017306762183829316], "policy_red_v7_reward": [1.8905468749999998, -1.7189999999999472, -0.1209499999999962], "policy_red_v17_reward": [-0.573307457227058, -1.0859999999999952], "policy_red_v16_reward": [0.37189062500000025], "policy_red_v6_reward": [-1.52, 2.644375000000002, -1.194999999999981, 0.9188437499999997, 0.488], "policy_red_v19_reward": [-2.034999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7980967436945177, "mean_inference_ms": 7.749852328338342, "mean_action_processing_ms": 0.29187006326741793, "mean_env_wait_ms": 0.38405818753997517, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10501468181610107, "StateBufferConnector_ms": 0.004332184791564941, "ViewRequirementAgentConnector_ms": 0.12026786804199219}}, "episode_reward_max": 4.063290112816174, "episode_reward_min": -1.2259999999999773, "episode_reward_mean": 1.4837682247915602, "episode_len_mean": 431.93, "episodes_this_iter": 5, "policy_reward_min": {"red_v4": -1.5439999999999998, "red": -5.069307457227051, "red_v10": -1.5859999999999999, "blue": -2.022999999999999, "red_v1": -2.012999999999999, "red_v3": -1.2470000000000003, "red_v2": -1.164999999999984, "red_v8": -0.18000000000000016, "red_v13": -2.0299999999999994, "red_v15": -2.017, "red_v5": -1.5219999999999998, "red_v11": 0.20290625000000728, "red_v9": -1.5379999999999998, "red_v12": 0.17228360500001294, "red_v18": -0.017306762183829316, "red_v7": -1.7189999999999472, "red_v17": -1.0859999999999952, "red_v16": 0.37189062500000025, "red_v6": -1.52, "red_v19": -2.034999999999999}, "policy_reward_max": {"red_v4": 2.256578125, "red": 3.9943338628152043, "red_v10": 0.9186932378161892, "blue": 4.292203125000004, "red_v1": -1.2299999999999771, "red_v3": 0.19439062500000281, "red_v2": -0.3380000000000003, "red_v8": 2.233140625, "red_v13": -2.0299999999999994, "red_v15": 1.7353304800000051, "red_v5": 3.294971105000003, "red_v11": 1.2271906250000004, "red_v9": 0.3532656249999999, "red_v12": 0.17228360500001294, "red_v18": -0.017306762183829316, "red_v7": 1.8905468749999998, "red_v17": -0.573307457227058, "red_v16": 0.37189062500000025, "red_v6": 2.644375000000002, "red_v19": -2.034999999999999}, "policy_reward_mean": {"red_v4": 0.7384249268308819, "red": 1.9986239219149888, "red_v10": -0.06837762270588849, "blue": -0.9748507812499948, "red_v1": -1.5763333333333118, "red_v3": -0.6854186901393482, "red_v2": -0.7679999999999948, "red_v8": 1.0133654969540444, "red_v13": -2.0299999999999994, "red_v15": -0.1408347599999974, "red_v5": 0.42199036833333414, "red_v11": 0.7150484375000039, "red_v9": -0.49415150643675665, "red_v12": 0.17228360500001294, "red_v18": -0.017306762183829316, "red_v7": 0.016865625000018803, "red_v17": -0.8296537286135266, "red_v16": 0.37189062500000025, "red_v6": 0.2672437500000041, "red_v19": -2.034999999999999}, "hist_stats": {"episode_reward": [0.8605838628161728, 0.7868807378161771, 0.8553651128161716, 0.8621093750000002, 2.215271362816181, 1.8937088628161711, 1.9542401128161702, 1.3705179800000002, 1.4658721144425924, 0.8404119878161829, -1.2259999999999773, 1.1046932378162344, 1.710833862816172, 1.0736932378162487, 0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957, 2.201023717816181, 0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093, 2.325370850632347, 2.212599487816182, 1.727386475632418, 1.9764588628161854, 0.4226932378161854, 1.931693237816172, 2.1513182378161813, 0.5966932378161889, 1.9386151128161928, 1.8792401128161726, 0.7786932378162135, 2.749377852258771, 1.437646362815205, 0.7115213628161947, 0.8216932378161718, 1.2100682378162138, 0.9263721144425925, 1.1514432378161823, 2.3144276128161763, 1.1808807378162096, 2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312, 1.3085526128161722, 1.7067432378162177, 2.072386475632441, 1.4493494878161708, 1.6959463628161788, 1.331740112816175, 1.4289901128161726, 1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836, 0.8046932378162143, 1.9653807378161698, 1.386568237816173, 0.39693750000000017, 4.063290112816174, 0.8139588628161758, 0.6751742300000054, 0.8803564894425933, 2.6000682378161866, 0.37969323781620246, 1.690883862816193, 0.5620838628161788, 0.7007244878161765, 3.865792725632345, -0.7771043322270501, 1.0912401128162172, 0.7085369878161885, 1.9676776128161704, 1.4105057378161714, 1.8867432378162499, 2.27966198781618, 2.078964600632354, 1.9036307378161736, 3.450724487816171], "episode_lengths": [131, 132, 137, 61, 167, 91, 49, 21, 20, 474, 1280, 1280, 179, 1280, 1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85, 145, 1280, 36, 49, 317, 630, 270, 448, 165, 222, 1280, 427, 1280, 64, 312, 1280, 441, 113, 1280, 208, 47, 599, 1280, 968, 52, 336, 181, 964, 727, 31, 72, 83, 282, 836, 40, 1280, 832, 141, 1280, 1280, 46, 415, 145, 65, 49, 72, 1280, 152, 272, 337, 1280, 36, 104, 84, 113, 139, 131, 89, 264, 1280, 371, 355, 246, 126, 223, 1137, 562, 37, 60, 1280, 138, 423, 84, 54], "policy_red_v4_reward": [0.3818906250000007, 2.256578125, 0.13399999999999979, 0.6216932378161725, -1.5439999999999998, 1.3988749999999999, 1.9199375], "policy_red_v10_reward": [-1.5859999999999999, -0.06689696645591336, 0.9186932378161892, 0.4606932378161701], "policy_blue_reward": [-1.5349999999999997, -2.022999999999999, 1.955546875, -2.004, -2.0060000000000002, -0.8790000000000002, -1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475, -2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995, 0.43399999999999994, -1.1269999999999887, -2.0219999999999994, -1.0759999999999947, -1.3859999999999661, -1.1339999999999881, -2.016, 0.39182812499999986, -1.300999999999974, 0.4484375000000004, 0.6647499999999998, -1.0409999999999966, -1.2819999999999736, -2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657, -2.0139999999999993, -0.4399499999999984, -1.030999999999999, -2.017999999999999, -2.0119999999999996, -1.0719999999999936, -1.0929999999999929, -2.01, 0.6530500000000008, 0.26603125000000016, 4.292203125000004, -2.0109999999999997, -1.5219999999999998], "policy_red_v1_reward": [-2.012999999999999, -1.2299999999999771, -1.4859999999999594], "policy_red_v3_reward": [-1.2470000000000003, -0.5630653855574075, -1.1259999999999877, 0.19439062500000281], "policy_red_v2_reward": [-0.3380000000000003, -0.8010000000000002, -1.164999999999984], "policy_red_v8_reward": [2.233140625, 0.41405000000000436, -0.18000000000000016, 1.586271362816173], "policy_red_v13_reward": [-2.0299999999999994], "policy_red_v15_reward": [-2.017, 1.7353304800000051], "policy_red_v5_reward": [3.294971105000003, -0.5070000000000005, -1.5219999999999998], "policy_red_v11_reward": [0.20290625000000728, 1.2271906250000004], "policy_red_v9_reward": [0.14728360500001836, -0.22630676218382195, -1.5379999999999998, -1.2069999999999796, 0.3532656249999999], "policy_red_v12_reward": [0.17228360500001294], "policy_red_v18_reward": [-0.017306762183829316], "policy_red_v7_reward": [1.8905468749999998, -1.7189999999999472, -0.1209499999999962], "policy_red_v17_reward": [-0.573307457227058, -1.0859999999999952], "policy_red_v16_reward": [0.37189062500000025], "policy_red_v6_reward": [-1.52, 2.644375000000002, -1.194999999999981, 0.9188437499999997, 0.488], "policy_red_v19_reward": [-2.034999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7980967436945177, "mean_inference_ms": 7.749852328338342, "mean_action_processing_ms": 0.29187006326741793, "mean_env_wait_ms": 0.38405818753997517, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10501468181610107, "StateBufferConnector_ms": 0.004332184791564941, "ViewRequirementAgentConnector_ms": 0.12026786804199219}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 392000, "num_agent_steps_trained": 392000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 198.73838700803822, "num_env_steps_trained_throughput_per_sec": 198.73838700803822, "timesteps_total": 196000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 392000, "timers": {"training_iteration_time_ms": 19712.596, "sample_time_ms": 1167.696, "learn_time_ms": 18458.944, "learn_throughput": 216.697, "synch_weights_time_ms": 83.582}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 392000, "num_agent_steps_trained": 392000}, "done": false, "episodes_total": 330, "training_iteration": 49, "trial_id": "a9680_00000", "date": "2023-09-24_02-53-37", "timestamp": 1695538417, "time_this_iter_s": 20.13685941696167, "time_total_s": 973.3058700561523, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34572620>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3459f6d0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3459e050>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 973.3058700561523, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 4.86896551724138, "ram_util_percent": 18.99310344827586}, "win_rate": 0.65, "league_size": 23}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.079207125181953, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.004671591975056799, "policy_loss": -0.05779179387706487, "vf_loss": 0.11489861841546371, "vf_explained_var": 0.6174109211191535, "kl": 0.016778750497149962, "entropy": 2.536360317468643, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 47520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "sampler_results": {"episode_reward_max": 4.063290112816174, "episode_reward_min": -0.7771043322270501, "episode_reward_mean": 1.5279900268828823, "episode_len_mean": 443.21, "episode_media": {}, "episodes_this_iter": 14, "policy_reward_min": {"red_v1": -1.4859999999999594, "red": -5.069307457227051, "red_v13": -2.0299999999999994, "red_v15": -2.017, "red_v5": -1.5219999999999998, "blue": -2.0219999999999994, "red_v11": 0.20290625000000728, "red_v4": -1.5439999999999998, "red_v2": -1.525, "red_v9": -1.5379999999999998, "red_v12": 0.17228360500001294, "red_v18": -0.017306762183829316, "red_v7": -1.7189999999999472, "red_v3": -1.1259999999999877, "red_v17": -1.0859999999999952, "red_v10": -0.06689696645591336, "red_v8": -0.18000000000000016, "red_v16": -1.5439999999999996, "red_v6": -1.52, "red_v19": -2.034999999999999}, "policy_reward_max": {"red_v1": -1.2099999999999822, "red": 3.9943338628152043, "red_v13": 1.5267401128161695, "red_v15": 1.7353304800000051, "red_v5": 3.294971105000003, "blue": 4.292203125000004, "red_v11": 1.2271906250000004, "red_v4": 1.9199375, "red_v2": -1.164999999999984, "red_v9": 0.3532656249999999, "red_v12": 1.3792436585440782, "red_v18": -0.017306762183829316, "red_v7": 1.8905468749999998, "red_v3": 0.19439062500000281, "red_v17": 0.5520500000000093, "red_v10": 0.9186932378161892, "red_v8": 1.586271362816173, "red_v16": 0.37189062500000025, "red_v6": 2.644375000000002, "red_v19": -2.034999999999999}, "policy_reward_mean": {"red_v1": -1.3086666666666396, "red": 2.011317261292709, "red_v13": -0.25162994359191493, "red_v15": -0.1408347599999974, "red_v5": 0.42199036833333414, "blue": -0.8786483124999943, "red_v11": 0.7150484375000039, "red_v4": 0.5061011475632344, "red_v2": -1.344999999999992, "red_v9": -0.49415150643675665, "red_v12": 0.7757636317720455, "red_v18": -0.017306762183829316, "red_v7": 0.016865625000018803, "red_v3": -0.4982249201857975, "red_v17": -0.36908581907568133, "red_v10": 0.4374965030588153, "red_v8": 0.6067737876053925, "red_v16": -0.5860546874999997, "red_v6": 0.2672437500000041, "red_v19": -2.034999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957, 2.201023717816181, 0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093, 2.325370850632347, 2.212599487816182, 1.727386475632418, 1.9764588628161854, 0.4226932378161854, 1.931693237816172, 2.1513182378161813, 0.5966932378161889, 1.9386151128161928, 1.8792401128161726, 0.7786932378162135, 2.749377852258771, 1.437646362815205, 0.7115213628161947, 0.8216932378161718, 1.2100682378162138, 0.9263721144425925, 1.1514432378161823, 2.3144276128161763, 1.1808807378162096, 2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312, 1.3085526128161722, 1.7067432378162177, 2.072386475632441, 1.4493494878161708, 1.6959463628161788, 1.331740112816175, 1.4289901128161726, 1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836, 0.8046932378162143, 1.9653807378161698, 1.386568237816173, 0.39693750000000017, 4.063290112816174, 0.8139588628161758, 0.6751742300000054, 0.8803564894425933, 2.6000682378161866, 0.37969323781620246, 1.690883862816193, 0.5620838628161788, 0.7007244878161765, 3.865792725632345, -0.7771043322270501, 1.0912401128162172, 0.7085369878161885, 1.9676776128161704, 1.4105057378161714, 1.8867432378162499, 2.27966198781618, 2.078964600632354, 1.9036307378161736, 3.450724487816171, 0.673693237816217, 1.3260987927729422, 0.8926932378162121, 2.4650596144425925, 0.05651875000000128, 1.9874333506323607, 0.5652557378161749, 0.8865369878162115, 2.732633862816192, 0.7338182378161768, 1.7449368963602745, 1.3313437499999998, 2.310708862816176, 2.4836307378152043], "episode_lengths": [1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85, 145, 1280, 36, 49, 317, 630, 270, 448, 165, 222, 1280, 427, 1280, 64, 312, 1280, 441, 113, 1280, 208, 47, 599, 1280, 968, 52, 336, 181, 964, 727, 31, 72, 83, 282, 836, 40, 1280, 832, 141, 1280, 1280, 46, 415, 145, 65, 49, 72, 1280, 152, 272, 337, 1280, 36, 104, 84, 113, 139, 131, 89, 264, 1280, 371, 355, 246, 126, 223, 1137, 562, 37, 60, 1280, 138, 423, 84, 54, 1280, 190, 1280, 24, 106, 465, 396, 818, 323, 216, 1139, 18, 155, 20], "policy_red_v1_reward": [-1.2299999999999771, -1.4859999999999594, -1.2099999999999822], "policy_red_v13_reward": [-2.0299999999999994, 1.5267401128161695], "policy_red_v15_reward": [-2.017, 1.7353304800000051], "policy_red_v5_reward": [3.294971105000003, -0.5070000000000005, -1.5219999999999998], "policy_blue_reward": [-1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475, -2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995, 0.43399999999999994, -1.1269999999999887, -2.0219999999999994, -1.0759999999999947, -1.3859999999999661, -1.1339999999999881, -2.016, 0.39182812499999986, -1.300999999999974, 0.4484375000000004, 0.6647499999999998, -1.0409999999999966, -1.2819999999999736, -2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657, -2.0139999999999993, -0.4399499999999984, -1.030999999999999, -2.017999999999999, -2.0119999999999996, -1.0719999999999936, -1.0929999999999929, -2.01, 0.6530500000000008, 0.26603125000000016, 4.292203125000004, -2.0109999999999997, -1.5219999999999998, -1.3639999999999668, -1.0049999999999997, 0.971, 1.5438437500000035, 0.29112499999999997, -2.006, -1.055999999999996, -1.0059999999999996], "policy_red_v11_reward": [0.20290625000000728, 1.2271906250000004], "policy_red_v4_reward": [0.13399999999999979, 0.6216932378161725, -1.5439999999999998, 1.3988749999999999, 1.9199375], "policy_red_v2_reward": [-1.164999999999984, -1.525], "policy_red_v9_reward": [0.14728360500001836, -0.22630676218382195, -1.5379999999999998, -1.2069999999999796, 0.3532656249999999], "policy_red_v12_reward": [0.17228360500001294, 1.3792436585440782], "policy_red_v18_reward": [-0.017306762183829316], "policy_red_v7_reward": [1.8905468749999998, -1.7189999999999472, -0.1209499999999962], "policy_red_v3_reward": [-0.5630653855574075, -1.1259999999999877, 0.19439062500000281], "policy_red_v17_reward": [-0.573307457227058, -1.0859999999999952, 0.5520500000000093], "policy_red_v10_reward": [-0.06689696645591336, 0.9186932378161892, 0.4606932378161701], "policy_red_v8_reward": [0.41405000000000436, -0.18000000000000016, 1.586271362816173], "policy_red_v16_reward": [0.37189062500000025, -1.5439999999999996], "policy_red_v6_reward": [-1.52, 2.644375000000002, -1.194999999999981, 0.9188437499999997, 0.488], "policy_red_v19_reward": [-2.034999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7997016195084423, "mean_inference_ms": 7.772250454931111, "mean_action_processing_ms": 0.2927877372119258, "mean_env_wait_ms": 0.3851578412068918, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10606932640075684, "StateBufferConnector_ms": 0.004382729530334473, "ViewRequirementAgentConnector_ms": 0.12150037288665771}}, "episode_reward_max": 4.063290112816174, "episode_reward_min": -0.7771043322270501, "episode_reward_mean": 1.5279900268828823, "episode_len_mean": 443.21, "episodes_this_iter": 14, "policy_reward_min": {"red_v1": -1.4859999999999594, "red": -5.069307457227051, "red_v13": -2.0299999999999994, "red_v15": -2.017, "red_v5": -1.5219999999999998, "blue": -2.0219999999999994, "red_v11": 0.20290625000000728, "red_v4": -1.5439999999999998, "red_v2": -1.525, "red_v9": -1.5379999999999998, "red_v12": 0.17228360500001294, "red_v18": -0.017306762183829316, "red_v7": -1.7189999999999472, "red_v3": -1.1259999999999877, "red_v17": -1.0859999999999952, "red_v10": -0.06689696645591336, "red_v8": -0.18000000000000016, "red_v16": -1.5439999999999996, "red_v6": -1.52, "red_v19": -2.034999999999999}, "policy_reward_max": {"red_v1": -1.2099999999999822, "red": 3.9943338628152043, "red_v13": 1.5267401128161695, "red_v15": 1.7353304800000051, "red_v5": 3.294971105000003, "blue": 4.292203125000004, "red_v11": 1.2271906250000004, "red_v4": 1.9199375, "red_v2": -1.164999999999984, "red_v9": 0.3532656249999999, "red_v12": 1.3792436585440782, "red_v18": -0.017306762183829316, "red_v7": 1.8905468749999998, "red_v3": 0.19439062500000281, "red_v17": 0.5520500000000093, "red_v10": 0.9186932378161892, "red_v8": 1.586271362816173, "red_v16": 0.37189062500000025, "red_v6": 2.644375000000002, "red_v19": -2.034999999999999}, "policy_reward_mean": {"red_v1": -1.3086666666666396, "red": 2.011317261292709, "red_v13": -0.25162994359191493, "red_v15": -0.1408347599999974, "red_v5": 0.42199036833333414, "blue": -0.8786483124999943, "red_v11": 0.7150484375000039, "red_v4": 0.5061011475632344, "red_v2": -1.344999999999992, "red_v9": -0.49415150643675665, "red_v12": 0.7757636317720455, "red_v18": -0.017306762183829316, "red_v7": 0.016865625000018803, "red_v3": -0.4982249201857975, "red_v17": -0.36908581907568133, "red_v10": 0.4374965030588153, "red_v8": 0.6067737876053925, "red_v16": -0.5860546874999997, "red_v6": 0.2672437500000041, "red_v19": -2.034999999999999}, "hist_stats": {"episode_reward": [0.7846932378162125, 1.4446811585440562, 1.4515717835440565, 2.7866643428161737, 0.5766932378162013, 0.543009283544075, 1.8677054800000001, 1.5768468750000137, 1.9843338628152043, 1.9768963628161698, 0.19669323781621662, 3.3641689894425957, 2.201023717816181, 0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093, 2.325370850632347, 2.212599487816182, 1.727386475632418, 1.9764588628161854, 0.4226932378161854, 1.931693237816172, 2.1513182378161813, 0.5966932378161889, 1.9386151128161928, 1.8792401128161726, 0.7786932378162135, 2.749377852258771, 1.437646362815205, 0.7115213628161947, 0.8216932378161718, 1.2100682378162138, 0.9263721144425925, 1.1514432378161823, 2.3144276128161763, 1.1808807378162096, 2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312, 1.3085526128161722, 1.7067432378162177, 2.072386475632441, 1.4493494878161708, 1.6959463628161788, 1.331740112816175, 1.4289901128161726, 1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836, 0.8046932378162143, 1.9653807378161698, 1.386568237816173, 0.39693750000000017, 4.063290112816174, 0.8139588628161758, 0.6751742300000054, 0.8803564894425933, 2.6000682378161866, 0.37969323781620246, 1.690883862816193, 0.5620838628161788, 0.7007244878161765, 3.865792725632345, -0.7771043322270501, 1.0912401128162172, 0.7085369878161885, 1.9676776128161704, 1.4105057378161714, 1.8867432378162499, 2.27966198781618, 2.078964600632354, 1.9036307378161736, 3.450724487816171, 0.673693237816217, 1.3260987927729422, 0.8926932378162121, 2.4650596144425925, 0.05651875000000128, 1.9874333506323607, 0.5652557378161749, 0.8865369878162115, 2.732633862816192, 0.7338182378161768, 1.7449368963602745, 1.3313437499999998, 2.310708862816176, 2.4836307378152043], "episode_lengths": [1280, 39, 42, 100, 1280, 286, 25, 417, 19, 31, 1280, 85, 145, 1280, 36, 49, 317, 630, 270, 448, 165, 222, 1280, 427, 1280, 64, 312, 1280, 441, 113, 1280, 208, 47, 599, 1280, 968, 52, 336, 181, 964, 727, 31, 72, 83, 282, 836, 40, 1280, 832, 141, 1280, 1280, 46, 415, 145, 65, 49, 72, 1280, 152, 272, 337, 1280, 36, 104, 84, 113, 139, 131, 89, 264, 1280, 371, 355, 246, 126, 223, 1137, 562, 37, 60, 1280, 138, 423, 84, 54, 1280, 190, 1280, 24, 106, 465, 396, 818, 323, 216, 1139, 18, 155, 20], "policy_red_v1_reward": [-1.2299999999999771, -1.4859999999999594, -1.2099999999999822], "policy_red_v13_reward": [-2.0299999999999994, 1.5267401128161695], "policy_red_v15_reward": [-2.017, 1.7353304800000051], "policy_red_v5_reward": [3.294971105000003, -0.5070000000000005, -1.5219999999999998], "policy_blue_reward": [-1.3709999999999645, -2.01, -1.1189999999999902, -2.01, -2.0039999999999996, 0.475, -2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995, 0.43399999999999994, -1.1269999999999887, -2.0219999999999994, -1.0759999999999947, -1.3859999999999661, -1.1339999999999881, -2.016, 0.39182812499999986, -1.300999999999974, 0.4484375000000004, 0.6647499999999998, -1.0409999999999966, -1.2819999999999736, -2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657, -2.0139999999999993, -0.4399499999999984, -1.030999999999999, -2.017999999999999, -2.0119999999999996, -1.0719999999999936, -1.0929999999999929, -2.01, 0.6530500000000008, 0.26603125000000016, 4.292203125000004, -2.0109999999999997, -1.5219999999999998, -1.3639999999999668, -1.0049999999999997, 0.971, 1.5438437500000035, 0.29112499999999997, -2.006, -1.055999999999996, -1.0059999999999996], "policy_red_v11_reward": [0.20290625000000728, 1.2271906250000004], "policy_red_v4_reward": [0.13399999999999979, 0.6216932378161725, -1.5439999999999998, 1.3988749999999999, 1.9199375], "policy_red_v2_reward": [-1.164999999999984, -1.525], "policy_red_v9_reward": [0.14728360500001836, -0.22630676218382195, -1.5379999999999998, -1.2069999999999796, 0.3532656249999999], "policy_red_v12_reward": [0.17228360500001294, 1.3792436585440782], "policy_red_v18_reward": [-0.017306762183829316], "policy_red_v7_reward": [1.8905468749999998, -1.7189999999999472, -0.1209499999999962], "policy_red_v3_reward": [-0.5630653855574075, -1.1259999999999877, 0.19439062500000281], "policy_red_v17_reward": [-0.573307457227058, -1.0859999999999952, 0.5520500000000093], "policy_red_v10_reward": [-0.06689696645591336, 0.9186932378161892, 0.4606932378161701], "policy_red_v8_reward": [0.41405000000000436, -0.18000000000000016, 1.586271362816173], "policy_red_v16_reward": [0.37189062500000025, -1.5439999999999996], "policy_red_v6_reward": [-1.52, 2.644375000000002, -1.194999999999981, 0.9188437499999997, 0.488], "policy_red_v19_reward": [-2.034999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7997016195084423, "mean_inference_ms": 7.772250454931111, "mean_action_processing_ms": 0.2927877372119258, "mean_env_wait_ms": 0.3851578412068918, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10606932640075684, "StateBufferConnector_ms": 0.004382729530334473, "ViewRequirementAgentConnector_ms": 0.12150037288665771}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 203.7483283306721, "num_env_steps_trained_throughput_per_sec": 203.7483283306721, "timesteps_total": 200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 19686.87, "sample_time_ms": 1164.999, "learn_time_ms": 18435.768, "learn_throughput": 216.97, "synch_weights_time_ms": 83.815}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "episodes_total": 344, "training_iteration": 50, "trial_id": "a9680_00000", "date": "2023-09-24_02-53-56", "timestamp": 1695538436, "time_this_iter_s": 19.642462015151978, "time_total_s": 992.9483320713043, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b344522f0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b344195a0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b344196c0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 992.9483320713043, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 5.096428571428572, "ram_util_percent": 18.99285714285714}, "win_rate": 0.63, "league_size": 23}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1216341412315765, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.018973092596327963, "policy_loss": -0.056440251297317445, "vf_loss": 0.0643169057283861, "vf_explained_var": 0.6740445489063859, "kl": 0.017321355950715163, "entropy": 2.4859042309224604, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 48480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 408000, "num_agent_steps_trained": 408000}, "sampler_results": {"episode_reward_max": 4.063290112816174, "episode_reward_min": -0.7771043322270501, "episode_reward_mean": 1.517182459644792, "episode_len_mean": 439.75, "episode_media": {}, "episodes_this_iter": 13, "policy_reward_min": {"red_v2": -1.525, "red": -5.069307457227051, "blue": -2.0219999999999994, "red_v9": -1.5379999999999998, "red_v12": 0.17228360500001294, "red_v18": -0.017306762183829316, "red_v4": -1.5439999999999998, "red_v1": -1.4859999999999594, "red_v7": -1.7189999999999472, "red_v5": -1.5219999999999998, "red_v3": -1.1259999999999877, "red_v17": -1.0859999999999952, "red_v10": -0.06689696645591336, "red_v8": -1.172999999999985, "red_v16": -1.5439999999999996, "red_v6": -1.52, "red_v11": 1.2271906250000004, "red_v19": -2.034999999999999, "red_v13": 1.5267401128161695, "red_v20": -0.28600000000000014}, "policy_reward_max": {"red_v2": 1.94121875, "red": 3.97867761281617, "blue": 4.292203125000004, "red_v9": 0.3532656249999999, "red_v12": 1.3792436585440782, "red_v18": 0.3076932378161894, "red_v4": 1.9199375, "red_v1": -1.2099999999999822, "red_v7": 1.8905468749999998, "red_v5": -0.5070000000000005, "red_v3": 0.19439062500000281, "red_v17": 0.5520500000000093, "red_v10": 0.9186932378161892, "red_v8": 1.586271362816173, "red_v16": 0.37189062500000025, "red_v6": 2.644375000000002, "red_v11": 1.2271906250000004, "red_v19": -2.034999999999999, "red_v13": 1.5267401128161695, "red_v20": -0.28600000000000014}, "policy_reward_mean": {"red_v2": -0.24959374999999465, "red": 2.0257759337764565, "blue": -0.8976483124999944, "red_v9": -0.49415150643675665, "red_v12": 0.7757636317720455, "red_v18": 0.14519323781618004, "red_v4": 0.5991264344540431, "red_v1": -1.3479999999999708, "red_v7": 0.11706718750001413, "red_v5": -1.0145000000000002, "red_v3": -0.4982249201857975, "red_v17": -0.36908581907568133, "red_v10": 0.4374965030588153, "red_v8": 0.16183034070404811, "red_v16": -0.898703124999999, "red_v6": 0.027703125000005862, "red_v11": 1.2271906250000004, "red_v19": -2.034999999999999, "red_v13": 1.5267401128161695, "red_v20": -0.28600000000000014}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093, 2.325370850632347, 2.212599487816182, 1.727386475632418, 1.9764588628161854, 0.4226932378161854, 1.931693237816172, 2.1513182378161813, 0.5966932378161889, 1.9386151128161928, 1.8792401128161726, 0.7786932378162135, 2.749377852258771, 1.437646362815205, 0.7115213628161947, 0.8216932378161718, 1.2100682378162138, 0.9263721144425925, 1.1514432378161823, 2.3144276128161763, 1.1808807378162096, 2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312, 1.3085526128161722, 1.7067432378162177, 2.072386475632441, 1.4493494878161708, 1.6959463628161788, 1.331740112816175, 1.4289901128161726, 1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836, 0.8046932378162143, 1.9653807378161698, 1.386568237816173, 0.39693750000000017, 4.063290112816174, 0.8139588628161758, 0.6751742300000054, 0.8803564894425933, 2.6000682378161866, 0.37969323781620246, 1.690883862816193, 0.5620838628161788, 0.7007244878161765, 3.865792725632345, -0.7771043322270501, 1.0912401128162172, 0.7085369878161885, 1.9676776128161704, 1.4105057378161714, 1.8867432378162499, 2.27966198781618, 2.078964600632354, 1.9036307378161736, 3.450724487816171, 0.673693237816217, 1.3260987927729422, 0.8926932378162121, 2.4650596144425925, 0.05651875000000128, 1.9874333506323607, 0.5652557378161749, 0.8865369878162115, 2.732633862816192, 0.7338182378161768, 1.7449368963602745, 1.3313437499999998, 2.310708862816176, 2.4836307378152043, 0.923474487816173, 2.721615112816205, 0.9555213628162148, 0.8540781250000001, 1.1628000000000003, 1.087802612816183, 0.9173651128161726, 1.8757557378161749, 2.851339600632374, 1.713005737816201, 0.8226932378162157, 1.9612713628161713, 1.8275023550000014], "episode_lengths": [1280, 36, 49, 317, 630, 270, 448, 165, 222, 1280, 427, 1280, 64, 312, 1280, 441, 113, 1280, 208, 47, 599, 1280, 968, 52, 336, 181, 964, 727, 31, 72, 83, 282, 836, 40, 1280, 832, 141, 1280, 1280, 46, 415, 145, 65, 49, 72, 1280, 152, 272, 337, 1280, 36, 104, 84, 113, 139, 131, 89, 264, 1280, 371, 355, 246, 126, 223, 1137, 562, 37, 60, 1280, 138, 423, 84, 54, 1280, 190, 1280, 24, 106, 465, 396, 818, 323, 216, 1139, 18, 155, 20, 70, 441, 1175, 71, 16, 253, 73, 108, 495, 604, 1280, 39, 58], "policy_red_v2_reward": [-1.164999999999984, -1.525, 1.94121875], "policy_blue_reward": [-2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995, 0.43399999999999994, -1.1269999999999887, -2.0219999999999994, -1.0759999999999947, -1.3859999999999661, -1.1339999999999881, -2.016, 0.39182812499999986, -1.300999999999974, 0.4484375000000004, 0.6647499999999998, -1.0409999999999966, -1.2819999999999736, -2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657, -2.0139999999999993, -0.4399499999999984, -1.030999999999999, -2.017999999999999, -2.0119999999999996, -1.0719999999999936, -1.0929999999999929, -2.01, 0.6530500000000008, 0.26603125000000016, 4.292203125000004, -2.0109999999999997, -1.5219999999999998, -1.3639999999999668, -1.0049999999999997, 0.971, 1.5438437500000035, 0.29112499999999997, -2.006, -1.055999999999996, -1.0059999999999996, -1.3109999999999704, -0.52, -2.005, -1.113999999999999, -2.0219999999999985, -2.0169999999999995], "policy_red_v9_reward": [0.14728360500001836, -0.22630676218382195, -1.5379999999999998, -1.2069999999999796, 0.3532656249999999], "policy_red_v12_reward": [0.17228360500001294, 1.3792436585440782], "policy_red_v18_reward": [-0.017306762183829316, 0.3076932378161894], "policy_red_v4_reward": [0.6216932378161725, -1.5439999999999998, 1.3988749999999999, 1.9199375], "policy_red_v1_reward": [-1.4859999999999594, -1.2099999999999822], "policy_red_v7_reward": [1.8905468749999998, -1.7189999999999472, -0.1209499999999962, 0.41767187500000014], "policy_red_v5_reward": [-0.5070000000000005, -1.5219999999999998], "policy_red_v3_reward": [-0.5630653855574075, -1.1259999999999877, 0.19439062500000281], "policy_red_v17_reward": [-0.573307457227058, -1.0859999999999952, 0.5520500000000093], "policy_red_v10_reward": [-0.06689696645591336, 0.9186932378161892, 0.4606932378161701], "policy_red_v8_reward": [0.41405000000000436, -0.18000000000000016, 1.586271362816173, -1.172999999999985], "policy_red_v16_reward": [0.37189062500000025, -1.5439999999999996, -1.5239999999999978], "policy_red_v6_reward": [-1.52, 2.644375000000002, -1.194999999999981, 0.9188437499999997, 0.488, -1.1699999999999855], "policy_red_v11_reward": [1.2271906250000004], "policy_red_v19_reward": [-2.034999999999999], "policy_red_v13_reward": [1.5267401128161695], "policy_red_v20_reward": [-0.28600000000000014]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8010433330308036, "mean_inference_ms": 7.787791924778281, "mean_action_processing_ms": 0.29309488101692394, "mean_env_wait_ms": 0.3857231303191043, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10653722286224365, "StateBufferConnector_ms": 0.00441741943359375, "ViewRequirementAgentConnector_ms": 0.12239682674407959}}, "episode_reward_max": 4.063290112816174, "episode_reward_min": -0.7771043322270501, "episode_reward_mean": 1.517182459644792, "episode_len_mean": 439.75, "episodes_this_iter": 13, "policy_reward_min": {"red_v2": -1.525, "red": -5.069307457227051, "blue": -2.0219999999999994, "red_v9": -1.5379999999999998, "red_v12": 0.17228360500001294, "red_v18": -0.017306762183829316, "red_v4": -1.5439999999999998, "red_v1": -1.4859999999999594, "red_v7": -1.7189999999999472, "red_v5": -1.5219999999999998, "red_v3": -1.1259999999999877, "red_v17": -1.0859999999999952, "red_v10": -0.06689696645591336, "red_v8": -1.172999999999985, "red_v16": -1.5439999999999996, "red_v6": -1.52, "red_v11": 1.2271906250000004, "red_v19": -2.034999999999999, "red_v13": 1.5267401128161695, "red_v20": -0.28600000000000014}, "policy_reward_max": {"red_v2": 1.94121875, "red": 3.97867761281617, "blue": 4.292203125000004, "red_v9": 0.3532656249999999, "red_v12": 1.3792436585440782, "red_v18": 0.3076932378161894, "red_v4": 1.9199375, "red_v1": -1.2099999999999822, "red_v7": 1.8905468749999998, "red_v5": -0.5070000000000005, "red_v3": 0.19439062500000281, "red_v17": 0.5520500000000093, "red_v10": 0.9186932378161892, "red_v8": 1.586271362816173, "red_v16": 0.37189062500000025, "red_v6": 2.644375000000002, "red_v11": 1.2271906250000004, "red_v19": -2.034999999999999, "red_v13": 1.5267401128161695, "red_v20": -0.28600000000000014}, "policy_reward_mean": {"red_v2": -0.24959374999999465, "red": 2.0257759337764565, "blue": -0.8976483124999944, "red_v9": -0.49415150643675665, "red_v12": 0.7757636317720455, "red_v18": 0.14519323781618004, "red_v4": 0.5991264344540431, "red_v1": -1.3479999999999708, "red_v7": 0.11706718750001413, "red_v5": -1.0145000000000002, "red_v3": -0.4982249201857975, "red_v17": -0.36908581907568133, "red_v10": 0.4374965030588153, "red_v8": 0.16183034070404811, "red_v16": -0.898703124999999, "red_v6": 0.027703125000005862, "red_v11": 1.2271906250000004, "red_v19": -2.034999999999999, "red_v13": 1.5267401128161695, "red_v20": -0.28600000000000014}, "hist_stats": {"episode_reward": [0.8316932378161899, 1.4657905335440553, 0.4502394177729424, 0.6188026128152071, 1.4120080928162255, 0.6838494878161785, 2.2109768428162093, 2.325370850632347, 2.212599487816182, 1.727386475632418, 1.9764588628161854, 0.4226932378161854, 1.931693237816172, 2.1513182378161813, 0.5966932378161889, 1.9386151128161928, 1.8792401128161726, 0.7786932378162135, 2.749377852258771, 1.437646362815205, 0.7115213628161947, 0.8216932378161718, 1.2100682378162138, 0.9263721144425925, 1.1514432378161823, 2.3144276128161763, 1.1808807378162096, 2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312, 1.3085526128161722, 1.7067432378162177, 2.072386475632441, 1.4493494878161708, 1.6959463628161788, 1.331740112816175, 1.4289901128161726, 1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836, 0.8046932378162143, 1.9653807378161698, 1.386568237816173, 0.39693750000000017, 4.063290112816174, 0.8139588628161758, 0.6751742300000054, 0.8803564894425933, 2.6000682378161866, 0.37969323781620246, 1.690883862816193, 0.5620838628161788, 0.7007244878161765, 3.865792725632345, -0.7771043322270501, 1.0912401128162172, 0.7085369878161885, 1.9676776128161704, 1.4105057378161714, 1.8867432378162499, 2.27966198781618, 2.078964600632354, 1.9036307378161736, 3.450724487816171, 0.673693237816217, 1.3260987927729422, 0.8926932378162121, 2.4650596144425925, 0.05651875000000128, 1.9874333506323607, 0.5652557378161749, 0.8865369878162115, 2.732633862816192, 0.7338182378161768, 1.7449368963602745, 1.3313437499999998, 2.310708862816176, 2.4836307378152043, 0.923474487816173, 2.721615112816205, 0.9555213628162148, 0.8540781250000001, 1.1628000000000003, 1.087802612816183, 0.9173651128161726, 1.8757557378161749, 2.851339600632374, 1.713005737816201, 0.8226932378162157, 1.9612713628161713, 1.8275023550000014], "episode_lengths": [1280, 36, 49, 317, 630, 270, 448, 165, 222, 1280, 427, 1280, 64, 312, 1280, 441, 113, 1280, 208, 47, 599, 1280, 968, 52, 336, 181, 964, 727, 31, 72, 83, 282, 836, 40, 1280, 832, 141, 1280, 1280, 46, 415, 145, 65, 49, 72, 1280, 152, 272, 337, 1280, 36, 104, 84, 113, 139, 131, 89, 264, 1280, 371, 355, 246, 126, 223, 1137, 562, 37, 60, 1280, 138, 423, 84, 54, 1280, 190, 1280, 24, 106, 465, 396, 818, 323, 216, 1139, 18, 155, 20, 70, 441, 1175, 71, 16, 253, 73, 108, 495, 604, 1280, 39, 58], "policy_red_v2_reward": [-1.164999999999984, -1.525, 1.94121875], "policy_blue_reward": [-2.008, -1.5079999999999998, 0.1801093749999999, 0.22715624999999995, 0.43399999999999994, -1.1269999999999887, -2.0219999999999994, -1.0759999999999947, -1.3859999999999661, -1.1339999999999881, -2.016, 0.39182812499999986, -1.300999999999974, 0.4484375000000004, 0.6647499999999998, -1.0409999999999966, -1.2819999999999736, -2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657, -2.0139999999999993, -0.4399499999999984, -1.030999999999999, -2.017999999999999, -2.0119999999999996, -1.0719999999999936, -1.0929999999999929, -2.01, 0.6530500000000008, 0.26603125000000016, 4.292203125000004, -2.0109999999999997, -1.5219999999999998, -1.3639999999999668, -1.0049999999999997, 0.971, 1.5438437500000035, 0.29112499999999997, -2.006, -1.055999999999996, -1.0059999999999996, -1.3109999999999704, -0.52, -2.005, -1.113999999999999, -2.0219999999999985, -2.0169999999999995], "policy_red_v9_reward": [0.14728360500001836, -0.22630676218382195, -1.5379999999999998, -1.2069999999999796, 0.3532656249999999], "policy_red_v12_reward": [0.17228360500001294, 1.3792436585440782], "policy_red_v18_reward": [-0.017306762183829316, 0.3076932378161894], "policy_red_v4_reward": [0.6216932378161725, -1.5439999999999998, 1.3988749999999999, 1.9199375], "policy_red_v1_reward": [-1.4859999999999594, -1.2099999999999822], "policy_red_v7_reward": [1.8905468749999998, -1.7189999999999472, -0.1209499999999962, 0.41767187500000014], "policy_red_v5_reward": [-0.5070000000000005, -1.5219999999999998], "policy_red_v3_reward": [-0.5630653855574075, -1.1259999999999877, 0.19439062500000281], "policy_red_v17_reward": [-0.573307457227058, -1.0859999999999952, 0.5520500000000093], "policy_red_v10_reward": [-0.06689696645591336, 0.9186932378161892, 0.4606932378161701], "policy_red_v8_reward": [0.41405000000000436, -0.18000000000000016, 1.586271362816173, -1.172999999999985], "policy_red_v16_reward": [0.37189062500000025, -1.5439999999999996, -1.5239999999999978], "policy_red_v6_reward": [-1.52, 2.644375000000002, -1.194999999999981, 0.9188437499999997, 0.488, -1.1699999999999855], "policy_red_v11_reward": [1.2271906250000004], "policy_red_v19_reward": [-2.034999999999999], "policy_red_v13_reward": [1.5267401128161695], "policy_red_v20_reward": [-0.28600000000000014]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8010433330308036, "mean_inference_ms": 7.787791924778281, "mean_action_processing_ms": 0.29309488101692394, "mean_env_wait_ms": 0.3857231303191043, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10653722286224365, "StateBufferConnector_ms": 0.00441741943359375, "ViewRequirementAgentConnector_ms": 0.12239682674407959}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 408000, "num_agent_steps_trained": 408000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 195.72502706160856, "num_env_steps_trained_throughput_per_sec": 195.72502706160856, "timesteps_total": 204000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 408000, "timers": {"training_iteration_time_ms": 19819.921, "sample_time_ms": 1169.871, "learn_time_ms": 18565.421, "learn_throughput": 215.454, "synch_weights_time_ms": 82.301}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 408000, "num_agent_steps_trained": 408000}, "done": false, "episodes_total": 357, "training_iteration": 51, "trial_id": "a9680_00000", "date": "2023-09-24_02-54-19", "timestamp": 1695538459, "time_this_iter_s": 20.44975185394287, "time_total_s": 1013.3980839252472, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34453ac0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34419990>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34419a20>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1013.3980839252472, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 4.735483870967744, "ram_util_percent": 18.996774193548386}, "win_rate": 0.65, "league_size": 23}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9725133175651233, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.015085783247923246, "policy_loss": -0.06185102179297246, "vf_loss": 0.08149533586692996, "vf_explained_var": 0.6332471596697966, "kl": 0.018914982187682956, "entropy": 2.4941709861159325, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 49440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "sampler_results": {"episode_reward_max": 4.063290112816174, "episode_reward_min": -0.7771043322270501, "episode_reward_mean": 1.595798698017822, "episode_len_mean": 450.75, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {"red_v4": -1.5439999999999998, "red": -5.069307457227051, "blue": -2.0219999999999994, "red_v1": -1.4859999999999594, "red_v7": -1.7189999999999472, "red_v5": -1.5219999999999998, "red_v3": -1.1259999999999877, "red_v9": -1.5379999999999998, "red_v17": -1.0859999999999952, "red_v10": -0.06689696645591336, "red_v8": -1.172999999999985, "red_v16": -1.5439999999999996, "red_v6": -1.52, "red_v11": -1.0189999999999988, "red_v19": -2.034999999999999, "red_v2": -1.525, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.3076932378161894}, "policy_reward_max": {"red_v4": 1.9199375, "red": 3.97867761281617, "blue": 4.292203125000004, "red_v1": -1.2099999999999822, "red_v7": 1.8905468749999998, "red_v5": 0.19969323781617176, "red_v3": 0.19439062500000281, "red_v9": 0.3532656249999999, "red_v17": 0.5520500000000093, "red_v10": 0.9186932378161892, "red_v8": 1.586271362816173, "red_v16": 0.37189062500000025, "red_v6": 3.323184614442594, "red_v11": 1.2271906250000004, "red_v19": -2.034999999999999, "red_v2": 1.94121875, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.3076932378161894}, "policy_reward_mean": {"red_v4": 0.5991264344540431, "red": 2.09895762401962, "blue": -0.9496953457446743, "red_v1": -1.3479999999999708, "red_v7": -0.011771369409314688, "red_v5": -0.821076690545947, "red_v3": -0.4982249201857975, "red_v9": -0.7388082274367592, "red_v17": -0.36908581907568133, "red_v10": 0.4374965030588153, "red_v8": 0.16183034070404811, "red_v16": -0.898703124999999, "red_v6": 0.4984861949203756, "red_v11": 0.10409531250000081, "red_v19": -2.034999999999999, "red_v2": 0.20810937500000004, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.3076932378161894}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.727386475632418, 1.9764588628161854, 0.4226932378161854, 1.931693237816172, 2.1513182378161813, 0.5966932378161889, 1.9386151128161928, 1.8792401128161726, 0.7786932378162135, 2.749377852258771, 1.437646362815205, 0.7115213628161947, 0.8216932378161718, 1.2100682378162138, 0.9263721144425925, 1.1514432378161823, 2.3144276128161763, 1.1808807378162096, 2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312, 1.3085526128161722, 1.7067432378162177, 2.072386475632441, 1.4493494878161708, 1.6959463628161788, 1.331740112816175, 1.4289901128161726, 1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836, 0.8046932378162143, 1.9653807378161698, 1.386568237816173, 0.39693750000000017, 4.063290112816174, 0.8139588628161758, 0.6751742300000054, 0.8803564894425933, 2.6000682378161866, 0.37969323781620246, 1.690883862816193, 0.5620838628161788, 0.7007244878161765, 3.865792725632345, -0.7771043322270501, 1.0912401128162172, 0.7085369878161885, 1.9676776128161704, 1.4105057378161714, 1.8867432378162499, 2.27966198781618, 2.078964600632354, 1.9036307378161736, 3.450724487816171, 0.673693237816217, 1.3260987927729422, 0.8926932378162121, 2.4650596144425925, 0.05651875000000128, 1.9874333506323607, 0.5652557378161749, 0.8865369878162115, 2.732633862816192, 0.7338182378161768, 1.7449368963602745, 1.3313437499999998, 2.310708862816176, 2.4836307378152043, 0.923474487816173, 2.721615112816205, 0.9555213628162148, 0.8540781250000001, 1.1628000000000003, 1.087802612816183, 0.9173651128161726, 1.8757557378161749, 2.851339600632374, 1.713005737816201, 0.8226932378162157, 1.9612713628161713, 1.8275023550000014, 2.2791619878161784, 2.189386475632428, 2.3534588628161752, 3.2758778522587706, 3.894968146360229, 2.2524432378161783, 0.6076932378162131, 0.768724487816211, 2.4512401128161705], "episode_lengths": [1280, 427, 1280, 64, 312, 1280, 441, 113, 1280, 208, 47, 599, 1280, 968, 52, 336, 181, 964, 727, 31, 72, 83, 282, 836, 40, 1280, 832, 141, 1280, 1280, 46, 415, 145, 65, 49, 72, 1280, 152, 272, 337, 1280, 36, 104, 84, 113, 139, 131, 89, 264, 1280, 371, 355, 246, 126, 223, 1137, 562, 37, 60, 1280, 138, 423, 84, 54, 1280, 190, 1280, 24, 106, 465, 396, 818, 323, 216, 1139, 18, 155, 20, 70, 441, 1175, 71, 16, 253, 73, 108, 495, 604, 1280, 39, 58, 170, 1280, 107, 176, 105, 208, 1280, 1142, 49], "policy_red_v4_reward": [0.6216932378161725, -1.5439999999999998, 1.3988749999999999, 1.9199375], "policy_blue_reward": [-1.1269999999999887, -2.0219999999999994, -1.0759999999999947, -1.3859999999999661, -1.1339999999999881, -2.016, 0.39182812499999986, -1.300999999999974, 0.4484375000000004, 0.6647499999999998, -1.0409999999999966, -1.2819999999999736, -2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657, -2.0139999999999993, -0.4399499999999984, -1.030999999999999, -2.017999999999999, -2.0119999999999996, -1.0719999999999936, -1.0929999999999929, -2.01, 0.6530500000000008, 0.26603125000000016, 4.292203125000004, -2.0109999999999997, -1.5219999999999998, -1.3639999999999668, -1.0049999999999997, 0.971, 1.5438437500000035, 0.29112499999999997, -2.006, -1.055999999999996, -1.0059999999999996, -1.3109999999999704, -0.52, -2.005, -1.113999999999999, -2.0219999999999985, -2.0169999999999995, -1.0589999999999968, -1.368999999999968], "policy_red_v1_reward": [-1.4859999999999594, -1.2099999999999822], "policy_red_v7_reward": [1.8905468749999998, -1.7189999999999472, -0.1209499999999962, 0.41767187500000014, 0.4741030335440548, -1.0129999999999995], "policy_red_v5_reward": [-0.5070000000000005, -1.5219999999999998, 0.19969323781617176, -1.4549999999999594], "policy_red_v3_reward": [-0.5630653855574075, -1.1259999999999877, 0.19439062500000281], "policy_red_v9_reward": [-0.22630676218382195, -1.5379999999999998, -1.2069999999999796, 0.3532656249999999, -1.075999999999994], "policy_red_v17_reward": [-0.573307457227058, -1.0859999999999952, 0.5520500000000093], "policy_red_v10_reward": [-0.06689696645591336, 0.9186932378161892, 0.4606932378161701], "policy_red_v8_reward": [0.41405000000000436, -0.18000000000000016, 1.586271362816173, -1.172999999999985], "policy_red_v16_reward": [0.37189062500000025, -1.5439999999999996, -1.5239999999999978], "policy_red_v6_reward": [-1.52, 2.644375000000002, -1.194999999999981, 0.9188437499999997, 0.488, -1.1699999999999855, 3.323184614442594], "policy_red_v11_reward": [1.2271906250000004, -1.0189999999999988], "policy_red_v19_reward": [-2.034999999999999], "policy_red_v2_reward": [-1.525, 1.94121875], "policy_red_v13_reward": [1.5267401128161695], "policy_red_v12_reward": [1.3792436585440782], "policy_red_v20_reward": [-0.28600000000000014], "policy_red_v18_reward": [0.3076932378161894]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8005568532349038, "mean_inference_ms": 7.783507039541079, "mean_action_processing_ms": 0.29297434245543075, "mean_env_wait_ms": 0.3853073451320343, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10719859600067139, "StateBufferConnector_ms": 0.004451155662536621, "ViewRequirementAgentConnector_ms": 0.12325882911682129}}, "episode_reward_max": 4.063290112816174, "episode_reward_min": -0.7771043322270501, "episode_reward_mean": 1.595798698017822, "episode_len_mean": 450.75, "episodes_this_iter": 9, "policy_reward_min": {"red_v4": -1.5439999999999998, "red": -5.069307457227051, "blue": -2.0219999999999994, "red_v1": -1.4859999999999594, "red_v7": -1.7189999999999472, "red_v5": -1.5219999999999998, "red_v3": -1.1259999999999877, "red_v9": -1.5379999999999998, "red_v17": -1.0859999999999952, "red_v10": -0.06689696645591336, "red_v8": -1.172999999999985, "red_v16": -1.5439999999999996, "red_v6": -1.52, "red_v11": -1.0189999999999988, "red_v19": -2.034999999999999, "red_v2": -1.525, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.3076932378161894}, "policy_reward_max": {"red_v4": 1.9199375, "red": 3.97867761281617, "blue": 4.292203125000004, "red_v1": -1.2099999999999822, "red_v7": 1.8905468749999998, "red_v5": 0.19969323781617176, "red_v3": 0.19439062500000281, "red_v9": 0.3532656249999999, "red_v17": 0.5520500000000093, "red_v10": 0.9186932378161892, "red_v8": 1.586271362816173, "red_v16": 0.37189062500000025, "red_v6": 3.323184614442594, "red_v11": 1.2271906250000004, "red_v19": -2.034999999999999, "red_v2": 1.94121875, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.3076932378161894}, "policy_reward_mean": {"red_v4": 0.5991264344540431, "red": 2.09895762401962, "blue": -0.9496953457446743, "red_v1": -1.3479999999999708, "red_v7": -0.011771369409314688, "red_v5": -0.821076690545947, "red_v3": -0.4982249201857975, "red_v9": -0.7388082274367592, "red_v17": -0.36908581907568133, "red_v10": 0.4374965030588153, "red_v8": 0.16183034070404811, "red_v16": -0.898703124999999, "red_v6": 0.4984861949203756, "red_v11": 0.10409531250000081, "red_v19": -2.034999999999999, "red_v2": 0.20810937500000004, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.3076932378161894}, "hist_stats": {"episode_reward": [1.727386475632418, 1.9764588628161854, 0.4226932378161854, 1.931693237816172, 2.1513182378161813, 0.5966932378161889, 1.9386151128161928, 1.8792401128161726, 0.7786932378162135, 2.749377852258771, 1.437646362815205, 0.7115213628161947, 0.8216932378161718, 1.2100682378162138, 0.9263721144425925, 1.1514432378161823, 2.3144276128161763, 1.1808807378162096, 2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312, 1.3085526128161722, 1.7067432378162177, 2.072386475632441, 1.4493494878161708, 1.6959463628161788, 1.331740112816175, 1.4289901128161726, 1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836, 0.8046932378162143, 1.9653807378161698, 1.386568237816173, 0.39693750000000017, 4.063290112816174, 0.8139588628161758, 0.6751742300000054, 0.8803564894425933, 2.6000682378161866, 0.37969323781620246, 1.690883862816193, 0.5620838628161788, 0.7007244878161765, 3.865792725632345, -0.7771043322270501, 1.0912401128162172, 0.7085369878161885, 1.9676776128161704, 1.4105057378161714, 1.8867432378162499, 2.27966198781618, 2.078964600632354, 1.9036307378161736, 3.450724487816171, 0.673693237816217, 1.3260987927729422, 0.8926932378162121, 2.4650596144425925, 0.05651875000000128, 1.9874333506323607, 0.5652557378161749, 0.8865369878162115, 2.732633862816192, 0.7338182378161768, 1.7449368963602745, 1.3313437499999998, 2.310708862816176, 2.4836307378152043, 0.923474487816173, 2.721615112816205, 0.9555213628162148, 0.8540781250000001, 1.1628000000000003, 1.087802612816183, 0.9173651128161726, 1.8757557378161749, 2.851339600632374, 1.713005737816201, 0.8226932378162157, 1.9612713628161713, 1.8275023550000014, 2.2791619878161784, 2.189386475632428, 2.3534588628161752, 3.2758778522587706, 3.894968146360229, 2.2524432378161783, 0.6076932378162131, 0.768724487816211, 2.4512401128161705], "episode_lengths": [1280, 427, 1280, 64, 312, 1280, 441, 113, 1280, 208, 47, 599, 1280, 968, 52, 336, 181, 964, 727, 31, 72, 83, 282, 836, 40, 1280, 832, 141, 1280, 1280, 46, 415, 145, 65, 49, 72, 1280, 152, 272, 337, 1280, 36, 104, 84, 113, 139, 131, 89, 264, 1280, 371, 355, 246, 126, 223, 1137, 562, 37, 60, 1280, 138, 423, 84, 54, 1280, 190, 1280, 24, 106, 465, 396, 818, 323, 216, 1139, 18, 155, 20, 70, 441, 1175, 71, 16, 253, 73, 108, 495, 604, 1280, 39, 58, 170, 1280, 107, 176, 105, 208, 1280, 1142, 49], "policy_red_v4_reward": [0.6216932378161725, -1.5439999999999998, 1.3988749999999999, 1.9199375], "policy_blue_reward": [-1.1269999999999887, -2.0219999999999994, -1.0759999999999947, -1.3859999999999661, -1.1339999999999881, -2.016, 0.39182812499999986, -1.300999999999974, 0.4484375000000004, 0.6647499999999998, -1.0409999999999966, -1.2819999999999736, -2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657, -2.0139999999999993, -0.4399499999999984, -1.030999999999999, -2.017999999999999, -2.0119999999999996, -1.0719999999999936, -1.0929999999999929, -2.01, 0.6530500000000008, 0.26603125000000016, 4.292203125000004, -2.0109999999999997, -1.5219999999999998, -1.3639999999999668, -1.0049999999999997, 0.971, 1.5438437500000035, 0.29112499999999997, -2.006, -1.055999999999996, -1.0059999999999996, -1.3109999999999704, -0.52, -2.005, -1.113999999999999, -2.0219999999999985, -2.0169999999999995, -1.0589999999999968, -1.368999999999968], "policy_red_v1_reward": [-1.4859999999999594, -1.2099999999999822], "policy_red_v7_reward": [1.8905468749999998, -1.7189999999999472, -0.1209499999999962, 0.41767187500000014, 0.4741030335440548, -1.0129999999999995], "policy_red_v5_reward": [-0.5070000000000005, -1.5219999999999998, 0.19969323781617176, -1.4549999999999594], "policy_red_v3_reward": [-0.5630653855574075, -1.1259999999999877, 0.19439062500000281], "policy_red_v9_reward": [-0.22630676218382195, -1.5379999999999998, -1.2069999999999796, 0.3532656249999999, -1.075999999999994], "policy_red_v17_reward": [-0.573307457227058, -1.0859999999999952, 0.5520500000000093], "policy_red_v10_reward": [-0.06689696645591336, 0.9186932378161892, 0.4606932378161701], "policy_red_v8_reward": [0.41405000000000436, -0.18000000000000016, 1.586271362816173, -1.172999999999985], "policy_red_v16_reward": [0.37189062500000025, -1.5439999999999996, -1.5239999999999978], "policy_red_v6_reward": [-1.52, 2.644375000000002, -1.194999999999981, 0.9188437499999997, 0.488, -1.1699999999999855, 3.323184614442594], "policy_red_v11_reward": [1.2271906250000004, -1.0189999999999988], "policy_red_v19_reward": [-2.034999999999999], "policy_red_v2_reward": [-1.525, 1.94121875], "policy_red_v13_reward": [1.5267401128161695], "policy_red_v12_reward": [1.3792436585440782], "policy_red_v20_reward": [-0.28600000000000014], "policy_red_v18_reward": [0.3076932378161894]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8005568532349038, "mean_inference_ms": 7.783507039541079, "mean_action_processing_ms": 0.29297434245543075, "mean_env_wait_ms": 0.3853073451320343, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10719859600067139, "StateBufferConnector_ms": 0.004451155662536621, "ViewRequirementAgentConnector_ms": 0.12325882911682129}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 205.64190932322228, "num_env_steps_trained_throughput_per_sec": 205.64190932322228, "timesteps_total": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 19795.649, "sample_time_ms": 1168.369, "learn_time_ms": 18542.732, "learn_throughput": 215.718, "synch_weights_time_ms": 82.212}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "episodes_total": 366, "training_iteration": 52, "trial_id": "a9680_00000", "date": "2023-09-24_02-54-38", "timestamp": 1695538478, "time_this_iter_s": 19.461214303970337, "time_total_s": 1032.8592982292175, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b343c7e50>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34419ea0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34419bd0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1032.8592982292175, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 4.9750000000000005, "ram_util_percent": 18.99642857142857}, "win_rate": 0.67, "league_size": 24}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.95375667574505, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.023286283937947398, "policy_loss": -0.05660290396917844, "vf_loss": 0.05603263088366172, "vf_explained_var": 0.6849512929717699, "kl": 0.01725675533783336, "entropy": 2.4652352412541707, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 50400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 424000, "num_agent_steps_trained": 424000}, "sampler_results": {"episode_reward_max": 4.063290112816174, "episode_reward_min": -0.7771043322270501, "episode_reward_mean": 1.6108459498306635, "episode_len_mean": 422.43, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"blue": -2.0219999999999985, "red": -5.069307457227051, "red_v3": -1.1259999999999877, "red_v9": -1.5379999999999998, "red_v17": -1.0859999999999952, "red_v10": -1.591, "red_v4": -1.5439999999999998, "red_v8": -1.172999999999985, "red_v5": -1.5219999999999998, "red_v16": -1.5439999999999996, "red_v6": -1.52, "red_v7": -1.7189999999999472, "red_v11": -1.5569999999999977, "red_v19": -2.034999999999999, "red_v2": -1.525, "red_v1": -1.2099999999999822, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.3076932378161894}, "policy_reward_max": {"blue": 4.292203125000004, "red": 3.97867761281617, "red_v3": 0.19439062500000281, "red_v9": 0.3532656249999999, "red_v17": 0.5520500000000093, "red_v10": 0.9186932378161892, "red_v4": 1.9199375, "red_v8": 1.586271362816173, "red_v5": 0.19969323781617176, "red_v16": 0.37189062500000025, "red_v6": 3.323184614442594, "red_v7": 0.4741030335440548, "red_v11": 1.2271906250000004, "red_v19": -2.034999999999999, "red_v2": 1.94121875, "red_v1": 0.45599999999999996, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.4836932378161698}, "policy_reward_mean": {"blue": -0.919862635869559, "red": 2.1008578157268887, "red_v3": -0.46580468749999243, "red_v9": -0.7340068561972993, "red_v17": -0.36908581907568133, "red_v10": -0.06962762270588851, "red_v4": 0.9105000000000001, "red_v8": 0.16183034070404811, "red_v5": -0.9257689207279292, "red_v16": -0.898703124999999, "red_v6": 0.4984861949203756, "red_v7": -0.3922350182911776, "red_v11": -0.4496031249999987, "red_v19": -2.034999999999999, "red_v2": 0.20810937500000004, "red_v1": -0.3769999999999911, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.3956932378161796}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.437646362815205, 0.7115213628161947, 0.8216932378161718, 1.2100682378162138, 0.9263721144425925, 1.1514432378161823, 2.3144276128161763, 1.1808807378162096, 2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312, 1.3085526128161722, 1.7067432378162177, 2.072386475632441, 1.4493494878161708, 1.6959463628161788, 1.331740112816175, 1.4289901128161726, 1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836, 0.8046932378162143, 1.9653807378161698, 1.386568237816173, 0.39693750000000017, 4.063290112816174, 0.8139588628161758, 0.6751742300000054, 0.8803564894425933, 2.6000682378161866, 0.37969323781620246, 1.690883862816193, 0.5620838628161788, 0.7007244878161765, 3.865792725632345, -0.7771043322270501, 1.0912401128162172, 0.7085369878161885, 1.9676776128161704, 1.4105057378161714, 1.8867432378162499, 2.27966198781618, 2.078964600632354, 1.9036307378161736, 3.450724487816171, 0.673693237816217, 1.3260987927729422, 0.8926932378162121, 2.4650596144425925, 0.05651875000000128, 1.9874333506323607, 0.5652557378161749, 0.8865369878162115, 2.732633862816192, 0.7338182378161768, 1.7449368963602745, 1.3313437499999998, 2.310708862816176, 2.4836307378152043, 0.923474487816173, 2.721615112816205, 0.9555213628162148, 0.8540781250000001, 1.1628000000000003, 1.087802612816183, 0.9173651128161726, 1.8757557378161749, 2.851339600632374, 1.713005737816201, 0.8226932378162157, 1.9612713628161713, 1.8275023550000014, 2.2791619878161784, 2.189386475632428, 2.3534588628161752, 3.2758778522587706, 3.894968146360229, 2.2524432378161783, 0.6076932378162131, 0.768724487816211, 2.4512401128161705, 1.6618842835440633, 1.9787401128161908, 3.889902100632343, 0.8668651128161736, 2.3355057378161765, 0.19569323781520298, 0.7753182378162151, 1.8602088628161728, 1.8608807378161742, 2.2318963628161796], "episode_lengths": [47, 599, 1280, 968, 52, 336, 181, 964, 727, 31, 72, 83, 282, 836, 40, 1280, 832, 141, 1280, 1280, 46, 415, 145, 65, 49, 72, 1280, 152, 272, 337, 1280, 36, 104, 84, 113, 139, 131, 89, 264, 1280, 371, 355, 246, 126, 223, 1137, 562, 37, 60, 1280, 138, 423, 84, 54, 1280, 190, 1280, 24, 106, 465, 396, 818, 323, 216, 1139, 18, 155, 20, 70, 441, 1175, 71, 16, 253, 73, 108, 495, 604, 1280, 39, 58, 170, 1280, 107, 176, 105, 208, 1280, 1142, 49, 134, 401, 123, 105, 124, 1280, 1272, 59, 132, 223], "policy_blue_reward": [-2.016, 0.39182812499999986, -1.300999999999974, 0.4484375000000004, 0.6647499999999998, -1.0409999999999966, -1.2819999999999736, -2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657, -2.0139999999999993, -0.4399499999999984, -1.030999999999999, -2.017999999999999, -2.0119999999999996, -1.0719999999999936, -1.0929999999999929, -2.01, 0.6530500000000008, 0.26603125000000016, 4.292203125000004, -2.0109999999999997, -1.5219999999999998, -1.3639999999999668, -1.0049999999999997, 0.971, 1.5438437500000035, 0.29112499999999997, -2.006, -1.055999999999996, -1.0059999999999996, -1.3109999999999704, -0.52, -2.005, -1.113999999999999, -2.0219999999999985, -2.0169999999999995, -1.0589999999999968, -1.368999999999968, -1.125999999999992, -0.8850000000000003, -1.3539999999999661, -1.0579999999999985], "policy_red_v3_reward": [-1.1259999999999877, 0.19439062500000281], "policy_red_v9_reward": [-0.22630676218382195, -1.5379999999999998, -1.2069999999999796, 0.3532656249999999, -1.075999999999994, -0.7099999999999997], "policy_red_v17_reward": [-0.573307457227058, -1.0859999999999952, 0.5520500000000093], "policy_red_v10_reward": [-0.06689696645591336, 0.9186932378161892, 0.4606932378161701, -1.591], "policy_red_v4_reward": [-1.5439999999999998, 1.3988749999999999, 1.9199375, 1.8671875], "policy_red_v8_reward": [0.41405000000000436, -0.18000000000000016, 1.586271362816173, -1.172999999999985], "policy_red_v5_reward": [-1.5219999999999998, 0.19969323781617176, -1.4549999999999594], "policy_red_v16_reward": [0.37189062500000025, -1.5439999999999996, -1.5239999999999978], "policy_red_v6_reward": [-1.52, 2.644375000000002, -1.194999999999981, 0.9188437499999997, 0.488, -1.1699999999999855, 3.323184614442594], "policy_red_v7_reward": [-1.7189999999999472, -0.1209499999999962, 0.41767187500000014, 0.4741030335440548, -1.0129999999999995], "policy_red_v11_reward": [1.2271906250000004, -1.0189999999999988, -1.5569999999999977], "policy_red_v19_reward": [-2.034999999999999], "policy_red_v2_reward": [-1.525, 1.94121875], "policy_red_v1_reward": [-1.2099999999999822, 0.45599999999999996], "policy_red_v13_reward": [1.5267401128161695], "policy_red_v12_reward": [1.3792436585440782], "policy_red_v20_reward": [-0.28600000000000014], "policy_red_v18_reward": [0.3076932378161894, 0.4836932378161698]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8013442201367114, "mean_inference_ms": 7.792720996621139, "mean_action_processing_ms": 0.2933119844860871, "mean_env_wait_ms": 0.38546776515762315, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10543406009674072, "StateBufferConnector_ms": 0.004350900650024414, "ViewRequirementAgentConnector_ms": 0.12063002586364746}}, "episode_reward_max": 4.063290112816174, "episode_reward_min": -0.7771043322270501, "episode_reward_mean": 1.6108459498306635, "episode_len_mean": 422.43, "episodes_this_iter": 10, "policy_reward_min": {"blue": -2.0219999999999985, "red": -5.069307457227051, "red_v3": -1.1259999999999877, "red_v9": -1.5379999999999998, "red_v17": -1.0859999999999952, "red_v10": -1.591, "red_v4": -1.5439999999999998, "red_v8": -1.172999999999985, "red_v5": -1.5219999999999998, "red_v16": -1.5439999999999996, "red_v6": -1.52, "red_v7": -1.7189999999999472, "red_v11": -1.5569999999999977, "red_v19": -2.034999999999999, "red_v2": -1.525, "red_v1": -1.2099999999999822, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.3076932378161894}, "policy_reward_max": {"blue": 4.292203125000004, "red": 3.97867761281617, "red_v3": 0.19439062500000281, "red_v9": 0.3532656249999999, "red_v17": 0.5520500000000093, "red_v10": 0.9186932378161892, "red_v4": 1.9199375, "red_v8": 1.586271362816173, "red_v5": 0.19969323781617176, "red_v16": 0.37189062500000025, "red_v6": 3.323184614442594, "red_v7": 0.4741030335440548, "red_v11": 1.2271906250000004, "red_v19": -2.034999999999999, "red_v2": 1.94121875, "red_v1": 0.45599999999999996, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.4836932378161698}, "policy_reward_mean": {"blue": -0.919862635869559, "red": 2.1008578157268887, "red_v3": -0.46580468749999243, "red_v9": -0.7340068561972993, "red_v17": -0.36908581907568133, "red_v10": -0.06962762270588851, "red_v4": 0.9105000000000001, "red_v8": 0.16183034070404811, "red_v5": -0.9257689207279292, "red_v16": -0.898703124999999, "red_v6": 0.4984861949203756, "red_v7": -0.3922350182911776, "red_v11": -0.4496031249999987, "red_v19": -2.034999999999999, "red_v2": 0.20810937500000004, "red_v1": -0.3769999999999911, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.3956932378161796}, "hist_stats": {"episode_reward": [1.437646362815205, 0.7115213628161947, 0.8216932378161718, 1.2100682378162138, 0.9263721144425925, 1.1514432378161823, 2.3144276128161763, 1.1808807378162096, 2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312, 1.3085526128161722, 1.7067432378162177, 2.072386475632441, 1.4493494878161708, 1.6959463628161788, 1.331740112816175, 1.4289901128161726, 1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836, 0.8046932378162143, 1.9653807378161698, 1.386568237816173, 0.39693750000000017, 4.063290112816174, 0.8139588628161758, 0.6751742300000054, 0.8803564894425933, 2.6000682378161866, 0.37969323781620246, 1.690883862816193, 0.5620838628161788, 0.7007244878161765, 3.865792725632345, -0.7771043322270501, 1.0912401128162172, 0.7085369878161885, 1.9676776128161704, 1.4105057378161714, 1.8867432378162499, 2.27966198781618, 2.078964600632354, 1.9036307378161736, 3.450724487816171, 0.673693237816217, 1.3260987927729422, 0.8926932378162121, 2.4650596144425925, 0.05651875000000128, 1.9874333506323607, 0.5652557378161749, 0.8865369878162115, 2.732633862816192, 0.7338182378161768, 1.7449368963602745, 1.3313437499999998, 2.310708862816176, 2.4836307378152043, 0.923474487816173, 2.721615112816205, 0.9555213628162148, 0.8540781250000001, 1.1628000000000003, 1.087802612816183, 0.9173651128161726, 1.8757557378161749, 2.851339600632374, 1.713005737816201, 0.8226932378162157, 1.9612713628161713, 1.8275023550000014, 2.2791619878161784, 2.189386475632428, 2.3534588628161752, 3.2758778522587706, 3.894968146360229, 2.2524432378161783, 0.6076932378162131, 0.768724487816211, 2.4512401128161705, 1.6618842835440633, 1.9787401128161908, 3.889902100632343, 0.8668651128161736, 2.3355057378161765, 0.19569323781520298, 0.7753182378162151, 1.8602088628161728, 1.8608807378161742, 2.2318963628161796], "episode_lengths": [47, 599, 1280, 968, 52, 336, 181, 964, 727, 31, 72, 83, 282, 836, 40, 1280, 832, 141, 1280, 1280, 46, 415, 145, 65, 49, 72, 1280, 152, 272, 337, 1280, 36, 104, 84, 113, 139, 131, 89, 264, 1280, 371, 355, 246, 126, 223, 1137, 562, 37, 60, 1280, 138, 423, 84, 54, 1280, 190, 1280, 24, 106, 465, 396, 818, 323, 216, 1139, 18, 155, 20, 70, 441, 1175, 71, 16, 253, 73, 108, 495, 604, 1280, 39, 58, 170, 1280, 107, 176, 105, 208, 1280, 1142, 49, 134, 401, 123, 105, 124, 1280, 1272, 59, 132, 223], "policy_blue_reward": [-2.016, 0.39182812499999986, -1.300999999999974, 0.4484375000000004, 0.6647499999999998, -1.0409999999999966, -1.2819999999999736, -2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657, -2.0139999999999993, -0.4399499999999984, -1.030999999999999, -2.017999999999999, -2.0119999999999996, -1.0719999999999936, -1.0929999999999929, -2.01, 0.6530500000000008, 0.26603125000000016, 4.292203125000004, -2.0109999999999997, -1.5219999999999998, -1.3639999999999668, -1.0049999999999997, 0.971, 1.5438437500000035, 0.29112499999999997, -2.006, -1.055999999999996, -1.0059999999999996, -1.3109999999999704, -0.52, -2.005, -1.113999999999999, -2.0219999999999985, -2.0169999999999995, -1.0589999999999968, -1.368999999999968, -1.125999999999992, -0.8850000000000003, -1.3539999999999661, -1.0579999999999985], "policy_red_v3_reward": [-1.1259999999999877, 0.19439062500000281], "policy_red_v9_reward": [-0.22630676218382195, -1.5379999999999998, -1.2069999999999796, 0.3532656249999999, -1.075999999999994, -0.7099999999999997], "policy_red_v17_reward": [-0.573307457227058, -1.0859999999999952, 0.5520500000000093], "policy_red_v10_reward": [-0.06689696645591336, 0.9186932378161892, 0.4606932378161701, -1.591], "policy_red_v4_reward": [-1.5439999999999998, 1.3988749999999999, 1.9199375, 1.8671875], "policy_red_v8_reward": [0.41405000000000436, -0.18000000000000016, 1.586271362816173, -1.172999999999985], "policy_red_v5_reward": [-1.5219999999999998, 0.19969323781617176, -1.4549999999999594], "policy_red_v16_reward": [0.37189062500000025, -1.5439999999999996, -1.5239999999999978], "policy_red_v6_reward": [-1.52, 2.644375000000002, -1.194999999999981, 0.9188437499999997, 0.488, -1.1699999999999855, 3.323184614442594], "policy_red_v7_reward": [-1.7189999999999472, -0.1209499999999962, 0.41767187500000014, 0.4741030335440548, -1.0129999999999995], "policy_red_v11_reward": [1.2271906250000004, -1.0189999999999988, -1.5569999999999977], "policy_red_v19_reward": [-2.034999999999999], "policy_red_v2_reward": [-1.525, 1.94121875], "policy_red_v1_reward": [-1.2099999999999822, 0.45599999999999996], "policy_red_v13_reward": [1.5267401128161695], "policy_red_v12_reward": [1.3792436585440782], "policy_red_v20_reward": [-0.28600000000000014], "policy_red_v18_reward": [0.3076932378161894, 0.4836932378161698]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8013442201367114, "mean_inference_ms": 7.792720996621139, "mean_action_processing_ms": 0.2933119844860871, "mean_env_wait_ms": 0.38546776515762315, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10543406009674072, "StateBufferConnector_ms": 0.004350900650024414, "ViewRequirementAgentConnector_ms": 0.12063002586364746}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 424000, "num_agent_steps_trained": 424000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 198.1863015136882, "num_env_steps_trained_throughput_per_sec": 198.1863015136882, "timesteps_total": 212000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 424000, "timers": {"training_iteration_time_ms": 19814.184, "sample_time_ms": 1167.458, "learn_time_ms": 18562.722, "learn_throughput": 215.486, "synch_weights_time_ms": 81.666}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 424000, "num_agent_steps_trained": 424000}, "done": false, "episodes_total": 376, "training_iteration": 53, "trial_id": "a9680_00000", "date": "2023-09-24_02-55-00", "timestamp": 1695538500, "time_this_iter_s": 20.193443775177002, "time_total_s": 1053.0527420043945, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34439e40>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3441bb50>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3441bbe0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1053.0527420043945, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 5.03125, "ram_util_percent": 19.087500000000002}, "win_rate": 0.66, "league_size": 25}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6494438599795105, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.00015917372511466965, "policy_loss": -0.05345731480047107, "vf_loss": 0.09767562664540795, "vf_explained_var": 0.694045199205478, "kl": 0.015288688697789135, "entropy": 2.4195807116727033, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 51360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "sampler_results": {"episode_reward_max": 4.063290112816174, "episode_reward_min": -0.7771043322270501, "episode_reward_mean": 1.6835503096144098, "episode_len_mean": 406.61, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"red_v9": -1.5379999999999998, "red": -5.069307457227051, "blue": -2.0219999999999985, "red_v17": -1.0859999999999952, "red_v10": -2.027999999999998, "red_v4": -1.5439999999999998, "red_v8": -1.172999999999985, "red_v5": -1.5219999999999998, "red_v16": -1.5439999999999996, "red_v6": -1.52, "red_v7": -1.7189999999999472, "red_v11": -1.5569999999999977, "red_v3": 0.19439062500000281, "red_v19": -2.034999999999999, "red_v2": -1.525, "red_v1": -1.2099999999999822, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.3076932378161894, "red_v14": -0.09930676218382961}, "policy_reward_max": {"red_v9": 0.3532656249999999, "red": 3.97867761281617, "blue": 4.292203125000004, "red_v17": 0.5520500000000093, "red_v10": 0.9186932378161892, "red_v4": 1.9199375, "red_v8": 1.586271362816173, "red_v5": 0.19969323781617176, "red_v16": 0.37189062500000025, "red_v6": 3.323184614442594, "red_v7": 0.4741030335440548, "red_v11": 1.2271906250000004, "red_v3": 0.19439062500000281, "red_v19": -2.034999999999999, "red_v2": 1.94121875, "red_v1": 0.45599999999999996, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.4836932378161698, "red_v14": -0.09930676218382961}, "policy_reward_mean": {"red_v9": -0.7340068561972993, "red": 2.18426846700431, "blue": -0.989992950581389, "red_v17": -0.1571410548527185, "red_v10": -0.46130209816471035, "red_v4": 0.9105000000000001, "red_v8": 0.16183034070404811, "red_v5": -0.9257689207279292, "red_v16": -0.898703124999999, "red_v6": 0.4984861949203756, "red_v7": -0.3922350182911776, "red_v11": -0.41020234374999903, "red_v3": 0.19439062500000281, "red_v19": -2.034999999999999, "red_v2": 0.20810937500000004, "red_v1": -0.3769999999999911, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.3956932378161796, "red_v14": -0.09930676218382961}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312, 1.3085526128161722, 1.7067432378162177, 2.072386475632441, 1.4493494878161708, 1.6959463628161788, 1.331740112816175, 1.4289901128161726, 1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836, 0.8046932378162143, 1.9653807378161698, 1.386568237816173, 0.39693750000000017, 4.063290112816174, 0.8139588628161758, 0.6751742300000054, 0.8803564894425933, 2.6000682378161866, 0.37969323781620246, 1.690883862816193, 0.5620838628161788, 0.7007244878161765, 3.865792725632345, -0.7771043322270501, 1.0912401128162172, 0.7085369878161885, 1.9676776128161704, 1.4105057378161714, 1.8867432378162499, 2.27966198781618, 2.078964600632354, 1.9036307378161736, 3.450724487816171, 0.673693237816217, 1.3260987927729422, 0.8926932378162121, 2.4650596144425925, 0.05651875000000128, 1.9874333506323607, 0.5652557378161749, 0.8865369878162115, 2.732633862816192, 0.7338182378161768, 1.7449368963602745, 1.3313437499999998, 2.310708862816176, 2.4836307378152043, 0.923474487816173, 2.721615112816205, 0.9555213628162148, 0.8540781250000001, 1.1628000000000003, 1.087802612816183, 0.9173651128161726, 1.8757557378161749, 2.851339600632374, 1.713005737816201, 0.8226932378162157, 1.9612713628161713, 1.8275023550000014, 2.2791619878161784, 2.189386475632428, 2.3534588628161752, 3.2758778522587706, 3.894968146360229, 2.2524432378161783, 0.6076932378162131, 0.768724487816211, 2.4512401128161705, 1.6618842835440633, 1.9787401128161908, 3.889902100632343, 0.8668651128161736, 2.3355057378161765, 0.19569323781520298, 0.7753182378162151, 1.8602088628161728, 1.8608807378161742, 2.2318963628161796, 1.5316307378162026, 1.8781307378161733, 3.8600271006323443, 1.5743304800000306, 1.9033026128161943, 1.5506182378161935, 2.404224487816172, 2.322224487816177], "episode_lengths": [727, 31, 72, 83, 282, 836, 40, 1280, 832, 141, 1280, 1280, 46, 415, 145, 65, 49, 72, 1280, 152, 272, 337, 1280, 36, 104, 84, 113, 139, 131, 89, 264, 1280, 371, 355, 246, 126, 223, 1137, 562, 37, 60, 1280, 138, 423, 84, 54, 1280, 190, 1280, 24, 106, 465, 396, 818, 323, 216, 1139, 18, 155, 20, 70, 441, 1175, 71, 16, 253, 73, 108, 495, 604, 1280, 39, 58, 170, 1280, 107, 176, 105, 208, 1280, 1142, 49, 134, 401, 123, 105, 124, 1280, 1272, 59, 132, 223, 724, 116, 147, 593, 477, 552, 86, 150], "policy_red_v9_reward": [-0.22630676218382195, -1.5379999999999998, -1.2069999999999796, 0.3532656249999999, -1.075999999999994, -0.7099999999999997], "policy_blue_reward": [-2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657, -2.0139999999999993, -0.4399499999999984, -1.030999999999999, -2.017999999999999, -2.0119999999999996, -1.0719999999999936, -1.0929999999999929, -2.01, 0.6530500000000008, 0.26603125000000016, 4.292203125000004, -2.0109999999999997, -1.5219999999999998, -1.3639999999999668, -1.0049999999999997, 0.971, 1.5438437500000035, 0.29112499999999997, -2.006, -1.055999999999996, -1.0059999999999996, -1.3109999999999704, -0.52, -2.005, -1.113999999999999, -2.0219999999999985, -2.0169999999999995, -1.0589999999999968, -1.368999999999968, -1.125999999999992, -0.8850000000000003, -1.3539999999999661, -1.0579999999999985, -1.190999999999982, -1.139999999999988, -1.0219999999999987, -1.0379999999999974], "policy_red_v17_reward": [-0.573307457227058, -1.0859999999999952, 0.5520500000000093, 0.4786932378161699], "policy_red_v10_reward": [-0.06689696645591336, 0.9186932378161892, 0.4606932378161701, -1.591, -2.027999999999998], "policy_red_v4_reward": [-1.5439999999999998, 1.3988749999999999, 1.9199375, 1.8671875], "policy_red_v8_reward": [0.41405000000000436, -0.18000000000000016, 1.586271362816173, -1.172999999999985], "policy_red_v5_reward": [-1.5219999999999998, 0.19969323781617176, -1.4549999999999594], "policy_red_v16_reward": [0.37189062500000025, -1.5439999999999996, -1.5239999999999978], "policy_red_v6_reward": [-1.52, 2.644375000000002, -1.194999999999981, 0.9188437499999997, 0.488, -1.1699999999999855, 3.323184614442594], "policy_red_v7_reward": [-1.7189999999999472, -0.1209499999999962, 0.41767187500000014, 0.4741030335440548, -1.0129999999999995], "policy_red_v11_reward": [1.2271906250000004, -1.0189999999999988, -1.5569999999999977, -0.29200000000000004], "policy_red_v3_reward": [0.19439062500000281], "policy_red_v19_reward": [-2.034999999999999], "policy_red_v2_reward": [-1.525, 1.94121875], "policy_red_v1_reward": [-1.2099999999999822, 0.45599999999999996], "policy_red_v13_reward": [1.5267401128161695], "policy_red_v12_reward": [1.3792436585440782], "policy_red_v20_reward": [-0.28600000000000014], "policy_red_v18_reward": [0.3076932378161894, 0.4836932378161698], "policy_red_v14_reward": [-0.09930676218382961]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8012647749909999, "mean_inference_ms": 7.790472175126274, "mean_action_processing_ms": 0.2932101272352731, "mean_env_wait_ms": 0.3857475930014629, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10442709922790527, "StateBufferConnector_ms": 0.004338741302490234, "ViewRequirementAgentConnector_ms": 0.12000763416290283}}, "episode_reward_max": 4.063290112816174, "episode_reward_min": -0.7771043322270501, "episode_reward_mean": 1.6835503096144098, "episode_len_mean": 406.61, "episodes_this_iter": 8, "policy_reward_min": {"red_v9": -1.5379999999999998, "red": -5.069307457227051, "blue": -2.0219999999999985, "red_v17": -1.0859999999999952, "red_v10": -2.027999999999998, "red_v4": -1.5439999999999998, "red_v8": -1.172999999999985, "red_v5": -1.5219999999999998, "red_v16": -1.5439999999999996, "red_v6": -1.52, "red_v7": -1.7189999999999472, "red_v11": -1.5569999999999977, "red_v3": 0.19439062500000281, "red_v19": -2.034999999999999, "red_v2": -1.525, "red_v1": -1.2099999999999822, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.3076932378161894, "red_v14": -0.09930676218382961}, "policy_reward_max": {"red_v9": 0.3532656249999999, "red": 3.97867761281617, "blue": 4.292203125000004, "red_v17": 0.5520500000000093, "red_v10": 0.9186932378161892, "red_v4": 1.9199375, "red_v8": 1.586271362816173, "red_v5": 0.19969323781617176, "red_v16": 0.37189062500000025, "red_v6": 3.323184614442594, "red_v7": 0.4741030335440548, "red_v11": 1.2271906250000004, "red_v3": 0.19439062500000281, "red_v19": -2.034999999999999, "red_v2": 1.94121875, "red_v1": 0.45599999999999996, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.4836932378161698, "red_v14": -0.09930676218382961}, "policy_reward_mean": {"red_v9": -0.7340068561972993, "red": 2.18426846700431, "blue": -0.989992950581389, "red_v17": -0.1571410548527185, "red_v10": -0.46130209816471035, "red_v4": 0.9105000000000001, "red_v8": 0.16183034070404811, "red_v5": -0.9257689207279292, "red_v16": -0.898703124999999, "red_v6": 0.4984861949203756, "red_v7": -0.3922350182911776, "red_v11": -0.41020234374999903, "red_v3": 0.19439062500000281, "red_v19": -2.034999999999999, "red_v2": 0.20810937500000004, "red_v1": -0.3769999999999911, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.3956932378161796, "red_v14": -0.09930676218382961}, "hist_stats": {"episode_reward": [2.1184559772588005, 1.47289636281617, 2.426068237816172, 2.4153338628161722, 3.1351045305891305, 1.374880737816215, 1.4645682378161706, 0.5536932378162157, 2.109796271360312, 1.3085526128161722, 1.7067432378162177, 2.072386475632441, 1.4493494878161708, 1.6959463628161788, 1.331740112816175, 1.4289901128161726, 1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836, 0.8046932378162143, 1.9653807378161698, 1.386568237816173, 0.39693750000000017, 4.063290112816174, 0.8139588628161758, 0.6751742300000054, 0.8803564894425933, 2.6000682378161866, 0.37969323781620246, 1.690883862816193, 0.5620838628161788, 0.7007244878161765, 3.865792725632345, -0.7771043322270501, 1.0912401128162172, 0.7085369878161885, 1.9676776128161704, 1.4105057378161714, 1.8867432378162499, 2.27966198781618, 2.078964600632354, 1.9036307378161736, 3.450724487816171, 0.673693237816217, 1.3260987927729422, 0.8926932378162121, 2.4650596144425925, 0.05651875000000128, 1.9874333506323607, 0.5652557378161749, 0.8865369878162115, 2.732633862816192, 0.7338182378161768, 1.7449368963602745, 1.3313437499999998, 2.310708862816176, 2.4836307378152043, 0.923474487816173, 2.721615112816205, 0.9555213628162148, 0.8540781250000001, 1.1628000000000003, 1.087802612816183, 0.9173651128161726, 1.8757557378161749, 2.851339600632374, 1.713005737816201, 0.8226932378162157, 1.9612713628161713, 1.8275023550000014, 2.2791619878161784, 2.189386475632428, 2.3534588628161752, 3.2758778522587706, 3.894968146360229, 2.2524432378161783, 0.6076932378162131, 0.768724487816211, 2.4512401128161705, 1.6618842835440633, 1.9787401128161908, 3.889902100632343, 0.8668651128161736, 2.3355057378161765, 0.19569323781520298, 0.7753182378162151, 1.8602088628161728, 1.8608807378161742, 2.2318963628161796, 1.5316307378162026, 1.8781307378161733, 3.8600271006323443, 1.5743304800000306, 1.9033026128161943, 1.5506182378161935, 2.404224487816172, 2.322224487816177], "episode_lengths": [727, 31, 72, 83, 282, 836, 40, 1280, 832, 141, 1280, 1280, 46, 415, 145, 65, 49, 72, 1280, 152, 272, 337, 1280, 36, 104, 84, 113, 139, 131, 89, 264, 1280, 371, 355, 246, 126, 223, 1137, 562, 37, 60, 1280, 138, 423, 84, 54, 1280, 190, 1280, 24, 106, 465, 396, 818, 323, 216, 1139, 18, 155, 20, 70, 441, 1175, 71, 16, 253, 73, 108, 495, 604, 1280, 39, 58, 170, 1280, 107, 176, 105, 208, 1280, 1142, 49, 134, 401, 123, 105, 124, 1280, 1272, 59, 132, 223, 724, 116, 147, 593, 477, 552, 86, 150], "policy_red_v9_reward": [-0.22630676218382195, -1.5379999999999998, -1.2069999999999796, 0.3532656249999999, -1.075999999999994, -0.7099999999999997], "policy_blue_reward": [-2.0069999999999997, -1.0189999999999986, -1.023999999999998, -1.251999999999978, -2.011999999999999, -1.3819999999999657, -2.0139999999999993, -0.4399499999999984, -1.030999999999999, -2.017999999999999, -2.0119999999999996, -1.0719999999999936, -1.0929999999999929, -2.01, 0.6530500000000008, 0.26603125000000016, 4.292203125000004, -2.0109999999999997, -1.5219999999999998, -1.3639999999999668, -1.0049999999999997, 0.971, 1.5438437500000035, 0.29112499999999997, -2.006, -1.055999999999996, -1.0059999999999996, -1.3109999999999704, -0.52, -2.005, -1.113999999999999, -2.0219999999999985, -2.0169999999999995, -1.0589999999999968, -1.368999999999968, -1.125999999999992, -0.8850000000000003, -1.3539999999999661, -1.0579999999999985, -1.190999999999982, -1.139999999999988, -1.0219999999999987, -1.0379999999999974], "policy_red_v17_reward": [-0.573307457227058, -1.0859999999999952, 0.5520500000000093, 0.4786932378161699], "policy_red_v10_reward": [-0.06689696645591336, 0.9186932378161892, 0.4606932378161701, -1.591, -2.027999999999998], "policy_red_v4_reward": [-1.5439999999999998, 1.3988749999999999, 1.9199375, 1.8671875], "policy_red_v8_reward": [0.41405000000000436, -0.18000000000000016, 1.586271362816173, -1.172999999999985], "policy_red_v5_reward": [-1.5219999999999998, 0.19969323781617176, -1.4549999999999594], "policy_red_v16_reward": [0.37189062500000025, -1.5439999999999996, -1.5239999999999978], "policy_red_v6_reward": [-1.52, 2.644375000000002, -1.194999999999981, 0.9188437499999997, 0.488, -1.1699999999999855, 3.323184614442594], "policy_red_v7_reward": [-1.7189999999999472, -0.1209499999999962, 0.41767187500000014, 0.4741030335440548, -1.0129999999999995], "policy_red_v11_reward": [1.2271906250000004, -1.0189999999999988, -1.5569999999999977, -0.29200000000000004], "policy_red_v3_reward": [0.19439062500000281], "policy_red_v19_reward": [-2.034999999999999], "policy_red_v2_reward": [-1.525, 1.94121875], "policy_red_v1_reward": [-1.2099999999999822, 0.45599999999999996], "policy_red_v13_reward": [1.5267401128161695], "policy_red_v12_reward": [1.3792436585440782], "policy_red_v20_reward": [-0.28600000000000014], "policy_red_v18_reward": [0.3076932378161894, 0.4836932378161698], "policy_red_v14_reward": [-0.09930676218382961]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8012647749909999, "mean_inference_ms": 7.790472175126274, "mean_action_processing_ms": 0.2932101272352731, "mean_env_wait_ms": 0.3857475930014629, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10442709922790527, "StateBufferConnector_ms": 0.004338741302490234, "ViewRequirementAgentConnector_ms": 0.12000763416290283}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.08659675546514, "num_env_steps_trained_throughput_per_sec": 201.08659675546514, "timesteps_total": 216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 19758.533, "sample_time_ms": 1165.191, "learn_time_ms": 18508.254, "learn_throughput": 216.12, "synch_weights_time_ms": 82.671}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "episodes_total": 384, "training_iteration": 54, "trial_id": "a9680_00000", "date": "2023-09-24_02-55-22", "timestamp": 1695538522, "time_this_iter_s": 19.90189552307129, "time_total_s": 1072.9546375274658, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34439a20>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34419b40>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3441a0e0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1072.9546375274658, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 5.223333333333333, "ram_util_percent": 19.190000000000005}, "win_rate": 0.68, "league_size": 26}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2870911279072366, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.04117046929871625, "policy_loss": -0.053228809012216514, "vf_loss": 0.17808085056797912, "vf_explained_var": 0.6315371546273431, "kl": 0.01720232831789589, "entropy": 2.38219469388326, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 52320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 440000, "num_agent_steps_trained": 440000}, "sampler_results": {"episode_reward_max": 4.063290112816174, "episode_reward_min": -0.8229038949999959, "episode_reward_mean": 1.740805775220413, "episode_len_mean": 362.46, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"blue": -2.0219999999999985, "red": -5.069307457227051, "red_v5": -1.5219999999999998, "red_v8": -1.172999999999985, "red_v9": -1.5379999999999998, "red_v4": 1.3988749999999999, "red_v16": -1.5439999999999996, "red_v6": -1.52, "red_v7": -1.7189999999999472, "red_v11": -1.5569999999999977, "red_v3": 0.19439062500000281, "red_v10": -2.027999999999998, "red_v19": -2.034999999999999, "red_v17": -1.718999999999994, "red_v2": -1.525, "red_v1": -1.2099999999999822, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": -1.21, "red_v14": -0.09930676218382961, "red_v22": 0.4766932378161698}, "policy_reward_max": {"blue": 4.292203125000004, "red": 3.97867761281617, "red_v5": 0.19969323781617176, "red_v8": 1.586271362816173, "red_v9": 0.3532656249999999, "red_v4": 1.9199375, "red_v16": 0.37189062500000025, "red_v6": 3.323184614442594, "red_v7": 0.4741030335440548, "red_v11": 1.2271906250000004, "red_v3": 0.19439062500000281, "red_v10": 0.4996932378161698, "red_v19": 3.2936307378161738, "red_v17": 0.5520500000000093, "red_v2": 1.94121875, "red_v1": 0.45599999999999996, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.4836932378161698, "red_v14": -0.09930676218382961, "red_v22": 0.4766932378161698}, "policy_reward_mean": {"blue": -0.823839663461533, "red": 2.111796778739, "red_v5": -0.9257689207279292, "red_v8": -0.09293215929595297, "red_v9": -0.6415068561973001, "red_v4": 1.7286666666666666, "red_v16": -0.898703124999999, "red_v6": 0.4894996393053287, "red_v7": -0.4126958485759813, "red_v11": -0.41020234374999903, "red_v3": 0.19439062500000281, "red_v10": -0.6646533810919144, "red_v19": 0.6293153689080875, "red_v17": -0.25911270487352767, "red_v2": 0.20810937500000004, "red_v1": -0.3769999999999911, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": -0.13953784145588025, "red_v14": -0.09930676218382961, "red_v22": 0.4766932378161698}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836, 0.8046932378162143, 1.9653807378161698, 1.386568237816173, 0.39693750000000017, 4.063290112816174, 0.8139588628161758, 0.6751742300000054, 0.8803564894425933, 2.6000682378161866, 0.37969323781620246, 1.690883862816193, 0.5620838628161788, 0.7007244878161765, 3.865792725632345, -0.7771043322270501, 1.0912401128162172, 0.7085369878161885, 1.9676776128161704, 1.4105057378161714, 1.8867432378162499, 2.27966198781618, 2.078964600632354, 1.9036307378161736, 3.450724487816171, 0.673693237816217, 1.3260987927729422, 0.8926932378162121, 2.4650596144425925, 0.05651875000000128, 1.9874333506323607, 0.5652557378161749, 0.8865369878162115, 2.732633862816192, 0.7338182378161768, 1.7449368963602745, 1.3313437499999998, 2.310708862816176, 2.4836307378152043, 0.923474487816173, 2.721615112816205, 0.9555213628162148, 0.8540781250000001, 1.1628000000000003, 1.087802612816183, 0.9173651128161726, 1.8757557378161749, 2.851339600632374, 1.713005737816201, 0.8226932378162157, 1.9612713628161713, 1.8275023550000014, 2.2791619878161784, 2.189386475632428, 2.3534588628161752, 3.2758778522587706, 3.894968146360229, 2.2524432378161783, 0.6076932378162131, 0.768724487816211, 2.4512401128161705, 1.6618842835440633, 1.9787401128161908, 3.889902100632343, 0.8668651128161736, 2.3355057378161765, 0.19569323781520298, 0.7753182378162151, 1.8602088628161728, 1.8608807378161742, 2.2318963628161796, 1.5316307378162026, 1.8781307378161733, 3.8600271006323443, 1.5743304800000306, 1.9033026128161943, 1.5506182378161935, 2.404224487816172, 2.322224487816177, 2.4101151128161726, 0.9935838628161813, 2.7353239756323506, 3.8772458506323435, 3.9835896006323415, 0.9182869878161719, 0.9348651128161741, 1.2728125000000001, 2.775677612816176, 0.4654588628161769, 3.058214600632388, 3.809370850632349, 2.9447557378161706, 2.465974487816171, 1.9676811585440557, -0.8229038949999959], "episode_lengths": [49, 72, 1280, 152, 272, 337, 1280, 36, 104, 84, 113, 139, 131, 89, 264, 1280, 371, 355, 246, 126, 223, 1137, 562, 37, 60, 1280, 138, 423, 84, 54, 1280, 190, 1280, 24, 106, 465, 396, 818, 323, 216, 1139, 18, 155, 20, 70, 441, 1175, 71, 16, 253, 73, 108, 495, 604, 1280, 39, 58, 170, 1280, 107, 176, 105, 208, 1280, 1142, 49, 134, 401, 123, 105, 124, 1280, 1272, 59, 132, 223, 724, 116, 147, 593, 477, 552, 86, 150, 89, 387, 212, 141, 31, 66, 425, 60, 165, 363, 727, 165, 44, 38, 39, 188], "policy_blue_reward": [-2.0119999999999996, -1.0719999999999936, -1.0929999999999929, -2.01, 0.6530500000000008, 0.26603125000000016, 4.292203125000004, -2.0109999999999997, -1.5219999999999998, -1.3639999999999668, -1.0049999999999997, 0.971, 1.5438437500000035, 0.29112499999999997, -2.006, -1.055999999999996, -1.0059999999999996, -1.3109999999999704, -0.52, -2.005, -1.113999999999999, -2.0219999999999985, -2.0169999999999995, -1.0589999999999968, -1.368999999999968, -1.125999999999992, -0.8850000000000003, -1.3539999999999661, -1.0579999999999985, -1.190999999999982, -1.139999999999988, -1.0219999999999987, -1.0379999999999974, -1.0279999999999991, -1.1409999999999982, -0.519, -1.0139999999999996, -2.01, 1.9530000000000007], "policy_red_v5_reward": [-1.5219999999999998, 0.19969323781617176, -1.4549999999999594], "policy_red_v8_reward": [-0.18000000000000016, 1.586271362816173, -1.172999999999985, -0.6049999999999999], "policy_red_v9_reward": [-1.5379999999999998, -1.2069999999999796, 0.3532656249999999, -1.075999999999994, -0.7099999999999997, 0.32869323781617366], "policy_red_v4_reward": [1.3988749999999999, 1.9199375, 1.8671875], "policy_red_v16_reward": [0.37189062500000025, -1.5439999999999996, -1.5239999999999978], "policy_red_v6_reward": [-1.52, 2.644375000000002, -1.194999999999981, 0.9188437499999997, 0.488, -1.1699999999999855, 3.323184614442594, 0.4265937500000001], "policy_red_v7_reward": [-1.7189999999999472, -0.1209499999999962, 0.41767187500000014, 0.4741030335440548, -1.0129999999999995, -0.515], "policy_red_v11_reward": [1.2271906250000004, -1.0189999999999988, -1.5569999999999977, -0.29200000000000004], "policy_red_v3_reward": [0.19439062500000281], "policy_red_v10_reward": [0.4606932378161701, -1.591, -2.027999999999998, 0.4996932378161698], "policy_red_v19_reward": [-2.034999999999999, 3.2936307378161738], "policy_red_v17_reward": [-1.0859999999999952, 0.5520500000000093, 0.4786932378161699, 0.4786932378161719, -1.718999999999994], "policy_red_v2_reward": [-1.525, 1.94121875], "policy_red_v1_reward": [-1.2099999999999822, 0.45599999999999996], "policy_red_v13_reward": [1.5267401128161695], "policy_red_v12_reward": [1.3792436585440782], "policy_red_v20_reward": [-0.28600000000000014], "policy_red_v18_reward": [0.3076932378161894, 0.4836932378161698, -1.21], "policy_red_v14_reward": [-0.09930676218382961], "policy_red_v22_reward": [0.4766932378161698]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.802321398858027, "mean_inference_ms": 7.802186402343384, "mean_action_processing_ms": 0.29370959292084803, "mean_env_wait_ms": 0.38643072804830747, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10406792163848877, "StateBufferConnector_ms": 0.0043582916259765625, "ViewRequirementAgentConnector_ms": 0.12059283256530762}}, "episode_reward_max": 4.063290112816174, "episode_reward_min": -0.8229038949999959, "episode_reward_mean": 1.740805775220413, "episode_len_mean": 362.46, "episodes_this_iter": 16, "policy_reward_min": {"blue": -2.0219999999999985, "red": -5.069307457227051, "red_v5": -1.5219999999999998, "red_v8": -1.172999999999985, "red_v9": -1.5379999999999998, "red_v4": 1.3988749999999999, "red_v16": -1.5439999999999996, "red_v6": -1.52, "red_v7": -1.7189999999999472, "red_v11": -1.5569999999999977, "red_v3": 0.19439062500000281, "red_v10": -2.027999999999998, "red_v19": -2.034999999999999, "red_v17": -1.718999999999994, "red_v2": -1.525, "red_v1": -1.2099999999999822, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": -1.21, "red_v14": -0.09930676218382961, "red_v22": 0.4766932378161698}, "policy_reward_max": {"blue": 4.292203125000004, "red": 3.97867761281617, "red_v5": 0.19969323781617176, "red_v8": 1.586271362816173, "red_v9": 0.3532656249999999, "red_v4": 1.9199375, "red_v16": 0.37189062500000025, "red_v6": 3.323184614442594, "red_v7": 0.4741030335440548, "red_v11": 1.2271906250000004, "red_v3": 0.19439062500000281, "red_v10": 0.4996932378161698, "red_v19": 3.2936307378161738, "red_v17": 0.5520500000000093, "red_v2": 1.94121875, "red_v1": 0.45599999999999996, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": 0.4836932378161698, "red_v14": -0.09930676218382961, "red_v22": 0.4766932378161698}, "policy_reward_mean": {"blue": -0.823839663461533, "red": 2.111796778739, "red_v5": -0.9257689207279292, "red_v8": -0.09293215929595297, "red_v9": -0.6415068561973001, "red_v4": 1.7286666666666666, "red_v16": -0.898703124999999, "red_v6": 0.4894996393053287, "red_v7": -0.4126958485759813, "red_v11": -0.41020234374999903, "red_v3": 0.19439062500000281, "red_v10": -0.6646533810919144, "red_v19": 0.6293153689080875, "red_v17": -0.25911270487352767, "red_v2": 0.20810937500000004, "red_v1": -0.3769999999999911, "red_v13": 1.5267401128161695, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": -0.13953784145588025, "red_v14": -0.09930676218382961, "red_v22": 0.4766932378161698}, "hist_stats": {"episode_reward": [1.9576499085440553, 0.8026586050000021, 1.0176932378162151, 0.8112280335440551, 2.19144323781618, 2.1047401128161836, 0.8046932378162143, 1.9653807378161698, 1.386568237816173, 0.39693750000000017, 4.063290112816174, 0.8139588628161758, 0.6751742300000054, 0.8803564894425933, 2.6000682378161866, 0.37969323781620246, 1.690883862816193, 0.5620838628161788, 0.7007244878161765, 3.865792725632345, -0.7771043322270501, 1.0912401128162172, 0.7085369878161885, 1.9676776128161704, 1.4105057378161714, 1.8867432378162499, 2.27966198781618, 2.078964600632354, 1.9036307378161736, 3.450724487816171, 0.673693237816217, 1.3260987927729422, 0.8926932378162121, 2.4650596144425925, 0.05651875000000128, 1.9874333506323607, 0.5652557378161749, 0.8865369878162115, 2.732633862816192, 0.7338182378161768, 1.7449368963602745, 1.3313437499999998, 2.310708862816176, 2.4836307378152043, 0.923474487816173, 2.721615112816205, 0.9555213628162148, 0.8540781250000001, 1.1628000000000003, 1.087802612816183, 0.9173651128161726, 1.8757557378161749, 2.851339600632374, 1.713005737816201, 0.8226932378162157, 1.9612713628161713, 1.8275023550000014, 2.2791619878161784, 2.189386475632428, 2.3534588628161752, 3.2758778522587706, 3.894968146360229, 2.2524432378161783, 0.6076932378162131, 0.768724487816211, 2.4512401128161705, 1.6618842835440633, 1.9787401128161908, 3.889902100632343, 0.8668651128161736, 2.3355057378161765, 0.19569323781520298, 0.7753182378162151, 1.8602088628161728, 1.8608807378161742, 2.2318963628161796, 1.5316307378162026, 1.8781307378161733, 3.8600271006323443, 1.5743304800000306, 1.9033026128161943, 1.5506182378161935, 2.404224487816172, 2.322224487816177, 2.4101151128161726, 0.9935838628161813, 2.7353239756323506, 3.8772458506323435, 3.9835896006323415, 0.9182869878161719, 0.9348651128161741, 1.2728125000000001, 2.775677612816176, 0.4654588628161769, 3.058214600632388, 3.809370850632349, 2.9447557378161706, 2.465974487816171, 1.9676811585440557, -0.8229038949999959], "episode_lengths": [49, 72, 1280, 152, 272, 337, 1280, 36, 104, 84, 113, 139, 131, 89, 264, 1280, 371, 355, 246, 126, 223, 1137, 562, 37, 60, 1280, 138, 423, 84, 54, 1280, 190, 1280, 24, 106, 465, 396, 818, 323, 216, 1139, 18, 155, 20, 70, 441, 1175, 71, 16, 253, 73, 108, 495, 604, 1280, 39, 58, 170, 1280, 107, 176, 105, 208, 1280, 1142, 49, 134, 401, 123, 105, 124, 1280, 1272, 59, 132, 223, 724, 116, 147, 593, 477, 552, 86, 150, 89, 387, 212, 141, 31, 66, 425, 60, 165, 363, 727, 165, 44, 38, 39, 188], "policy_blue_reward": [-2.0119999999999996, -1.0719999999999936, -1.0929999999999929, -2.01, 0.6530500000000008, 0.26603125000000016, 4.292203125000004, -2.0109999999999997, -1.5219999999999998, -1.3639999999999668, -1.0049999999999997, 0.971, 1.5438437500000035, 0.29112499999999997, -2.006, -1.055999999999996, -1.0059999999999996, -1.3109999999999704, -0.52, -2.005, -1.113999999999999, -2.0219999999999985, -2.0169999999999995, -1.0589999999999968, -1.368999999999968, -1.125999999999992, -0.8850000000000003, -1.3539999999999661, -1.0579999999999985, -1.190999999999982, -1.139999999999988, -1.0219999999999987, -1.0379999999999974, -1.0279999999999991, -1.1409999999999982, -0.519, -1.0139999999999996, -2.01, 1.9530000000000007], "policy_red_v5_reward": [-1.5219999999999998, 0.19969323781617176, -1.4549999999999594], "policy_red_v8_reward": [-0.18000000000000016, 1.586271362816173, -1.172999999999985, -0.6049999999999999], "policy_red_v9_reward": [-1.5379999999999998, -1.2069999999999796, 0.3532656249999999, -1.075999999999994, -0.7099999999999997, 0.32869323781617366], "policy_red_v4_reward": [1.3988749999999999, 1.9199375, 1.8671875], "policy_red_v16_reward": [0.37189062500000025, -1.5439999999999996, -1.5239999999999978], "policy_red_v6_reward": [-1.52, 2.644375000000002, -1.194999999999981, 0.9188437499999997, 0.488, -1.1699999999999855, 3.323184614442594, 0.4265937500000001], "policy_red_v7_reward": [-1.7189999999999472, -0.1209499999999962, 0.41767187500000014, 0.4741030335440548, -1.0129999999999995, -0.515], "policy_red_v11_reward": [1.2271906250000004, -1.0189999999999988, -1.5569999999999977, -0.29200000000000004], "policy_red_v3_reward": [0.19439062500000281], "policy_red_v10_reward": [0.4606932378161701, -1.591, -2.027999999999998, 0.4996932378161698], "policy_red_v19_reward": [-2.034999999999999, 3.2936307378161738], "policy_red_v17_reward": [-1.0859999999999952, 0.5520500000000093, 0.4786932378161699, 0.4786932378161719, -1.718999999999994], "policy_red_v2_reward": [-1.525, 1.94121875], "policy_red_v1_reward": [-1.2099999999999822, 0.45599999999999996], "policy_red_v13_reward": [1.5267401128161695], "policy_red_v12_reward": [1.3792436585440782], "policy_red_v20_reward": [-0.28600000000000014], "policy_red_v18_reward": [0.3076932378161894, 0.4836932378161698, -1.21], "policy_red_v14_reward": [-0.09930676218382961], "policy_red_v22_reward": [0.4766932378161698]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.802321398858027, "mean_inference_ms": 7.802186402343384, "mean_action_processing_ms": 0.29370959292084803, "mean_env_wait_ms": 0.38643072804830747, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10406792163848877, "StateBufferConnector_ms": 0.0043582916259765625, "ViewRequirementAgentConnector_ms": 0.12059283256530762}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 440000, "num_agent_steps_trained": 440000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.6218421867741, "num_env_steps_trained_throughput_per_sec": 201.6218421867741, "timesteps_total": 220000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 440000, "timers": {"training_iteration_time_ms": 19815.35, "sample_time_ms": 1166.629, "learn_time_ms": 18563.455, "learn_throughput": 215.477, "synch_weights_time_ms": 82.859}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 440000, "num_agent_steps_trained": 440000}, "done": false, "episodes_total": 400, "training_iteration": 55, "trial_id": "a9680_00000", "date": "2023-09-24_02-55-43", "timestamp": 1695538543, "time_this_iter_s": 19.848129272460938, "time_total_s": 1092.8027667999268, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b3443b760>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3441a200>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3441a560>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1092.8027667999268, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 5.10967741935484, "ram_util_percent": 19.380645161290317}, "win_rate": 0.63, "league_size": 26}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9385578533013663, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.016173853802805147, "policy_loss": -0.05069902025376602, "vf_loss": 0.12402223895381516, "vf_explained_var": 0.608678319118917, "kl": 0.015995929705316787, "entropy": 2.3364136641224227, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 53280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "sampler_results": {"episode_reward_max": 4.249052612816173, "episode_reward_min": -2.737822387183771, "episode_reward_mean": 1.7682578967784337, "episode_len_mean": 369.22, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"red_v7": -1.7189999999999472, "red": -5.958822387183821, "red_v11": -1.5569999999999977, "red_v3": 0.19439062500000281, "blue": -2.0219999999999985, "red_v10": -2.027999999999998, "red_v6": -1.194999999999981, "red_v19": -2.034999999999999, "red_v17": -1.718999999999994, "red_v8": -1.172999999999985, "red_v2": -1.525, "red_v1": -1.2099999999999822, "red_v13": 1.5267401128161695, "red_v16": -1.5439999999999996, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": -1.21, "red_v9": -1.075999999999994, "red_v5": -1.4549999999999594, "red_v4": 1.8671875, "red_v14": -0.09930676218382961, "red_v22": 0.4766932378161698}, "policy_reward_max": {"red_v7": 0.4741030335440548, "red": 3.97867761281617, "red_v11": 1.2271906250000004, "red_v3": 1.9464375, "blue": 4.292203125000004, "red_v10": 0.4996932378161698, "red_v6": 3.323184614442594, "red_v19": 3.2936307378161738, "red_v17": 0.5520500000000093, "red_v8": 1.586271362816173, "red_v2": 1.94121875, "red_v1": 0.45599999999999996, "red_v13": 1.5267401128161695, "red_v16": -1.5239999999999978, "red_v12": 2.43178125, "red_v20": -0.28600000000000014, "red_v18": 0.4836932378161698, "red_v9": 0.32869323781617366, "red_v5": 0.19969323781617176, "red_v4": 1.8671875, "red_v14": 0.44193461444259247, "red_v22": 0.4766932378161698}, "policy_reward_mean": {"red_v7": -0.4126958485759813, "red": 2.086840804152594, "red_v11": -0.41020234374999903, "red_v3": 1.0704140625000014, "blue": -0.6666772017045398, "red_v10": -0.6646533810919144, "red_v6": 0.31823887349180396, "red_v19": 0.6293153689080875, "red_v17": -0.3975939207279397, "red_v8": -0.06390954572793724, "red_v2": 0.20810937500000004, "red_v1": -0.3769999999999911, "red_v13": 1.5267401128161695, "red_v16": -1.5339999999999987, "red_v12": 1.905512454272039, "red_v20": -0.28600000000000014, "red_v18": -0.13953784145588025, "red_v9": -0.48576892072794003, "red_v5": -0.6276533810918938, "red_v4": 1.8671875, "red_v14": 0.17131392612938143, "red_v22": 0.4766932378161698}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.37969323781620246, 1.690883862816193, 0.5620838628161788, 0.7007244878161765, 3.865792725632345, -0.7771043322270501, 1.0912401128162172, 0.7085369878161885, 1.9676776128161704, 1.4105057378161714, 1.8867432378162499, 2.27966198781618, 2.078964600632354, 1.9036307378161736, 3.450724487816171, 0.673693237816217, 1.3260987927729422, 0.8926932378162121, 2.4650596144425925, 0.05651875000000128, 1.9874333506323607, 0.5652557378161749, 0.8865369878162115, 2.732633862816192, 0.7338182378161768, 1.7449368963602745, 1.3313437499999998, 2.310708862816176, 2.4836307378152043, 0.923474487816173, 2.721615112816205, 0.9555213628162148, 0.8540781250000001, 1.1628000000000003, 1.087802612816183, 0.9173651128161726, 1.8757557378161749, 2.851339600632374, 1.713005737816201, 0.8226932378162157, 1.9612713628161713, 1.8275023550000014, 2.2791619878161784, 2.189386475632428, 2.3534588628161752, 3.2758778522587706, 3.894968146360229, 2.2524432378161783, 0.6076932378162131, 0.768724487816211, 2.4512401128161705, 1.6618842835440633, 1.9787401128161908, 3.889902100632343, 0.8668651128161736, 2.3355057378161765, 0.19569323781520298, 0.7753182378162151, 1.8602088628161728, 1.8608807378161742, 2.2318963628161796, 1.5316307378162026, 1.8781307378161733, 3.8600271006323443, 1.5743304800000306, 1.9033026128161943, 1.5506182378161935, 2.404224487816172, 2.322224487816177, 2.4101151128161726, 0.9935838628161813, 2.7353239756323506, 3.8772458506323435, 3.9835896006323415, 0.9182869878161719, 0.9348651128161741, 1.2728125000000001, 2.775677612816176, 0.4654588628161769, 3.058214600632388, 3.809370850632349, 2.9447557378161706, 2.465974487816171, 1.9676811585440557, -0.8229038949999959, 3.8473622272587678, 1.4728963628152034, -0.12585937499999988, -2.737822387183771, 1.3768148550000001, 2.418927612816172, 2.4334744878161714, 1.3273283644426501, 1.9491307378161697, 4.249052612816173, 1.3126932378162357, 2.319349487816174, 1.2928807378161755, 2.9093026128161723, 1.1715213628162058], "episode_lengths": [1280, 371, 355, 246, 126, 223, 1137, 562, 37, 60, 1280, 138, 423, 84, 54, 1280, 190, 1280, 24, 106, 465, 396, 818, 323, 216, 1139, 18, 155, 20, 70, 441, 1175, 71, 16, 253, 73, 108, 495, 604, 1280, 39, 58, 170, 1280, 107, 176, 105, 208, 1280, 1142, 49, 134, 401, 123, 105, 124, 1280, 1272, 59, 132, 223, 724, 116, 147, 593, 477, 552, 86, 150, 89, 387, 212, 141, 31, 66, 425, 60, 165, 363, 727, 165, 44, 38, 39, 188, 117, 31, 51, 837, 22, 85, 70, 1042, 52, 109, 1280, 174, 132, 93, 983], "policy_red_v7_reward": [-1.7189999999999472, -0.1209499999999962, 0.41767187500000014, 0.4741030335440548, -1.0129999999999995, -0.515], "policy_red_v11_reward": [1.2271906250000004, -1.0189999999999988, -1.5569999999999977, -0.29200000000000004], "policy_red_v3_reward": [0.19439062500000281, 1.9464375], "policy_blue_reward": [0.26603125000000016, 4.292203125000004, -2.0109999999999997, -1.5219999999999998, -1.3639999999999668, -1.0049999999999997, 0.971, 1.5438437500000035, 0.29112499999999997, -2.006, -1.055999999999996, -1.0059999999999996, -1.3109999999999704, -0.52, -2.005, -1.113999999999999, -2.0219999999999985, -2.0169999999999995, -1.0589999999999968, -1.368999999999968, -1.125999999999992, -0.8850000000000003, -1.3539999999999661, -1.0579999999999985, -1.190999999999982, -1.139999999999988, -1.0219999999999987, -1.0379999999999974, -1.0279999999999991, -1.1409999999999982, -0.519, -1.0139999999999996, -2.01, 1.9530000000000007, -2.0059999999999993, -1.5179999999999998, 3.2210000000000027, -2.002, -1.0259999999999978, 1.3220000000000007, 1.588000000000018, -1.0459999999999958, -0.023000000000000013, -1.2479999999999756], "policy_red_v10_reward": [0.4606932378161701, -1.591, -2.027999999999998, 0.4996932378161698], "policy_red_v6_reward": [-1.194999999999981, 0.9188437499999997, 0.488, -1.1699999999999855, 3.323184614442594, 0.4265937500000001, -0.5639499999999991], "policy_red_v19_reward": [-2.034999999999999, 3.2936307378161738], "policy_red_v17_reward": [-1.0859999999999952, 0.5520500000000093, 0.4786932378161699, 0.4786932378161719, -1.718999999999994, -1.0899999999999999], "policy_red_v8_reward": [1.586271362816173, -1.172999999999985, -0.6049999999999999], "policy_red_v2_reward": [-1.525, 1.94121875], "policy_red_v1_reward": [-1.2099999999999822, 0.45599999999999996], "policy_red_v13_reward": [1.5267401128161695], "policy_red_v16_reward": [-1.5439999999999996, -1.5239999999999978], "policy_red_v12_reward": [1.3792436585440782, 2.43178125], "policy_red_v20_reward": [-0.28600000000000014], "policy_red_v18_reward": [0.3076932378161894, 0.4836932378161698, -1.21], "policy_red_v9_reward": [-1.075999999999994, -0.7099999999999997, 0.32869323781617366], "policy_red_v5_reward": [0.19969323781617176, -1.4549999999999594], "policy_red_v4_reward": [1.8671875], "policy_red_v14_reward": [-0.09930676218382961, 0.44193461444259247], "policy_red_v22_reward": [0.4766932378161698]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8035500055775517, "mean_inference_ms": 7.808514410339256, "mean_action_processing_ms": 0.29397284527478784, "mean_env_wait_ms": 0.38717630954607857, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10411310195922852, "StateBufferConnector_ms": 0.004379868507385254, "ViewRequirementAgentConnector_ms": 0.12098515033721924}}, "episode_reward_max": 4.249052612816173, "episode_reward_min": -2.737822387183771, "episode_reward_mean": 1.7682578967784337, "episode_len_mean": 369.22, "episodes_this_iter": 15, "policy_reward_min": {"red_v7": -1.7189999999999472, "red": -5.958822387183821, "red_v11": -1.5569999999999977, "red_v3": 0.19439062500000281, "blue": -2.0219999999999985, "red_v10": -2.027999999999998, "red_v6": -1.194999999999981, "red_v19": -2.034999999999999, "red_v17": -1.718999999999994, "red_v8": -1.172999999999985, "red_v2": -1.525, "red_v1": -1.2099999999999822, "red_v13": 1.5267401128161695, "red_v16": -1.5439999999999996, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v18": -1.21, "red_v9": -1.075999999999994, "red_v5": -1.4549999999999594, "red_v4": 1.8671875, "red_v14": -0.09930676218382961, "red_v22": 0.4766932378161698}, "policy_reward_max": {"red_v7": 0.4741030335440548, "red": 3.97867761281617, "red_v11": 1.2271906250000004, "red_v3": 1.9464375, "blue": 4.292203125000004, "red_v10": 0.4996932378161698, "red_v6": 3.323184614442594, "red_v19": 3.2936307378161738, "red_v17": 0.5520500000000093, "red_v8": 1.586271362816173, "red_v2": 1.94121875, "red_v1": 0.45599999999999996, "red_v13": 1.5267401128161695, "red_v16": -1.5239999999999978, "red_v12": 2.43178125, "red_v20": -0.28600000000000014, "red_v18": 0.4836932378161698, "red_v9": 0.32869323781617366, "red_v5": 0.19969323781617176, "red_v4": 1.8671875, "red_v14": 0.44193461444259247, "red_v22": 0.4766932378161698}, "policy_reward_mean": {"red_v7": -0.4126958485759813, "red": 2.086840804152594, "red_v11": -0.41020234374999903, "red_v3": 1.0704140625000014, "blue": -0.6666772017045398, "red_v10": -0.6646533810919144, "red_v6": 0.31823887349180396, "red_v19": 0.6293153689080875, "red_v17": -0.3975939207279397, "red_v8": -0.06390954572793724, "red_v2": 0.20810937500000004, "red_v1": -0.3769999999999911, "red_v13": 1.5267401128161695, "red_v16": -1.5339999999999987, "red_v12": 1.905512454272039, "red_v20": -0.28600000000000014, "red_v18": -0.13953784145588025, "red_v9": -0.48576892072794003, "red_v5": -0.6276533810918938, "red_v4": 1.8671875, "red_v14": 0.17131392612938143, "red_v22": 0.4766932378161698}, "hist_stats": {"episode_reward": [0.37969323781620246, 1.690883862816193, 0.5620838628161788, 0.7007244878161765, 3.865792725632345, -0.7771043322270501, 1.0912401128162172, 0.7085369878161885, 1.9676776128161704, 1.4105057378161714, 1.8867432378162499, 2.27966198781618, 2.078964600632354, 1.9036307378161736, 3.450724487816171, 0.673693237816217, 1.3260987927729422, 0.8926932378162121, 2.4650596144425925, 0.05651875000000128, 1.9874333506323607, 0.5652557378161749, 0.8865369878162115, 2.732633862816192, 0.7338182378161768, 1.7449368963602745, 1.3313437499999998, 2.310708862816176, 2.4836307378152043, 0.923474487816173, 2.721615112816205, 0.9555213628162148, 0.8540781250000001, 1.1628000000000003, 1.087802612816183, 0.9173651128161726, 1.8757557378161749, 2.851339600632374, 1.713005737816201, 0.8226932378162157, 1.9612713628161713, 1.8275023550000014, 2.2791619878161784, 2.189386475632428, 2.3534588628161752, 3.2758778522587706, 3.894968146360229, 2.2524432378161783, 0.6076932378162131, 0.768724487816211, 2.4512401128161705, 1.6618842835440633, 1.9787401128161908, 3.889902100632343, 0.8668651128161736, 2.3355057378161765, 0.19569323781520298, 0.7753182378162151, 1.8602088628161728, 1.8608807378161742, 2.2318963628161796, 1.5316307378162026, 1.8781307378161733, 3.8600271006323443, 1.5743304800000306, 1.9033026128161943, 1.5506182378161935, 2.404224487816172, 2.322224487816177, 2.4101151128161726, 0.9935838628161813, 2.7353239756323506, 3.8772458506323435, 3.9835896006323415, 0.9182869878161719, 0.9348651128161741, 1.2728125000000001, 2.775677612816176, 0.4654588628161769, 3.058214600632388, 3.809370850632349, 2.9447557378161706, 2.465974487816171, 1.9676811585440557, -0.8229038949999959, 3.8473622272587678, 1.4728963628152034, -0.12585937499999988, -2.737822387183771, 1.3768148550000001, 2.418927612816172, 2.4334744878161714, 1.3273283644426501, 1.9491307378161697, 4.249052612816173, 1.3126932378162357, 2.319349487816174, 1.2928807378161755, 2.9093026128161723, 1.1715213628162058], "episode_lengths": [1280, 371, 355, 246, 126, 223, 1137, 562, 37, 60, 1280, 138, 423, 84, 54, 1280, 190, 1280, 24, 106, 465, 396, 818, 323, 216, 1139, 18, 155, 20, 70, 441, 1175, 71, 16, 253, 73, 108, 495, 604, 1280, 39, 58, 170, 1280, 107, 176, 105, 208, 1280, 1142, 49, 134, 401, 123, 105, 124, 1280, 1272, 59, 132, 223, 724, 116, 147, 593, 477, 552, 86, 150, 89, 387, 212, 141, 31, 66, 425, 60, 165, 363, 727, 165, 44, 38, 39, 188, 117, 31, 51, 837, 22, 85, 70, 1042, 52, 109, 1280, 174, 132, 93, 983], "policy_red_v7_reward": [-1.7189999999999472, -0.1209499999999962, 0.41767187500000014, 0.4741030335440548, -1.0129999999999995, -0.515], "policy_red_v11_reward": [1.2271906250000004, -1.0189999999999988, -1.5569999999999977, -0.29200000000000004], "policy_red_v3_reward": [0.19439062500000281, 1.9464375], "policy_blue_reward": [0.26603125000000016, 4.292203125000004, -2.0109999999999997, -1.5219999999999998, -1.3639999999999668, -1.0049999999999997, 0.971, 1.5438437500000035, 0.29112499999999997, -2.006, -1.055999999999996, -1.0059999999999996, -1.3109999999999704, -0.52, -2.005, -1.113999999999999, -2.0219999999999985, -2.0169999999999995, -1.0589999999999968, -1.368999999999968, -1.125999999999992, -0.8850000000000003, -1.3539999999999661, -1.0579999999999985, -1.190999999999982, -1.139999999999988, -1.0219999999999987, -1.0379999999999974, -1.0279999999999991, -1.1409999999999982, -0.519, -1.0139999999999996, -2.01, 1.9530000000000007, -2.0059999999999993, -1.5179999999999998, 3.2210000000000027, -2.002, -1.0259999999999978, 1.3220000000000007, 1.588000000000018, -1.0459999999999958, -0.023000000000000013, -1.2479999999999756], "policy_red_v10_reward": [0.4606932378161701, -1.591, -2.027999999999998, 0.4996932378161698], "policy_red_v6_reward": [-1.194999999999981, 0.9188437499999997, 0.488, -1.1699999999999855, 3.323184614442594, 0.4265937500000001, -0.5639499999999991], "policy_red_v19_reward": [-2.034999999999999, 3.2936307378161738], "policy_red_v17_reward": [-1.0859999999999952, 0.5520500000000093, 0.4786932378161699, 0.4786932378161719, -1.718999999999994, -1.0899999999999999], "policy_red_v8_reward": [1.586271362816173, -1.172999999999985, -0.6049999999999999], "policy_red_v2_reward": [-1.525, 1.94121875], "policy_red_v1_reward": [-1.2099999999999822, 0.45599999999999996], "policy_red_v13_reward": [1.5267401128161695], "policy_red_v16_reward": [-1.5439999999999996, -1.5239999999999978], "policy_red_v12_reward": [1.3792436585440782, 2.43178125], "policy_red_v20_reward": [-0.28600000000000014], "policy_red_v18_reward": [0.3076932378161894, 0.4836932378161698, -1.21], "policy_red_v9_reward": [-1.075999999999994, -0.7099999999999997, 0.32869323781617366], "policy_red_v5_reward": [0.19969323781617176, -1.4549999999999594], "policy_red_v4_reward": [1.8671875], "policy_red_v14_reward": [-0.09930676218382961, 0.44193461444259247], "policy_red_v22_reward": [0.4766932378161698]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8035500055775517, "mean_inference_ms": 7.808514410339256, "mean_action_processing_ms": 0.29397284527478784, "mean_env_wait_ms": 0.38717630954607857, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10411310195922852, "StateBufferConnector_ms": 0.004379868507385254, "ViewRequirementAgentConnector_ms": 0.12098515033721924}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.44811678513935, "num_env_steps_trained_throughput_per_sec": 201.44811678513935, "timesteps_total": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 19923.734, "sample_time_ms": 1172.395, "learn_time_ms": 18666.211, "learn_throughput": 214.291, "synch_weights_time_ms": 82.713}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "episodes_total": 415, "training_iteration": 56, "trial_id": "a9680_00000", "date": "2023-09-24_02-56-04", "timestamp": 1695538564, "time_this_iter_s": 19.869965076446533, "time_total_s": 1112.6727318763733, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b342ec760>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b342cc940>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b342cc9d0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1112.6727318763733, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 4.879310344827587, "ram_util_percent": 19.4}, "win_rate": 0.63, "league_size": 26}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.113738976791501, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.010539670984144323, "policy_loss": -0.058560598537345264, "vf_loss": 0.12748823180251445, "vf_explained_var": 0.6247791642323136, "kl": 0.017262775914393083, "entropy": 2.412094990412394, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 54240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 456000, "num_agent_steps_trained": 456000}, "sampler_results": {"episode_reward_max": 4.249052612816173, "episode_reward_min": -2.737822387183771, "episode_reward_mean": 1.8480291075084136, "episode_len_mean": 316.25, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"red_v13": 1.5267401128161695, "red": -5.958822387183821, "red_v16": -2.0039999999999996, "blue": -2.0219999999999985, "red_v17": -1.718999999999994, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v7": -1.0129999999999995, "red_v18": -1.21, "red_v6": -2.013, "red_v8": -1.172999999999985, "red_v2": -2.0179999999999993, "red_v9": -1.075999999999994, "red_v5": -1.4549999999999594, "red_v11": -1.5569999999999977, "red_v1": 0.45599999999999996, "red_v10": -2.027999999999998, "red_v4": 1.8671875, "red_v14": -2.0069999999999997, "red_v19": 3.2936307378161738, "red_v22": -1.043999999999998, "red_v3": -2.01}, "policy_reward_max": {"red_v13": 1.5267401128161695, "red": 3.98781823781617, "red_v16": -1.5239999999999978, "blue": 3.2210000000000027, "red_v17": 1.973203125, "red_v12": 2.43178125, "red_v20": -0.28600000000000014, "red_v7": 0.4741030335440548, "red_v18": 0.6570500000000006, "red_v6": 3.323184614442594, "red_v8": -0.6049999999999999, "red_v2": 1.94121875, "red_v9": 2.304421875, "red_v5": 0.19969323781617176, "red_v11": -0.29200000000000004, "red_v1": 0.45599999999999996, "red_v10": 0.4996932378161698, "red_v4": 1.8671875, "red_v14": 3.325021362816173, "red_v19": 3.2936307378161738, "red_v22": 0.4766932378161698, "red_v3": 1.9464375}, "policy_reward_mean": {"red_v13": 1.5267401128161695, "red": 2.231325384760736, "red_v16": -1.6906666666666659, "blue": -0.7975746527777717, "red_v17": 0.11227326677205951, "red_v12": 1.905512454272039, "red_v20": -0.28600000000000014, "red_v7": -0.15905627286398613, "red_v18": 0.05960911890808995, "red_v6": 0.0005656728885218953, "red_v8": -0.8889999999999925, "red_v2": -0.03839062499999968, "red_v9": 0.211778778204045, "red_v5": -0.6276533810918938, "red_v11": -0.955999999999999, "red_v1": 0.45599999999999996, "red_v10": -1.1665766905459565, "red_v4": 1.8671875, "red_v14": 0.42282359301498723, "red_v19": 3.2936307378161738, "red_v22": -0.2836533810919141, "red_v3": -0.03178124999999987}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.9874333506323607, 0.5652557378161749, 0.8865369878162115, 2.732633862816192, 0.7338182378161768, 1.7449368963602745, 1.3313437499999998, 2.310708862816176, 2.4836307378152043, 0.923474487816173, 2.721615112816205, 0.9555213628162148, 0.8540781250000001, 1.1628000000000003, 1.087802612816183, 0.9173651128161726, 1.8757557378161749, 2.851339600632374, 1.713005737816201, 0.8226932378162157, 1.9612713628161713, 1.8275023550000014, 2.2791619878161784, 2.189386475632428, 2.3534588628161752, 3.2758778522587706, 3.894968146360229, 2.2524432378161783, 0.6076932378162131, 0.768724487816211, 2.4512401128161705, 1.6618842835440633, 1.9787401128161908, 3.889902100632343, 0.8668651128161736, 2.3355057378161765, 0.19569323781520298, 0.7753182378162151, 1.8602088628161728, 1.8608807378161742, 2.2318963628161796, 1.5316307378162026, 1.8781307378161733, 3.8600271006323443, 1.5743304800000306, 1.9033026128161943, 1.5506182378161935, 2.404224487816172, 2.322224487816177, 2.4101151128161726, 0.9935838628161813, 2.7353239756323506, 3.8772458506323435, 3.9835896006323415, 0.9182869878161719, 0.9348651128161741, 1.2728125000000001, 2.775677612816176, 0.4654588628161769, 3.058214600632388, 3.809370850632349, 2.9447557378161706, 2.465974487816171, 1.9676811585440557, -0.8229038949999959, 3.8473622272587678, 1.4728963628152034, -0.12585937499999988, -2.737822387183771, 1.3768148550000001, 2.418927612816172, 2.4334744878161714, 1.3273283644426501, 1.9491307378161697, 4.249052612816173, 1.3126932378162357, 2.319349487816174, 1.2928807378161755, 2.9093026128161723, 1.1715213628162058, 2.2891151128161757, 0.8169588628161747, 0.828474487816213, 2.3814901128161745, 2.4428026128161715, 3.2857146006323497, 4.093540112816173, 1.9748182378161705, 0.7591307378161717, 1.9605994878161903, 1.4638651128161704, 1.9831151128161701, 1.450052612816171, 0.7214276128162022, 1.485743658544055, 2.437396362816172, 0.9561619878161707, 1.6414901128162114, 1.9591377394425922, 1.6599093750000002], "episode_lengths": [465, 396, 818, 323, 216, 1139, 18, 155, 20, 70, 441, 1175, 71, 16, 253, 73, 108, 495, 604, 1280, 39, 58, 170, 1280, 107, 176, 105, 208, 1280, 1142, 49, 134, 401, 123, 105, 124, 1280, 1272, 59, 132, 223, 724, 116, 147, 593, 477, 552, 86, 150, 89, 387, 212, 141, 31, 66, 425, 60, 165, 363, 727, 165, 44, 38, 39, 188, 117, 31, 51, 837, 22, 85, 70, 1042, 52, 109, 1280, 174, 132, 93, 983, 153, 139, 1094, 97, 61, 183, 97, 24, 180, 478, 41, 25, 45, 629, 19, 63, 42, 545, 31, 13], "policy_red_v13_reward": [1.5267401128161695], "policy_red_v16_reward": [-1.5439999999999996, -1.5239999999999978, -2.0039999999999996], "policy_blue_reward": [1.5438437500000035, 0.29112499999999997, -2.006, -1.055999999999996, -1.0059999999999996, -1.3109999999999704, -0.52, -2.005, -1.113999999999999, -2.0219999999999985, -2.0169999999999995, -1.0589999999999968, -1.368999999999968, -1.125999999999992, -0.8850000000000003, -1.3539999999999661, -1.0579999999999985, -1.190999999999982, -1.139999999999988, -1.0219999999999987, -1.0379999999999974, -1.0279999999999991, -1.1409999999999982, -0.519, -1.0139999999999996, -2.01, 1.9530000000000007, -2.0059999999999993, -1.5179999999999998, 3.2210000000000027, -2.002, -1.0259999999999978, 1.3220000000000007, 1.588000000000018, -1.0459999999999958, -0.023000000000000013, -1.2479999999999756, -1.3179999999999699, -1.0139999999999998, -1.5519999999999994, -1.1309999999999891, 1.459171875, -1.1920000000000002, -1.0179999999999993, -1.1639999999999855], "policy_red_v17_reward": [0.5520500000000093, 0.4786932378161699, 0.4786932378161719, -1.718999999999994, -1.0899999999999999, 1.973203125], "policy_red_v12_reward": [1.3792436585440782, 2.43178125], "policy_red_v20_reward": [-0.28600000000000014], "policy_red_v7_reward": [0.41767187500000014, 0.4741030335440548, -1.0129999999999995, -0.515], "policy_red_v18_reward": [0.3076932378161894, 0.4836932378161698, -1.21, 0.6570500000000006], "policy_red_v6_reward": [-1.1699999999999855, 3.323184614442594, 0.4265937500000001, -0.5639499999999991, -2.013], "policy_red_v8_reward": [-1.172999999999985, -0.6049999999999999], "policy_red_v2_reward": [1.94121875, -2.0179999999999993], "policy_red_v9_reward": [-1.075999999999994, -0.7099999999999997, 0.32869323781617366, 2.304421875], "policy_red_v5_reward": [0.19969323781617176, -1.4549999999999594], "policy_red_v11_reward": [-1.0189999999999988, -1.5569999999999977, -0.29200000000000004], "policy_red_v1_reward": [0.45599999999999996], "policy_red_v10_reward": [-1.591, -2.027999999999998, 0.4996932378161698, -1.5469999999999975], "policy_red_v4_reward": [1.8671875], "policy_red_v14_reward": [-0.09930676218382961, 0.44193461444259247, 3.325021362816173, -2.0069999999999997, 0.45346875], "policy_red_v19_reward": [3.2936307378161738], "policy_red_v22_reward": [0.4766932378161698, -1.043999999999998], "policy_red_v3_reward": [1.9464375, -2.01]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8041276120524427, "mean_inference_ms": 7.799192861428662, "mean_action_processing_ms": 0.2933639073221691, "mean_env_wait_ms": 0.38671798750896735, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10482943058013916, "StateBufferConnector_ms": 0.004430413246154785, "ViewRequirementAgentConnector_ms": 0.12171852588653564}}, "episode_reward_max": 4.249052612816173, "episode_reward_min": -2.737822387183771, "episode_reward_mean": 1.8480291075084136, "episode_len_mean": 316.25, "episodes_this_iter": 20, "policy_reward_min": {"red_v13": 1.5267401128161695, "red": -5.958822387183821, "red_v16": -2.0039999999999996, "blue": -2.0219999999999985, "red_v17": -1.718999999999994, "red_v12": 1.3792436585440782, "red_v20": -0.28600000000000014, "red_v7": -1.0129999999999995, "red_v18": -1.21, "red_v6": -2.013, "red_v8": -1.172999999999985, "red_v2": -2.0179999999999993, "red_v9": -1.075999999999994, "red_v5": -1.4549999999999594, "red_v11": -1.5569999999999977, "red_v1": 0.45599999999999996, "red_v10": -2.027999999999998, "red_v4": 1.8671875, "red_v14": -2.0069999999999997, "red_v19": 3.2936307378161738, "red_v22": -1.043999999999998, "red_v3": -2.01}, "policy_reward_max": {"red_v13": 1.5267401128161695, "red": 3.98781823781617, "red_v16": -1.5239999999999978, "blue": 3.2210000000000027, "red_v17": 1.973203125, "red_v12": 2.43178125, "red_v20": -0.28600000000000014, "red_v7": 0.4741030335440548, "red_v18": 0.6570500000000006, "red_v6": 3.323184614442594, "red_v8": -0.6049999999999999, "red_v2": 1.94121875, "red_v9": 2.304421875, "red_v5": 0.19969323781617176, "red_v11": -0.29200000000000004, "red_v1": 0.45599999999999996, "red_v10": 0.4996932378161698, "red_v4": 1.8671875, "red_v14": 3.325021362816173, "red_v19": 3.2936307378161738, "red_v22": 0.4766932378161698, "red_v3": 1.9464375}, "policy_reward_mean": {"red_v13": 1.5267401128161695, "red": 2.231325384760736, "red_v16": -1.6906666666666659, "blue": -0.7975746527777717, "red_v17": 0.11227326677205951, "red_v12": 1.905512454272039, "red_v20": -0.28600000000000014, "red_v7": -0.15905627286398613, "red_v18": 0.05960911890808995, "red_v6": 0.0005656728885218953, "red_v8": -0.8889999999999925, "red_v2": -0.03839062499999968, "red_v9": 0.211778778204045, "red_v5": -0.6276533810918938, "red_v11": -0.955999999999999, "red_v1": 0.45599999999999996, "red_v10": -1.1665766905459565, "red_v4": 1.8671875, "red_v14": 0.42282359301498723, "red_v19": 3.2936307378161738, "red_v22": -0.2836533810919141, "red_v3": -0.03178124999999987}, "hist_stats": {"episode_reward": [1.9874333506323607, 0.5652557378161749, 0.8865369878162115, 2.732633862816192, 0.7338182378161768, 1.7449368963602745, 1.3313437499999998, 2.310708862816176, 2.4836307378152043, 0.923474487816173, 2.721615112816205, 0.9555213628162148, 0.8540781250000001, 1.1628000000000003, 1.087802612816183, 0.9173651128161726, 1.8757557378161749, 2.851339600632374, 1.713005737816201, 0.8226932378162157, 1.9612713628161713, 1.8275023550000014, 2.2791619878161784, 2.189386475632428, 2.3534588628161752, 3.2758778522587706, 3.894968146360229, 2.2524432378161783, 0.6076932378162131, 0.768724487816211, 2.4512401128161705, 1.6618842835440633, 1.9787401128161908, 3.889902100632343, 0.8668651128161736, 2.3355057378161765, 0.19569323781520298, 0.7753182378162151, 1.8602088628161728, 1.8608807378161742, 2.2318963628161796, 1.5316307378162026, 1.8781307378161733, 3.8600271006323443, 1.5743304800000306, 1.9033026128161943, 1.5506182378161935, 2.404224487816172, 2.322224487816177, 2.4101151128161726, 0.9935838628161813, 2.7353239756323506, 3.8772458506323435, 3.9835896006323415, 0.9182869878161719, 0.9348651128161741, 1.2728125000000001, 2.775677612816176, 0.4654588628161769, 3.058214600632388, 3.809370850632349, 2.9447557378161706, 2.465974487816171, 1.9676811585440557, -0.8229038949999959, 3.8473622272587678, 1.4728963628152034, -0.12585937499999988, -2.737822387183771, 1.3768148550000001, 2.418927612816172, 2.4334744878161714, 1.3273283644426501, 1.9491307378161697, 4.249052612816173, 1.3126932378162357, 2.319349487816174, 1.2928807378161755, 2.9093026128161723, 1.1715213628162058, 2.2891151128161757, 0.8169588628161747, 0.828474487816213, 2.3814901128161745, 2.4428026128161715, 3.2857146006323497, 4.093540112816173, 1.9748182378161705, 0.7591307378161717, 1.9605994878161903, 1.4638651128161704, 1.9831151128161701, 1.450052612816171, 0.7214276128162022, 1.485743658544055, 2.437396362816172, 0.9561619878161707, 1.6414901128162114, 1.9591377394425922, 1.6599093750000002], "episode_lengths": [465, 396, 818, 323, 216, 1139, 18, 155, 20, 70, 441, 1175, 71, 16, 253, 73, 108, 495, 604, 1280, 39, 58, 170, 1280, 107, 176, 105, 208, 1280, 1142, 49, 134, 401, 123, 105, 124, 1280, 1272, 59, 132, 223, 724, 116, 147, 593, 477, 552, 86, 150, 89, 387, 212, 141, 31, 66, 425, 60, 165, 363, 727, 165, 44, 38, 39, 188, 117, 31, 51, 837, 22, 85, 70, 1042, 52, 109, 1280, 174, 132, 93, 983, 153, 139, 1094, 97, 61, 183, 97, 24, 180, 478, 41, 25, 45, 629, 19, 63, 42, 545, 31, 13], "policy_red_v13_reward": [1.5267401128161695], "policy_red_v16_reward": [-1.5439999999999996, -1.5239999999999978, -2.0039999999999996], "policy_blue_reward": [1.5438437500000035, 0.29112499999999997, -2.006, -1.055999999999996, -1.0059999999999996, -1.3109999999999704, -0.52, -2.005, -1.113999999999999, -2.0219999999999985, -2.0169999999999995, -1.0589999999999968, -1.368999999999968, -1.125999999999992, -0.8850000000000003, -1.3539999999999661, -1.0579999999999985, -1.190999999999982, -1.139999999999988, -1.0219999999999987, -1.0379999999999974, -1.0279999999999991, -1.1409999999999982, -0.519, -1.0139999999999996, -2.01, 1.9530000000000007, -2.0059999999999993, -1.5179999999999998, 3.2210000000000027, -2.002, -1.0259999999999978, 1.3220000000000007, 1.588000000000018, -1.0459999999999958, -0.023000000000000013, -1.2479999999999756, -1.3179999999999699, -1.0139999999999998, -1.5519999999999994, -1.1309999999999891, 1.459171875, -1.1920000000000002, -1.0179999999999993, -1.1639999999999855], "policy_red_v17_reward": [0.5520500000000093, 0.4786932378161699, 0.4786932378161719, -1.718999999999994, -1.0899999999999999, 1.973203125], "policy_red_v12_reward": [1.3792436585440782, 2.43178125], "policy_red_v20_reward": [-0.28600000000000014], "policy_red_v7_reward": [0.41767187500000014, 0.4741030335440548, -1.0129999999999995, -0.515], "policy_red_v18_reward": [0.3076932378161894, 0.4836932378161698, -1.21, 0.6570500000000006], "policy_red_v6_reward": [-1.1699999999999855, 3.323184614442594, 0.4265937500000001, -0.5639499999999991, -2.013], "policy_red_v8_reward": [-1.172999999999985, -0.6049999999999999], "policy_red_v2_reward": [1.94121875, -2.0179999999999993], "policy_red_v9_reward": [-1.075999999999994, -0.7099999999999997, 0.32869323781617366, 2.304421875], "policy_red_v5_reward": [0.19969323781617176, -1.4549999999999594], "policy_red_v11_reward": [-1.0189999999999988, -1.5569999999999977, -0.29200000000000004], "policy_red_v1_reward": [0.45599999999999996], "policy_red_v10_reward": [-1.591, -2.027999999999998, 0.4996932378161698, -1.5469999999999975], "policy_red_v4_reward": [1.8671875], "policy_red_v14_reward": [-0.09930676218382961, 0.44193461444259247, 3.325021362816173, -2.0069999999999997, 0.45346875], "policy_red_v19_reward": [3.2936307378161738], "policy_red_v22_reward": [0.4766932378161698, -1.043999999999998], "policy_red_v3_reward": [1.9464375, -2.01]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8041276120524427, "mean_inference_ms": 7.799192861428662, "mean_action_processing_ms": 0.2933639073221691, "mean_env_wait_ms": 0.38671798750896735, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10482943058013916, "StateBufferConnector_ms": 0.004430413246154785, "ViewRequirementAgentConnector_ms": 0.12171852588653564}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 456000, "num_agent_steps_trained": 456000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 195.98313456999276, "num_env_steps_trained_throughput_per_sec": 195.98313456999276, "timesteps_total": 228000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 456000, "timers": {"training_iteration_time_ms": 19964.971, "sample_time_ms": 1172.568, "learn_time_ms": 18709.33, "learn_throughput": 213.797, "synch_weights_time_ms": 80.659}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 456000, "num_agent_steps_trained": 456000}, "done": false, "episodes_total": 435, "training_iteration": 57, "trial_id": "a9680_00000", "date": "2023-09-24_02-56-24", "timestamp": 1695538584, "time_this_iter_s": 20.422730922698975, "time_total_s": 1133.0954627990723, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34512b30>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34419a20>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34419990>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1133.0954627990723, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 5.631034482758621, "ram_util_percent": 19.4}, "win_rate": 0.66, "league_size": 27}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0417517156650624, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0019737860275199637, "policy_loss": -0.06065264904076078, "vf_loss": 0.11433042337109024, "vf_explained_var": 0.628341634819905, "kl": 0.01722817990940181, "entropy": 2.2914570115506647, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 55200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "sampler_results": {"episode_reward_max": 4.249052612816173, "episode_reward_min": -2.737822387183771, "episode_reward_mean": 1.9495823664237322, "episode_len_mean": 320.28, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"red_v18": -1.21, "red": -5.958822387183821, "red_v6": -2.013, "red_v8": -1.172999999999985, "blue": -2.0169999999999995, "red_v2": -2.0179999999999993, "red_v9": -1.075999999999994, "red_v5": -1.4549999999999594, "red_v11": -1.5569999999999977, "red_v7": -1.0129999999999995, "red_v1": 0.45599999999999996, "red_v10": -2.027999999999998, "red_v4": 1.8671875, "red_v17": -1.718999999999994, "red_v14": -2.0069999999999997, "red_v19": 3.2936307378161738, "red_v22": -1.043999999999998, "red_v12": 2.43178125, "red_v3": -2.01, "red_v16": -2.0039999999999996, "red_v24": 2.465984375}, "policy_reward_max": {"red_v18": 0.6570500000000006, "red": 3.98781823781617, "red_v6": 3.323184614442594, "red_v8": 0.7466932378161746, "blue": 3.2210000000000027, "red_v2": 1.94121875, "red_v9": 2.304421875, "red_v5": 0.19969323781617176, "red_v11": -0.29200000000000004, "red_v7": 0.4741030335440548, "red_v1": 0.45599999999999996, "red_v10": 0.4996932378161698, "red_v4": 1.8671875, "red_v17": 1.973203125, "red_v14": 3.325021362816173, "red_v19": 3.2936307378161738, "red_v22": 0.4766932378161698, "red_v12": 2.43178125, "red_v3": 1.9464375, "red_v16": -0.1190000000000001, "red_v24": 2.465984375}, "policy_reward_mean": {"red_v18": -0.053574057310293896, "red": 2.3434135305833332, "red_v6": 0.0005656728885218953, "red_v8": -0.3437689207279368, "blue": -0.8082981546808451, "red_v2": -0.03839062499999968, "red_v9": 0.211778778204045, "red_v5": -0.6276533810918938, "red_v11": -0.955999999999999, "red_v7": -0.3512989888186482, "red_v1": 0.45599999999999996, "red_v10": -1.1665766905459565, "red_v4": 1.8671875, "red_v17": 0.02431792012646956, "red_v14": 0.42282359301498723, "red_v19": 3.2936307378161738, "red_v22": -0.2836533810919141, "red_v12": 2.43178125, "red_v3": -0.3611874999999995, "red_v16": -1.0614999999999999, "red_v24": 2.465984375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.851339600632374, 1.713005737816201, 0.8226932378162157, 1.9612713628161713, 1.8275023550000014, 2.2791619878161784, 2.189386475632428, 2.3534588628161752, 3.2758778522587706, 3.894968146360229, 2.2524432378161783, 0.6076932378162131, 0.768724487816211, 2.4512401128161705, 1.6618842835440633, 1.9787401128161908, 3.889902100632343, 0.8668651128161736, 2.3355057378161765, 0.19569323781520298, 0.7753182378162151, 1.8602088628161728, 1.8608807378161742, 2.2318963628161796, 1.5316307378162026, 1.8781307378161733, 3.8600271006323443, 1.5743304800000306, 1.9033026128161943, 1.5506182378161935, 2.404224487816172, 2.322224487816177, 2.4101151128161726, 0.9935838628161813, 2.7353239756323506, 3.8772458506323435, 3.9835896006323415, 0.9182869878161719, 0.9348651128161741, 1.2728125000000001, 2.775677612816176, 0.4654588628161769, 3.058214600632388, 3.809370850632349, 2.9447557378161706, 2.465974487816171, 1.9676811585440557, -0.8229038949999959, 3.8473622272587678, 1.4728963628152034, -0.12585937499999988, -2.737822387183771, 1.3768148550000001, 2.418927612816172, 2.4334744878161714, 1.3273283644426501, 1.9491307378161697, 4.249052612816173, 1.3126932378162357, 2.319349487816174, 1.2928807378161755, 2.9093026128161723, 1.1715213628162058, 2.2891151128161757, 0.8169588628161747, 0.828474487816213, 2.3814901128161745, 2.4428026128161715, 3.2857146006323497, 4.093540112816173, 1.9748182378161705, 0.7591307378161717, 1.9605994878161903, 1.4638651128161704, 1.9831151128161701, 1.450052612816171, 0.7214276128162022, 1.485743658544055, 2.437396362816172, 0.9561619878161707, 1.6414901128162114, 1.9591377394425922, 1.6599093750000002, 2.9495369878161712, 2.120802612816184, 1.8475080928162333, 2.4676776128161713, 2.349740112816174, 1.4525369878161711, 1.8762211050000002, 2.433802612816172, 2.949792725632342, 0.6626932378162138, 1.458052612816171, 0.5097939894425918, 2.410927612816173, 2.4741932378161704, 2.136386475632377, 2.1593338628162053, 3.1710369878161844], "episode_lengths": [495, 604, 1280, 39, 58, 170, 1280, 107, 176, 105, 208, 1280, 1142, 49, 134, 401, 123, 105, 124, 1280, 1272, 59, 132, 223, 724, 116, 147, 593, 477, 552, 86, 150, 89, 387, 212, 141, 31, 66, 425, 60, 165, 363, 727, 165, 44, 38, 39, 188, 117, 31, 51, 837, 22, 85, 70, 1042, 52, 109, 1280, 174, 132, 93, 983, 153, 139, 1094, 97, 61, 183, 97, 24, 180, 478, 41, 25, 45, 629, 19, 63, 42, 545, 31, 13, 50, 317, 662, 37, 145, 50, 20, 61, 62, 1280, 45, 1165, 85, 32, 1280, 659, 210], "policy_red_v18_reward": [0.3076932378161894, 0.4836932378161698, -1.21, 0.6570500000000006, -0.5063067621838293], "policy_red_v6_reward": [-1.1699999999999855, 3.323184614442594, 0.4265937500000001, -0.5639499999999991, -2.013], "policy_red_v8_reward": [-1.172999999999985, -0.6049999999999999, 0.7466932378161746], "policy_blue_reward": [-2.0169999999999995, -1.0589999999999968, -1.368999999999968, -1.125999999999992, -0.8850000000000003, -1.3539999999999661, -1.0579999999999985, -1.190999999999982, -1.139999999999988, -1.0219999999999987, -1.0379999999999974, -1.0279999999999991, -1.1409999999999982, -0.519, -1.0139999999999996, -2.01, 1.9530000000000007, -2.0059999999999993, -1.5179999999999998, 3.2210000000000027, -2.002, -1.0259999999999978, 1.3220000000000007, 1.588000000000018, -1.0459999999999958, -0.023000000000000013, -1.2479999999999756, -1.3179999999999699, -1.0139999999999998, -1.5519999999999994, -1.1309999999999891, 1.459171875, -1.1920000000000002, -1.0179999999999993, -1.1639999999999855, -0.012000000000000004, -1.097999999999992, 1.738814855000007, -2.012999999999999, -2.005, -1.0209999999999988, -1.3489999999999684, -2.0119999999999996, -0.8210000000000003, -1.0249999999999986, -1.0059999999999996, -0.6810000000000002], "policy_red_v2_reward": [1.94121875, -2.0179999999999993], "policy_red_v9_reward": [-1.075999999999994, -0.7099999999999997, 0.32869323781617366, 2.304421875], "policy_red_v5_reward": [0.19969323781617176, -1.4549999999999594], "policy_red_v11_reward": [-1.0189999999999988, -1.5569999999999977, -0.29200000000000004], "policy_red_v7_reward": [0.4741030335440548, -1.0129999999999995, -0.515], "policy_red_v1_reward": [0.45599999999999996], "policy_red_v10_reward": [-1.591, -2.027999999999998, 0.4996932378161698, -1.5469999999999975], "policy_red_v4_reward": [1.8671875], "policy_red_v17_reward": [0.4786932378161699, 0.4786932378161719, -1.718999999999994, -1.0899999999999999, 1.973203125], "policy_red_v14_reward": [-0.09930676218382961, 0.44193461444259247, 3.325021362816173, -2.0069999999999997, 0.45346875], "policy_red_v19_reward": [3.2936307378161738], "policy_red_v22_reward": [0.4766932378161698, -1.043999999999998], "policy_red_v12_reward": [2.43178125], "policy_red_v3_reward": [1.9464375, -2.01, -1.0199999999999987], "policy_red_v16_reward": [-2.0039999999999996, -0.1190000000000001], "policy_red_v24_reward": [2.465984375]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8051721244198964, "mean_inference_ms": 7.801745515561012, "mean_action_processing_ms": 0.29379461563284504, "mean_env_wait_ms": 0.386996523055063, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10532689094543457, "StateBufferConnector_ms": 0.004428744316101074, "ViewRequirementAgentConnector_ms": 0.12233424186706543}}, "episode_reward_max": 4.249052612816173, "episode_reward_min": -2.737822387183771, "episode_reward_mean": 1.9495823664237322, "episode_len_mean": 320.28, "episodes_this_iter": 17, "policy_reward_min": {"red_v18": -1.21, "red": -5.958822387183821, "red_v6": -2.013, "red_v8": -1.172999999999985, "blue": -2.0169999999999995, "red_v2": -2.0179999999999993, "red_v9": -1.075999999999994, "red_v5": -1.4549999999999594, "red_v11": -1.5569999999999977, "red_v7": -1.0129999999999995, "red_v1": 0.45599999999999996, "red_v10": -2.027999999999998, "red_v4": 1.8671875, "red_v17": -1.718999999999994, "red_v14": -2.0069999999999997, "red_v19": 3.2936307378161738, "red_v22": -1.043999999999998, "red_v12": 2.43178125, "red_v3": -2.01, "red_v16": -2.0039999999999996, "red_v24": 2.465984375}, "policy_reward_max": {"red_v18": 0.6570500000000006, "red": 3.98781823781617, "red_v6": 3.323184614442594, "red_v8": 0.7466932378161746, "blue": 3.2210000000000027, "red_v2": 1.94121875, "red_v9": 2.304421875, "red_v5": 0.19969323781617176, "red_v11": -0.29200000000000004, "red_v7": 0.4741030335440548, "red_v1": 0.45599999999999996, "red_v10": 0.4996932378161698, "red_v4": 1.8671875, "red_v17": 1.973203125, "red_v14": 3.325021362816173, "red_v19": 3.2936307378161738, "red_v22": 0.4766932378161698, "red_v12": 2.43178125, "red_v3": 1.9464375, "red_v16": -0.1190000000000001, "red_v24": 2.465984375}, "policy_reward_mean": {"red_v18": -0.053574057310293896, "red": 2.3434135305833332, "red_v6": 0.0005656728885218953, "red_v8": -0.3437689207279368, "blue": -0.8082981546808451, "red_v2": -0.03839062499999968, "red_v9": 0.211778778204045, "red_v5": -0.6276533810918938, "red_v11": -0.955999999999999, "red_v7": -0.3512989888186482, "red_v1": 0.45599999999999996, "red_v10": -1.1665766905459565, "red_v4": 1.8671875, "red_v17": 0.02431792012646956, "red_v14": 0.42282359301498723, "red_v19": 3.2936307378161738, "red_v22": -0.2836533810919141, "red_v12": 2.43178125, "red_v3": -0.3611874999999995, "red_v16": -1.0614999999999999, "red_v24": 2.465984375}, "hist_stats": {"episode_reward": [2.851339600632374, 1.713005737816201, 0.8226932378162157, 1.9612713628161713, 1.8275023550000014, 2.2791619878161784, 2.189386475632428, 2.3534588628161752, 3.2758778522587706, 3.894968146360229, 2.2524432378161783, 0.6076932378162131, 0.768724487816211, 2.4512401128161705, 1.6618842835440633, 1.9787401128161908, 3.889902100632343, 0.8668651128161736, 2.3355057378161765, 0.19569323781520298, 0.7753182378162151, 1.8602088628161728, 1.8608807378161742, 2.2318963628161796, 1.5316307378162026, 1.8781307378161733, 3.8600271006323443, 1.5743304800000306, 1.9033026128161943, 1.5506182378161935, 2.404224487816172, 2.322224487816177, 2.4101151128161726, 0.9935838628161813, 2.7353239756323506, 3.8772458506323435, 3.9835896006323415, 0.9182869878161719, 0.9348651128161741, 1.2728125000000001, 2.775677612816176, 0.4654588628161769, 3.058214600632388, 3.809370850632349, 2.9447557378161706, 2.465974487816171, 1.9676811585440557, -0.8229038949999959, 3.8473622272587678, 1.4728963628152034, -0.12585937499999988, -2.737822387183771, 1.3768148550000001, 2.418927612816172, 2.4334744878161714, 1.3273283644426501, 1.9491307378161697, 4.249052612816173, 1.3126932378162357, 2.319349487816174, 1.2928807378161755, 2.9093026128161723, 1.1715213628162058, 2.2891151128161757, 0.8169588628161747, 0.828474487816213, 2.3814901128161745, 2.4428026128161715, 3.2857146006323497, 4.093540112816173, 1.9748182378161705, 0.7591307378161717, 1.9605994878161903, 1.4638651128161704, 1.9831151128161701, 1.450052612816171, 0.7214276128162022, 1.485743658544055, 2.437396362816172, 0.9561619878161707, 1.6414901128162114, 1.9591377394425922, 1.6599093750000002, 2.9495369878161712, 2.120802612816184, 1.8475080928162333, 2.4676776128161713, 2.349740112816174, 1.4525369878161711, 1.8762211050000002, 2.433802612816172, 2.949792725632342, 0.6626932378162138, 1.458052612816171, 0.5097939894425918, 2.410927612816173, 2.4741932378161704, 2.136386475632377, 2.1593338628162053, 3.1710369878161844], "episode_lengths": [495, 604, 1280, 39, 58, 170, 1280, 107, 176, 105, 208, 1280, 1142, 49, 134, 401, 123, 105, 124, 1280, 1272, 59, 132, 223, 724, 116, 147, 593, 477, 552, 86, 150, 89, 387, 212, 141, 31, 66, 425, 60, 165, 363, 727, 165, 44, 38, 39, 188, 117, 31, 51, 837, 22, 85, 70, 1042, 52, 109, 1280, 174, 132, 93, 983, 153, 139, 1094, 97, 61, 183, 97, 24, 180, 478, 41, 25, 45, 629, 19, 63, 42, 545, 31, 13, 50, 317, 662, 37, 145, 50, 20, 61, 62, 1280, 45, 1165, 85, 32, 1280, 659, 210], "policy_red_v18_reward": [0.3076932378161894, 0.4836932378161698, -1.21, 0.6570500000000006, -0.5063067621838293], "policy_red_v6_reward": [-1.1699999999999855, 3.323184614442594, 0.4265937500000001, -0.5639499999999991, -2.013], "policy_red_v8_reward": [-1.172999999999985, -0.6049999999999999, 0.7466932378161746], "policy_blue_reward": [-2.0169999999999995, -1.0589999999999968, -1.368999999999968, -1.125999999999992, -0.8850000000000003, -1.3539999999999661, -1.0579999999999985, -1.190999999999982, -1.139999999999988, -1.0219999999999987, -1.0379999999999974, -1.0279999999999991, -1.1409999999999982, -0.519, -1.0139999999999996, -2.01, 1.9530000000000007, -2.0059999999999993, -1.5179999999999998, 3.2210000000000027, -2.002, -1.0259999999999978, 1.3220000000000007, 1.588000000000018, -1.0459999999999958, -0.023000000000000013, -1.2479999999999756, -1.3179999999999699, -1.0139999999999998, -1.5519999999999994, -1.1309999999999891, 1.459171875, -1.1920000000000002, -1.0179999999999993, -1.1639999999999855, -0.012000000000000004, -1.097999999999992, 1.738814855000007, -2.012999999999999, -2.005, -1.0209999999999988, -1.3489999999999684, -2.0119999999999996, -0.8210000000000003, -1.0249999999999986, -1.0059999999999996, -0.6810000000000002], "policy_red_v2_reward": [1.94121875, -2.0179999999999993], "policy_red_v9_reward": [-1.075999999999994, -0.7099999999999997, 0.32869323781617366, 2.304421875], "policy_red_v5_reward": [0.19969323781617176, -1.4549999999999594], "policy_red_v11_reward": [-1.0189999999999988, -1.5569999999999977, -0.29200000000000004], "policy_red_v7_reward": [0.4741030335440548, -1.0129999999999995, -0.515], "policy_red_v1_reward": [0.45599999999999996], "policy_red_v10_reward": [-1.591, -2.027999999999998, 0.4996932378161698, -1.5469999999999975], "policy_red_v4_reward": [1.8671875], "policy_red_v17_reward": [0.4786932378161699, 0.4786932378161719, -1.718999999999994, -1.0899999999999999, 1.973203125], "policy_red_v14_reward": [-0.09930676218382961, 0.44193461444259247, 3.325021362816173, -2.0069999999999997, 0.45346875], "policy_red_v19_reward": [3.2936307378161738], "policy_red_v22_reward": [0.4766932378161698, -1.043999999999998], "policy_red_v12_reward": [2.43178125], "policy_red_v3_reward": [1.9464375, -2.01, -1.0199999999999987], "policy_red_v16_reward": [-2.0039999999999996, -0.1190000000000001], "policy_red_v24_reward": [2.465984375]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8051721244198964, "mean_inference_ms": 7.801745515561012, "mean_action_processing_ms": 0.29379461563284504, "mean_env_wait_ms": 0.386996523055063, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10532689094543457, "StateBufferConnector_ms": 0.004428744316101074, "ViewRequirementAgentConnector_ms": 0.12233424186706543}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 196.7259233587621, "num_env_steps_trained_throughput_per_sec": 196.7259233587621, "timesteps_total": 232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 20015.987, "sample_time_ms": 1170.677, "learn_time_ms": 18761.279, "learn_throughput": 213.205, "synch_weights_time_ms": 81.584}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "episodes_total": 452, "training_iteration": 58, "trial_id": "a9680_00000", "date": "2023-09-24_02-56-46", "timestamp": 1695538606, "time_this_iter_s": 20.342623949050903, "time_total_s": 1153.4380867481232, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34439930>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b347a4790>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b347a5e10>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1153.4380867481232, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 5.129032258064517, "ram_util_percent": 19.48709677419355}, "win_rate": 0.69, "league_size": 28}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8803305524090925, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01945646685223134, "policy_loss": -0.054552868867176585, "vf_loss": 0.05895398628199473, "vf_explained_var": 0.732679901085794, "kl": 0.017726113676618145, "entropy": 2.357342361162106, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 56160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 472000, "num_agent_steps_trained": 472000}, "sampler_results": {"episode_reward_max": 4.249052612816173, "episode_reward_min": -2.737822387183771, "episode_reward_mean": 1.9144458083152713, "episode_len_mean": 320.09, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {"blue": -2.012999999999999, "red": -5.958822387183821, "red_v5": -1.4549999999999594, "red_v7": -1.0129999999999995, "red_v9": -1.11799999999999, "red_v18": -1.21, "red_v11": -1.5569999999999977, "red_v1": 0.45599999999999996, "red_v10": -2.027999999999998, "red_v4": -1.0109999999999992, "red_v17": -1.718999999999994, "red_v14": -2.0069999999999997, "red_v19": 3.2936307378161738, "red_v6": -2.013, "red_v8": -2.031999999999999, "red_v22": -1.043999999999998, "red_v12": 2.43178125, "red_v3": -2.01, "red_v16": -2.0039999999999996, "red_v2": -2.0179999999999993, "red_v24": 2.465984375, "red_v23": 3.1836875000000053, "red_v13": -0.15799999999999847}, "policy_reward_max": {"blue": 3.2210000000000027, "red": 3.98781823781617, "red_v5": -1.4549999999999594, "red_v7": -0.515, "red_v9": 2.304421875, "red_v18": 0.6570500000000006, "red_v11": -0.29200000000000004, "red_v1": 0.45599999999999996, "red_v10": 0.4996932378161698, "red_v4": 1.8671875, "red_v17": 1.973203125, "red_v14": 3.325021362816173, "red_v19": 3.2936307378161738, "red_v6": 0.4265937500000001, "red_v8": 0.7466932378161746, "red_v22": 0.4766932378161698, "red_v12": 2.9141456677729436, "red_v3": 1.9464375, "red_v16": -0.1190000000000001, "red_v2": -1.0019999999999998, "red_v24": 2.465984375, "red_v23": 3.1836875000000053, "red_v13": -0.15799999999999847}, "policy_reward_mean": {"blue": -0.7926737402040752, "red": 2.327097569533333, "red_v5": -1.4549999999999594, "red_v7": -0.7639999999999998, "red_v9": 0.201278778204046, "red_v18": -0.14389088109191472, "red_v11": -0.9244999999999989, "red_v1": 0.45599999999999996, "red_v10": -1.1665766905459565, "red_v4": 0.4280937500000004, "red_v17": 0.02431792012646956, "red_v14": 0.42282359301498723, "red_v19": 3.2936307378161738, "red_v6": -0.7167854166666663, "red_v8": -0.6301022540612747, "red_v22": -0.2836533810919141, "red_v12": 2.6729634588864717, "red_v3": -0.3611874999999995, "red_v16": -1.0614999999999999, "red_v2": -1.5099999999999996, "red_v24": 2.465984375, "red_v23": 3.1836875000000053, "red_v13": -0.15799999999999847}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.6076932378162131, 0.768724487816211, 2.4512401128161705, 1.6618842835440633, 1.9787401128161908, 3.889902100632343, 0.8668651128161736, 2.3355057378161765, 0.19569323781520298, 0.7753182378162151, 1.8602088628161728, 1.8608807378161742, 2.2318963628161796, 1.5316307378162026, 1.8781307378161733, 3.8600271006323443, 1.5743304800000306, 1.9033026128161943, 1.5506182378161935, 2.404224487816172, 2.322224487816177, 2.4101151128161726, 0.9935838628161813, 2.7353239756323506, 3.8772458506323435, 3.9835896006323415, 0.9182869878161719, 0.9348651128161741, 1.2728125000000001, 2.775677612816176, 0.4654588628161769, 3.058214600632388, 3.809370850632349, 2.9447557378161706, 2.465974487816171, 1.9676811585440557, -0.8229038949999959, 3.8473622272587678, 1.4728963628152034, -0.12585937499999988, -2.737822387183771, 1.3768148550000001, 2.418927612816172, 2.4334744878161714, 1.3273283644426501, 1.9491307378161697, 4.249052612816173, 1.3126932378162357, 2.319349487816174, 1.2928807378161755, 2.9093026128161723, 1.1715213628162058, 2.2891151128161757, 0.8169588628161747, 0.828474487816213, 2.3814901128161745, 2.4428026128161715, 3.2857146006323497, 4.093540112816173, 1.9748182378161705, 0.7591307378161717, 1.9605994878161903, 1.4638651128161704, 1.9831151128161701, 1.450052612816171, 0.7214276128162022, 1.485743658544055, 2.437396362816172, 0.9561619878161707, 1.6414901128162114, 1.9591377394425922, 1.6599093750000002, 2.9495369878161712, 2.120802612816184, 1.8475080928162333, 2.4676776128161713, 2.349740112816174, 1.4525369878161711, 1.8762211050000002, 2.433802612816172, 2.949792725632342, 0.6626932378162138, 1.458052612816171, 0.5097939894425918, 2.410927612816173, 2.4741932378161704, 2.136386475632377, 2.1593338628162053, 3.1710369878161844, 0.9946932378162164, 1.3774432378161747, 2.465677612816171, 2.08968750000001, 1.3649119878161966, 2.384943237816174, 2.4758651128161704, 2.811490112816177, 1.1036932378162074, 2.904838905589115, 1.9342088628161949], "episode_lengths": [1280, 1142, 49, 134, 401, 123, 105, 124, 1280, 1272, 59, 132, 223, 724, 116, 147, 593, 477, 552, 86, 150, 89, 387, 212, 141, 31, 66, 425, 60, 165, 363, 727, 165, 44, 38, 39, 188, 117, 31, 51, 837, 22, 85, 70, 1042, 52, 109, 1280, 174, 132, 93, 983, 153, 139, 1094, 97, 61, 183, 97, 24, 180, 478, 41, 25, 45, 629, 19, 63, 42, 545, 31, 13, 50, 317, 662, 37, 145, 50, 20, 61, 62, 1280, 45, 1165, 85, 32, 1280, 659, 210, 1280, 80, 37, 164, 826, 112, 41, 161, 1280, 79, 443], "policy_blue_reward": [-1.368999999999968, -1.125999999999992, -0.8850000000000003, -1.3539999999999661, -1.0579999999999985, -1.190999999999982, -1.139999999999988, -1.0219999999999987, -1.0379999999999974, -1.0279999999999991, -1.1409999999999982, -0.519, -1.0139999999999996, -2.01, 1.9530000000000007, -2.0059999999999993, -1.5179999999999998, 3.2210000000000027, -2.002, -1.0259999999999978, 1.3220000000000007, 1.588000000000018, -1.0459999999999958, -0.023000000000000013, -1.2479999999999756, -1.3179999999999699, -1.0139999999999998, -1.5519999999999994, -1.1309999999999891, 1.459171875, -1.1920000000000002, -1.0179999999999993, -1.1639999999999855, -0.012000000000000004, -1.097999999999992, 1.738814855000007, -2.012999999999999, -2.005, -1.0209999999999988, -1.3489999999999684, -2.0119999999999996, -0.8210000000000003, -1.0249999999999986, -1.0059999999999996, -0.6810000000000002, -1.2269999999999783, -1.0319999999999974, -0.5379999999999974, -1.1299999999999881], "policy_red_v5_reward": [-1.4549999999999594], "policy_red_v7_reward": [-1.0129999999999995, -0.515], "policy_red_v9_reward": [-0.7099999999999997, 0.32869323781617366, 2.304421875, -1.11799999999999], "policy_red_v18_reward": [0.4836932378161698, -1.21, 0.6570500000000006, -0.5063067621838293], "policy_red_v11_reward": [-1.5569999999999977, -0.29200000000000004], "policy_red_v1_reward": [0.45599999999999996], "policy_red_v10_reward": [-1.591, -2.027999999999998, 0.4996932378161698, -1.5469999999999975], "policy_red_v4_reward": [1.8671875, -1.0109999999999992], "policy_red_v17_reward": [0.4786932378161699, 0.4786932378161719, -1.718999999999994, -1.0899999999999999, 1.973203125], "policy_red_v14_reward": [-0.09930676218382961, 0.44193461444259247, 3.325021362816173, -2.0069999999999997, 0.45346875], "policy_red_v19_reward": [3.2936307378161738], "policy_red_v6_reward": [0.4265937500000001, -0.5639499999999991, -2.013], "policy_red_v8_reward": [-0.6049999999999999, 0.7466932378161746, -2.031999999999999], "policy_red_v22_reward": [0.4766932378161698, -1.043999999999998], "policy_red_v12_reward": [2.43178125, 2.9141456677729436], "policy_red_v3_reward": [1.9464375, -2.01, -1.0199999999999987], "policy_red_v16_reward": [-2.0039999999999996, -0.1190000000000001], "policy_red_v2_reward": [-2.0179999999999993, -1.0019999999999998], "policy_red_v24_reward": [2.465984375], "policy_red_v23_reward": [3.1836875000000053], "policy_red_v13_reward": [-0.15799999999999847]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8060363398648728, "mean_inference_ms": 7.808700708049308, "mean_action_processing_ms": 0.2941263722564883, "mean_env_wait_ms": 0.38748159291562084, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10359811782836914, "StateBufferConnector_ms": 0.004356265068054199, "ViewRequirementAgentConnector_ms": 0.12070858478546143}}, "episode_reward_max": 4.249052612816173, "episode_reward_min": -2.737822387183771, "episode_reward_mean": 1.9144458083152713, "episode_len_mean": 320.09, "episodes_this_iter": 11, "policy_reward_min": {"blue": -2.012999999999999, "red": -5.958822387183821, "red_v5": -1.4549999999999594, "red_v7": -1.0129999999999995, "red_v9": -1.11799999999999, "red_v18": -1.21, "red_v11": -1.5569999999999977, "red_v1": 0.45599999999999996, "red_v10": -2.027999999999998, "red_v4": -1.0109999999999992, "red_v17": -1.718999999999994, "red_v14": -2.0069999999999997, "red_v19": 3.2936307378161738, "red_v6": -2.013, "red_v8": -2.031999999999999, "red_v22": -1.043999999999998, "red_v12": 2.43178125, "red_v3": -2.01, "red_v16": -2.0039999999999996, "red_v2": -2.0179999999999993, "red_v24": 2.465984375, "red_v23": 3.1836875000000053, "red_v13": -0.15799999999999847}, "policy_reward_max": {"blue": 3.2210000000000027, "red": 3.98781823781617, "red_v5": -1.4549999999999594, "red_v7": -0.515, "red_v9": 2.304421875, "red_v18": 0.6570500000000006, "red_v11": -0.29200000000000004, "red_v1": 0.45599999999999996, "red_v10": 0.4996932378161698, "red_v4": 1.8671875, "red_v17": 1.973203125, "red_v14": 3.325021362816173, "red_v19": 3.2936307378161738, "red_v6": 0.4265937500000001, "red_v8": 0.7466932378161746, "red_v22": 0.4766932378161698, "red_v12": 2.9141456677729436, "red_v3": 1.9464375, "red_v16": -0.1190000000000001, "red_v2": -1.0019999999999998, "red_v24": 2.465984375, "red_v23": 3.1836875000000053, "red_v13": -0.15799999999999847}, "policy_reward_mean": {"blue": -0.7926737402040752, "red": 2.327097569533333, "red_v5": -1.4549999999999594, "red_v7": -0.7639999999999998, "red_v9": 0.201278778204046, "red_v18": -0.14389088109191472, "red_v11": -0.9244999999999989, "red_v1": 0.45599999999999996, "red_v10": -1.1665766905459565, "red_v4": 0.4280937500000004, "red_v17": 0.02431792012646956, "red_v14": 0.42282359301498723, "red_v19": 3.2936307378161738, "red_v6": -0.7167854166666663, "red_v8": -0.6301022540612747, "red_v22": -0.2836533810919141, "red_v12": 2.6729634588864717, "red_v3": -0.3611874999999995, "red_v16": -1.0614999999999999, "red_v2": -1.5099999999999996, "red_v24": 2.465984375, "red_v23": 3.1836875000000053, "red_v13": -0.15799999999999847}, "hist_stats": {"episode_reward": [0.6076932378162131, 0.768724487816211, 2.4512401128161705, 1.6618842835440633, 1.9787401128161908, 3.889902100632343, 0.8668651128161736, 2.3355057378161765, 0.19569323781520298, 0.7753182378162151, 1.8602088628161728, 1.8608807378161742, 2.2318963628161796, 1.5316307378162026, 1.8781307378161733, 3.8600271006323443, 1.5743304800000306, 1.9033026128161943, 1.5506182378161935, 2.404224487816172, 2.322224487816177, 2.4101151128161726, 0.9935838628161813, 2.7353239756323506, 3.8772458506323435, 3.9835896006323415, 0.9182869878161719, 0.9348651128161741, 1.2728125000000001, 2.775677612816176, 0.4654588628161769, 3.058214600632388, 3.809370850632349, 2.9447557378161706, 2.465974487816171, 1.9676811585440557, -0.8229038949999959, 3.8473622272587678, 1.4728963628152034, -0.12585937499999988, -2.737822387183771, 1.3768148550000001, 2.418927612816172, 2.4334744878161714, 1.3273283644426501, 1.9491307378161697, 4.249052612816173, 1.3126932378162357, 2.319349487816174, 1.2928807378161755, 2.9093026128161723, 1.1715213628162058, 2.2891151128161757, 0.8169588628161747, 0.828474487816213, 2.3814901128161745, 2.4428026128161715, 3.2857146006323497, 4.093540112816173, 1.9748182378161705, 0.7591307378161717, 1.9605994878161903, 1.4638651128161704, 1.9831151128161701, 1.450052612816171, 0.7214276128162022, 1.485743658544055, 2.437396362816172, 0.9561619878161707, 1.6414901128162114, 1.9591377394425922, 1.6599093750000002, 2.9495369878161712, 2.120802612816184, 1.8475080928162333, 2.4676776128161713, 2.349740112816174, 1.4525369878161711, 1.8762211050000002, 2.433802612816172, 2.949792725632342, 0.6626932378162138, 1.458052612816171, 0.5097939894425918, 2.410927612816173, 2.4741932378161704, 2.136386475632377, 2.1593338628162053, 3.1710369878161844, 0.9946932378162164, 1.3774432378161747, 2.465677612816171, 2.08968750000001, 1.3649119878161966, 2.384943237816174, 2.4758651128161704, 2.811490112816177, 1.1036932378162074, 2.904838905589115, 1.9342088628161949], "episode_lengths": [1280, 1142, 49, 134, 401, 123, 105, 124, 1280, 1272, 59, 132, 223, 724, 116, 147, 593, 477, 552, 86, 150, 89, 387, 212, 141, 31, 66, 425, 60, 165, 363, 727, 165, 44, 38, 39, 188, 117, 31, 51, 837, 22, 85, 70, 1042, 52, 109, 1280, 174, 132, 93, 983, 153, 139, 1094, 97, 61, 183, 97, 24, 180, 478, 41, 25, 45, 629, 19, 63, 42, 545, 31, 13, 50, 317, 662, 37, 145, 50, 20, 61, 62, 1280, 45, 1165, 85, 32, 1280, 659, 210, 1280, 80, 37, 164, 826, 112, 41, 161, 1280, 79, 443], "policy_blue_reward": [-1.368999999999968, -1.125999999999992, -0.8850000000000003, -1.3539999999999661, -1.0579999999999985, -1.190999999999982, -1.139999999999988, -1.0219999999999987, -1.0379999999999974, -1.0279999999999991, -1.1409999999999982, -0.519, -1.0139999999999996, -2.01, 1.9530000000000007, -2.0059999999999993, -1.5179999999999998, 3.2210000000000027, -2.002, -1.0259999999999978, 1.3220000000000007, 1.588000000000018, -1.0459999999999958, -0.023000000000000013, -1.2479999999999756, -1.3179999999999699, -1.0139999999999998, -1.5519999999999994, -1.1309999999999891, 1.459171875, -1.1920000000000002, -1.0179999999999993, -1.1639999999999855, -0.012000000000000004, -1.097999999999992, 1.738814855000007, -2.012999999999999, -2.005, -1.0209999999999988, -1.3489999999999684, -2.0119999999999996, -0.8210000000000003, -1.0249999999999986, -1.0059999999999996, -0.6810000000000002, -1.2269999999999783, -1.0319999999999974, -0.5379999999999974, -1.1299999999999881], "policy_red_v5_reward": [-1.4549999999999594], "policy_red_v7_reward": [-1.0129999999999995, -0.515], "policy_red_v9_reward": [-0.7099999999999997, 0.32869323781617366, 2.304421875, -1.11799999999999], "policy_red_v18_reward": [0.4836932378161698, -1.21, 0.6570500000000006, -0.5063067621838293], "policy_red_v11_reward": [-1.5569999999999977, -0.29200000000000004], "policy_red_v1_reward": [0.45599999999999996], "policy_red_v10_reward": [-1.591, -2.027999999999998, 0.4996932378161698, -1.5469999999999975], "policy_red_v4_reward": [1.8671875, -1.0109999999999992], "policy_red_v17_reward": [0.4786932378161699, 0.4786932378161719, -1.718999999999994, -1.0899999999999999, 1.973203125], "policy_red_v14_reward": [-0.09930676218382961, 0.44193461444259247, 3.325021362816173, -2.0069999999999997, 0.45346875], "policy_red_v19_reward": [3.2936307378161738], "policy_red_v6_reward": [0.4265937500000001, -0.5639499999999991, -2.013], "policy_red_v8_reward": [-0.6049999999999999, 0.7466932378161746, -2.031999999999999], "policy_red_v22_reward": [0.4766932378161698, -1.043999999999998], "policy_red_v12_reward": [2.43178125, 2.9141456677729436], "policy_red_v3_reward": [1.9464375, -2.01, -1.0199999999999987], "policy_red_v16_reward": [-2.0039999999999996, -0.1190000000000001], "policy_red_v2_reward": [-2.0179999999999993, -1.0019999999999998], "policy_red_v24_reward": [2.465984375], "policy_red_v23_reward": [3.1836875000000053], "policy_red_v13_reward": [-0.15799999999999847]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8060363398648728, "mean_inference_ms": 7.808700708049308, "mean_action_processing_ms": 0.2941263722564883, "mean_env_wait_ms": 0.38748159291562084, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10359811782836914, "StateBufferConnector_ms": 0.004356265068054199, "ViewRequirementAgentConnector_ms": 0.12070858478546143}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 472000, "num_agent_steps_trained": 472000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 197.83301759305655, "num_env_steps_trained_throughput_per_sec": 197.83301759305655, "timesteps_total": 236000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 472000, "timers": {"training_iteration_time_ms": 20025.198, "sample_time_ms": 1167.223, "learn_time_ms": 18774.639, "learn_throughput": 213.053, "synch_weights_time_ms": 80.925}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 472000, "num_agent_steps_trained": 472000}, "done": false, "episodes_total": 463, "training_iteration": 59, "trial_id": "a9680_00000", "date": "2023-09-24_02-57-09", "timestamp": 1695538629, "time_this_iter_s": 20.229179859161377, "time_total_s": 1173.6672666072845, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b342edd50>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b342ccf70>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b342cd000>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1173.6672666072845, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 5.116129032258066, "ram_util_percent": 19.587096774193554}, "win_rate": 0.72, "league_size": 29}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.925858648618062, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0131292400318974, "policy_loss": -0.05200718043682476, "vf_loss": 0.12024425778072327, "vf_explained_var": 0.6602944531167547, "kl": 0.016186327689336703, "entropy": 2.269555211812258, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 57120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "sampler_results": {"episode_reward_max": 4.288105225632352, "episode_reward_min": -2.737822387183771, "episode_reward_mean": 1.9582647719434327, "episode_len_mean": 297.36, "episode_media": {}, "episodes_this_iter": 14, "policy_reward_min": {"red_v10": -2.027999999999998, "red": -5.958822387183821, "red_v17": -1.718999999999994, "red_v11": -0.29200000000000004, "blue": -2.012999999999999, "red_v14": -2.0069999999999997, "red_v19": 3.2936307378161738, "red_v6": -2.013, "red_v18": -1.21, "red_v8": -2.031999999999999, "red_v9": -1.2669999999999986, "red_v22": -1.043999999999998, "red_v7": -0.515, "red_v12": 2.43178125, "red_v3": -2.01, "red_v16": -2.0039999999999996, "red_v2": -2.0179999999999993, "red_v24": 2.465984375, "red_v4": -1.0109999999999992, "red_v23": 0.2516932378161749, "red_v13": -1.5349999999999997, "red_v26": 1.4436932378161742}, "policy_reward_max": {"red_v10": 0.4996932378161698, "red": 3.9882244878152036, "red_v17": 1.973203125, "red_v11": -0.29200000000000004, "blue": 3.2210000000000027, "red_v14": 3.325021362816173, "red_v19": 3.2936307378161738, "red_v6": 0.4265937500000001, "red_v18": 0.6570500000000006, "red_v8": 0.7466932378161746, "red_v9": 2.304421875, "red_v22": 0.4766932378161698, "red_v7": -0.515, "red_v12": 2.9141456677729436, "red_v3": 1.9464375, "red_v16": -0.1190000000000001, "red_v2": -1.0019999999999998, "red_v24": 2.465984375, "red_v4": -1.0109999999999992, "red_v23": 3.1836875000000053, "red_v13": 0.44200000000000006, "red_v26": 1.4436932378161742}, "policy_reward_mean": {"red_v10": -1.0251022540612753, "red": 2.299287945447891, "red_v17": 0.02431792012646956, "red_v11": -0.29200000000000004, "blue": -0.6543658869893271, "red_v14": 0.42282359301498723, "red_v19": 3.2936307378161738, "red_v6": -0.7167854166666663, "red_v18": -0.35308558739460955, "red_v8": -0.6301022540612747, "red_v9": 0.06202877820404634, "red_v22": -0.2836533810919141, "red_v7": -0.515, "red_v12": 2.6729634588864717, "red_v3": -0.3611874999999995, "red_v16": -1.0943333333333287, "red_v2": -1.5099999999999996, "red_v24": 2.465984375, "red_v4": -1.0109999999999992, "red_v23": 1.71769036890809, "red_v13": -0.41699999999999937, "red_v26": 1.4436932378161742}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.8781307378161733, 3.8600271006323443, 1.5743304800000306, 1.9033026128161943, 1.5506182378161935, 2.404224487816172, 2.322224487816177, 2.4101151128161726, 0.9935838628161813, 2.7353239756323506, 3.8772458506323435, 3.9835896006323415, 0.9182869878161719, 0.9348651128161741, 1.2728125000000001, 2.775677612816176, 0.4654588628161769, 3.058214600632388, 3.809370850632349, 2.9447557378161706, 2.465974487816171, 1.9676811585440557, -0.8229038949999959, 3.8473622272587678, 1.4728963628152034, -0.12585937499999988, -2.737822387183771, 1.3768148550000001, 2.418927612816172, 2.4334744878161714, 1.3273283644426501, 1.9491307378161697, 4.249052612816173, 1.3126932378162357, 2.319349487816174, 1.2928807378161755, 2.9093026128161723, 1.1715213628162058, 2.2891151128161757, 0.8169588628161747, 0.828474487816213, 2.3814901128161745, 2.4428026128161715, 3.2857146006323497, 4.093540112816173, 1.9748182378161705, 0.7591307378161717, 1.9605994878161903, 1.4638651128161704, 1.9831151128161701, 1.450052612816171, 0.7214276128162022, 1.485743658544055, 2.437396362816172, 0.9561619878161707, 1.6414901128162114, 1.9591377394425922, 1.6599093750000002, 2.9495369878161712, 2.120802612816184, 1.8475080928162333, 2.4676776128161713, 2.349740112816174, 1.4525369878161711, 1.8762211050000002, 2.433802612816172, 2.949792725632342, 0.6626932378162138, 1.458052612816171, 0.5097939894425918, 2.410927612816173, 2.4741932378161704, 2.136386475632377, 2.1593338628162053, 3.1710369878161844, 0.9946932378162164, 1.3774432378161747, 2.465677612816171, 2.08968750000001, 1.3649119878161966, 2.384943237816174, 2.4758651128161704, 2.811490112816177, 1.1036932378162074, 2.904838905589115, 1.9342088628161949, 1.7867244878162025, 1.1251406249999998, 4.288105225632352, 0.8539276128161921, 1.299146362816219, 3.4749177256323724, 1.9928651128161807, 1.6240306463602732, 1.7748026128161776, 1.985224487815204, 2.9631619878161706, 0.8970994878161727, 2.3852401128161733, 0.9476932378161704], "episode_lengths": [116, 147, 593, 477, 552, 86, 150, 89, 387, 212, 141, 31, 66, 425, 60, 165, 363, 727, 165, 44, 38, 39, 188, 117, 31, 51, 837, 22, 85, 70, 1042, 52, 109, 1280, 174, 132, 93, 983, 153, 139, 1094, 97, 61, 183, 97, 24, 180, 478, 41, 25, 45, 629, 19, 63, 42, 545, 31, 13, 50, 317, 662, 37, 145, 50, 20, 61, 62, 1280, 45, 1165, 85, 32, 1280, 659, 210, 1280, 80, 37, 164, 826, 112, 41, 161, 1280, 79, 443, 502, 179, 154, 533, 975, 342, 361, 1237, 189, 22, 42, 62, 113, 64], "policy_red_v10_reward": [-2.027999999999998, 0.4996932378161698, -1.5469999999999975], "policy_red_v17_reward": [0.4786932378161699, 0.4786932378161719, -1.718999999999994, -1.0899999999999999, 1.973203125], "policy_red_v11_reward": [-0.29200000000000004], "policy_blue_reward": [-1.139999999999988, -1.0219999999999987, -1.0379999999999974, -1.0279999999999991, -1.1409999999999982, -0.519, -1.0139999999999996, -2.01, 1.9530000000000007, -2.0059999999999993, -1.5179999999999998, 3.2210000000000027, -2.002, -1.0259999999999978, 1.3220000000000007, 1.588000000000018, -1.0459999999999958, -0.023000000000000013, -1.2479999999999756, -1.3179999999999699, -1.0139999999999998, -1.5519999999999994, -1.1309999999999891, 1.459171875, -1.1920000000000002, -1.0179999999999993, -1.1639999999999855, -0.012000000000000004, -1.097999999999992, 1.738814855000007, -2.012999999999999, -2.005, -1.0209999999999988, -1.3489999999999684, -2.0119999999999996, -0.8210000000000003, -1.0249999999999986, -1.0059999999999996, -0.6810000000000002, -1.2269999999999783, -1.0319999999999974, -0.5379999999999974, -1.1299999999999881, -1.1409999999999898, 1.813140625, -1.1059999999999905, 0.1501030335440734, 1.811109375, -2.0029999999999997, -0.010000000000000002, -1.0289999999999975], "policy_red_v14_reward": [-0.09930676218382961, 0.44193461444259247, 3.325021362816173, -2.0069999999999997, 0.45346875], "policy_red_v19_reward": [3.2936307378161738], "policy_red_v6_reward": [0.4265937500000001, -0.5639499999999991, -2.013], "policy_red_v18_reward": [-1.21, 0.6570500000000006, -0.5063067621838293], "policy_red_v8_reward": [-0.6049999999999999, 0.7466932378161746, -2.031999999999999], "policy_red_v9_reward": [0.32869323781617366, 2.304421875, -1.11799999999999, -1.2669999999999986], "policy_red_v22_reward": [0.4766932378161698, -1.043999999999998], "policy_red_v7_reward": [-0.515], "policy_red_v12_reward": [2.43178125, 2.9141456677729436], "policy_red_v3_reward": [1.9464375, -2.01, -1.0199999999999987], "policy_red_v16_reward": [-2.0039999999999996, -0.1190000000000001, -1.1599999999999866], "policy_red_v2_reward": [-2.0179999999999993, -1.0019999999999998], "policy_red_v24_reward": [2.465984375], "policy_red_v4_reward": [-1.0109999999999992], "policy_red_v23_reward": [3.1836875000000053, 0.2516932378161749], "policy_red_v13_reward": [-0.15799999999999847, -1.5349999999999997, 0.44200000000000006], "policy_red_v26_reward": [1.4436932378161742]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8070831740209057, "mean_inference_ms": 7.815699187798202, "mean_action_processing_ms": 0.29479408575146304, "mean_env_wait_ms": 0.3887368179908364, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1044381856918335, "StateBufferConnector_ms": 0.004427671432495117, "ViewRequirementAgentConnector_ms": 0.12242293357849121}}, "episode_reward_max": 4.288105225632352, "episode_reward_min": -2.737822387183771, "episode_reward_mean": 1.9582647719434327, "episode_len_mean": 297.36, "episodes_this_iter": 14, "policy_reward_min": {"red_v10": -2.027999999999998, "red": -5.958822387183821, "red_v17": -1.718999999999994, "red_v11": -0.29200000000000004, "blue": -2.012999999999999, "red_v14": -2.0069999999999997, "red_v19": 3.2936307378161738, "red_v6": -2.013, "red_v18": -1.21, "red_v8": -2.031999999999999, "red_v9": -1.2669999999999986, "red_v22": -1.043999999999998, "red_v7": -0.515, "red_v12": 2.43178125, "red_v3": -2.01, "red_v16": -2.0039999999999996, "red_v2": -2.0179999999999993, "red_v24": 2.465984375, "red_v4": -1.0109999999999992, "red_v23": 0.2516932378161749, "red_v13": -1.5349999999999997, "red_v26": 1.4436932378161742}, "policy_reward_max": {"red_v10": 0.4996932378161698, "red": 3.9882244878152036, "red_v17": 1.973203125, "red_v11": -0.29200000000000004, "blue": 3.2210000000000027, "red_v14": 3.325021362816173, "red_v19": 3.2936307378161738, "red_v6": 0.4265937500000001, "red_v18": 0.6570500000000006, "red_v8": 0.7466932378161746, "red_v9": 2.304421875, "red_v22": 0.4766932378161698, "red_v7": -0.515, "red_v12": 2.9141456677729436, "red_v3": 1.9464375, "red_v16": -0.1190000000000001, "red_v2": -1.0019999999999998, "red_v24": 2.465984375, "red_v4": -1.0109999999999992, "red_v23": 3.1836875000000053, "red_v13": 0.44200000000000006, "red_v26": 1.4436932378161742}, "policy_reward_mean": {"red_v10": -1.0251022540612753, "red": 2.299287945447891, "red_v17": 0.02431792012646956, "red_v11": -0.29200000000000004, "blue": -0.6543658869893271, "red_v14": 0.42282359301498723, "red_v19": 3.2936307378161738, "red_v6": -0.7167854166666663, "red_v18": -0.35308558739460955, "red_v8": -0.6301022540612747, "red_v9": 0.06202877820404634, "red_v22": -0.2836533810919141, "red_v7": -0.515, "red_v12": 2.6729634588864717, "red_v3": -0.3611874999999995, "red_v16": -1.0943333333333287, "red_v2": -1.5099999999999996, "red_v24": 2.465984375, "red_v4": -1.0109999999999992, "red_v23": 1.71769036890809, "red_v13": -0.41699999999999937, "red_v26": 1.4436932378161742}, "hist_stats": {"episode_reward": [1.8781307378161733, 3.8600271006323443, 1.5743304800000306, 1.9033026128161943, 1.5506182378161935, 2.404224487816172, 2.322224487816177, 2.4101151128161726, 0.9935838628161813, 2.7353239756323506, 3.8772458506323435, 3.9835896006323415, 0.9182869878161719, 0.9348651128161741, 1.2728125000000001, 2.775677612816176, 0.4654588628161769, 3.058214600632388, 3.809370850632349, 2.9447557378161706, 2.465974487816171, 1.9676811585440557, -0.8229038949999959, 3.8473622272587678, 1.4728963628152034, -0.12585937499999988, -2.737822387183771, 1.3768148550000001, 2.418927612816172, 2.4334744878161714, 1.3273283644426501, 1.9491307378161697, 4.249052612816173, 1.3126932378162357, 2.319349487816174, 1.2928807378161755, 2.9093026128161723, 1.1715213628162058, 2.2891151128161757, 0.8169588628161747, 0.828474487816213, 2.3814901128161745, 2.4428026128161715, 3.2857146006323497, 4.093540112816173, 1.9748182378161705, 0.7591307378161717, 1.9605994878161903, 1.4638651128161704, 1.9831151128161701, 1.450052612816171, 0.7214276128162022, 1.485743658544055, 2.437396362816172, 0.9561619878161707, 1.6414901128162114, 1.9591377394425922, 1.6599093750000002, 2.9495369878161712, 2.120802612816184, 1.8475080928162333, 2.4676776128161713, 2.349740112816174, 1.4525369878161711, 1.8762211050000002, 2.433802612816172, 2.949792725632342, 0.6626932378162138, 1.458052612816171, 0.5097939894425918, 2.410927612816173, 2.4741932378161704, 2.136386475632377, 2.1593338628162053, 3.1710369878161844, 0.9946932378162164, 1.3774432378161747, 2.465677612816171, 2.08968750000001, 1.3649119878161966, 2.384943237816174, 2.4758651128161704, 2.811490112816177, 1.1036932378162074, 2.904838905589115, 1.9342088628161949, 1.7867244878162025, 1.1251406249999998, 4.288105225632352, 0.8539276128161921, 1.299146362816219, 3.4749177256323724, 1.9928651128161807, 1.6240306463602732, 1.7748026128161776, 1.985224487815204, 2.9631619878161706, 0.8970994878161727, 2.3852401128161733, 0.9476932378161704], "episode_lengths": [116, 147, 593, 477, 552, 86, 150, 89, 387, 212, 141, 31, 66, 425, 60, 165, 363, 727, 165, 44, 38, 39, 188, 117, 31, 51, 837, 22, 85, 70, 1042, 52, 109, 1280, 174, 132, 93, 983, 153, 139, 1094, 97, 61, 183, 97, 24, 180, 478, 41, 25, 45, 629, 19, 63, 42, 545, 31, 13, 50, 317, 662, 37, 145, 50, 20, 61, 62, 1280, 45, 1165, 85, 32, 1280, 659, 210, 1280, 80, 37, 164, 826, 112, 41, 161, 1280, 79, 443, 502, 179, 154, 533, 975, 342, 361, 1237, 189, 22, 42, 62, 113, 64], "policy_red_v10_reward": [-2.027999999999998, 0.4996932378161698, -1.5469999999999975], "policy_red_v17_reward": [0.4786932378161699, 0.4786932378161719, -1.718999999999994, -1.0899999999999999, 1.973203125], "policy_red_v11_reward": [-0.29200000000000004], "policy_blue_reward": [-1.139999999999988, -1.0219999999999987, -1.0379999999999974, -1.0279999999999991, -1.1409999999999982, -0.519, -1.0139999999999996, -2.01, 1.9530000000000007, -2.0059999999999993, -1.5179999999999998, 3.2210000000000027, -2.002, -1.0259999999999978, 1.3220000000000007, 1.588000000000018, -1.0459999999999958, -0.023000000000000013, -1.2479999999999756, -1.3179999999999699, -1.0139999999999998, -1.5519999999999994, -1.1309999999999891, 1.459171875, -1.1920000000000002, -1.0179999999999993, -1.1639999999999855, -0.012000000000000004, -1.097999999999992, 1.738814855000007, -2.012999999999999, -2.005, -1.0209999999999988, -1.3489999999999684, -2.0119999999999996, -0.8210000000000003, -1.0249999999999986, -1.0059999999999996, -0.6810000000000002, -1.2269999999999783, -1.0319999999999974, -0.5379999999999974, -1.1299999999999881, -1.1409999999999898, 1.813140625, -1.1059999999999905, 0.1501030335440734, 1.811109375, -2.0029999999999997, -0.010000000000000002, -1.0289999999999975], "policy_red_v14_reward": [-0.09930676218382961, 0.44193461444259247, 3.325021362816173, -2.0069999999999997, 0.45346875], "policy_red_v19_reward": [3.2936307378161738], "policy_red_v6_reward": [0.4265937500000001, -0.5639499999999991, -2.013], "policy_red_v18_reward": [-1.21, 0.6570500000000006, -0.5063067621838293], "policy_red_v8_reward": [-0.6049999999999999, 0.7466932378161746, -2.031999999999999], "policy_red_v9_reward": [0.32869323781617366, 2.304421875, -1.11799999999999, -1.2669999999999986], "policy_red_v22_reward": [0.4766932378161698, -1.043999999999998], "policy_red_v7_reward": [-0.515], "policy_red_v12_reward": [2.43178125, 2.9141456677729436], "policy_red_v3_reward": [1.9464375, -2.01, -1.0199999999999987], "policy_red_v16_reward": [-2.0039999999999996, -0.1190000000000001, -1.1599999999999866], "policy_red_v2_reward": [-2.0179999999999993, -1.0019999999999998], "policy_red_v24_reward": [2.465984375], "policy_red_v4_reward": [-1.0109999999999992], "policy_red_v23_reward": [3.1836875000000053, 0.2516932378161749], "policy_red_v13_reward": [-0.15799999999999847, -1.5349999999999997, 0.44200000000000006], "policy_red_v26_reward": [1.4436932378161742]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8070831740209057, "mean_inference_ms": 7.815699187798202, "mean_action_processing_ms": 0.29479408575146304, "mean_env_wait_ms": 0.3887368179908364, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1044381856918335, "StateBufferConnector_ms": 0.004427671432495117, "ViewRequirementAgentConnector_ms": 0.12242293357849121}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.79055426904654, "num_env_steps_trained_throughput_per_sec": 199.79055426904654, "timesteps_total": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 20064.088, "sample_time_ms": 1167.256, "learn_time_ms": 18814.809, "learn_throughput": 212.598, "synch_weights_time_ms": 79.552}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "episodes_total": 477, "training_iteration": 60, "trial_id": "a9680_00000", "date": "2023-09-24_02-57-31", "timestamp": 1695538651, "time_this_iter_s": 20.030272960662842, "time_total_s": 1193.6975395679474, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b342ec3d0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3459f760>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3459f400>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1193.6975395679474, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 5.09375, "ram_util_percent": 19.6875}, "win_rate": 0.69, "league_size": 30}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.212539184714357, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.002497088509941629, "policy_loss": -0.05743652695576505, "vf_loss": 0.10939148333078871, "vf_explained_var": 0.6497100928798318, "kl": 0.016589723685679778, "entropy": 2.227502029389143, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 58080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 488000, "num_agent_steps_trained": 488000}, "sampler_results": {"episode_reward_max": 4.288105225632352, "episode_reward_min": -2.737822387183771, "episode_reward_mean": 1.965742610222858, "episode_len_mean": 301.53, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"red_v17": -1.718999999999994, "red": -5.958822387183821, "red_v9": -1.2669999999999986, "red_v22": -1.043999999999998, "red_v7": -0.515, "blue": -2.012999999999999, "red_v14": -2.0069999999999997, "red_v12": 2.43178125, "red_v6": -2.013, "red_v3": -2.01, "red_v10": -1.5469999999999975, "red_v18": -0.5063067621838293, "red_v16": -2.0039999999999996, "red_v2": -2.0179999999999993, "red_v24": 0.8932187500000002, "red_v8": -2.031999999999999, "red_v4": -1.0109999999999992, "red_v23": -0.5253067621838298, "red_v13": -1.5349999999999997, "red_v26": 0.3726932378161725, "red_v15": -2.0329999999999986}, "policy_reward_max": {"red_v17": 1.973203125, "red": 3.9951499085440547, "red_v9": 2.304421875, "red_v22": 0.4766932378161698, "red_v7": -0.515, "blue": 3.2210000000000027, "red_v14": 3.325021362816173, "red_v12": 2.9141456677729436, "red_v6": -0.5639499999999991, "red_v3": 1.9464375, "red_v10": -1.5469999999999975, "red_v18": 0.6570500000000006, "red_v16": -0.1190000000000001, "red_v2": -1.0019999999999998, "red_v24": 2.465984375, "red_v8": 0.7466932378161746, "red_v4": -1.0109999999999992, "red_v23": 3.1836875000000053, "red_v13": 0.44200000000000006, "red_v26": 1.4436932378161742, "red_v15": -2.0329999999999986}, "policy_reward_mean": {"red_v17": -0.2785989583333313, "red": 2.395106494961062, "red_v9": 0.06202877820404634, "red_v22": -0.2836533810919141, "red_v7": -0.515, "blue": -0.7752344488232531, "red_v14": 0.4312718683402723, "red_v12": 2.6729634588864717, "red_v6": -1.2884749999999996, "red_v3": -0.3611874999999995, "red_v10": -1.5469999999999975, "red_v18": 0.2058121585441138, "red_v16": -1.0943333333333287, "red_v2": -1.5099999999999996, "red_v24": 1.6136321209384017, "red_v8": -0.6426533810919123, "red_v4": -1.0109999999999992, "red_v23": 0.9700246585441167, "red_v13": -0.41699999999999937, "red_v26": 0.9081932378161733, "red_v15": -2.0329999999999986}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.4654588628161769, 3.058214600632388, 3.809370850632349, 2.9447557378161706, 2.465974487816171, 1.9676811585440557, -0.8229038949999959, 3.8473622272587678, 1.4728963628152034, -0.12585937499999988, -2.737822387183771, 1.3768148550000001, 2.418927612816172, 2.4334744878161714, 1.3273283644426501, 1.9491307378161697, 4.249052612816173, 1.3126932378162357, 2.319349487816174, 1.2928807378161755, 2.9093026128161723, 1.1715213628162058, 2.2891151128161757, 0.8169588628161747, 0.828474487816213, 2.3814901128161745, 2.4428026128161715, 3.2857146006323497, 4.093540112816173, 1.9748182378161705, 0.7591307378161717, 1.9605994878161903, 1.4638651128161704, 1.9831151128161701, 1.450052612816171, 0.7214276128162022, 1.485743658544055, 2.437396362816172, 0.9561619878161707, 1.6414901128162114, 1.9591377394425922, 1.6599093750000002, 2.9495369878161712, 2.120802612816184, 1.8475080928162333, 2.4676776128161713, 2.349740112816174, 1.4525369878161711, 1.8762211050000002, 2.433802612816172, 2.949792725632342, 0.6626932378162138, 1.458052612816171, 0.5097939894425918, 2.410927612816173, 2.4741932378161704, 2.136386475632377, 2.1593338628162053, 3.1710369878161844, 0.9946932378162164, 1.3774432378161747, 2.465677612816171, 2.08968750000001, 1.3649119878161966, 2.384943237816174, 2.4758651128161704, 2.811490112816177, 1.1036932378162074, 2.904838905589115, 1.9342088628161949, 1.7867244878162025, 1.1251406249999998, 4.288105225632352, 0.8539276128161921, 1.299146362816219, 3.4749177256323724, 1.9928651128161807, 1.6240306463602732, 1.7748026128161776, 1.985224487815204, 2.9631619878161706, 0.8970994878161727, 2.3852401128161733, 0.9476932378161704, 1.381536987816173, 1.393552612816237, 3.8578778522587682, 2.652620850632347, 0.6917869878162151, 3.8559958506323433, 1.985333167772942, 2.4724901128161703, 1.3979119878161712, 1.990149908544055, 3.6882146006323593, 2.099224487816186, 3.775008092815208, 1.4612713628161709, 1.9615682378161707, 1.4775994878161702], "episode_lengths": [363, 727, 165, 44, 38, 39, 188, 117, 31, 51, 837, 22, 85, 70, 1042, 52, 109, 1280, 174, 132, 93, 983, 153, 139, 1094, 97, 61, 183, 97, 24, 180, 478, 41, 25, 45, 629, 19, 63, 42, 545, 31, 13, 50, 317, 662, 37, 145, 50, 20, 61, 62, 1280, 45, 1165, 85, 32, 1280, 659, 210, 1280, 80, 37, 164, 826, 112, 41, 161, 1280, 79, 443, 502, 179, 154, 533, 975, 342, 361, 1237, 189, 22, 42, 62, 113, 64, 114, 1165, 112, 405, 1250, 157, 19, 33, 58, 17, 215, 342, 118, 39, 40, 30], "policy_red_v17_reward": [-1.718999999999994, -1.0899999999999999, 1.973203125], "policy_red_v9_reward": [0.32869323781617366, 2.304421875, -1.11799999999999, -1.2669999999999986], "policy_red_v22_reward": [0.4766932378161698, -1.043999999999998], "policy_red_v7_reward": [-0.515], "policy_blue_reward": [-1.0139999999999996, -2.01, 1.9530000000000007, -2.0059999999999993, -1.5179999999999998, 3.2210000000000027, -2.002, -1.0259999999999978, 1.3220000000000007, 1.588000000000018, -1.0459999999999958, -0.023000000000000013, -1.2479999999999756, -1.3179999999999699, -1.0139999999999998, -1.5519999999999994, -1.1309999999999891, 1.459171875, -1.1920000000000002, -1.0179999999999993, -1.1639999999999855, -0.012000000000000004, -1.097999999999992, 1.738814855000007, -2.012999999999999, -2.005, -1.0209999999999988, -1.3489999999999684, -2.0119999999999996, -0.8210000000000003, -1.0249999999999986, -1.0059999999999996, -0.6810000000000002, -1.2269999999999783, -1.0319999999999974, -0.5379999999999974, -1.1299999999999881, -1.1409999999999898, 1.813140625, -1.1059999999999905, 0.1501030335440734, 1.811109375, -2.0029999999999997, -0.010000000000000002, -1.0289999999999975, -0.8350000000000003, -1.391999999999966, -2.0069999999999997, -1.0099999999999993, -2.005, -1.0989999999999935, -2.012999999999999, -2.0109999999999992, -2.006], "policy_red_v14_reward": [0.44193461444259247, 3.325021362816173, -2.0069999999999997, 0.45346875, -0.05706538555740459], "policy_red_v12_reward": [2.43178125, 2.9141456677729436], "policy_red_v6_reward": [-0.5639499999999991, -2.013], "policy_red_v3_reward": [1.9464375, -2.01, -1.0199999999999987], "policy_red_v10_reward": [-1.5469999999999975], "policy_red_v18_reward": [0.6570500000000006, -0.5063067621838293, 0.46669323781617006], "policy_red_v16_reward": [-2.0039999999999996, -0.1190000000000001, -1.1599999999999866], "policy_red_v2_reward": [-2.0179999999999993, -1.0019999999999998], "policy_red_v24_reward": [2.465984375, 0.8932187500000002, 1.4816932378152048], "policy_red_v8_reward": [0.7466932378161746, -2.031999999999999], "policy_red_v4_reward": [-1.0109999999999992], "policy_red_v23_reward": [3.1836875000000053, 0.2516932378161749, -0.5253067621838298], "policy_red_v13_reward": [-0.15799999999999847, -1.5349999999999997, 0.44200000000000006], "policy_red_v26_reward": [1.4436932378161742, 0.3726932378161725], "policy_red_v15_reward": [-2.0329999999999986]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8058770025027687, "mean_inference_ms": 7.783443248363341, "mean_action_processing_ms": 0.29404587182060843, "mean_env_wait_ms": 0.38755425887173656, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1035081148147583, "StateBufferConnector_ms": 0.00437617301940918, "ViewRequirementAgentConnector_ms": 0.1212165355682373}}, "episode_reward_max": 4.288105225632352, "episode_reward_min": -2.737822387183771, "episode_reward_mean": 1.965742610222858, "episode_len_mean": 301.53, "episodes_this_iter": 16, "policy_reward_min": {"red_v17": -1.718999999999994, "red": -5.958822387183821, "red_v9": -1.2669999999999986, "red_v22": -1.043999999999998, "red_v7": -0.515, "blue": -2.012999999999999, "red_v14": -2.0069999999999997, "red_v12": 2.43178125, "red_v6": -2.013, "red_v3": -2.01, "red_v10": -1.5469999999999975, "red_v18": -0.5063067621838293, "red_v16": -2.0039999999999996, "red_v2": -2.0179999999999993, "red_v24": 0.8932187500000002, "red_v8": -2.031999999999999, "red_v4": -1.0109999999999992, "red_v23": -0.5253067621838298, "red_v13": -1.5349999999999997, "red_v26": 0.3726932378161725, "red_v15": -2.0329999999999986}, "policy_reward_max": {"red_v17": 1.973203125, "red": 3.9951499085440547, "red_v9": 2.304421875, "red_v22": 0.4766932378161698, "red_v7": -0.515, "blue": 3.2210000000000027, "red_v14": 3.325021362816173, "red_v12": 2.9141456677729436, "red_v6": -0.5639499999999991, "red_v3": 1.9464375, "red_v10": -1.5469999999999975, "red_v18": 0.6570500000000006, "red_v16": -0.1190000000000001, "red_v2": -1.0019999999999998, "red_v24": 2.465984375, "red_v8": 0.7466932378161746, "red_v4": -1.0109999999999992, "red_v23": 3.1836875000000053, "red_v13": 0.44200000000000006, "red_v26": 1.4436932378161742, "red_v15": -2.0329999999999986}, "policy_reward_mean": {"red_v17": -0.2785989583333313, "red": 2.395106494961062, "red_v9": 0.06202877820404634, "red_v22": -0.2836533810919141, "red_v7": -0.515, "blue": -0.7752344488232531, "red_v14": 0.4312718683402723, "red_v12": 2.6729634588864717, "red_v6": -1.2884749999999996, "red_v3": -0.3611874999999995, "red_v10": -1.5469999999999975, "red_v18": 0.2058121585441138, "red_v16": -1.0943333333333287, "red_v2": -1.5099999999999996, "red_v24": 1.6136321209384017, "red_v8": -0.6426533810919123, "red_v4": -1.0109999999999992, "red_v23": 0.9700246585441167, "red_v13": -0.41699999999999937, "red_v26": 0.9081932378161733, "red_v15": -2.0329999999999986}, "hist_stats": {"episode_reward": [0.4654588628161769, 3.058214600632388, 3.809370850632349, 2.9447557378161706, 2.465974487816171, 1.9676811585440557, -0.8229038949999959, 3.8473622272587678, 1.4728963628152034, -0.12585937499999988, -2.737822387183771, 1.3768148550000001, 2.418927612816172, 2.4334744878161714, 1.3273283644426501, 1.9491307378161697, 4.249052612816173, 1.3126932378162357, 2.319349487816174, 1.2928807378161755, 2.9093026128161723, 1.1715213628162058, 2.2891151128161757, 0.8169588628161747, 0.828474487816213, 2.3814901128161745, 2.4428026128161715, 3.2857146006323497, 4.093540112816173, 1.9748182378161705, 0.7591307378161717, 1.9605994878161903, 1.4638651128161704, 1.9831151128161701, 1.450052612816171, 0.7214276128162022, 1.485743658544055, 2.437396362816172, 0.9561619878161707, 1.6414901128162114, 1.9591377394425922, 1.6599093750000002, 2.9495369878161712, 2.120802612816184, 1.8475080928162333, 2.4676776128161713, 2.349740112816174, 1.4525369878161711, 1.8762211050000002, 2.433802612816172, 2.949792725632342, 0.6626932378162138, 1.458052612816171, 0.5097939894425918, 2.410927612816173, 2.4741932378161704, 2.136386475632377, 2.1593338628162053, 3.1710369878161844, 0.9946932378162164, 1.3774432378161747, 2.465677612816171, 2.08968750000001, 1.3649119878161966, 2.384943237816174, 2.4758651128161704, 2.811490112816177, 1.1036932378162074, 2.904838905589115, 1.9342088628161949, 1.7867244878162025, 1.1251406249999998, 4.288105225632352, 0.8539276128161921, 1.299146362816219, 3.4749177256323724, 1.9928651128161807, 1.6240306463602732, 1.7748026128161776, 1.985224487815204, 2.9631619878161706, 0.8970994878161727, 2.3852401128161733, 0.9476932378161704, 1.381536987816173, 1.393552612816237, 3.8578778522587682, 2.652620850632347, 0.6917869878162151, 3.8559958506323433, 1.985333167772942, 2.4724901128161703, 1.3979119878161712, 1.990149908544055, 3.6882146006323593, 2.099224487816186, 3.775008092815208, 1.4612713628161709, 1.9615682378161707, 1.4775994878161702], "episode_lengths": [363, 727, 165, 44, 38, 39, 188, 117, 31, 51, 837, 22, 85, 70, 1042, 52, 109, 1280, 174, 132, 93, 983, 153, 139, 1094, 97, 61, 183, 97, 24, 180, 478, 41, 25, 45, 629, 19, 63, 42, 545, 31, 13, 50, 317, 662, 37, 145, 50, 20, 61, 62, 1280, 45, 1165, 85, 32, 1280, 659, 210, 1280, 80, 37, 164, 826, 112, 41, 161, 1280, 79, 443, 502, 179, 154, 533, 975, 342, 361, 1237, 189, 22, 42, 62, 113, 64, 114, 1165, 112, 405, 1250, 157, 19, 33, 58, 17, 215, 342, 118, 39, 40, 30], "policy_red_v17_reward": [-1.718999999999994, -1.0899999999999999, 1.973203125], "policy_red_v9_reward": [0.32869323781617366, 2.304421875, -1.11799999999999, -1.2669999999999986], "policy_red_v22_reward": [0.4766932378161698, -1.043999999999998], "policy_red_v7_reward": [-0.515], "policy_blue_reward": [-1.0139999999999996, -2.01, 1.9530000000000007, -2.0059999999999993, -1.5179999999999998, 3.2210000000000027, -2.002, -1.0259999999999978, 1.3220000000000007, 1.588000000000018, -1.0459999999999958, -0.023000000000000013, -1.2479999999999756, -1.3179999999999699, -1.0139999999999998, -1.5519999999999994, -1.1309999999999891, 1.459171875, -1.1920000000000002, -1.0179999999999993, -1.1639999999999855, -0.012000000000000004, -1.097999999999992, 1.738814855000007, -2.012999999999999, -2.005, -1.0209999999999988, -1.3489999999999684, -2.0119999999999996, -0.8210000000000003, -1.0249999999999986, -1.0059999999999996, -0.6810000000000002, -1.2269999999999783, -1.0319999999999974, -0.5379999999999974, -1.1299999999999881, -1.1409999999999898, 1.813140625, -1.1059999999999905, 0.1501030335440734, 1.811109375, -2.0029999999999997, -0.010000000000000002, -1.0289999999999975, -0.8350000000000003, -1.391999999999966, -2.0069999999999997, -1.0099999999999993, -2.005, -1.0989999999999935, -2.012999999999999, -2.0109999999999992, -2.006], "policy_red_v14_reward": [0.44193461444259247, 3.325021362816173, -2.0069999999999997, 0.45346875, -0.05706538555740459], "policy_red_v12_reward": [2.43178125, 2.9141456677729436], "policy_red_v6_reward": [-0.5639499999999991, -2.013], "policy_red_v3_reward": [1.9464375, -2.01, -1.0199999999999987], "policy_red_v10_reward": [-1.5469999999999975], "policy_red_v18_reward": [0.6570500000000006, -0.5063067621838293, 0.46669323781617006], "policy_red_v16_reward": [-2.0039999999999996, -0.1190000000000001, -1.1599999999999866], "policy_red_v2_reward": [-2.0179999999999993, -1.0019999999999998], "policy_red_v24_reward": [2.465984375, 0.8932187500000002, 1.4816932378152048], "policy_red_v8_reward": [0.7466932378161746, -2.031999999999999], "policy_red_v4_reward": [-1.0109999999999992], "policy_red_v23_reward": [3.1836875000000053, 0.2516932378161749, -0.5253067621838298], "policy_red_v13_reward": [-0.15799999999999847, -1.5349999999999997, 0.44200000000000006], "policy_red_v26_reward": [1.4436932378161742, 0.3726932378161725], "policy_red_v15_reward": [-2.0329999999999986]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8058770025027687, "mean_inference_ms": 7.783443248363341, "mean_action_processing_ms": 0.29404587182060843, "mean_env_wait_ms": 0.38755425887173656, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1035081148147583, "StateBufferConnector_ms": 0.00437617301940918, "ViewRequirementAgentConnector_ms": 0.1212165355682373}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 488000, "num_agent_steps_trained": 488000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.1826594030701, "num_env_steps_trained_throughput_per_sec": 200.1826594030701, "timesteps_total": 244000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 488000, "timers": {"training_iteration_time_ms": 20018.579, "sample_time_ms": 1175.33, "learn_time_ms": 18759.494, "learn_throughput": 213.225, "synch_weights_time_ms": 81.279}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 488000, "num_agent_steps_trained": 488000}, "done": false, "episodes_total": 493, "training_iteration": 61, "trial_id": "a9680_00000", "date": "2023-09-24_02-57-54", "timestamp": 1695538674, "time_this_iter_s": 19.99223303794861, "time_total_s": 1213.689772605896, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b342ecaf0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3459f5b0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3459e320>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1213.689772605896, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 4.836363636363636, "ram_util_percent": 19.875757575757575}, "win_rate": 0.7, "league_size": 31}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.263598680247863, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.08094761330721667, "policy_loss": -0.04498972480214434, "vf_loss": 0.23981756067369134, "vf_explained_var": 0.6471519012004137, "kl": 0.017986730653747902, "entropy": 2.0654706403613092, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 59040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "sampler_results": {"episode_reward_max": 4.288105225632352, "episode_reward_min": 0.20392187500000014, "episode_reward_mean": 2.0442723741429694, "episode_len_mean": 264.63, "episode_media": {}, "episodes_this_iter": 22, "policy_reward_min": {"red_v9": -1.2669999999999986, "red": -1.0939999999999999, "red_v10": -1.5469999999999975, "blue": -2.022999999999998, "red_v22": -1.043999999999998, "red_v14": -2.0069999999999997, "red_v18": -0.5063067621838293, "red_v6": -2.013, "red_v16": -2.0039999999999996, "red_v2": -2.0179999999999993, "red_v17": 1.973203125, "red_v3": -2.01, "red_v24": 0.8932187500000002, "red_v8": -2.031999999999999, "red_v4": -1.0109999999999992, "red_v23": -0.5253067621838298, "red_v13": -1.5349999999999997, "red_v12": 2.9141456677729436, "red_v26": 0.3726932378161725, "red_v15": -2.0329999999999986}, "policy_reward_max": {"red_v9": 2.304421875, "red": 3.9951499085440547, "red_v10": -1.5469999999999975, "blue": 1.813140625, "red_v22": -1.043999999999998, "red_v14": 3.325021362816173, "red_v18": 0.6570500000000006, "red_v6": -2.013, "red_v16": 0.4306932378161703, "red_v2": -1.0019999999999998, "red_v17": 1.973203125, "red_v3": -1.0199999999999987, "red_v24": 2.465984375, "red_v8": 0.7466932378161746, "red_v4": -0.649, "red_v23": 3.1836875000000053, "red_v13": 0.44200000000000006, "red_v12": 2.9141456677729436, "red_v26": 1.4436932378161742, "red_v15": -2.0329999999999986}, "policy_reward_mean": {"red_v9": -0.026859374999996133, "red": 2.628946198775601, "red_v10": -1.5469999999999975, "blue": -0.9677465063413281, "red_v22": -1.043999999999998, "red_v14": 0.4286061818146922, "red_v18": 0.15335911890808535, "red_v6": -2.013, "red_v16": -0.713076690545954, "red_v2": -1.5099999999999996, "red_v17": 1.973203125, "red_v3": -1.5149999999999992, "red_v24": 1.6136321209384017, "red_v8": -0.6426533810919123, "red_v4": -0.8299999999999996, "red_v23": 0.7001634426897048, "red_v13": -0.5284874999999988, "red_v12": 2.9141456677729436, "red_v26": 0.9081932378161733, "red_v15": -2.0329999999999986}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.2891151128161757, 0.8169588628161747, 0.828474487816213, 2.3814901128161745, 2.4428026128161715, 3.2857146006323497, 4.093540112816173, 1.9748182378161705, 0.7591307378161717, 1.9605994878161903, 1.4638651128161704, 1.9831151128161701, 1.450052612816171, 0.7214276128162022, 1.485743658544055, 2.437396362816172, 0.9561619878161707, 1.6414901128162114, 1.9591377394425922, 1.6599093750000002, 2.9495369878161712, 2.120802612816184, 1.8475080928162333, 2.4676776128161713, 2.349740112816174, 1.4525369878161711, 1.8762211050000002, 2.433802612816172, 2.949792725632342, 0.6626932378162138, 1.458052612816171, 0.5097939894425918, 2.410927612816173, 2.4741932378161704, 2.136386475632377, 2.1593338628162053, 3.1710369878161844, 0.9946932378162164, 1.3774432378161747, 2.465677612816171, 2.08968750000001, 1.3649119878161966, 2.384943237816174, 2.4758651128161704, 2.811490112816177, 1.1036932378162074, 2.904838905589115, 1.9342088628161949, 1.7867244878162025, 1.1251406249999998, 4.288105225632352, 0.8539276128161921, 1.299146362816219, 3.4749177256323724, 1.9928651128161807, 1.6240306463602732, 1.7748026128161776, 1.985224487815204, 2.9631619878161706, 0.8970994878161727, 2.3852401128161733, 0.9476932378161704, 1.381536987816173, 1.393552612816237, 3.8578778522587682, 2.652620850632347, 0.6917869878162151, 3.8559958506323433, 1.985333167772942, 2.4724901128161703, 1.3979119878161712, 1.990149908544055, 3.6882146006323593, 2.099224487816186, 3.775008092815208, 1.4612713628161709, 1.9615682378161707, 1.4775994878161702, 1.2955213628161744, 2.5805057378161838, 2.9866307378152035, 1.8363437500000002, 0.20392187500000014, 1.9715752394425927, 3.6639489756323567, 2.9917401128152035, 2.372974487816185, 0.884052612816171, 2.3056776128161776, 3.5438213628161748, 1.9220682378161729, 3.0658682378161757, 1.4896307378152036, 2.341411987816174, 0.30628125000000006, 2.4693807378161705, 2.7448396006323534, 2.2579588628161797, 1.34315625, 2.3812713628161717], "episode_lengths": [153, 139, 1094, 97, 61, 183, 97, 24, 180, 478, 41, 25, 45, 629, 19, 63, 42, 545, 31, 13, 50, 317, 662, 37, 145, 50, 20, 61, 62, 1280, 45, 1165, 85, 32, 1280, 659, 210, 1280, 80, 37, 164, 826, 112, 41, 161, 1280, 79, 443, 502, 179, 154, 533, 975, 342, 361, 1237, 189, 22, 42, 62, 113, 64, 114, 1165, 112, 405, 1250, 157, 19, 33, 58, 17, 215, 342, 118, 39, 40, 30, 215, 316, 20, 18, 121, 19, 268, 17, 550, 109, 165, 135, 72, 88, 20, 154, 102, 36, 207, 203, 14, 103], "policy_red_v9_reward": [2.304421875, -1.11799999999999, -1.2669999999999986], "policy_red_v10_reward": [-1.5469999999999975], "policy_blue_reward": [-1.3179999999999699, -1.0139999999999998, -1.5519999999999994, -1.1309999999999891, 1.459171875, -1.1920000000000002, -1.0179999999999993, -1.1639999999999855, -0.012000000000000004, -1.097999999999992, 1.738814855000007, -2.012999999999999, -2.005, -1.0209999999999988, -1.3489999999999684, -2.0119999999999996, -0.8210000000000003, -1.0249999999999986, -1.0059999999999996, -0.6810000000000002, -1.2269999999999783, -1.0319999999999974, -0.5379999999999974, -1.1299999999999881, -1.1409999999999898, 1.813140625, -1.1059999999999905, 0.1501030335440734, 1.811109375, -2.0029999999999997, -0.010000000000000002, -1.0289999999999975, -0.8350000000000003, -1.391999999999966, -2.0069999999999997, -1.0099999999999993, -2.005, -1.0989999999999935, -2.012999999999999, -2.0109999999999992, -2.006, 0.7888281250000002, -0.005, -1.0059999999999998, -1.541, -2.0039999999999996, 0.9392812500000001, -1.5289999999999995, -1.0539999999999958, -2.022999999999998, -2.0039999999999996, -1.040999999999997, -1.533, -1.0079999999999993, -1.0609999999999966, -2.0, -1.0269999999999988], "policy_red_v22_reward": [-1.043999999999998], "policy_red_v14_reward": [3.325021362816173, -2.0069999999999997, 0.45346875, -0.05706538555740459], "policy_red_v18_reward": [0.6570500000000006, -0.5063067621838293, 0.46669323781617006, -0.004], "policy_red_v6_reward": [-2.013], "policy_red_v16_reward": [-2.0039999999999996, -0.1190000000000001, -1.1599999999999866, 0.4306932378161703], "policy_red_v2_reward": [-2.0179999999999993, -1.0019999999999998], "policy_red_v17_reward": [1.973203125], "policy_red_v3_reward": [-2.01, -1.0199999999999987], "policy_red_v24_reward": [2.465984375, 0.8932187500000002, 1.4816932378152048], "policy_red_v8_reward": [0.7466932378161746, -2.031999999999999], "policy_red_v4_reward": [-1.0109999999999992, -0.649], "policy_red_v23_reward": [3.1836875000000053, 0.2516932378161749, -0.5253067621838298, 0.14405000000000046, 0.4466932378161732], "policy_red_v13_reward": [-0.15799999999999847, -1.5349999999999997, 0.44200000000000006, -0.8629499999999969], "policy_red_v12_reward": [2.9141456677729436], "policy_red_v26_reward": [1.4436932378161742, 0.3726932378161725], "policy_red_v15_reward": [-2.0329999999999986]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8067858530726728, "mean_inference_ms": 7.794881877903353, "mean_action_processing_ms": 0.29484367457404337, "mean_env_wait_ms": 0.38853559138825366, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10163843631744385, "StateBufferConnector_ms": 0.0042836666107177734, "ViewRequirementAgentConnector_ms": 0.11855792999267578}}, "episode_reward_max": 4.288105225632352, "episode_reward_min": 0.20392187500000014, "episode_reward_mean": 2.0442723741429694, "episode_len_mean": 264.63, "episodes_this_iter": 22, "policy_reward_min": {"red_v9": -1.2669999999999986, "red": -1.0939999999999999, "red_v10": -1.5469999999999975, "blue": -2.022999999999998, "red_v22": -1.043999999999998, "red_v14": -2.0069999999999997, "red_v18": -0.5063067621838293, "red_v6": -2.013, "red_v16": -2.0039999999999996, "red_v2": -2.0179999999999993, "red_v17": 1.973203125, "red_v3": -2.01, "red_v24": 0.8932187500000002, "red_v8": -2.031999999999999, "red_v4": -1.0109999999999992, "red_v23": -0.5253067621838298, "red_v13": -1.5349999999999997, "red_v12": 2.9141456677729436, "red_v26": 0.3726932378161725, "red_v15": -2.0329999999999986}, "policy_reward_max": {"red_v9": 2.304421875, "red": 3.9951499085440547, "red_v10": -1.5469999999999975, "blue": 1.813140625, "red_v22": -1.043999999999998, "red_v14": 3.325021362816173, "red_v18": 0.6570500000000006, "red_v6": -2.013, "red_v16": 0.4306932378161703, "red_v2": -1.0019999999999998, "red_v17": 1.973203125, "red_v3": -1.0199999999999987, "red_v24": 2.465984375, "red_v8": 0.7466932378161746, "red_v4": -0.649, "red_v23": 3.1836875000000053, "red_v13": 0.44200000000000006, "red_v12": 2.9141456677729436, "red_v26": 1.4436932378161742, "red_v15": -2.0329999999999986}, "policy_reward_mean": {"red_v9": -0.026859374999996133, "red": 2.628946198775601, "red_v10": -1.5469999999999975, "blue": -0.9677465063413281, "red_v22": -1.043999999999998, "red_v14": 0.4286061818146922, "red_v18": 0.15335911890808535, "red_v6": -2.013, "red_v16": -0.713076690545954, "red_v2": -1.5099999999999996, "red_v17": 1.973203125, "red_v3": -1.5149999999999992, "red_v24": 1.6136321209384017, "red_v8": -0.6426533810919123, "red_v4": -0.8299999999999996, "red_v23": 0.7001634426897048, "red_v13": -0.5284874999999988, "red_v12": 2.9141456677729436, "red_v26": 0.9081932378161733, "red_v15": -2.0329999999999986}, "hist_stats": {"episode_reward": [2.2891151128161757, 0.8169588628161747, 0.828474487816213, 2.3814901128161745, 2.4428026128161715, 3.2857146006323497, 4.093540112816173, 1.9748182378161705, 0.7591307378161717, 1.9605994878161903, 1.4638651128161704, 1.9831151128161701, 1.450052612816171, 0.7214276128162022, 1.485743658544055, 2.437396362816172, 0.9561619878161707, 1.6414901128162114, 1.9591377394425922, 1.6599093750000002, 2.9495369878161712, 2.120802612816184, 1.8475080928162333, 2.4676776128161713, 2.349740112816174, 1.4525369878161711, 1.8762211050000002, 2.433802612816172, 2.949792725632342, 0.6626932378162138, 1.458052612816171, 0.5097939894425918, 2.410927612816173, 2.4741932378161704, 2.136386475632377, 2.1593338628162053, 3.1710369878161844, 0.9946932378162164, 1.3774432378161747, 2.465677612816171, 2.08968750000001, 1.3649119878161966, 2.384943237816174, 2.4758651128161704, 2.811490112816177, 1.1036932378162074, 2.904838905589115, 1.9342088628161949, 1.7867244878162025, 1.1251406249999998, 4.288105225632352, 0.8539276128161921, 1.299146362816219, 3.4749177256323724, 1.9928651128161807, 1.6240306463602732, 1.7748026128161776, 1.985224487815204, 2.9631619878161706, 0.8970994878161727, 2.3852401128161733, 0.9476932378161704, 1.381536987816173, 1.393552612816237, 3.8578778522587682, 2.652620850632347, 0.6917869878162151, 3.8559958506323433, 1.985333167772942, 2.4724901128161703, 1.3979119878161712, 1.990149908544055, 3.6882146006323593, 2.099224487816186, 3.775008092815208, 1.4612713628161709, 1.9615682378161707, 1.4775994878161702, 1.2955213628161744, 2.5805057378161838, 2.9866307378152035, 1.8363437500000002, 0.20392187500000014, 1.9715752394425927, 3.6639489756323567, 2.9917401128152035, 2.372974487816185, 0.884052612816171, 2.3056776128161776, 3.5438213628161748, 1.9220682378161729, 3.0658682378161757, 1.4896307378152036, 2.341411987816174, 0.30628125000000006, 2.4693807378161705, 2.7448396006323534, 2.2579588628161797, 1.34315625, 2.3812713628161717], "episode_lengths": [153, 139, 1094, 97, 61, 183, 97, 24, 180, 478, 41, 25, 45, 629, 19, 63, 42, 545, 31, 13, 50, 317, 662, 37, 145, 50, 20, 61, 62, 1280, 45, 1165, 85, 32, 1280, 659, 210, 1280, 80, 37, 164, 826, 112, 41, 161, 1280, 79, 443, 502, 179, 154, 533, 975, 342, 361, 1237, 189, 22, 42, 62, 113, 64, 114, 1165, 112, 405, 1250, 157, 19, 33, 58, 17, 215, 342, 118, 39, 40, 30, 215, 316, 20, 18, 121, 19, 268, 17, 550, 109, 165, 135, 72, 88, 20, 154, 102, 36, 207, 203, 14, 103], "policy_red_v9_reward": [2.304421875, -1.11799999999999, -1.2669999999999986], "policy_red_v10_reward": [-1.5469999999999975], "policy_blue_reward": [-1.3179999999999699, -1.0139999999999998, -1.5519999999999994, -1.1309999999999891, 1.459171875, -1.1920000000000002, -1.0179999999999993, -1.1639999999999855, -0.012000000000000004, -1.097999999999992, 1.738814855000007, -2.012999999999999, -2.005, -1.0209999999999988, -1.3489999999999684, -2.0119999999999996, -0.8210000000000003, -1.0249999999999986, -1.0059999999999996, -0.6810000000000002, -1.2269999999999783, -1.0319999999999974, -0.5379999999999974, -1.1299999999999881, -1.1409999999999898, 1.813140625, -1.1059999999999905, 0.1501030335440734, 1.811109375, -2.0029999999999997, -0.010000000000000002, -1.0289999999999975, -0.8350000000000003, -1.391999999999966, -2.0069999999999997, -1.0099999999999993, -2.005, -1.0989999999999935, -2.012999999999999, -2.0109999999999992, -2.006, 0.7888281250000002, -0.005, -1.0059999999999998, -1.541, -2.0039999999999996, 0.9392812500000001, -1.5289999999999995, -1.0539999999999958, -2.022999999999998, -2.0039999999999996, -1.040999999999997, -1.533, -1.0079999999999993, -1.0609999999999966, -2.0, -1.0269999999999988], "policy_red_v22_reward": [-1.043999999999998], "policy_red_v14_reward": [3.325021362816173, -2.0069999999999997, 0.45346875, -0.05706538555740459], "policy_red_v18_reward": [0.6570500000000006, -0.5063067621838293, 0.46669323781617006, -0.004], "policy_red_v6_reward": [-2.013], "policy_red_v16_reward": [-2.0039999999999996, -0.1190000000000001, -1.1599999999999866, 0.4306932378161703], "policy_red_v2_reward": [-2.0179999999999993, -1.0019999999999998], "policy_red_v17_reward": [1.973203125], "policy_red_v3_reward": [-2.01, -1.0199999999999987], "policy_red_v24_reward": [2.465984375, 0.8932187500000002, 1.4816932378152048], "policy_red_v8_reward": [0.7466932378161746, -2.031999999999999], "policy_red_v4_reward": [-1.0109999999999992, -0.649], "policy_red_v23_reward": [3.1836875000000053, 0.2516932378161749, -0.5253067621838298, 0.14405000000000046, 0.4466932378161732], "policy_red_v13_reward": [-0.15799999999999847, -1.5349999999999997, 0.44200000000000006, -0.8629499999999969], "policy_red_v12_reward": [2.9141456677729436], "policy_red_v26_reward": [1.4436932378161742, 0.3726932378161725], "policy_red_v15_reward": [-2.0329999999999986]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8067858530726728, "mean_inference_ms": 7.794881877903353, "mean_action_processing_ms": 0.29484367457404337, "mean_env_wait_ms": 0.38853559138825366, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10163843631744385, "StateBufferConnector_ms": 0.0042836666107177734, "ViewRequirementAgentConnector_ms": 0.11855792999267578}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 202.37447814334922, "num_env_steps_trained_throughput_per_sec": 202.37447814334922, "timesteps_total": 248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 20049.983, "sample_time_ms": 1171.859, "learn_time_ms": 18795.283, "learn_throughput": 212.819, "synch_weights_time_ms": 80.334}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "episodes_total": 515, "training_iteration": 62, "trial_id": "a9680_00000", "date": "2023-09-24_02-58-16", "timestamp": 1695538696, "time_this_iter_s": 19.774845123291016, "time_total_s": 1233.464617729187, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34340d30>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b342cf640>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b342cf6d0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1233.464617729187, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 5.151612903225807, "ram_util_percent": 19.983870967741936}, "win_rate": 0.74, "league_size": 32}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1849390633404253, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0010843050952341097, "policy_loss": -0.05527404489354618, "vf_loss": 0.09745074910654997, "vf_explained_var": 0.6759941124046842, "kl": 0.016905416911186317, "entropy": 2.1430724653104942, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 504000, "num_agent_steps_trained": 504000}, "sampler_results": {"episode_reward_max": 4.288105225632352, "episode_reward_min": 0.20392187500000014, "episode_reward_mean": 2.096359309830116, "episode_len_mean": 254.33, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"red_v17": 1.973203125, "red": -1.0939999999999999, "red_v3": -2.01, "blue": -2.102999999999991, "red_v24": 0.8932187500000002, "red_v18": -0.5063067621838293, "red_v8": -2.031999999999999, "red_v16": -1.1599999999999866, "red_v9": -1.2669999999999986, "red_v4": -1.0109999999999992, "red_v23": -1.4419999999999662, "red_v2": -1.0479999999999974, "red_v13": -1.5349999999999997, "red_v12": 2.9141456677729436, "red_v26": 0.3726932378161725, "red_v15": -2.0329999999999986, "red_v14": -0.5173067621838289, "red_v29": -0.5233067621838287, "red_v27": -0.5089999999999999, "red_v28": -0.6019999999999999}, "policy_reward_max": {"red_v17": 1.973203125, "red": 3.9951499085440547, "red_v3": 0.46343749999999984, "blue": 1.813140625, "red_v24": 2.465984375, "red_v18": 0.46669323781617006, "red_v8": 1.953765625, "red_v16": 0.4306932378161703, "red_v9": -1.11799999999999, "red_v4": -0.649, "red_v23": 3.1836875000000053, "red_v2": -1.0019999999999998, "red_v13": 2.35696875, "red_v12": 2.9141456677729436, "red_v26": 1.4436932378161742, "red_v15": -2.0329999999999986, "red_v14": -0.05706538555740459, "red_v29": -0.5233067621838287, "red_v27": -0.5089999999999999, "red_v28": -0.6019999999999999}, "policy_reward_mean": {"red_v17": 1.973203125, "red": 2.7040988895845857, "red_v3": -0.8555208333333328, "blue": -1.0608723287097497, "red_v24": 1.6136321209384017, "red_v18": -0.014537841455886416, "red_v8": 0.22281962093872512, "red_v16": -0.28276892072793874, "red_v9": -1.1924999999999941, "red_v4": -0.8299999999999996, "red_v23": 0.3431362022414263, "red_v2": -1.024666666666665, "red_v13": 0.048603750000000986, "red_v12": 2.9141456677729436, "red_v26": 0.9081932378161733, "red_v15": -2.0329999999999986, "red_v14": -0.28718607387061673, "red_v29": -0.5233067621838287, "red_v27": -0.5089999999999999, "red_v28": -0.6019999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.9591377394425922, 1.6599093750000002, 2.9495369878161712, 2.120802612816184, 1.8475080928162333, 2.4676776128161713, 2.349740112816174, 1.4525369878161711, 1.8762211050000002, 2.433802612816172, 2.949792725632342, 0.6626932378162138, 1.458052612816171, 0.5097939894425918, 2.410927612816173, 2.4741932378161704, 2.136386475632377, 2.1593338628162053, 3.1710369878161844, 0.9946932378162164, 1.3774432378161747, 2.465677612816171, 2.08968750000001, 1.3649119878161966, 2.384943237816174, 2.4758651128161704, 2.811490112816177, 1.1036932378162074, 2.904838905589115, 1.9342088628161949, 1.7867244878162025, 1.1251406249999998, 4.288105225632352, 0.8539276128161921, 1.299146362816219, 3.4749177256323724, 1.9928651128161807, 1.6240306463602732, 1.7748026128161776, 1.985224487815204, 2.9631619878161706, 0.8970994878161727, 2.3852401128161733, 0.9476932378161704, 1.381536987816173, 1.393552612816237, 3.8578778522587682, 2.652620850632347, 0.6917869878162151, 3.8559958506323433, 1.985333167772942, 2.4724901128161703, 1.3979119878161712, 1.990149908544055, 3.6882146006323593, 2.099224487816186, 3.775008092815208, 1.4612713628161709, 1.9615682378161707, 1.4775994878161702, 1.2955213628161744, 2.5805057378161838, 2.9866307378152035, 1.8363437500000002, 0.20392187500000014, 1.9715752394425927, 3.6639489756323567, 2.9917401128152035, 2.372974487816185, 0.884052612816171, 2.3056776128161776, 3.5438213628161748, 1.9220682378161729, 3.0658682378161757, 1.4896307378152036, 2.341411987816174, 0.30628125000000006, 2.4693807378161705, 2.7448396006323534, 2.2579588628161797, 1.34315625, 2.3812713628161717, 2.2913494878161775, 1.620052612816187, 2.359661987816174, 1.434880737816171, 2.9242146006323426, 2.399068237816171, 2.4679744878161705, 1.4686776128161703, 2.4624588628161708, 0.9251307378161879, 3.398933350632343, 1.9740057378161708, 1.9617557378161714, 0.9952869878162097, 2.344896362816174, 2.8166776128161746, 2.402865112816172, 1.9327002394425938], "episode_lengths": [31, 13, 50, 317, 662, 37, 145, 50, 20, 61, 62, 1280, 45, 1165, 85, 32, 1280, 659, 210, 1280, 80, 37, 164, 826, 112, 41, 161, 1280, 79, 443, 502, 179, 154, 533, 975, 342, 361, 1237, 189, 22, 42, 62, 113, 64, 114, 1165, 112, 405, 1250, 157, 19, 33, 58, 17, 215, 342, 118, 39, 40, 30, 215, 316, 20, 18, 121, 19, 268, 17, 550, 109, 165, 135, 72, 88, 20, 154, 102, 36, 207, 203, 14, 103, 174, 301, 74, 68, 87, 72, 38, 37, 43, 500, 113, 28, 44, 898, 159, 101, 105, 43], "policy_red_v17_reward": [1.973203125], "policy_red_v3_reward": [-2.01, -1.0199999999999987, 0.46343749999999984], "policy_blue_reward": [-0.012000000000000004, -1.097999999999992, 1.738814855000007, -2.012999999999999, -2.005, -1.0209999999999988, -1.3489999999999684, -2.0119999999999996, -0.8210000000000003, -1.0249999999999986, -1.0059999999999996, -0.6810000000000002, -1.2269999999999783, -1.0319999999999974, -0.5379999999999974, -1.1299999999999881, -1.1409999999999898, 1.813140625, -1.1059999999999905, 0.1501030335440734, 1.811109375, -2.0029999999999997, -0.010000000000000002, -1.0289999999999975, -0.8350000000000003, -1.391999999999966, -2.0069999999999997, -1.0099999999999993, -2.005, -1.0989999999999935, -2.012999999999999, -2.0109999999999992, -2.006, 0.7888281250000002, -0.005, -1.0059999999999998, -1.541, -2.0039999999999996, 0.9392812500000001, -1.5289999999999995, -1.0539999999999958, -2.022999999999998, -2.0039999999999996, -1.040999999999997, -1.533, -1.0079999999999993, -1.0609999999999966, -2.0, -1.0269999999999988, -1.0499999999999963, -2.102999999999991, -2.015999999999999, -1.0069999999999997, -2.009999999999999, -1.011999999999999, -2.0139999999999993, -1.025999999999998], "policy_red_v24_reward": [2.465984375, 0.8932187500000002, 1.4816932378152048], "policy_red_v18_reward": [-0.5063067621838293, 0.46669323781617006, -0.004], "policy_red_v8_reward": [0.7466932378161746, -2.031999999999999, 1.953765625], "policy_red_v16_reward": [-0.1190000000000001, -1.1599999999999866, 0.4306932378161703], "policy_red_v9_reward": [-1.11799999999999, -1.2669999999999986], "policy_red_v4_reward": [-1.0109999999999992, -0.649], "policy_red_v23_reward": [3.1836875000000053, 0.2516932378161749, -0.5253067621838298, 0.14405000000000046, 0.4466932378161732, -1.4419999999999662], "policy_red_v2_reward": [-1.0019999999999998, -1.0479999999999974, -1.0239999999999982], "policy_red_v13_reward": [-0.15799999999999847, -1.5349999999999997, 0.44200000000000006, -0.8629499999999969, 2.35696875], "policy_red_v12_reward": [2.9141456677729436], "policy_red_v26_reward": [1.4436932378161742, 0.3726932378161725], "policy_red_v15_reward": [-2.0329999999999986], "policy_red_v14_reward": [-0.05706538555740459, -0.5173067621838289], "policy_red_v29_reward": [-0.5233067621838287], "policy_red_v27_reward": [-0.5089999999999999], "policy_red_v28_reward": [-0.6019999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8080707238285295, "mean_inference_ms": 7.809583073557031, "mean_action_processing_ms": 0.2959702682091094, "mean_env_wait_ms": 0.3889774092593016, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1003800630569458, "StateBufferConnector_ms": 0.0042389631271362305, "ViewRequirementAgentConnector_ms": 0.1177445650100708}}, "episode_reward_max": 4.288105225632352, "episode_reward_min": 0.20392187500000014, "episode_reward_mean": 2.096359309830116, "episode_len_mean": 254.33, "episodes_this_iter": 18, "policy_reward_min": {"red_v17": 1.973203125, "red": -1.0939999999999999, "red_v3": -2.01, "blue": -2.102999999999991, "red_v24": 0.8932187500000002, "red_v18": -0.5063067621838293, "red_v8": -2.031999999999999, "red_v16": -1.1599999999999866, "red_v9": -1.2669999999999986, "red_v4": -1.0109999999999992, "red_v23": -1.4419999999999662, "red_v2": -1.0479999999999974, "red_v13": -1.5349999999999997, "red_v12": 2.9141456677729436, "red_v26": 0.3726932378161725, "red_v15": -2.0329999999999986, "red_v14": -0.5173067621838289, "red_v29": -0.5233067621838287, "red_v27": -0.5089999999999999, "red_v28": -0.6019999999999999}, "policy_reward_max": {"red_v17": 1.973203125, "red": 3.9951499085440547, "red_v3": 0.46343749999999984, "blue": 1.813140625, "red_v24": 2.465984375, "red_v18": 0.46669323781617006, "red_v8": 1.953765625, "red_v16": 0.4306932378161703, "red_v9": -1.11799999999999, "red_v4": -0.649, "red_v23": 3.1836875000000053, "red_v2": -1.0019999999999998, "red_v13": 2.35696875, "red_v12": 2.9141456677729436, "red_v26": 1.4436932378161742, "red_v15": -2.0329999999999986, "red_v14": -0.05706538555740459, "red_v29": -0.5233067621838287, "red_v27": -0.5089999999999999, "red_v28": -0.6019999999999999}, "policy_reward_mean": {"red_v17": 1.973203125, "red": 2.7040988895845857, "red_v3": -0.8555208333333328, "blue": -1.0608723287097497, "red_v24": 1.6136321209384017, "red_v18": -0.014537841455886416, "red_v8": 0.22281962093872512, "red_v16": -0.28276892072793874, "red_v9": -1.1924999999999941, "red_v4": -0.8299999999999996, "red_v23": 0.3431362022414263, "red_v2": -1.024666666666665, "red_v13": 0.048603750000000986, "red_v12": 2.9141456677729436, "red_v26": 0.9081932378161733, "red_v15": -2.0329999999999986, "red_v14": -0.28718607387061673, "red_v29": -0.5233067621838287, "red_v27": -0.5089999999999999, "red_v28": -0.6019999999999999}, "hist_stats": {"episode_reward": [1.9591377394425922, 1.6599093750000002, 2.9495369878161712, 2.120802612816184, 1.8475080928162333, 2.4676776128161713, 2.349740112816174, 1.4525369878161711, 1.8762211050000002, 2.433802612816172, 2.949792725632342, 0.6626932378162138, 1.458052612816171, 0.5097939894425918, 2.410927612816173, 2.4741932378161704, 2.136386475632377, 2.1593338628162053, 3.1710369878161844, 0.9946932378162164, 1.3774432378161747, 2.465677612816171, 2.08968750000001, 1.3649119878161966, 2.384943237816174, 2.4758651128161704, 2.811490112816177, 1.1036932378162074, 2.904838905589115, 1.9342088628161949, 1.7867244878162025, 1.1251406249999998, 4.288105225632352, 0.8539276128161921, 1.299146362816219, 3.4749177256323724, 1.9928651128161807, 1.6240306463602732, 1.7748026128161776, 1.985224487815204, 2.9631619878161706, 0.8970994878161727, 2.3852401128161733, 0.9476932378161704, 1.381536987816173, 1.393552612816237, 3.8578778522587682, 2.652620850632347, 0.6917869878162151, 3.8559958506323433, 1.985333167772942, 2.4724901128161703, 1.3979119878161712, 1.990149908544055, 3.6882146006323593, 2.099224487816186, 3.775008092815208, 1.4612713628161709, 1.9615682378161707, 1.4775994878161702, 1.2955213628161744, 2.5805057378161838, 2.9866307378152035, 1.8363437500000002, 0.20392187500000014, 1.9715752394425927, 3.6639489756323567, 2.9917401128152035, 2.372974487816185, 0.884052612816171, 2.3056776128161776, 3.5438213628161748, 1.9220682378161729, 3.0658682378161757, 1.4896307378152036, 2.341411987816174, 0.30628125000000006, 2.4693807378161705, 2.7448396006323534, 2.2579588628161797, 1.34315625, 2.3812713628161717, 2.2913494878161775, 1.620052612816187, 2.359661987816174, 1.434880737816171, 2.9242146006323426, 2.399068237816171, 2.4679744878161705, 1.4686776128161703, 2.4624588628161708, 0.9251307378161879, 3.398933350632343, 1.9740057378161708, 1.9617557378161714, 0.9952869878162097, 2.344896362816174, 2.8166776128161746, 2.402865112816172, 1.9327002394425938], "episode_lengths": [31, 13, 50, 317, 662, 37, 145, 50, 20, 61, 62, 1280, 45, 1165, 85, 32, 1280, 659, 210, 1280, 80, 37, 164, 826, 112, 41, 161, 1280, 79, 443, 502, 179, 154, 533, 975, 342, 361, 1237, 189, 22, 42, 62, 113, 64, 114, 1165, 112, 405, 1250, 157, 19, 33, 58, 17, 215, 342, 118, 39, 40, 30, 215, 316, 20, 18, 121, 19, 268, 17, 550, 109, 165, 135, 72, 88, 20, 154, 102, 36, 207, 203, 14, 103, 174, 301, 74, 68, 87, 72, 38, 37, 43, 500, 113, 28, 44, 898, 159, 101, 105, 43], "policy_red_v17_reward": [1.973203125], "policy_red_v3_reward": [-2.01, -1.0199999999999987, 0.46343749999999984], "policy_blue_reward": [-0.012000000000000004, -1.097999999999992, 1.738814855000007, -2.012999999999999, -2.005, -1.0209999999999988, -1.3489999999999684, -2.0119999999999996, -0.8210000000000003, -1.0249999999999986, -1.0059999999999996, -0.6810000000000002, -1.2269999999999783, -1.0319999999999974, -0.5379999999999974, -1.1299999999999881, -1.1409999999999898, 1.813140625, -1.1059999999999905, 0.1501030335440734, 1.811109375, -2.0029999999999997, -0.010000000000000002, -1.0289999999999975, -0.8350000000000003, -1.391999999999966, -2.0069999999999997, -1.0099999999999993, -2.005, -1.0989999999999935, -2.012999999999999, -2.0109999999999992, -2.006, 0.7888281250000002, -0.005, -1.0059999999999998, -1.541, -2.0039999999999996, 0.9392812500000001, -1.5289999999999995, -1.0539999999999958, -2.022999999999998, -2.0039999999999996, -1.040999999999997, -1.533, -1.0079999999999993, -1.0609999999999966, -2.0, -1.0269999999999988, -1.0499999999999963, -2.102999999999991, -2.015999999999999, -1.0069999999999997, -2.009999999999999, -1.011999999999999, -2.0139999999999993, -1.025999999999998], "policy_red_v24_reward": [2.465984375, 0.8932187500000002, 1.4816932378152048], "policy_red_v18_reward": [-0.5063067621838293, 0.46669323781617006, -0.004], "policy_red_v8_reward": [0.7466932378161746, -2.031999999999999, 1.953765625], "policy_red_v16_reward": [-0.1190000000000001, -1.1599999999999866, 0.4306932378161703], "policy_red_v9_reward": [-1.11799999999999, -1.2669999999999986], "policy_red_v4_reward": [-1.0109999999999992, -0.649], "policy_red_v23_reward": [3.1836875000000053, 0.2516932378161749, -0.5253067621838298, 0.14405000000000046, 0.4466932378161732, -1.4419999999999662], "policy_red_v2_reward": [-1.0019999999999998, -1.0479999999999974, -1.0239999999999982], "policy_red_v13_reward": [-0.15799999999999847, -1.5349999999999997, 0.44200000000000006, -0.8629499999999969, 2.35696875], "policy_red_v12_reward": [2.9141456677729436], "policy_red_v26_reward": [1.4436932378161742, 0.3726932378161725], "policy_red_v15_reward": [-2.0329999999999986], "policy_red_v14_reward": [-0.05706538555740459, -0.5173067621838289], "policy_red_v29_reward": [-0.5233067621838287], "policy_red_v27_reward": [-0.5089999999999999], "policy_red_v28_reward": [-0.6019999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8080707238285295, "mean_inference_ms": 7.809583073557031, "mean_action_processing_ms": 0.2959702682091094, "mean_env_wait_ms": 0.3889774092593016, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1003800630569458, "StateBufferConnector_ms": 0.0042389631271362305, "ViewRequirementAgentConnector_ms": 0.1177445650100708}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 504000, "num_agent_steps_trained": 504000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 196.9103512292261, "num_env_steps_trained_throughput_per_sec": 196.9103512292261, "timesteps_total": 252000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 504000, "timers": {"training_iteration_time_ms": 20063.061, "sample_time_ms": 1176.79, "learn_time_ms": 18803.14, "learn_throughput": 212.73, "synch_weights_time_ms": 80.586}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 504000, "num_agent_steps_trained": 504000}, "done": false, "episodes_total": 533, "training_iteration": 63, "trial_id": "a9680_00000", "date": "2023-09-24_02-58-38", "timestamp": 1695538718, "time_this_iter_s": 20.324579000473022, "time_total_s": 1253.78919672966, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34341ba0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b342cff40>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34338040>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1253.78919672966, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 5.203225806451615, "ram_util_percent": 20.180645161290332}, "win_rate": 0.76, "league_size": 33}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.360996948679288, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.03215196000310243, "policy_loss": -0.05425458175692863, "vf_loss": 0.16213339421277245, "vf_explained_var": 0.7094499724606673, "kl": 0.01678401483838267, "entropy": 2.212961026405295, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "sampler_results": {"episode_reward_max": 4.3933396006313785, "episode_reward_min": -1.7813067621837853, "episode_reward_mean": 2.050457836558575, "episode_len_mean": 237.03, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"blue": -2.102999999999991, "red": -4.752306762183853, "red_v2": -1.0639999999999938, "red_v13": -1.5349999999999997, "red_v12": 2.9141456677729436, "red_v26": 0.3726932378161725, "red_v9": -2.028999999999998, "red_v16": -1.1599999999999866, "red_v23": -1.4419999999999662, "red_v15": -2.0329999999999986, "red_v14": -0.5173067621838289, "red_v18": -0.004, "red_v24": -0.5920000000000001, "red_v4": -0.649, "red_v3": 0.46343749999999984, "red_v29": -0.5233067621838287, "red_v27": -0.6920000000000001, "red_v28": -0.6019999999999999, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v5": -2.0199999999999996, "red_v17": -0.09530676218383005, "red_v19": -0.5273067621847961, "red_v22": -1.018}, "policy_reward_max": {"blue": 2.971000000000031, "red": 3.9951499085440547, "red_v2": -1.0019999999999998, "red_v13": 2.35696875, "red_v12": 2.9141456677729436, "red_v26": 1.4436932378161742, "red_v9": -1.2669999999999986, "red_v16": 0.4306932378161703, "red_v23": 0.4466932378161732, "red_v15": -2.0329999999999986, "red_v14": -0.05706538555740459, "red_v18": 0.46669323781617006, "red_v24": 1.4816932378152048, "red_v4": -0.649, "red_v3": 0.46343749999999984, "red_v29": -0.5233067621838287, "red_v27": -0.5089999999999999, "red_v28": 0.5056925427729417, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v5": -1.032999999999999, "red_v17": 1.4856932378161716, "red_v19": -0.5273067621847961, "red_v22": 0.44432812499999996}, "policy_reward_mean": {"blue": -0.9675981635579558, "red": 2.6449520484127356, "red_v2": -1.0344999999999973, "red_v13": 0.005836458333334182, "red_v12": 2.9141456677729436, "red_v26": 0.9081932378161733, "red_v9": -1.6479999999999984, "red_v16": -0.36465338109190815, "red_v23": -0.2249740573102895, "red_v15": -2.0329999999999986, "red_v14": -0.28718607387061673, "red_v18": 0.23134661890808503, "red_v24": 0.5943039959384016, "red_v4": -0.649, "red_v3": 0.46343749999999984, "red_v29": -0.5233067621838287, "red_v27": -0.6005, "red_v28": -0.04545761426148779, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v5": -1.454999999999999, "red_v17": 0.6951932378161707, "red_v19": -0.5273067621847961, "red_v22": -0.2868359375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.384943237816174, 2.4758651128161704, 2.811490112816177, 1.1036932378162074, 2.904838905589115, 1.9342088628161949, 1.7867244878162025, 1.1251406249999998, 4.288105225632352, 0.8539276128161921, 1.299146362816219, 3.4749177256323724, 1.9928651128161807, 1.6240306463602732, 1.7748026128161776, 1.985224487815204, 2.9631619878161706, 0.8970994878161727, 2.3852401128161733, 0.9476932378161704, 1.381536987816173, 1.393552612816237, 3.8578778522587682, 2.652620850632347, 0.6917869878162151, 3.8559958506323433, 1.985333167772942, 2.4724901128161703, 1.3979119878161712, 1.990149908544055, 3.6882146006323593, 2.099224487816186, 3.775008092815208, 1.4612713628161709, 1.9615682378161707, 1.4775994878161702, 1.2955213628161744, 2.5805057378161838, 2.9866307378152035, 1.8363437500000002, 0.20392187500000014, 1.9715752394425927, 3.6639489756323567, 2.9917401128152035, 2.372974487816185, 0.884052612816171, 2.3056776128161776, 3.5438213628161748, 1.9220682378161729, 3.0658682378161757, 1.4896307378152036, 2.341411987816174, 0.30628125000000006, 2.4693807378161705, 2.7448396006323534, 2.2579588628161797, 1.34315625, 2.3812713628161717, 2.2913494878161775, 1.620052612816187, 2.359661987816174, 1.434880737816171, 2.9242146006323426, 2.399068237816171, 2.4679744878161705, 1.4686776128161703, 2.4624588628161708, 0.9251307378161879, 3.398933350632343, 1.9740057378161708, 1.9617557378161714, 0.9952869878162097, 2.344896362816174, 2.8166776128161746, 2.402865112816172, 1.9327002394425938, 0.9032401128161709, 1.433833862816172, 1.4525682378161708, 1.9757088628161703, 1.7208182378161805, 1.4777088628161703, 2.4644658644425923, 1.3415625000000002, 0.580724487816195, -1.4595281250000003, 0.7806932378162115, 3.9976201555891113, 4.3933396006313785, 1.663115112816179, 2.4021122272587663, 2.4172557378161725, 2.3871619878161736, 2.569839600632392, 2.1516307378161863, 3.3567302256313787, 0.9490213628161699, 3.1997557378161785, -1.7813067621837853, 2.3732783644425925], "episode_lengths": [112, 41, 161, 1280, 79, 443, 502, 179, 154, 533, 975, 342, 361, 1237, 189, 22, 42, 62, 113, 64, 114, 1165, 112, 405, 1250, 157, 19, 33, 58, 17, 215, 342, 118, 39, 40, 30, 215, 316, 20, 18, 121, 19, 268, 17, 550, 109, 165, 135, 72, 88, 20, 154, 102, 36, 207, 203, 14, 103, 174, 301, 74, 68, 87, 72, 38, 37, 43, 500, 113, 28, 44, 898, 159, 101, 105, 43, 113, 51, 40, 27, 216, 27, 22, 12, 694, 1241, 1280, 21, 111, 153, 69, 76, 106, 655, 276, 146, 55, 108, 1280, 82], "policy_blue_reward": [-1.0319999999999974, -0.5379999999999974, -1.1299999999999881, -1.1409999999999898, 1.813140625, -1.1059999999999905, 0.1501030335440734, 1.811109375, -2.0029999999999997, -0.010000000000000002, -1.0289999999999975, -0.8350000000000003, -1.391999999999966, -2.0069999999999997, -1.0099999999999993, -2.005, -1.0989999999999935, -2.012999999999999, -2.0109999999999992, -2.006, 0.7888281250000002, -0.005, -1.0059999999999998, -1.541, -2.0039999999999996, 0.9392812500000001, -1.5289999999999995, -1.0539999999999958, -2.022999999999998, -2.0039999999999996, -1.040999999999997, -1.533, -1.0079999999999993, -1.0609999999999966, -2.0, -1.0269999999999988, -1.0499999999999963, -2.102999999999991, -2.015999999999999, -1.0069999999999997, -2.009999999999999, -1.011999999999999, -2.0139999999999993, -1.025999999999998, -2.0099999999999993, -2.01, -1.0069999999999997, -2.0039999999999996, 2.166031250000013, 0.48500000000001386, 2.971000000000031], "policy_red_v2_reward": [-1.0019999999999998, -1.0479999999999974, -1.0239999999999982, -1.0639999999999938], "policy_red_v13_reward": [-0.15799999999999847, -1.5349999999999997, 0.44200000000000006, -0.8629499999999969, 2.35696875, -0.20799999999999985], "policy_red_v12_reward": [2.9141456677729436], "policy_red_v26_reward": [1.4436932378161742, 0.3726932378161725], "policy_red_v9_reward": [-1.2669999999999986, -2.028999999999998], "policy_red_v16_reward": [-1.1599999999999866, 0.4306932378161703], "policy_red_v23_reward": [0.2516932378161749, -0.5253067621838298, 0.14405000000000046, 0.4466932378161732, -1.4419999999999662], "policy_red_v15_reward": [-2.0329999999999986], "policy_red_v14_reward": [-0.05706538555740459, -0.5173067621838289], "policy_red_v18_reward": [0.46669323781617006, -0.004], "policy_red_v24_reward": [0.8932187500000002, 1.4816932378152048, -0.5920000000000001], "policy_red_v4_reward": [-0.649], "policy_red_v3_reward": [0.46343749999999984], "policy_red_v29_reward": [-0.5233067621838287], "policy_red_v27_reward": [-0.5089999999999999, -0.6920000000000001], "policy_red_v28_reward": [-0.6019999999999999, 0.5056925427729417, -0.04006538555740524], "policy_red_v8_reward": [1.953765625], "policy_red_v1_reward": [0.405546875], "policy_red_v5_reward": [-2.0199999999999996, -1.73, -1.032999999999999, -1.0369999999999973], "policy_red_v17_reward": [1.4856932378161716, -0.09530676218383005], "policy_red_v19_reward": [-0.5273067621847961], "policy_red_v22_reward": [0.44432812499999996, -1.018]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.809008867690893, "mean_inference_ms": 7.820940505571133, "mean_action_processing_ms": 0.2960764958292074, "mean_env_wait_ms": 0.3895084248976468, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10023045539855957, "StateBufferConnector_ms": 0.004210829734802246, "ViewRequirementAgentConnector_ms": 0.11585545539855957}}, "episode_reward_max": 4.3933396006313785, "episode_reward_min": -1.7813067621837853, "episode_reward_mean": 2.050457836558575, "episode_len_mean": 237.03, "episodes_this_iter": 24, "policy_reward_min": {"blue": -2.102999999999991, "red": -4.752306762183853, "red_v2": -1.0639999999999938, "red_v13": -1.5349999999999997, "red_v12": 2.9141456677729436, "red_v26": 0.3726932378161725, "red_v9": -2.028999999999998, "red_v16": -1.1599999999999866, "red_v23": -1.4419999999999662, "red_v15": -2.0329999999999986, "red_v14": -0.5173067621838289, "red_v18": -0.004, "red_v24": -0.5920000000000001, "red_v4": -0.649, "red_v3": 0.46343749999999984, "red_v29": -0.5233067621838287, "red_v27": -0.6920000000000001, "red_v28": -0.6019999999999999, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v5": -2.0199999999999996, "red_v17": -0.09530676218383005, "red_v19": -0.5273067621847961, "red_v22": -1.018}, "policy_reward_max": {"blue": 2.971000000000031, "red": 3.9951499085440547, "red_v2": -1.0019999999999998, "red_v13": 2.35696875, "red_v12": 2.9141456677729436, "red_v26": 1.4436932378161742, "red_v9": -1.2669999999999986, "red_v16": 0.4306932378161703, "red_v23": 0.4466932378161732, "red_v15": -2.0329999999999986, "red_v14": -0.05706538555740459, "red_v18": 0.46669323781617006, "red_v24": 1.4816932378152048, "red_v4": -0.649, "red_v3": 0.46343749999999984, "red_v29": -0.5233067621838287, "red_v27": -0.5089999999999999, "red_v28": 0.5056925427729417, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v5": -1.032999999999999, "red_v17": 1.4856932378161716, "red_v19": -0.5273067621847961, "red_v22": 0.44432812499999996}, "policy_reward_mean": {"blue": -0.9675981635579558, "red": 2.6449520484127356, "red_v2": -1.0344999999999973, "red_v13": 0.005836458333334182, "red_v12": 2.9141456677729436, "red_v26": 0.9081932378161733, "red_v9": -1.6479999999999984, "red_v16": -0.36465338109190815, "red_v23": -0.2249740573102895, "red_v15": -2.0329999999999986, "red_v14": -0.28718607387061673, "red_v18": 0.23134661890808503, "red_v24": 0.5943039959384016, "red_v4": -0.649, "red_v3": 0.46343749999999984, "red_v29": -0.5233067621838287, "red_v27": -0.6005, "red_v28": -0.04545761426148779, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v5": -1.454999999999999, "red_v17": 0.6951932378161707, "red_v19": -0.5273067621847961, "red_v22": -0.2868359375}, "hist_stats": {"episode_reward": [2.384943237816174, 2.4758651128161704, 2.811490112816177, 1.1036932378162074, 2.904838905589115, 1.9342088628161949, 1.7867244878162025, 1.1251406249999998, 4.288105225632352, 0.8539276128161921, 1.299146362816219, 3.4749177256323724, 1.9928651128161807, 1.6240306463602732, 1.7748026128161776, 1.985224487815204, 2.9631619878161706, 0.8970994878161727, 2.3852401128161733, 0.9476932378161704, 1.381536987816173, 1.393552612816237, 3.8578778522587682, 2.652620850632347, 0.6917869878162151, 3.8559958506323433, 1.985333167772942, 2.4724901128161703, 1.3979119878161712, 1.990149908544055, 3.6882146006323593, 2.099224487816186, 3.775008092815208, 1.4612713628161709, 1.9615682378161707, 1.4775994878161702, 1.2955213628161744, 2.5805057378161838, 2.9866307378152035, 1.8363437500000002, 0.20392187500000014, 1.9715752394425927, 3.6639489756323567, 2.9917401128152035, 2.372974487816185, 0.884052612816171, 2.3056776128161776, 3.5438213628161748, 1.9220682378161729, 3.0658682378161757, 1.4896307378152036, 2.341411987816174, 0.30628125000000006, 2.4693807378161705, 2.7448396006323534, 2.2579588628161797, 1.34315625, 2.3812713628161717, 2.2913494878161775, 1.620052612816187, 2.359661987816174, 1.434880737816171, 2.9242146006323426, 2.399068237816171, 2.4679744878161705, 1.4686776128161703, 2.4624588628161708, 0.9251307378161879, 3.398933350632343, 1.9740057378161708, 1.9617557378161714, 0.9952869878162097, 2.344896362816174, 2.8166776128161746, 2.402865112816172, 1.9327002394425938, 0.9032401128161709, 1.433833862816172, 1.4525682378161708, 1.9757088628161703, 1.7208182378161805, 1.4777088628161703, 2.4644658644425923, 1.3415625000000002, 0.580724487816195, -1.4595281250000003, 0.7806932378162115, 3.9976201555891113, 4.3933396006313785, 1.663115112816179, 2.4021122272587663, 2.4172557378161725, 2.3871619878161736, 2.569839600632392, 2.1516307378161863, 3.3567302256313787, 0.9490213628161699, 3.1997557378161785, -1.7813067621837853, 2.3732783644425925], "episode_lengths": [112, 41, 161, 1280, 79, 443, 502, 179, 154, 533, 975, 342, 361, 1237, 189, 22, 42, 62, 113, 64, 114, 1165, 112, 405, 1250, 157, 19, 33, 58, 17, 215, 342, 118, 39, 40, 30, 215, 316, 20, 18, 121, 19, 268, 17, 550, 109, 165, 135, 72, 88, 20, 154, 102, 36, 207, 203, 14, 103, 174, 301, 74, 68, 87, 72, 38, 37, 43, 500, 113, 28, 44, 898, 159, 101, 105, 43, 113, 51, 40, 27, 216, 27, 22, 12, 694, 1241, 1280, 21, 111, 153, 69, 76, 106, 655, 276, 146, 55, 108, 1280, 82], "policy_blue_reward": [-1.0319999999999974, -0.5379999999999974, -1.1299999999999881, -1.1409999999999898, 1.813140625, -1.1059999999999905, 0.1501030335440734, 1.811109375, -2.0029999999999997, -0.010000000000000002, -1.0289999999999975, -0.8350000000000003, -1.391999999999966, -2.0069999999999997, -1.0099999999999993, -2.005, -1.0989999999999935, -2.012999999999999, -2.0109999999999992, -2.006, 0.7888281250000002, -0.005, -1.0059999999999998, -1.541, -2.0039999999999996, 0.9392812500000001, -1.5289999999999995, -1.0539999999999958, -2.022999999999998, -2.0039999999999996, -1.040999999999997, -1.533, -1.0079999999999993, -1.0609999999999966, -2.0, -1.0269999999999988, -1.0499999999999963, -2.102999999999991, -2.015999999999999, -1.0069999999999997, -2.009999999999999, -1.011999999999999, -2.0139999999999993, -1.025999999999998, -2.0099999999999993, -2.01, -1.0069999999999997, -2.0039999999999996, 2.166031250000013, 0.48500000000001386, 2.971000000000031], "policy_red_v2_reward": [-1.0019999999999998, -1.0479999999999974, -1.0239999999999982, -1.0639999999999938], "policy_red_v13_reward": [-0.15799999999999847, -1.5349999999999997, 0.44200000000000006, -0.8629499999999969, 2.35696875, -0.20799999999999985], "policy_red_v12_reward": [2.9141456677729436], "policy_red_v26_reward": [1.4436932378161742, 0.3726932378161725], "policy_red_v9_reward": [-1.2669999999999986, -2.028999999999998], "policy_red_v16_reward": [-1.1599999999999866, 0.4306932378161703], "policy_red_v23_reward": [0.2516932378161749, -0.5253067621838298, 0.14405000000000046, 0.4466932378161732, -1.4419999999999662], "policy_red_v15_reward": [-2.0329999999999986], "policy_red_v14_reward": [-0.05706538555740459, -0.5173067621838289], "policy_red_v18_reward": [0.46669323781617006, -0.004], "policy_red_v24_reward": [0.8932187500000002, 1.4816932378152048, -0.5920000000000001], "policy_red_v4_reward": [-0.649], "policy_red_v3_reward": [0.46343749999999984], "policy_red_v29_reward": [-0.5233067621838287], "policy_red_v27_reward": [-0.5089999999999999, -0.6920000000000001], "policy_red_v28_reward": [-0.6019999999999999, 0.5056925427729417, -0.04006538555740524], "policy_red_v8_reward": [1.953765625], "policy_red_v1_reward": [0.405546875], "policy_red_v5_reward": [-2.0199999999999996, -1.73, -1.032999999999999, -1.0369999999999973], "policy_red_v17_reward": [1.4856932378161716, -0.09530676218383005], "policy_red_v19_reward": [-0.5273067621847961], "policy_red_v22_reward": [0.44432812499999996, -1.018]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.809008867690893, "mean_inference_ms": 7.820940505571133, "mean_action_processing_ms": 0.2960764958292074, "mean_env_wait_ms": 0.3895084248976468, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10023045539855957, "StateBufferConnector_ms": 0.004210829734802246, "ViewRequirementAgentConnector_ms": 0.11585545539855957}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 195.96513713312362, "num_env_steps_trained_throughput_per_sec": 195.96513713312362, "timesteps_total": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 20115.049, "sample_time_ms": 1176.147, "learn_time_ms": 18855.463, "learn_throughput": 212.14, "synch_weights_time_ms": 80.949}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "episodes_total": 557, "training_iteration": 64, "trial_id": "a9680_00000", "date": "2023-09-24_02-59-01", "timestamp": 1695538741, "time_this_iter_s": 20.421868324279785, "time_total_s": 1274.2110650539398, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34340a30>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b342cc1f0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b342ccd30>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1274.2110650539398, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 5.109375, "ram_util_percent": 20.284375}, "win_rate": 0.74, "league_size": 34}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4459893410404523, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.026157997580836916, "policy_loss": -0.05301162498362828, "vf_loss": 0.14755541552246237, "vf_explained_var": 0.7225235287100077, "kl": 0.01689062110540763, "entropy": 2.2088642661770184, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 61920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 520000, "num_agent_steps_trained": 520000}, "sampler_results": {"episode_reward_max": 4.3933396006313785, "episode_reward_min": -1.7813067621837853, "episode_reward_mean": 2.098418475614455, "episode_len_mean": 200.3, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"blue": -2.102999999999991, "red": -4.752306762183853, "red_v13": -1.5349999999999997, "red_v15": -2.0329999999999986, "red_v14": -0.5173067621838289, "red_v23": -1.4419999999999662, "red_v18": -0.004, "red_v24": -0.5920000000000001, "red_v26": 0.3726932378161725, "red_v4": -1.0109999999999997, "red_v16": 0.4306932378161703, "red_v2": -1.0639999999999938, "red_v3": -1.5099999999999998, "red_v29": -0.5233067621838287, "red_v27": -0.6920000000000001, "red_v28": -0.6019999999999999, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v9": -2.028999999999998, "red_v5": -2.0199999999999996, "red_v17": -0.09530676218383005, "red_v19": -0.5273067621847961, "red_v22": -1.018, "red_v30": -0.5193074572270584, "red_v25": -0.034306762183826445, "red_v7": 0.5700500000000015, "red_v20": 1.17305}, "policy_reward_max": {"blue": 2.971000000000031, "red": 3.9951499085440547, "red_v13": 2.35696875, "red_v15": -2.0329999999999986, "red_v14": -0.05706538555740459, "red_v23": 0.4466932378161732, "red_v18": 1.4706932378161717, "red_v24": 1.4816932378152048, "red_v26": 0.3726932378161725, "red_v4": -0.649, "red_v16": 0.4306932378161703, "red_v2": -1.0239999999999982, "red_v3": 0.46343749999999984, "red_v29": 1.8099588628161696, "red_v27": -0.5089999999999999, "red_v28": 0.5056925427729417, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v9": 1.005946783544089, "red_v5": -1.032999999999999, "red_v17": 1.4856932378161716, "red_v19": -0.516, "red_v22": 0.44432812499999996, "red_v30": -0.5193074572270584, "red_v25": -0.034306762183826445, "red_v7": 0.5700500000000015, "red_v20": 1.17305}, "policy_reward_mean": {"blue": -1.1577204122340392, "red": 2.734990692590455, "red_v13": 0.038603750000000735, "red_v15": -2.0329999999999986, "red_v14": -0.28718607387061673, "red_v23": -0.34414088109190555, "red_v18": 0.6444621585441139, "red_v24": 0.5943039959384016, "red_v26": 0.3726932378161725, "red_v4": -0.8299999999999998, "red_v16": 0.4306932378161703, "red_v2": -1.04533333333333, "red_v3": -0.5232812499999999, "red_v29": 0.6433260503161704, "red_v27": -0.6005, "red_v28": -0.04545761426148779, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v9": -0.5273510721519697, "red_v5": -1.454999999999999, "red_v17": 0.6951932378161707, "red_v19": -0.521653381092398, "red_v22": -0.2868359375, "red_v30": -0.5193074572270584, "red_v25": -0.034306762183826445, "red_v7": 0.5700500000000015, "red_v20": 1.17305}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.985224487815204, 2.9631619878161706, 0.8970994878161727, 2.3852401128161733, 0.9476932378161704, 1.381536987816173, 1.393552612816237, 3.8578778522587682, 2.652620850632347, 0.6917869878162151, 3.8559958506323433, 1.985333167772942, 2.4724901128161703, 1.3979119878161712, 1.990149908544055, 3.6882146006323593, 2.099224487816186, 3.775008092815208, 1.4612713628161709, 1.9615682378161707, 1.4775994878161702, 1.2955213628161744, 2.5805057378161838, 2.9866307378152035, 1.8363437500000002, 0.20392187500000014, 1.9715752394425927, 3.6639489756323567, 2.9917401128152035, 2.372974487816185, 0.884052612816171, 2.3056776128161776, 3.5438213628161748, 1.9220682378161729, 3.0658682378161757, 1.4896307378152036, 2.341411987816174, 0.30628125000000006, 2.4693807378161705, 2.7448396006323534, 2.2579588628161797, 1.34315625, 2.3812713628161717, 2.2913494878161775, 1.620052612816187, 2.359661987816174, 1.434880737816171, 2.9242146006323426, 2.399068237816171, 2.4679744878161705, 1.4686776128161703, 2.4624588628161708, 0.9251307378161879, 3.398933350632343, 1.9740057378161708, 1.9617557378161714, 0.9952869878162097, 2.344896362816174, 2.8166776128161746, 2.402865112816172, 1.9327002394425938, 0.9032401128161709, 1.433833862816172, 1.4525682378161708, 1.9757088628161703, 1.7208182378161805, 1.4777088628161703, 2.4644658644425923, 1.3415625000000002, 0.580724487816195, -1.4595281250000003, 0.7806932378162115, 3.9976201555891113, 4.3933396006313785, 1.663115112816179, 2.4021122272587663, 2.4172557378161725, 2.3871619878161736, 2.569839600632392, 2.1516307378161863, 3.3567302256313787, 0.9490213628161699, 3.1997557378161785, -1.7813067621837853, 2.3732783644425925, 2.8629744878161754, 1.4166400213603225, 4.375417725632346, 2.903698280589115, 2.437318237816172, 2.3739333506323455, 2.4809276128152042, 1.446802612816171, 3.903055737816184, 1.6893338628161931, 0.9517244878161711, 2.3086521006323477, 4.159055737816171, 1.8709894177729423, 1.450240112816171], "episode_lengths": [22, 42, 62, 113, 64, 114, 1165, 112, 405, 1250, 157, 19, 33, 58, 17, 215, 342, 118, 39, 40, 30, 215, 316, 20, 18, 121, 19, 268, 17, 550, 109, 165, 135, 72, 88, 20, 154, 102, 36, 207, 203, 14, 103, 174, 301, 74, 68, 87, 72, 38, 37, 43, 500, 113, 28, 44, 898, 159, 101, 105, 43, 113, 51, 40, 27, 216, 27, 22, 12, 694, 1241, 1280, 21, 111, 153, 69, 76, 106, 655, 276, 146, 55, 108, 1280, 82, 102, 1010, 118, 92, 56, 113, 21, 61, 220, 659, 54, 203, 28, 129, 49], "policy_blue_reward": [-2.0029999999999997, -0.010000000000000002, -1.0289999999999975, -0.8350000000000003, -1.391999999999966, -2.0069999999999997, -1.0099999999999993, -2.005, -1.0989999999999935, -2.012999999999999, -2.0109999999999992, -2.006, 0.7888281250000002, -0.005, -1.0059999999999998, -1.541, -2.0039999999999996, 0.9392812500000001, -1.5289999999999995, -1.0539999999999958, -2.022999999999998, -2.0039999999999996, -1.040999999999997, -1.533, -1.0079999999999993, -1.0609999999999966, -2.0, -1.0269999999999988, -1.0499999999999963, -2.102999999999991, -2.015999999999999, -1.0069999999999997, -2.009999999999999, -1.011999999999999, -2.0139999999999993, -1.025999999999998, -2.0099999999999993, -2.01, -1.0069999999999997, -2.0039999999999996, 2.166031250000013, 0.48500000000001386, 2.971000000000031, -1.0229999999999992, -2.0119999999999996, -1.183999999999982, -2.0189999999999992], "policy_red_v13_reward": [-1.5349999999999997, 0.44200000000000006, -0.8629499999999969, 2.35696875, -0.20799999999999985], "policy_red_v15_reward": [-2.0329999999999986], "policy_red_v14_reward": [-0.05706538555740459, -0.5173067621838289], "policy_red_v23_reward": [-0.5253067621838298, 0.14405000000000046, 0.4466932378161732, -1.4419999999999662], "policy_red_v18_reward": [0.46669323781617006, -0.004, 1.4706932378161717], "policy_red_v24_reward": [0.8932187500000002, 1.4816932378152048, -0.5920000000000001], "policy_red_v26_reward": [0.3726932378161725], "policy_red_v4_reward": [-0.649, -1.0109999999999997], "policy_red_v16_reward": [0.4306932378161703], "policy_red_v2_reward": [-1.0479999999999974, -1.0239999999999982, -1.0639999999999938], "policy_red_v3_reward": [0.46343749999999984, -1.5099999999999998], "policy_red_v29_reward": [-0.5233067621838287, 1.8099588628161696], "policy_red_v27_reward": [-0.5089999999999999, -0.6920000000000001], "policy_red_v28_reward": [-0.6019999999999999, 0.5056925427729417, -0.04006538555740524], "policy_red_v8_reward": [1.953765625], "policy_red_v1_reward": [0.405546875], "policy_red_v9_reward": [-2.028999999999998, -0.5589999999999999, 1.005946783544089], "policy_red_v5_reward": [-2.0199999999999996, -1.73, -1.032999999999999, -1.0369999999999973], "policy_red_v17_reward": [1.4856932378161716, -0.09530676218383005], "policy_red_v19_reward": [-0.5273067621847961, -0.516], "policy_red_v22_reward": [0.44432812499999996, -1.018], "policy_red_v30_reward": [-0.5193074572270584], "policy_red_v25_reward": [-0.034306762183826445], "policy_red_v7_reward": [0.5700500000000015], "policy_red_v20_reward": [1.17305]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8083155251955145, "mean_inference_ms": 7.808815453353958, "mean_action_processing_ms": 0.2954788473184731, "mean_env_wait_ms": 0.38903574037500094, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10119032859802246, "StateBufferConnector_ms": 0.004249930381774902, "ViewRequirementAgentConnector_ms": 0.11686527729034424}}, "episode_reward_max": 4.3933396006313785, "episode_reward_min": -1.7813067621837853, "episode_reward_mean": 2.098418475614455, "episode_len_mean": 200.3, "episodes_this_iter": 15, "policy_reward_min": {"blue": -2.102999999999991, "red": -4.752306762183853, "red_v13": -1.5349999999999997, "red_v15": -2.0329999999999986, "red_v14": -0.5173067621838289, "red_v23": -1.4419999999999662, "red_v18": -0.004, "red_v24": -0.5920000000000001, "red_v26": 0.3726932378161725, "red_v4": -1.0109999999999997, "red_v16": 0.4306932378161703, "red_v2": -1.0639999999999938, "red_v3": -1.5099999999999998, "red_v29": -0.5233067621838287, "red_v27": -0.6920000000000001, "red_v28": -0.6019999999999999, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v9": -2.028999999999998, "red_v5": -2.0199999999999996, "red_v17": -0.09530676218383005, "red_v19": -0.5273067621847961, "red_v22": -1.018, "red_v30": -0.5193074572270584, "red_v25": -0.034306762183826445, "red_v7": 0.5700500000000015, "red_v20": 1.17305}, "policy_reward_max": {"blue": 2.971000000000031, "red": 3.9951499085440547, "red_v13": 2.35696875, "red_v15": -2.0329999999999986, "red_v14": -0.05706538555740459, "red_v23": 0.4466932378161732, "red_v18": 1.4706932378161717, "red_v24": 1.4816932378152048, "red_v26": 0.3726932378161725, "red_v4": -0.649, "red_v16": 0.4306932378161703, "red_v2": -1.0239999999999982, "red_v3": 0.46343749999999984, "red_v29": 1.8099588628161696, "red_v27": -0.5089999999999999, "red_v28": 0.5056925427729417, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v9": 1.005946783544089, "red_v5": -1.032999999999999, "red_v17": 1.4856932378161716, "red_v19": -0.516, "red_v22": 0.44432812499999996, "red_v30": -0.5193074572270584, "red_v25": -0.034306762183826445, "red_v7": 0.5700500000000015, "red_v20": 1.17305}, "policy_reward_mean": {"blue": -1.1577204122340392, "red": 2.734990692590455, "red_v13": 0.038603750000000735, "red_v15": -2.0329999999999986, "red_v14": -0.28718607387061673, "red_v23": -0.34414088109190555, "red_v18": 0.6444621585441139, "red_v24": 0.5943039959384016, "red_v26": 0.3726932378161725, "red_v4": -0.8299999999999998, "red_v16": 0.4306932378161703, "red_v2": -1.04533333333333, "red_v3": -0.5232812499999999, "red_v29": 0.6433260503161704, "red_v27": -0.6005, "red_v28": -0.04545761426148779, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v9": -0.5273510721519697, "red_v5": -1.454999999999999, "red_v17": 0.6951932378161707, "red_v19": -0.521653381092398, "red_v22": -0.2868359375, "red_v30": -0.5193074572270584, "red_v25": -0.034306762183826445, "red_v7": 0.5700500000000015, "red_v20": 1.17305}, "hist_stats": {"episode_reward": [1.985224487815204, 2.9631619878161706, 0.8970994878161727, 2.3852401128161733, 0.9476932378161704, 1.381536987816173, 1.393552612816237, 3.8578778522587682, 2.652620850632347, 0.6917869878162151, 3.8559958506323433, 1.985333167772942, 2.4724901128161703, 1.3979119878161712, 1.990149908544055, 3.6882146006323593, 2.099224487816186, 3.775008092815208, 1.4612713628161709, 1.9615682378161707, 1.4775994878161702, 1.2955213628161744, 2.5805057378161838, 2.9866307378152035, 1.8363437500000002, 0.20392187500000014, 1.9715752394425927, 3.6639489756323567, 2.9917401128152035, 2.372974487816185, 0.884052612816171, 2.3056776128161776, 3.5438213628161748, 1.9220682378161729, 3.0658682378161757, 1.4896307378152036, 2.341411987816174, 0.30628125000000006, 2.4693807378161705, 2.7448396006323534, 2.2579588628161797, 1.34315625, 2.3812713628161717, 2.2913494878161775, 1.620052612816187, 2.359661987816174, 1.434880737816171, 2.9242146006323426, 2.399068237816171, 2.4679744878161705, 1.4686776128161703, 2.4624588628161708, 0.9251307378161879, 3.398933350632343, 1.9740057378161708, 1.9617557378161714, 0.9952869878162097, 2.344896362816174, 2.8166776128161746, 2.402865112816172, 1.9327002394425938, 0.9032401128161709, 1.433833862816172, 1.4525682378161708, 1.9757088628161703, 1.7208182378161805, 1.4777088628161703, 2.4644658644425923, 1.3415625000000002, 0.580724487816195, -1.4595281250000003, 0.7806932378162115, 3.9976201555891113, 4.3933396006313785, 1.663115112816179, 2.4021122272587663, 2.4172557378161725, 2.3871619878161736, 2.569839600632392, 2.1516307378161863, 3.3567302256313787, 0.9490213628161699, 3.1997557378161785, -1.7813067621837853, 2.3732783644425925, 2.8629744878161754, 1.4166400213603225, 4.375417725632346, 2.903698280589115, 2.437318237816172, 2.3739333506323455, 2.4809276128152042, 1.446802612816171, 3.903055737816184, 1.6893338628161931, 0.9517244878161711, 2.3086521006323477, 4.159055737816171, 1.8709894177729423, 1.450240112816171], "episode_lengths": [22, 42, 62, 113, 64, 114, 1165, 112, 405, 1250, 157, 19, 33, 58, 17, 215, 342, 118, 39, 40, 30, 215, 316, 20, 18, 121, 19, 268, 17, 550, 109, 165, 135, 72, 88, 20, 154, 102, 36, 207, 203, 14, 103, 174, 301, 74, 68, 87, 72, 38, 37, 43, 500, 113, 28, 44, 898, 159, 101, 105, 43, 113, 51, 40, 27, 216, 27, 22, 12, 694, 1241, 1280, 21, 111, 153, 69, 76, 106, 655, 276, 146, 55, 108, 1280, 82, 102, 1010, 118, 92, 56, 113, 21, 61, 220, 659, 54, 203, 28, 129, 49], "policy_blue_reward": [-2.0029999999999997, -0.010000000000000002, -1.0289999999999975, -0.8350000000000003, -1.391999999999966, -2.0069999999999997, -1.0099999999999993, -2.005, -1.0989999999999935, -2.012999999999999, -2.0109999999999992, -2.006, 0.7888281250000002, -0.005, -1.0059999999999998, -1.541, -2.0039999999999996, 0.9392812500000001, -1.5289999999999995, -1.0539999999999958, -2.022999999999998, -2.0039999999999996, -1.040999999999997, -1.533, -1.0079999999999993, -1.0609999999999966, -2.0, -1.0269999999999988, -1.0499999999999963, -2.102999999999991, -2.015999999999999, -1.0069999999999997, -2.009999999999999, -1.011999999999999, -2.0139999999999993, -1.025999999999998, -2.0099999999999993, -2.01, -1.0069999999999997, -2.0039999999999996, 2.166031250000013, 0.48500000000001386, 2.971000000000031, -1.0229999999999992, -2.0119999999999996, -1.183999999999982, -2.0189999999999992], "policy_red_v13_reward": [-1.5349999999999997, 0.44200000000000006, -0.8629499999999969, 2.35696875, -0.20799999999999985], "policy_red_v15_reward": [-2.0329999999999986], "policy_red_v14_reward": [-0.05706538555740459, -0.5173067621838289], "policy_red_v23_reward": [-0.5253067621838298, 0.14405000000000046, 0.4466932378161732, -1.4419999999999662], "policy_red_v18_reward": [0.46669323781617006, -0.004, 1.4706932378161717], "policy_red_v24_reward": [0.8932187500000002, 1.4816932378152048, -0.5920000000000001], "policy_red_v26_reward": [0.3726932378161725], "policy_red_v4_reward": [-0.649, -1.0109999999999997], "policy_red_v16_reward": [0.4306932378161703], "policy_red_v2_reward": [-1.0479999999999974, -1.0239999999999982, -1.0639999999999938], "policy_red_v3_reward": [0.46343749999999984, -1.5099999999999998], "policy_red_v29_reward": [-0.5233067621838287, 1.8099588628161696], "policy_red_v27_reward": [-0.5089999999999999, -0.6920000000000001], "policy_red_v28_reward": [-0.6019999999999999, 0.5056925427729417, -0.04006538555740524], "policy_red_v8_reward": [1.953765625], "policy_red_v1_reward": [0.405546875], "policy_red_v9_reward": [-2.028999999999998, -0.5589999999999999, 1.005946783544089], "policy_red_v5_reward": [-2.0199999999999996, -1.73, -1.032999999999999, -1.0369999999999973], "policy_red_v17_reward": [1.4856932378161716, -0.09530676218383005], "policy_red_v19_reward": [-0.5273067621847961, -0.516], "policy_red_v22_reward": [0.44432812499999996, -1.018], "policy_red_v30_reward": [-0.5193074572270584], "policy_red_v25_reward": [-0.034306762183826445], "policy_red_v7_reward": [0.5700500000000015], "policy_red_v20_reward": [1.17305]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8083155251955145, "mean_inference_ms": 7.808815453353958, "mean_action_processing_ms": 0.2954788473184731, "mean_env_wait_ms": 0.38903574037500094, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10119032859802246, "StateBufferConnector_ms": 0.004249930381774902, "ViewRequirementAgentConnector_ms": 0.11686527729034424}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 520000, "num_agent_steps_trained": 520000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 196.7000771501772, "num_env_steps_trained_throughput_per_sec": 196.7000771501772, "timesteps_total": 260000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 520000, "timers": {"training_iteration_time_ms": 20164.69, "sample_time_ms": 1179.096, "learn_time_ms": 18903.216, "learn_throughput": 211.604, "synch_weights_time_ms": 79.926}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 520000, "num_agent_steps_trained": 520000}, "done": false, "episodes_total": 572, "training_iteration": 65, "trial_id": "a9680_00000", "date": "2023-09-24_02-59-23", "timestamp": 1695538763, "time_this_iter_s": 20.345529079437256, "time_total_s": 1294.556594133377, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b343707f0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34339c60>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34339cf0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1294.556594133377, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 5.409375, "ram_util_percent": 20.474999999999998}, "win_rate": 0.75, "league_size": 35}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3184025884916384, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0209522930138822, "policy_loss": -0.059188095662587634, "vf_loss": 0.14938987265729034, "vf_explained_var": 0.6780451195935409, "kl": 0.01710133095591319, "entropy": 2.2501461540659267, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 62880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "sampler_results": {"episode_reward_max": 4.3933396006313785, "episode_reward_min": -1.7813067621837853, "episode_reward_mean": 2.0456702823086728, "episode_len_mean": 184.53, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"blue": -2.102999999999991, "red": -4.752306762183853, "red_v4": -1.0109999999999997, "red_v16": -1.0149999999999997, "red_v18": -0.004, "red_v23": -1.525, "red_v13": -0.8629499999999969, "red_v14": -0.5173067621838289, "red_v2": -1.0639999999999938, "red_v3": -1.5099999999999998, "red_v29": -1.084999999999994, "red_v27": -0.6920000000000001, "red_v28": -0.6019999999999999, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v9": -2.028999999999998, "red_v5": -2.0199999999999996, "red_v24": -2.009, "red_v17": -0.09530676218383005, "red_v19": -0.5273067621847961, "red_v22": -1.018, "red_v30": -0.5193074572270584, "red_v25": -0.665, "red_v7": 0.5700500000000015, "red_v20": -0.1559999999999998}, "policy_reward_max": {"blue": 2.971000000000031, "red": 3.98570886281617, "red_v4": -0.649, "red_v16": 0.4306932378161703, "red_v18": 1.4706932378161717, "red_v23": 0.4466932378161732, "red_v13": 2.35696875, "red_v14": 1.971828125, "red_v2": -1.0239999999999982, "red_v3": 0.46343749999999984, "red_v29": 1.8099588628161696, "red_v27": -0.5089999999999999, "red_v28": 0.5056925427729417, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v9": 1.005946783544089, "red_v5": 1.9437031249999999, "red_v24": -0.5920000000000001, "red_v17": 1.4856932378161716, "red_v19": -0.516, "red_v22": 0.44432812499999996, "red_v30": -0.5193074572270584, "red_v25": -0.034306762183826445, "red_v7": 0.5700500000000015, "red_v20": 1.17305}, "policy_reward_mean": {"blue": -0.973728338068179, "red": 2.604311392563574, "red_v4": -0.8299999999999998, "red_v16": -0.2921533810919147, "red_v18": 0.7333466189080858, "red_v23": -0.5940641905459481, "red_v13": 0.4286729166666678, "red_v14": 0.7272606814080855, "red_v2": -1.04533333333333, "red_v3": -0.5232812499999999, "red_v29": 0.036336334612129984, "red_v27": -0.6005, "red_v28": -0.04545761426148779, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v9": -0.5273510721519697, "red_v5": -0.7752593749999992, "red_v24": -1.2113333333333323, "red_v17": 0.6951932378161707, "red_v19": -0.521653381092398, "red_v22": -0.193890625, "red_v30": -0.5193074572270584, "red_v25": -0.44410225406127557, "red_v7": 0.5700500000000015, "red_v20": 0.5085250000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.2955213628161744, 2.5805057378161838, 2.9866307378152035, 1.8363437500000002, 0.20392187500000014, 1.9715752394425927, 3.6639489756323567, 2.9917401128152035, 2.372974487816185, 0.884052612816171, 2.3056776128161776, 3.5438213628161748, 1.9220682378161729, 3.0658682378161757, 1.4896307378152036, 2.341411987816174, 0.30628125000000006, 2.4693807378161705, 2.7448396006323534, 2.2579588628161797, 1.34315625, 2.3812713628161717, 2.2913494878161775, 1.620052612816187, 2.359661987816174, 1.434880737816171, 2.9242146006323426, 2.399068237816171, 2.4679744878161705, 1.4686776128161703, 2.4624588628161708, 0.9251307378161879, 3.398933350632343, 1.9740057378161708, 1.9617557378161714, 0.9952869878162097, 2.344896362816174, 2.8166776128161746, 2.402865112816172, 1.9327002394425938, 0.9032401128161709, 1.433833862816172, 1.4525682378161708, 1.9757088628161703, 1.7208182378161805, 1.4777088628161703, 2.4644658644425923, 1.3415625000000002, 0.580724487816195, -1.4595281250000003, 0.7806932378162115, 3.9976201555891113, 4.3933396006313785, 1.663115112816179, 2.4021122272587663, 2.4172557378161725, 2.3871619878161736, 2.569839600632392, 2.1516307378161863, 3.3567302256313787, 0.9490213628161699, 3.1997557378161785, -1.7813067621837853, 2.3732783644425925, 2.8629744878161754, 1.4166400213603225, 4.375417725632346, 2.903698280589115, 2.437318237816172, 2.3739333506323455, 2.4809276128152042, 1.446802612816171, 3.903055737816184, 1.6893338628161931, 0.9517244878161711, 2.3086521006323477, 4.159055737816171, 1.8709894177729423, 1.450240112816171, 0.8484432378161719, 0.9581377394425926, 2.979005042772942, 1.4664588628161708, 2.272870850632351, 0.9264311585440562, 0.808203125, 1.9765213628161704, 2.4113651128161706, 1.5545994878161844, 2.310661987816177, 1.9453956677729414, 2.4498338628161704, 2.3473338628161744, 3.3301151128161703, 2.068724487816179, 1.2492557378161742, 0.8125057378161733, 2.975118658544055, 2.4221776128161725, 1.932583862816172], "episode_lengths": [215, 316, 20, 18, 121, 19, 268, 17, 550, 109, 165, 135, 72, 88, 20, 154, 102, 36, 207, 203, 14, 103, 174, 301, 74, 68, 87, 72, 38, 37, 43, 500, 113, 28, 44, 898, 159, 101, 105, 43, 113, 51, 40, 27, 216, 27, 22, 12, 694, 1241, 1280, 21, 111, 153, 69, 76, 106, 655, 276, 146, 55, 108, 1280, 82, 102, 1010, 118, 92, 56, 113, 21, 61, 220, 659, 54, 203, 28, 129, 49, 144, 31, 28, 43, 197, 55, 31, 23, 73, 350, 138, 63, 51, 147, 25, 502, 588, 188, 27, 69, 67], "policy_blue_reward": [0.7888281250000002, -0.005, -1.0059999999999998, -1.541, -2.0039999999999996, 0.9392812500000001, -1.5289999999999995, -1.0539999999999958, -2.022999999999998, -2.0039999999999996, -1.040999999999997, -1.533, -1.0079999999999993, -1.0609999999999966, -2.0, -1.0269999999999988, -1.0499999999999963, -2.102999999999991, -2.015999999999999, -1.0069999999999997, -2.009999999999999, -1.011999999999999, -2.0139999999999993, -1.025999999999998, -2.0099999999999993, -2.01, -1.0069999999999997, -2.0039999999999996, 2.166031250000013, 0.48500000000001386, 2.971000000000031, -1.0229999999999992, -2.0119999999999996, -1.183999999999982, -2.0189999999999992, -1.537, -1.507, -2.0109999999999992, -1.0249999999999984, -1.0419999999999965, 2.813812500000001, -0.004, -1.0199999999999987, -0.5189999999999998], "policy_red_v4_reward": [-0.649, -1.0109999999999997], "policy_red_v16_reward": [0.4306932378161703, -1.0149999999999997], "policy_red_v18_reward": [-0.004, 1.4706932378161717], "policy_red_v23_reward": [0.14405000000000046, 0.4466932378161732, -1.4419999999999662, -1.525], "policy_red_v13_reward": [-0.8629499999999969, 2.35696875, -0.20799999999999985], "policy_red_v14_reward": [-0.5173067621838289, 1.971828125], "policy_red_v2_reward": [-1.0479999999999974, -1.0239999999999982, -1.0639999999999938], "policy_red_v3_reward": [0.46343749999999984, -1.5099999999999998], "policy_red_v29_reward": [-0.5233067621838287, 1.8099588628161696, -0.0563067621838268, -1.084999999999994], "policy_red_v27_reward": [-0.5089999999999999, -0.6920000000000001], "policy_red_v28_reward": [-0.6019999999999999, 0.5056925427729417, -0.04006538555740524], "policy_red_v8_reward": [1.953765625], "policy_red_v1_reward": [0.405546875], "policy_red_v9_reward": [-2.028999999999998, -0.5589999999999999, 1.005946783544089], "policy_red_v5_reward": [-2.0199999999999996, -1.73, -1.032999999999999, -1.0369999999999973, 1.9437031249999999], "policy_red_v24_reward": [-0.5920000000000001, -2.009, -1.0329999999999968], "policy_red_v17_reward": [1.4856932378161716, -0.09530676218383005], "policy_red_v19_reward": [-0.5273067621847961, -0.516], "policy_red_v22_reward": [0.44432812499999996, -1.018, -0.008], "policy_red_v30_reward": [-0.5193074572270584], "policy_red_v25_reward": [-0.034306762183826445, -0.6330000000000001, -0.665], "policy_red_v7_reward": [0.5700500000000015], "policy_red_v20_reward": [1.17305, -0.1559999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8098301437497676, "mean_inference_ms": 7.833595244049321, "mean_action_processing_ms": 0.2958823242381292, "mean_env_wait_ms": 0.389759923427198, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1006617546081543, "StateBufferConnector_ms": 0.004219770431518555, "ViewRequirementAgentConnector_ms": 0.1163339614868164}}, "episode_reward_max": 4.3933396006313785, "episode_reward_min": -1.7813067621837853, "episode_reward_mean": 2.0456702823086728, "episode_len_mean": 184.53, "episodes_this_iter": 21, "policy_reward_min": {"blue": -2.102999999999991, "red": -4.752306762183853, "red_v4": -1.0109999999999997, "red_v16": -1.0149999999999997, "red_v18": -0.004, "red_v23": -1.525, "red_v13": -0.8629499999999969, "red_v14": -0.5173067621838289, "red_v2": -1.0639999999999938, "red_v3": -1.5099999999999998, "red_v29": -1.084999999999994, "red_v27": -0.6920000000000001, "red_v28": -0.6019999999999999, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v9": -2.028999999999998, "red_v5": -2.0199999999999996, "red_v24": -2.009, "red_v17": -0.09530676218383005, "red_v19": -0.5273067621847961, "red_v22": -1.018, "red_v30": -0.5193074572270584, "red_v25": -0.665, "red_v7": 0.5700500000000015, "red_v20": -0.1559999999999998}, "policy_reward_max": {"blue": 2.971000000000031, "red": 3.98570886281617, "red_v4": -0.649, "red_v16": 0.4306932378161703, "red_v18": 1.4706932378161717, "red_v23": 0.4466932378161732, "red_v13": 2.35696875, "red_v14": 1.971828125, "red_v2": -1.0239999999999982, "red_v3": 0.46343749999999984, "red_v29": 1.8099588628161696, "red_v27": -0.5089999999999999, "red_v28": 0.5056925427729417, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v9": 1.005946783544089, "red_v5": 1.9437031249999999, "red_v24": -0.5920000000000001, "red_v17": 1.4856932378161716, "red_v19": -0.516, "red_v22": 0.44432812499999996, "red_v30": -0.5193074572270584, "red_v25": -0.034306762183826445, "red_v7": 0.5700500000000015, "red_v20": 1.17305}, "policy_reward_mean": {"blue": -0.973728338068179, "red": 2.604311392563574, "red_v4": -0.8299999999999998, "red_v16": -0.2921533810919147, "red_v18": 0.7333466189080858, "red_v23": -0.5940641905459481, "red_v13": 0.4286729166666678, "red_v14": 0.7272606814080855, "red_v2": -1.04533333333333, "red_v3": -0.5232812499999999, "red_v29": 0.036336334612129984, "red_v27": -0.6005, "red_v28": -0.04545761426148779, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v9": -0.5273510721519697, "red_v5": -0.7752593749999992, "red_v24": -1.2113333333333323, "red_v17": 0.6951932378161707, "red_v19": -0.521653381092398, "red_v22": -0.193890625, "red_v30": -0.5193074572270584, "red_v25": -0.44410225406127557, "red_v7": 0.5700500000000015, "red_v20": 0.5085250000000001}, "hist_stats": {"episode_reward": [1.2955213628161744, 2.5805057378161838, 2.9866307378152035, 1.8363437500000002, 0.20392187500000014, 1.9715752394425927, 3.6639489756323567, 2.9917401128152035, 2.372974487816185, 0.884052612816171, 2.3056776128161776, 3.5438213628161748, 1.9220682378161729, 3.0658682378161757, 1.4896307378152036, 2.341411987816174, 0.30628125000000006, 2.4693807378161705, 2.7448396006323534, 2.2579588628161797, 1.34315625, 2.3812713628161717, 2.2913494878161775, 1.620052612816187, 2.359661987816174, 1.434880737816171, 2.9242146006323426, 2.399068237816171, 2.4679744878161705, 1.4686776128161703, 2.4624588628161708, 0.9251307378161879, 3.398933350632343, 1.9740057378161708, 1.9617557378161714, 0.9952869878162097, 2.344896362816174, 2.8166776128161746, 2.402865112816172, 1.9327002394425938, 0.9032401128161709, 1.433833862816172, 1.4525682378161708, 1.9757088628161703, 1.7208182378161805, 1.4777088628161703, 2.4644658644425923, 1.3415625000000002, 0.580724487816195, -1.4595281250000003, 0.7806932378162115, 3.9976201555891113, 4.3933396006313785, 1.663115112816179, 2.4021122272587663, 2.4172557378161725, 2.3871619878161736, 2.569839600632392, 2.1516307378161863, 3.3567302256313787, 0.9490213628161699, 3.1997557378161785, -1.7813067621837853, 2.3732783644425925, 2.8629744878161754, 1.4166400213603225, 4.375417725632346, 2.903698280589115, 2.437318237816172, 2.3739333506323455, 2.4809276128152042, 1.446802612816171, 3.903055737816184, 1.6893338628161931, 0.9517244878161711, 2.3086521006323477, 4.159055737816171, 1.8709894177729423, 1.450240112816171, 0.8484432378161719, 0.9581377394425926, 2.979005042772942, 1.4664588628161708, 2.272870850632351, 0.9264311585440562, 0.808203125, 1.9765213628161704, 2.4113651128161706, 1.5545994878161844, 2.310661987816177, 1.9453956677729414, 2.4498338628161704, 2.3473338628161744, 3.3301151128161703, 2.068724487816179, 1.2492557378161742, 0.8125057378161733, 2.975118658544055, 2.4221776128161725, 1.932583862816172], "episode_lengths": [215, 316, 20, 18, 121, 19, 268, 17, 550, 109, 165, 135, 72, 88, 20, 154, 102, 36, 207, 203, 14, 103, 174, 301, 74, 68, 87, 72, 38, 37, 43, 500, 113, 28, 44, 898, 159, 101, 105, 43, 113, 51, 40, 27, 216, 27, 22, 12, 694, 1241, 1280, 21, 111, 153, 69, 76, 106, 655, 276, 146, 55, 108, 1280, 82, 102, 1010, 118, 92, 56, 113, 21, 61, 220, 659, 54, 203, 28, 129, 49, 144, 31, 28, 43, 197, 55, 31, 23, 73, 350, 138, 63, 51, 147, 25, 502, 588, 188, 27, 69, 67], "policy_blue_reward": [0.7888281250000002, -0.005, -1.0059999999999998, -1.541, -2.0039999999999996, 0.9392812500000001, -1.5289999999999995, -1.0539999999999958, -2.022999999999998, -2.0039999999999996, -1.040999999999997, -1.533, -1.0079999999999993, -1.0609999999999966, -2.0, -1.0269999999999988, -1.0499999999999963, -2.102999999999991, -2.015999999999999, -1.0069999999999997, -2.009999999999999, -1.011999999999999, -2.0139999999999993, -1.025999999999998, -2.0099999999999993, -2.01, -1.0069999999999997, -2.0039999999999996, 2.166031250000013, 0.48500000000001386, 2.971000000000031, -1.0229999999999992, -2.0119999999999996, -1.183999999999982, -2.0189999999999992, -1.537, -1.507, -2.0109999999999992, -1.0249999999999984, -1.0419999999999965, 2.813812500000001, -0.004, -1.0199999999999987, -0.5189999999999998], "policy_red_v4_reward": [-0.649, -1.0109999999999997], "policy_red_v16_reward": [0.4306932378161703, -1.0149999999999997], "policy_red_v18_reward": [-0.004, 1.4706932378161717], "policy_red_v23_reward": [0.14405000000000046, 0.4466932378161732, -1.4419999999999662, -1.525], "policy_red_v13_reward": [-0.8629499999999969, 2.35696875, -0.20799999999999985], "policy_red_v14_reward": [-0.5173067621838289, 1.971828125], "policy_red_v2_reward": [-1.0479999999999974, -1.0239999999999982, -1.0639999999999938], "policy_red_v3_reward": [0.46343749999999984, -1.5099999999999998], "policy_red_v29_reward": [-0.5233067621838287, 1.8099588628161696, -0.0563067621838268, -1.084999999999994], "policy_red_v27_reward": [-0.5089999999999999, -0.6920000000000001], "policy_red_v28_reward": [-0.6019999999999999, 0.5056925427729417, -0.04006538555740524], "policy_red_v8_reward": [1.953765625], "policy_red_v1_reward": [0.405546875], "policy_red_v9_reward": [-2.028999999999998, -0.5589999999999999, 1.005946783544089], "policy_red_v5_reward": [-2.0199999999999996, -1.73, -1.032999999999999, -1.0369999999999973, 1.9437031249999999], "policy_red_v24_reward": [-0.5920000000000001, -2.009, -1.0329999999999968], "policy_red_v17_reward": [1.4856932378161716, -0.09530676218383005], "policy_red_v19_reward": [-0.5273067621847961, -0.516], "policy_red_v22_reward": [0.44432812499999996, -1.018, -0.008], "policy_red_v30_reward": [-0.5193074572270584], "policy_red_v25_reward": [-0.034306762183826445, -0.6330000000000001, -0.665], "policy_red_v7_reward": [0.5700500000000015], "policy_red_v20_reward": [1.17305, -0.1559999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8098301437497676, "mean_inference_ms": 7.833595244049321, "mean_action_processing_ms": 0.2958823242381292, "mean_env_wait_ms": 0.389759923427198, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1006617546081543, "StateBufferConnector_ms": 0.004219770431518555, "ViewRequirementAgentConnector_ms": 0.1163339614868164}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 197.03626833497407, "num_env_steps_trained_throughput_per_sec": 197.03626833497407, "timesteps_total": 264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 20209.15, "sample_time_ms": 1177.218, "learn_time_ms": 18950.334, "learn_throughput": 211.078, "synch_weights_time_ms": 79.152}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "episodes_total": 593, "training_iteration": 66, "trial_id": "a9680_00000", "date": "2023-09-24_02-59-46", "timestamp": 1695538786, "time_this_iter_s": 20.311126947402954, "time_total_s": 1314.86772108078, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b34372560>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3433a170>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3433a200>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1314.86772108078, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 5.134375, "ram_util_percent": 20.578125}, "win_rate": 0.77, "league_size": 36}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5082809584836165, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.01151103658194188, "policy_loss": -0.05759970579820219, "vf_loss": 0.12739636776580784, "vf_explained_var": 0.7161259201044837, "kl": 0.016914335089482316, "entropy": 2.1988921090960503, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 63840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 536000, "num_agent_steps_trained": 536000}, "sampler_results": {"episode_reward_max": 4.440198975632343, "episode_reward_min": -1.7813067621837853, "episode_reward_mean": 2.1335669802905057, "episode_len_mean": 184.74, "episode_media": {}, "episodes_this_iter": 23, "policy_reward_min": {"blue": -2.102999999999991, "red": -4.752306762183853, "red_v13": -0.20799999999999985, "red_v14": -0.5173067621838289, "red_v2": -2.0069999999999997, "red_v3": -1.5099999999999998, "red_v29": -1.084999999999994, "red_v27": -0.6920000000000001, "red_v23": -1.525, "red_v28": -0.6019999999999999, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v9": -2.028999999999998, "red_v5": -2.0199999999999996, "red_v24": -2.009, "red_v17": -0.09530676218383005, "red_v19": -0.5273067621847961, "red_v22": -1.018, "red_v18": 1.4706932378161717, "red_v30": -0.5193074572270584, "red_v25": -0.665, "red_v4": -1.0109999999999997, "red_v7": 0.5700500000000015, "red_v20": -1.0019999999999998, "red_v16": -1.0149999999999997, "red_v10": 1.976421875, "red_v34": 0.4851030335440556, "red_v11": 3.4032244878152067, "red_v6": -2.0109999999999992}, "policy_reward_max": {"blue": 2.971000000000031, "red": 3.98570886281617, "red_v13": 2.414265625, "red_v14": 1.971828125, "red_v2": -1.0239999999999982, "red_v3": 0.46343749999999984, "red_v29": 1.8099588628161696, "red_v27": -0.5089999999999999, "red_v23": 0.49, "red_v28": 0.5056925427729417, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v9": 1.005946783544089, "red_v5": 1.9437031249999999, "red_v24": 0.1812836050000164, "red_v17": 1.4856932378161716, "red_v19": -0.516, "red_v22": 2.340724487816171, "red_v18": 1.4706932378161717, "red_v30": -0.5193074572270584, "red_v25": -0.034306762183826445, "red_v4": -1.0109999999999997, "red_v7": 0.5700500000000015, "red_v20": 1.768740112816172, "red_v16": -1.0149999999999997, "red_v10": 1.976421875, "red_v34": 0.4851030335440556, "red_v11": 3.4032244878152067, "red_v6": -2.0109999999999992}, "policy_reward_mean": {"blue": -0.9068932291666633, "red": 2.487582552025491, "red_v13": 1.521078125, "red_v14": 0.7272606814080855, "red_v2": -1.2857499999999973, "red_v3": -0.5232812499999999, "red_v29": 0.32540771525293816, "red_v27": -0.6005, "red_v23": -0.9259999999999884, "red_v28": -0.04545761426148779, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v9": -0.5273510721519697, "red_v5": -0.39976727286397074, "red_v24": -0.8631790987499951, "red_v17": 0.6951932378161707, "red_v19": -0.521653381092398, "red_v22": 0.4397631532040427, "red_v18": 1.4706932378161717, "red_v30": -0.5193074572270584, "red_v25": -0.44410225406127557, "red_v4": -1.0109999999999997, "red_v7": 0.5700500000000015, "red_v20": 0.44594752820404304, "red_v16": -1.0149999999999997, "red_v10": 1.976421875, "red_v34": 0.4851030335440556, "red_v11": 3.4032244878152067, "red_v6": -2.0109999999999992}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.620052612816187, 2.359661987816174, 1.434880737816171, 2.9242146006323426, 2.399068237816171, 2.4679744878161705, 1.4686776128161703, 2.4624588628161708, 0.9251307378161879, 3.398933350632343, 1.9740057378161708, 1.9617557378161714, 0.9952869878162097, 2.344896362816174, 2.8166776128161746, 2.402865112816172, 1.9327002394425938, 0.9032401128161709, 1.433833862816172, 1.4525682378161708, 1.9757088628161703, 1.7208182378161805, 1.4777088628161703, 2.4644658644425923, 1.3415625000000002, 0.580724487816195, -1.4595281250000003, 0.7806932378162115, 3.9976201555891113, 4.3933396006313785, 1.663115112816179, 2.4021122272587663, 2.4172557378161725, 2.3871619878161736, 2.569839600632392, 2.1516307378161863, 3.3567302256313787, 0.9490213628161699, 3.1997557378161785, -1.7813067621837853, 2.3732783644425925, 2.8629744878161754, 1.4166400213603225, 4.375417725632346, 2.903698280589115, 2.437318237816172, 2.3739333506323455, 2.4809276128152042, 1.446802612816171, 3.903055737816184, 1.6893338628161931, 0.9517244878161711, 2.3086521006323477, 4.159055737816171, 1.8709894177729423, 1.450240112816171, 0.8484432378161719, 0.9581377394425926, 2.979005042772942, 1.4664588628161708, 2.272870850632351, 0.9264311585440562, 0.808203125, 1.9765213628161704, 2.4113651128161706, 1.5545994878161844, 2.310661987816177, 1.9453956677729414, 2.4498338628161704, 2.3473338628161744, 3.3301151128161703, 2.068724487816179, 1.2492557378161742, 0.8125057378161733, 2.975118658544055, 2.4221776128161725, 1.932583862816172, 2.1148807378161827, 1.9831151128161704, 2.26443335063235, 2.862189855, 1.9664588628161708, 2.405958862816173, 3.9315306463602275, 2.075615112816185, 2.4014901128161723, 2.3131018428162022, 3.413443237815206, 1.6512531250000002, 3.404917725631378, 0.8564554800000012, 2.0005369878161896, 2.421927612816172, 4.440198975632343, 1.4646776128161707, 4.410480225632343, 1.4673807378161707, 2.317417725632348, 3.464458862816171, 2.4076776128161725], "episode_lengths": [301, 74, 68, 87, 72, 38, 37, 43, 500, 113, 28, 44, 898, 159, 101, 105, 43, 113, 51, 40, 27, 216, 27, 22, 12, 694, 1241, 1280, 21, 111, 153, 69, 76, 106, 655, 276, 146, 55, 108, 1280, 82, 102, 1010, 118, 92, 56, 113, 21, 61, 220, 659, 54, 203, 28, 129, 49, 144, 31, 28, 43, 197, 55, 31, 23, 73, 350, 138, 63, 51, 147, 25, 502, 588, 188, 27, 69, 67, 708, 25, 209, 30, 43, 75, 53, 249, 97, 408, 80, 31, 86, 41, 370, 85, 60, 37, 98, 36, 182, 43, 101], "policy_blue_reward": [-2.102999999999991, -2.015999999999999, -1.0069999999999997, -2.009999999999999, -1.011999999999999, -2.0139999999999993, -1.025999999999998, -2.0099999999999993, -2.01, -1.0069999999999997, -2.0039999999999996, 2.166031250000013, 0.48500000000001386, 2.971000000000031, -1.0229999999999992, -2.0119999999999996, -1.183999999999982, -2.0189999999999992, -1.537, -1.507, -2.0109999999999992, -1.0249999999999984, -1.0419999999999965, 2.813812500000001, -0.004, -1.0199999999999987, -0.5189999999999998, 0.2479999999999999, -0.006, -1.0259999999999976, 0.48, -2.0069999999999997, -1.5079999999999998, -1.106999999999992, -1.022999999999998, -2.012999999999999], "policy_red_v13_reward": [2.35696875, -0.20799999999999985, 2.414265625], "policy_red_v14_reward": [-0.5173067621838289, 1.971828125], "policy_red_v2_reward": [-1.0479999999999974, -1.0239999999999982, -1.0639999999999938, -2.0069999999999997], "policy_red_v3_reward": [0.46343749999999984, -1.5099999999999998], "policy_red_v29_reward": [-0.5233067621838287, 1.8099588628161696, -0.0563067621838268, -1.084999999999994, 1.481693237816171], "policy_red_v27_reward": [-0.5089999999999999, -0.6920000000000001], "policy_red_v23_reward": [-1.4419999999999662, -1.525, -1.226999999999988, 0.49], "policy_red_v28_reward": [-0.6019999999999999, 0.5056925427729417, -0.04006538555740524], "policy_red_v8_reward": [1.953765625], "policy_red_v1_reward": [0.405546875], "policy_red_v9_reward": [-2.028999999999998, -0.5589999999999999, 1.005946783544089], "policy_red_v5_reward": [-2.0199999999999996, -1.73, -1.032999999999999, -1.0369999999999973, 1.9437031249999999, 1.4776932378161713], "policy_red_v24_reward": [-0.5920000000000001, -2.009, -1.0329999999999968, 0.1812836050000164], "policy_red_v17_reward": [1.4856932378161716, -0.09530676218383005], "policy_red_v19_reward": [-0.5273067621847961, -0.516], "policy_red_v22_reward": [0.44432812499999996, -1.018, -0.008, 2.340724487816171], "policy_red_v18_reward": [1.4706932378161717], "policy_red_v30_reward": [-0.5193074572270584], "policy_red_v25_reward": [-0.034306762183826445, -0.6330000000000001, -0.665], "policy_red_v4_reward": [-1.0109999999999997], "policy_red_v7_reward": [0.5700500000000015], "policy_red_v20_reward": [1.17305, -0.1559999999999998, 1.768740112816172, -1.0019999999999998], "policy_red_v16_reward": [-1.0149999999999997], "policy_red_v10_reward": [1.976421875], "policy_red_v34_reward": [0.4851030335440556], "policy_red_v11_reward": [3.4032244878152067], "policy_red_v6_reward": [-2.0109999999999992]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8099099269615627, "mean_inference_ms": 7.825934554914633, "mean_action_processing_ms": 0.29526711834015523, "mean_env_wait_ms": 0.38963021936732345, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1024017333984375, "StateBufferConnector_ms": 0.004245400428771973, "ViewRequirementAgentConnector_ms": 0.11700034141540527}}, "episode_reward_max": 4.440198975632343, "episode_reward_min": -1.7813067621837853, "episode_reward_mean": 2.1335669802905057, "episode_len_mean": 184.74, "episodes_this_iter": 23, "policy_reward_min": {"blue": -2.102999999999991, "red": -4.752306762183853, "red_v13": -0.20799999999999985, "red_v14": -0.5173067621838289, "red_v2": -2.0069999999999997, "red_v3": -1.5099999999999998, "red_v29": -1.084999999999994, "red_v27": -0.6920000000000001, "red_v23": -1.525, "red_v28": -0.6019999999999999, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v9": -2.028999999999998, "red_v5": -2.0199999999999996, "red_v24": -2.009, "red_v17": -0.09530676218383005, "red_v19": -0.5273067621847961, "red_v22": -1.018, "red_v18": 1.4706932378161717, "red_v30": -0.5193074572270584, "red_v25": -0.665, "red_v4": -1.0109999999999997, "red_v7": 0.5700500000000015, "red_v20": -1.0019999999999998, "red_v16": -1.0149999999999997, "red_v10": 1.976421875, "red_v34": 0.4851030335440556, "red_v11": 3.4032244878152067, "red_v6": -2.0109999999999992}, "policy_reward_max": {"blue": 2.971000000000031, "red": 3.98570886281617, "red_v13": 2.414265625, "red_v14": 1.971828125, "red_v2": -1.0239999999999982, "red_v3": 0.46343749999999984, "red_v29": 1.8099588628161696, "red_v27": -0.5089999999999999, "red_v23": 0.49, "red_v28": 0.5056925427729417, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v9": 1.005946783544089, "red_v5": 1.9437031249999999, "red_v24": 0.1812836050000164, "red_v17": 1.4856932378161716, "red_v19": -0.516, "red_v22": 2.340724487816171, "red_v18": 1.4706932378161717, "red_v30": -0.5193074572270584, "red_v25": -0.034306762183826445, "red_v4": -1.0109999999999997, "red_v7": 0.5700500000000015, "red_v20": 1.768740112816172, "red_v16": -1.0149999999999997, "red_v10": 1.976421875, "red_v34": 0.4851030335440556, "red_v11": 3.4032244878152067, "red_v6": -2.0109999999999992}, "policy_reward_mean": {"blue": -0.9068932291666633, "red": 2.487582552025491, "red_v13": 1.521078125, "red_v14": 0.7272606814080855, "red_v2": -1.2857499999999973, "red_v3": -0.5232812499999999, "red_v29": 0.32540771525293816, "red_v27": -0.6005, "red_v23": -0.9259999999999884, "red_v28": -0.04545761426148779, "red_v8": 1.953765625, "red_v1": 0.405546875, "red_v9": -0.5273510721519697, "red_v5": -0.39976727286397074, "red_v24": -0.8631790987499951, "red_v17": 0.6951932378161707, "red_v19": -0.521653381092398, "red_v22": 0.4397631532040427, "red_v18": 1.4706932378161717, "red_v30": -0.5193074572270584, "red_v25": -0.44410225406127557, "red_v4": -1.0109999999999997, "red_v7": 0.5700500000000015, "red_v20": 0.44594752820404304, "red_v16": -1.0149999999999997, "red_v10": 1.976421875, "red_v34": 0.4851030335440556, "red_v11": 3.4032244878152067, "red_v6": -2.0109999999999992}, "hist_stats": {"episode_reward": [1.620052612816187, 2.359661987816174, 1.434880737816171, 2.9242146006323426, 2.399068237816171, 2.4679744878161705, 1.4686776128161703, 2.4624588628161708, 0.9251307378161879, 3.398933350632343, 1.9740057378161708, 1.9617557378161714, 0.9952869878162097, 2.344896362816174, 2.8166776128161746, 2.402865112816172, 1.9327002394425938, 0.9032401128161709, 1.433833862816172, 1.4525682378161708, 1.9757088628161703, 1.7208182378161805, 1.4777088628161703, 2.4644658644425923, 1.3415625000000002, 0.580724487816195, -1.4595281250000003, 0.7806932378162115, 3.9976201555891113, 4.3933396006313785, 1.663115112816179, 2.4021122272587663, 2.4172557378161725, 2.3871619878161736, 2.569839600632392, 2.1516307378161863, 3.3567302256313787, 0.9490213628161699, 3.1997557378161785, -1.7813067621837853, 2.3732783644425925, 2.8629744878161754, 1.4166400213603225, 4.375417725632346, 2.903698280589115, 2.437318237816172, 2.3739333506323455, 2.4809276128152042, 1.446802612816171, 3.903055737816184, 1.6893338628161931, 0.9517244878161711, 2.3086521006323477, 4.159055737816171, 1.8709894177729423, 1.450240112816171, 0.8484432378161719, 0.9581377394425926, 2.979005042772942, 1.4664588628161708, 2.272870850632351, 0.9264311585440562, 0.808203125, 1.9765213628161704, 2.4113651128161706, 1.5545994878161844, 2.310661987816177, 1.9453956677729414, 2.4498338628161704, 2.3473338628161744, 3.3301151128161703, 2.068724487816179, 1.2492557378161742, 0.8125057378161733, 2.975118658544055, 2.4221776128161725, 1.932583862816172, 2.1148807378161827, 1.9831151128161704, 2.26443335063235, 2.862189855, 1.9664588628161708, 2.405958862816173, 3.9315306463602275, 2.075615112816185, 2.4014901128161723, 2.3131018428162022, 3.413443237815206, 1.6512531250000002, 3.404917725631378, 0.8564554800000012, 2.0005369878161896, 2.421927612816172, 4.440198975632343, 1.4646776128161707, 4.410480225632343, 1.4673807378161707, 2.317417725632348, 3.464458862816171, 2.4076776128161725], "episode_lengths": [301, 74, 68, 87, 72, 38, 37, 43, 500, 113, 28, 44, 898, 159, 101, 105, 43, 113, 51, 40, 27, 216, 27, 22, 12, 694, 1241, 1280, 21, 111, 153, 69, 76, 106, 655, 276, 146, 55, 108, 1280, 82, 102, 1010, 118, 92, 56, 113, 21, 61, 220, 659, 54, 203, 28, 129, 49, 144, 31, 28, 43, 197, 55, 31, 23, 73, 350, 138, 63, 51, 147, 25, 502, 588, 188, 27, 69, 67, 708, 25, 209, 30, 43, 75, 53, 249, 97, 408, 80, 31, 86, 41, 370, 85, 60, 37, 98, 36, 182, 43, 101], "policy_blue_reward": [-2.102999999999991, -2.015999999999999, -1.0069999999999997, -2.009999999999999, -1.011999999999999, -2.0139999999999993, -1.025999999999998, -2.0099999999999993, -2.01, -1.0069999999999997, -2.0039999999999996, 2.166031250000013, 0.48500000000001386, 2.971000000000031, -1.0229999999999992, -2.0119999999999996, -1.183999999999982, -2.0189999999999992, -1.537, -1.507, -2.0109999999999992, -1.0249999999999984, -1.0419999999999965, 2.813812500000001, -0.004, -1.0199999999999987, -0.5189999999999998, 0.2479999999999999, -0.006, -1.0259999999999976, 0.48, -2.0069999999999997, -1.5079999999999998, -1.106999999999992, -1.022999999999998, -2.012999999999999], "policy_red_v13_reward": [2.35696875, -0.20799999999999985, 2.414265625], "policy_red_v14_reward": [-0.5173067621838289, 1.971828125], "policy_red_v2_reward": [-1.0479999999999974, -1.0239999999999982, -1.0639999999999938, -2.0069999999999997], "policy_red_v3_reward": [0.46343749999999984, -1.5099999999999998], "policy_red_v29_reward": [-0.5233067621838287, 1.8099588628161696, -0.0563067621838268, -1.084999999999994, 1.481693237816171], "policy_red_v27_reward": [-0.5089999999999999, -0.6920000000000001], "policy_red_v23_reward": [-1.4419999999999662, -1.525, -1.226999999999988, 0.49], "policy_red_v28_reward": [-0.6019999999999999, 0.5056925427729417, -0.04006538555740524], "policy_red_v8_reward": [1.953765625], "policy_red_v1_reward": [0.405546875], "policy_red_v9_reward": [-2.028999999999998, -0.5589999999999999, 1.005946783544089], "policy_red_v5_reward": [-2.0199999999999996, -1.73, -1.032999999999999, -1.0369999999999973, 1.9437031249999999, 1.4776932378161713], "policy_red_v24_reward": [-0.5920000000000001, -2.009, -1.0329999999999968, 0.1812836050000164], "policy_red_v17_reward": [1.4856932378161716, -0.09530676218383005], "policy_red_v19_reward": [-0.5273067621847961, -0.516], "policy_red_v22_reward": [0.44432812499999996, -1.018, -0.008, 2.340724487816171], "policy_red_v18_reward": [1.4706932378161717], "policy_red_v30_reward": [-0.5193074572270584], "policy_red_v25_reward": [-0.034306762183826445, -0.6330000000000001, -0.665], "policy_red_v4_reward": [-1.0109999999999997], "policy_red_v7_reward": [0.5700500000000015], "policy_red_v20_reward": [1.17305, -0.1559999999999998, 1.768740112816172, -1.0019999999999998], "policy_red_v16_reward": [-1.0149999999999997], "policy_red_v10_reward": [1.976421875], "policy_red_v34_reward": [0.4851030335440556], "policy_red_v11_reward": [3.4032244878152067], "policy_red_v6_reward": [-2.0109999999999992]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8099099269615627, "mean_inference_ms": 7.825934554914633, "mean_action_processing_ms": 0.29526711834015523, "mean_env_wait_ms": 0.38963021936732345, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1024017333984375, "StateBufferConnector_ms": 0.004245400428771973, "ViewRequirementAgentConnector_ms": 0.11700034141540527}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 536000, "num_agent_steps_trained": 536000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.03908673021584, "num_env_steps_trained_throughput_per_sec": 199.03908673021584, "timesteps_total": 268000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 536000, "timers": {"training_iteration_time_ms": 20177.813, "sample_time_ms": 1182.296, "learn_time_ms": 18912.965, "learn_throughput": 211.495, "synch_weights_time_ms": 80.016}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 536000, "num_agent_steps_trained": 536000}, "done": false, "episodes_total": 616, "training_iteration": 67, "trial_id": "a9680_00000", "date": "2023-09-24_03-00-08", "timestamp": 1695538808, "time_this_iter_s": 20.10582137107849, "time_total_s": 1334.9735424518585, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b343728f0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3433a5f0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3433a560>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1334.9735424518585, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 5.2, "ram_util_percent": 20.681250000000002}, "win_rate": 0.7, "league_size": 37}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6484152575333915, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.04546228350579137, "policy_loss": -0.05629831116287581, "vf_loss": 0.19192122255141536, "vf_explained_var": 0.7361408081526558, "kl": 0.017617851050286504, "entropy": 2.1280497210721174, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 64800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "sampler_results": {"episode_reward_max": 4.440198975632343, "episode_reward_min": -1.7813067621837853, "episode_reward_mean": 2.1887678468409395, "episode_len_mean": 186.44, "episode_media": {}, "episodes_this_iter": 30, "policy_reward_min": {"red_v27": -0.6920000000000001, "red": -4.752306762183853, "red_v28": -0.04006538555740524, "red_v5": -1.0369999999999973, "red_v17": -0.09530676218383005, "red_v2": -2.0069999999999997, "red_v19": -0.5273067621847961, "red_v22": -2.0169999999999995, "red_v13": -0.20799999999999985, "blue": -2.0219999999999994, "red_v9": -1.007, "red_v18": 1.4706932378161717, "red_v30": -0.5193074572270584, "red_v25": -0.665, "red_v4": -1.0259999999999996, "red_v7": 0.5700500000000015, "red_v3": -1.5099999999999998, "red_v29": -1.084999999999994, "red_v20": -1.0019999999999998, "red_v23": -1.525, "red_v24": -2.009, "red_v14": 1.971828125, "red_v16": -1.0149999999999997, "red_v10": 1.976421875, "red_v34": 0.4851030335440556, "red_v11": 3.4032244878152067, "red_v6": -2.0109999999999992, "red_v8": -1.529, "red_v21": -1.0039999999999998, "red_v12": 1.4786932378161717}, "policy_reward_max": {"red_v27": -0.6920000000000001, "red": 3.97345886281617, "red_v28": -0.04006538555740524, "red_v5": 1.9437031249999999, "red_v17": -0.09530676218383005, "red_v2": -1.0639999999999938, "red_v19": 0.44684375, "red_v22": 2.340724487816171, "red_v13": 2.414265625, "blue": 2.971000000000031, "red_v9": 1.005946783544089, "red_v18": 1.4706932378161717, "red_v30": 0.4926932378161716, "red_v25": -0.034306762183826445, "red_v4": -1.0109999999999997, "red_v7": 0.5700500000000015, "red_v3": -1.0179999999999998, "red_v29": 1.8099588628161696, "red_v20": 1.768740112816172, "red_v23": 0.49, "red_v24": 0.1812836050000164, "red_v14": 1.971828125, "red_v16": -1.0149999999999997, "red_v10": 1.976421875, "red_v34": 0.4851030335440556, "red_v11": 3.4032244878152067, "red_v6": -2.0109999999999992, "red_v8": -1.529, "red_v21": -0.8843067621838304, "red_v12": 1.4786932378161717}, "policy_reward_mean": {"red_v27": -0.6920000000000001, "red": 2.5450295729973305, "red_v28": -0.04006538555740524, "red_v5": 0.33784909070404373, "red_v17": -0.09530676218383005, "red_v2": -1.5354999999999968, "red_v19": -0.19882100406159867, "red_v22": -0.014149564530638073, "red_v13": 1.1031328125000002, "blue": -0.8193410156249967, "red_v9": -0.18668440548530363, "red_v18": 1.4706932378161717, "red_v30": -0.01330710970544341, "red_v25": -0.44410225406127557, "red_v4": -1.0184999999999995, "red_v7": 0.5700500000000015, "red_v3": -1.2639999999999998, "red_v29": 0.5294077152529392, "red_v20": 0.4432966701264692, "red_v23": -0.753999999999996, "red_v24": -0.9535721316666601, "red_v14": 1.971828125, "red_v16": -1.0149999999999997, "red_v10": 1.976421875, "red_v34": 0.4851030335440556, "red_v11": 3.4032244878152067, "red_v6": -2.0109999999999992, "red_v8": -1.529, "red_v21": -0.9441533810919152, "red_v12": 1.4786932378161717}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.663115112816179, 2.4021122272587663, 2.4172557378161725, 2.3871619878161736, 2.569839600632392, 2.1516307378161863, 3.3567302256313787, 0.9490213628161699, 3.1997557378161785, -1.7813067621837853, 2.3732783644425925, 2.8629744878161754, 1.4166400213603225, 4.375417725632346, 2.903698280589115, 2.437318237816172, 2.3739333506323455, 2.4809276128152042, 1.446802612816171, 3.903055737816184, 1.6893338628161931, 0.9517244878161711, 2.3086521006323477, 4.159055737816171, 1.8709894177729423, 1.450240112816171, 0.8484432378161719, 0.9581377394425926, 2.979005042772942, 1.4664588628161708, 2.272870850632351, 0.9264311585440562, 0.808203125, 1.9765213628161704, 2.4113651128161706, 1.5545994878161844, 2.310661987816177, 1.9453956677729414, 2.4498338628161704, 2.3473338628161744, 3.3301151128161703, 2.068724487816179, 1.2492557378161742, 0.8125057378161733, 2.975118658544055, 2.4221776128161725, 1.932583862816172, 2.1148807378161827, 1.9831151128161704, 2.26443335063235, 2.862189855, 1.9664588628161708, 2.405958862816173, 3.9315306463602275, 2.075615112816185, 2.4014901128161723, 2.3131018428162022, 3.413443237815206, 1.6512531250000002, 3.404917725631378, 0.8564554800000012, 2.0005369878161896, 2.421927612816172, 4.440198975632343, 1.4646776128161707, 4.410480225632343, 1.4673807378161707, 2.317417725632348, 3.464458862816171, 2.4076776128161725, 2.9545369878161707, 3.8048708506323505, 0.9251533644425932, 2.6259901128161833, 2.4170682378161725, 1.0962687500000001, 0.9162939894425931, 1.96767761281617, 2.4604588628161705, 2.316583862816178, -1.5236192621837992, 2.379221105, 2.47589636281617, 2.3582869878161747, 2.4438338628161715, 1.867596105000001, 2.4645682378161706, 0.6992401128162058, 1.9785271006324296, 3.9522771006323403, 2.5130896006324015, 1.4306151128161715, 2.3937557378161722, 0.950536987816172, 4.400152100632344, 1.0408338628161817, 2.4253182378161724, 2.478708862815204, 3.655649487816171, 0.6026932378161804], "episode_lengths": [153, 69, 76, 106, 655, 276, 146, 55, 108, 1280, 82, 102, 1010, 118, 92, 56, 113, 21, 61, 220, 659, 54, 203, 28, 129, 49, 144, 31, 28, 43, 197, 55, 31, 23, 73, 350, 138, 63, 51, 147, 25, 502, 588, 188, 27, 69, 67, 708, 25, 209, 30, 43, 75, 53, 249, 97, 408, 80, 31, 86, 41, 370, 85, 60, 37, 98, 36, 182, 43, 101, 50, 133, 58, 257, 72, 58, 45, 37, 43, 131, 1188, 20, 31, 130, 51, 28, 40, 625, 1011, 67, 575, 57, 108, 50, 107, 371, 56, 27, 30, 1280], "policy_red_v27_reward": [-0.6920000000000001], "policy_red_v28_reward": [-0.04006538555740524], "policy_red_v5_reward": [-1.032999999999999, -1.0369999999999973, 1.9437031249999999, 1.4776932378161713], "policy_red_v17_reward": [-0.09530676218383005], "policy_red_v2_reward": [-1.0639999999999938, -2.0069999999999997], "policy_red_v19_reward": [-0.5273067621847961, -0.516, 0.44684375], "policy_red_v22_reward": [0.44432812499999996, -1.018, -0.008, 2.340724487816171, -2.0169999999999995, 0.17305000000000026], "policy_red_v13_reward": [-0.20799999999999985, 2.414265625], "policy_blue_reward": [2.971000000000031, -1.0229999999999992, -2.0119999999999996, -1.183999999999982, -2.0189999999999992, -1.537, -1.507, -2.0109999999999992, -1.0249999999999984, -1.0419999999999965, 2.813812500000001, -0.004, -1.0199999999999987, -0.5189999999999998, 0.2479999999999999, -0.006, -1.0259999999999976, 0.48, -2.0069999999999997, -1.5079999999999998, -1.106999999999992, -1.022999999999998, -2.012999999999999, -0.014000000000000005, -1.51, -0.6199999999999994, -1.0279999999999982, -2.005, -1.0149999999999995, -1.0439999999999978, 2.19100000000002, -1.003, -1.0339999999999976, -1.0169999999999995, -2.0089999999999995, 0.38254687499999984, -2.0219999999999994, -1.596, -1.0069999999999997, -1.3429999999999696], "policy_red_v9_reward": [-0.5589999999999999, 1.005946783544089, -1.007], "policy_red_v18_reward": [1.4706932378161717], "policy_red_v30_reward": [-0.5193074572270584, 0.4926932378161716], "policy_red_v25_reward": [-0.034306762183826445, -0.6330000000000001, -0.665], "policy_red_v4_reward": [-1.0109999999999997, -1.0259999999999996], "policy_red_v7_reward": [0.5700500000000015], "policy_red_v3_reward": [-1.5099999999999998, -1.0179999999999998], "policy_red_v29_reward": [1.8099588628161696, -0.0563067621838268, -1.084999999999994, 1.481693237816171, 0.49669323781617625], "policy_red_v20_reward": [1.17305, -0.1559999999999998, 1.768740112816172, -1.0019999999999998, 0.43269323781617386], "policy_red_v23_reward": [-1.525, -1.226999999999988, 0.49], "policy_red_v24_reward": [-2.009, -1.0329999999999968, 0.1812836050000164], "policy_red_v14_reward": [1.971828125], "policy_red_v16_reward": [-1.0149999999999997], "policy_red_v10_reward": [1.976421875], "policy_red_v34_reward": [0.4851030335440556], "policy_red_v11_reward": [3.4032244878152067], "policy_red_v6_reward": [-2.0109999999999992], "policy_red_v8_reward": [-1.529], "policy_red_v21_reward": [-1.0039999999999998, -0.8843067621838304], "policy_red_v12_reward": [1.4786932378161717]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8079769690659814, "mean_inference_ms": 7.7891503176056425, "mean_action_processing_ms": 0.29399678354529246, "mean_env_wait_ms": 0.3883318491852312, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10316610336303711, "StateBufferConnector_ms": 0.004221677780151367, "ViewRequirementAgentConnector_ms": 0.11711597442626953}}, "episode_reward_max": 4.440198975632343, "episode_reward_min": -1.7813067621837853, "episode_reward_mean": 2.1887678468409395, "episode_len_mean": 186.44, "episodes_this_iter": 30, "policy_reward_min": {"red_v27": -0.6920000000000001, "red": -4.752306762183853, "red_v28": -0.04006538555740524, "red_v5": -1.0369999999999973, "red_v17": -0.09530676218383005, "red_v2": -2.0069999999999997, "red_v19": -0.5273067621847961, "red_v22": -2.0169999999999995, "red_v13": -0.20799999999999985, "blue": -2.0219999999999994, "red_v9": -1.007, "red_v18": 1.4706932378161717, "red_v30": -0.5193074572270584, "red_v25": -0.665, "red_v4": -1.0259999999999996, "red_v7": 0.5700500000000015, "red_v3": -1.5099999999999998, "red_v29": -1.084999999999994, "red_v20": -1.0019999999999998, "red_v23": -1.525, "red_v24": -2.009, "red_v14": 1.971828125, "red_v16": -1.0149999999999997, "red_v10": 1.976421875, "red_v34": 0.4851030335440556, "red_v11": 3.4032244878152067, "red_v6": -2.0109999999999992, "red_v8": -1.529, "red_v21": -1.0039999999999998, "red_v12": 1.4786932378161717}, "policy_reward_max": {"red_v27": -0.6920000000000001, "red": 3.97345886281617, "red_v28": -0.04006538555740524, "red_v5": 1.9437031249999999, "red_v17": -0.09530676218383005, "red_v2": -1.0639999999999938, "red_v19": 0.44684375, "red_v22": 2.340724487816171, "red_v13": 2.414265625, "blue": 2.971000000000031, "red_v9": 1.005946783544089, "red_v18": 1.4706932378161717, "red_v30": 0.4926932378161716, "red_v25": -0.034306762183826445, "red_v4": -1.0109999999999997, "red_v7": 0.5700500000000015, "red_v3": -1.0179999999999998, "red_v29": 1.8099588628161696, "red_v20": 1.768740112816172, "red_v23": 0.49, "red_v24": 0.1812836050000164, "red_v14": 1.971828125, "red_v16": -1.0149999999999997, "red_v10": 1.976421875, "red_v34": 0.4851030335440556, "red_v11": 3.4032244878152067, "red_v6": -2.0109999999999992, "red_v8": -1.529, "red_v21": -0.8843067621838304, "red_v12": 1.4786932378161717}, "policy_reward_mean": {"red_v27": -0.6920000000000001, "red": 2.5450295729973305, "red_v28": -0.04006538555740524, "red_v5": 0.33784909070404373, "red_v17": -0.09530676218383005, "red_v2": -1.5354999999999968, "red_v19": -0.19882100406159867, "red_v22": -0.014149564530638073, "red_v13": 1.1031328125000002, "blue": -0.8193410156249967, "red_v9": -0.18668440548530363, "red_v18": 1.4706932378161717, "red_v30": -0.01330710970544341, "red_v25": -0.44410225406127557, "red_v4": -1.0184999999999995, "red_v7": 0.5700500000000015, "red_v3": -1.2639999999999998, "red_v29": 0.5294077152529392, "red_v20": 0.4432966701264692, "red_v23": -0.753999999999996, "red_v24": -0.9535721316666601, "red_v14": 1.971828125, "red_v16": -1.0149999999999997, "red_v10": 1.976421875, "red_v34": 0.4851030335440556, "red_v11": 3.4032244878152067, "red_v6": -2.0109999999999992, "red_v8": -1.529, "red_v21": -0.9441533810919152, "red_v12": 1.4786932378161717}, "hist_stats": {"episode_reward": [1.663115112816179, 2.4021122272587663, 2.4172557378161725, 2.3871619878161736, 2.569839600632392, 2.1516307378161863, 3.3567302256313787, 0.9490213628161699, 3.1997557378161785, -1.7813067621837853, 2.3732783644425925, 2.8629744878161754, 1.4166400213603225, 4.375417725632346, 2.903698280589115, 2.437318237816172, 2.3739333506323455, 2.4809276128152042, 1.446802612816171, 3.903055737816184, 1.6893338628161931, 0.9517244878161711, 2.3086521006323477, 4.159055737816171, 1.8709894177729423, 1.450240112816171, 0.8484432378161719, 0.9581377394425926, 2.979005042772942, 1.4664588628161708, 2.272870850632351, 0.9264311585440562, 0.808203125, 1.9765213628161704, 2.4113651128161706, 1.5545994878161844, 2.310661987816177, 1.9453956677729414, 2.4498338628161704, 2.3473338628161744, 3.3301151128161703, 2.068724487816179, 1.2492557378161742, 0.8125057378161733, 2.975118658544055, 2.4221776128161725, 1.932583862816172, 2.1148807378161827, 1.9831151128161704, 2.26443335063235, 2.862189855, 1.9664588628161708, 2.405958862816173, 3.9315306463602275, 2.075615112816185, 2.4014901128161723, 2.3131018428162022, 3.413443237815206, 1.6512531250000002, 3.404917725631378, 0.8564554800000012, 2.0005369878161896, 2.421927612816172, 4.440198975632343, 1.4646776128161707, 4.410480225632343, 1.4673807378161707, 2.317417725632348, 3.464458862816171, 2.4076776128161725, 2.9545369878161707, 3.8048708506323505, 0.9251533644425932, 2.6259901128161833, 2.4170682378161725, 1.0962687500000001, 0.9162939894425931, 1.96767761281617, 2.4604588628161705, 2.316583862816178, -1.5236192621837992, 2.379221105, 2.47589636281617, 2.3582869878161747, 2.4438338628161715, 1.867596105000001, 2.4645682378161706, 0.6992401128162058, 1.9785271006324296, 3.9522771006323403, 2.5130896006324015, 1.4306151128161715, 2.3937557378161722, 0.950536987816172, 4.400152100632344, 1.0408338628161817, 2.4253182378161724, 2.478708862815204, 3.655649487816171, 0.6026932378161804], "episode_lengths": [153, 69, 76, 106, 655, 276, 146, 55, 108, 1280, 82, 102, 1010, 118, 92, 56, 113, 21, 61, 220, 659, 54, 203, 28, 129, 49, 144, 31, 28, 43, 197, 55, 31, 23, 73, 350, 138, 63, 51, 147, 25, 502, 588, 188, 27, 69, 67, 708, 25, 209, 30, 43, 75, 53, 249, 97, 408, 80, 31, 86, 41, 370, 85, 60, 37, 98, 36, 182, 43, 101, 50, 133, 58, 257, 72, 58, 45, 37, 43, 131, 1188, 20, 31, 130, 51, 28, 40, 625, 1011, 67, 575, 57, 108, 50, 107, 371, 56, 27, 30, 1280], "policy_red_v27_reward": [-0.6920000000000001], "policy_red_v28_reward": [-0.04006538555740524], "policy_red_v5_reward": [-1.032999999999999, -1.0369999999999973, 1.9437031249999999, 1.4776932378161713], "policy_red_v17_reward": [-0.09530676218383005], "policy_red_v2_reward": [-1.0639999999999938, -2.0069999999999997], "policy_red_v19_reward": [-0.5273067621847961, -0.516, 0.44684375], "policy_red_v22_reward": [0.44432812499999996, -1.018, -0.008, 2.340724487816171, -2.0169999999999995, 0.17305000000000026], "policy_red_v13_reward": [-0.20799999999999985, 2.414265625], "policy_blue_reward": [2.971000000000031, -1.0229999999999992, -2.0119999999999996, -1.183999999999982, -2.0189999999999992, -1.537, -1.507, -2.0109999999999992, -1.0249999999999984, -1.0419999999999965, 2.813812500000001, -0.004, -1.0199999999999987, -0.5189999999999998, 0.2479999999999999, -0.006, -1.0259999999999976, 0.48, -2.0069999999999997, -1.5079999999999998, -1.106999999999992, -1.022999999999998, -2.012999999999999, -0.014000000000000005, -1.51, -0.6199999999999994, -1.0279999999999982, -2.005, -1.0149999999999995, -1.0439999999999978, 2.19100000000002, -1.003, -1.0339999999999976, -1.0169999999999995, -2.0089999999999995, 0.38254687499999984, -2.0219999999999994, -1.596, -1.0069999999999997, -1.3429999999999696], "policy_red_v9_reward": [-0.5589999999999999, 1.005946783544089, -1.007], "policy_red_v18_reward": [1.4706932378161717], "policy_red_v30_reward": [-0.5193074572270584, 0.4926932378161716], "policy_red_v25_reward": [-0.034306762183826445, -0.6330000000000001, -0.665], "policy_red_v4_reward": [-1.0109999999999997, -1.0259999999999996], "policy_red_v7_reward": [0.5700500000000015], "policy_red_v3_reward": [-1.5099999999999998, -1.0179999999999998], "policy_red_v29_reward": [1.8099588628161696, -0.0563067621838268, -1.084999999999994, 1.481693237816171, 0.49669323781617625], "policy_red_v20_reward": [1.17305, -0.1559999999999998, 1.768740112816172, -1.0019999999999998, 0.43269323781617386], "policy_red_v23_reward": [-1.525, -1.226999999999988, 0.49], "policy_red_v24_reward": [-2.009, -1.0329999999999968, 0.1812836050000164], "policy_red_v14_reward": [1.971828125], "policy_red_v16_reward": [-1.0149999999999997], "policy_red_v10_reward": [1.976421875], "policy_red_v34_reward": [0.4851030335440556], "policy_red_v11_reward": [3.4032244878152067], "policy_red_v6_reward": [-2.0109999999999992], "policy_red_v8_reward": [-1.529], "policy_red_v21_reward": [-1.0039999999999998, -0.8843067621838304], "policy_red_v12_reward": [1.4786932378161717]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8079769690659814, "mean_inference_ms": 7.7891503176056425, "mean_action_processing_ms": 0.29399678354529246, "mean_env_wait_ms": 0.3883318491852312, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10316610336303711, "StateBufferConnector_ms": 0.004221677780151367, "ViewRequirementAgentConnector_ms": 0.11711597442626953}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.40496385149635, "num_env_steps_trained_throughput_per_sec": 199.40496385149635, "timesteps_total": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 20150.495, "sample_time_ms": 1184.052, "learn_time_ms": 18884.504, "learn_throughput": 211.814, "synch_weights_time_ms": 79.42}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "episodes_total": 646, "training_iteration": 68, "trial_id": "a9680_00000", "date": "2023-09-24_03-00-31", "timestamp": 1695538831, "time_this_iter_s": 20.071483612060547, "time_total_s": 1355.045026063919, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b343707f0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3433add0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3433ad40>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1355.045026063919, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 5.11875, "ram_util_percent": 20.78125}, "win_rate": 0.7, "league_size": 38}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6421788473924, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.040017737312882676, "policy_loss": -0.05762721916738277, "vf_loss": 0.18153739012001704, "vf_explained_var": 0.7635951758672793, "kl": 0.019864507903472866, "entropy": 2.0627662241458893, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 65760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 552000, "num_agent_steps_trained": 552000}, "sampler_results": {"episode_reward_max": 4.446792725632342, "episode_reward_min": -3.084171874999964, "episode_reward_mean": 2.285284548356558, "episode_len_mean": 162.7, "episode_media": {}, "episodes_this_iter": 33, "policy_reward_min": {"red_v14": 1.971828125, "red": -7.325000000000047, "blue": -2.0219999999999994, "red_v25": -1.0069999999999997, "red_v29": -1.084999999999994, "red_v5": -1.0349999999999986, "red_v16": -1.0149999999999997, "red_v20": -1.0019999999999998, "red_v24": -1.0329999999999968, "red_v10": -1.0059999999999996, "red_v2": -2.0069999999999997, "red_v13": 0.44162500000000005, "red_v34": 0.4851030335440556, "red_v23": -1.226999999999988, "red_v11": 0.48769323781520385, "red_v6": -2.0109999999999992, "red_v22": -2.0169999999999995, "red_v8": -1.529, "red_v21": -1.5039999999999558, "red_v9": -1.007, "red_v30": 0.4926932378161716, "red_v3": -1.0179999999999998, "red_v19": 0.44684375, "red_v12": 1.4786932378161717, "red_v4": -2.009, "red_v35": 1.4896932378161714}, "policy_reward_max": {"red_v14": 1.971828125, "red": 3.99192761281617, "blue": 4.240828125000009, "red_v25": -0.6330000000000001, "red_v29": 1.481693237816171, "red_v5": 1.9437031249999999, "red_v16": -1.0149999999999997, "red_v20": 1.768740112816172, "red_v24": 0.49369323781617, "red_v10": 1.976421875, "red_v2": -2.0069999999999997, "red_v13": 2.414265625, "red_v34": 0.4851030335440556, "red_v23": 0.49, "red_v11": 3.4032244878152067, "red_v6": 2.29321875, "red_v22": 2.340724487816171, "red_v8": -1.529, "red_v21": -0.8843067621838304, "red_v9": -1.007, "red_v30": 0.4926932378161716, "red_v3": -1.0179999999999998, "red_v19": 0.44684375, "red_v12": 3.3946463628161725, "red_v4": -1.0259999999999996, "red_v35": 1.4896932378161714}, "policy_reward_mean": {"red_v14": 1.971828125, "red": 2.560744954913277, "blue": -0.7504554020212745, "red_v25": -0.7683333333333332, "red_v29": 0.5060259426895117, "red_v5": 0.5923490907040432, "red_v16": -1.0149999999999997, "red_v20": 0.2608583376580865, "red_v24": -0.11934105239460346, "red_v10": 0.4852109375000002, "red_v2": -2.0069999999999997, "red_v13": 1.4279453125000001, "red_v34": 0.4851030335440556, "red_v23": -0.2479656554853111, "red_v11": 1.9546079918768038, "red_v6": -0.43844531249999963, "red_v22": 0.16559149593872388, "red_v8": -1.529, "red_v21": -1.1307689207279286, "red_v9": -1.007, "red_v30": 0.4926932378161716, "red_v3": -1.0179999999999998, "red_v19": 0.44684375, "red_v12": 2.436669800316172, "red_v4": -1.5174999999999996, "red_v35": 1.4896932378161714}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.9765213628161704, 2.4113651128161706, 1.5545994878161844, 2.310661987816177, 1.9453956677729414, 2.4498338628161704, 2.3473338628161744, 3.3301151128161703, 2.068724487816179, 1.2492557378161742, 0.8125057378161733, 2.975118658544055, 2.4221776128161725, 1.932583862816172, 2.1148807378161827, 1.9831151128161704, 2.26443335063235, 2.862189855, 1.9664588628161708, 2.405958862816173, 3.9315306463602275, 2.075615112816185, 2.4014901128161723, 2.3131018428162022, 3.413443237815206, 1.6512531250000002, 3.404917725631378, 0.8564554800000012, 2.0005369878161896, 2.421927612816172, 4.440198975632343, 1.4646776128161707, 4.410480225632343, 1.4673807378161707, 2.317417725632348, 3.464458862816171, 2.4076776128161725, 2.9545369878161707, 3.8048708506323505, 0.9251533644425932, 2.6259901128161833, 2.4170682378161725, 1.0962687500000001, 0.9162939894425931, 1.96767761281617, 2.4604588628161705, 2.316583862816178, -1.5236192621837992, 2.379221105, 2.47589636281617, 2.3582869878161747, 2.4438338628161715, 1.867596105000001, 2.4645682378161706, 0.6992401128162058, 1.9785271006324296, 3.9522771006323403, 2.5130896006324015, 1.4306151128161715, 2.3937557378161722, 0.950536987816172, 4.400152100632344, 1.0408338628161817, 2.4253182378161724, 2.478708862815204, 3.655649487816171, 0.6026932378161804, 3.3953396006323433, 1.8773304800000004, 2.4698182378161704, 1.9851151128161701, 1.8661898550000005, 0.4226932378161944, 1.922075239442594, 3.943714600631374, 2.3217869878161728, 1.9282687500000089, -3.084171874999964, 4.446792725632342, 2.38453064636023, 2.469271362816171, 2.9258494878161723, 2.952755737816171, 2.4883331677729417, 4.116227612816172, 2.433130737816172, 2.4571619878161712, 0.9165596144425932, 3.942652100632341, 3.9209489756313776, 2.485040533544055, 2.4718963628161705, 1.9763026128161705, 1.4694588628161704, 2.475786987815204, 1.9698651128161702, 2.3804744878161723, 1.9849276128161701, 4.062101842816185, 2.4523494878161713], "episode_lengths": [23, 73, 350, 138, 63, 51, 147, 25, 502, 588, 188, 27, 69, 67, 708, 25, 209, 30, 43, 75, 53, 249, 97, 408, 80, 31, 86, 41, 370, 85, 60, 37, 98, 36, 182, 43, 101, 50, 133, 58, 257, 72, 58, 45, 37, 43, 131, 1188, 20, 31, 130, 51, 28, 40, 625, 1011, 67, 575, 57, 108, 50, 107, 371, 56, 27, 30, 1280, 111, 17, 24, 25, 30, 1280, 51, 55, 162, 186, 727, 62, 117, 39, 78, 44, 19, 69, 52, 42, 56, 75, 76, 20, 31, 29, 43, 34, 41, 134, 21, 280, 46], "policy_red_v14_reward": [1.971828125], "policy_blue_reward": [-1.0249999999999984, -1.0419999999999965, 2.813812500000001, -0.004, -1.0199999999999987, -0.5189999999999998, 0.2479999999999999, -0.006, -1.0259999999999976, 0.48, -2.0069999999999997, -1.5079999999999998, -1.106999999999992, -1.022999999999998, -2.012999999999999, -0.014000000000000005, -1.51, -0.6199999999999994, -1.0279999999999982, -2.005, -1.0149999999999995, -1.0439999999999978, 2.19100000000002, -1.003, -1.0339999999999976, -1.0169999999999995, -2.0089999999999995, 0.38254687499999984, -2.0219999999999994, -1.596, -1.0069999999999997, -1.3429999999999696, -2.006, -2.0049999999999994, -0.518, -1.0419999999999967, 4.240828125000009, -1.010999999999999, -0.01800000000000001, -1.003, -1.0129999999999995, -2.009, -2.0089999999999995, -1.0279999999999978, -2.0069999999999997, 1.6274086050000007, -1.018999999999999], "policy_red_v25_reward": [-0.6330000000000001, -0.665, -1.0069999999999997], "policy_red_v29_reward": [-1.084999999999994, 1.481693237816171, 0.49669323781617625, 1.1580500000000014, 0.4786932378152041], "policy_red_v5_reward": [1.9437031249999999, 1.4776932378161713, -0.017000000000000005, -1.0349999999999986], "policy_red_v16_reward": [-1.0149999999999997], "policy_red_v20_reward": [-0.1559999999999998, 1.768740112816172, -1.0019999999999998, 0.43269323781617386], "policy_red_v24_reward": [-1.0329999999999968, 0.1812836050000164, 0.49369323781617], "policy_red_v10_reward": [1.976421875, -1.0059999999999996], "policy_red_v2_reward": [-2.0069999999999997], "policy_red_v13_reward": [2.414265625, 0.44162500000000005], "policy_red_v34_reward": [0.4851030335440556], "policy_red_v23_reward": [-1.226999999999988, 0.49, -0.006896966455945175], "policy_red_v11_reward": [3.4032244878152067, 1.97290625, 0.48769323781520385], "policy_red_v6_reward": [-2.0109999999999992, -1.0179999999999996, 2.29321875, -1.0179999999999993], "policy_red_v22_reward": [2.340724487816171, -2.0169999999999995, 0.17305000000000026], "policy_red_v8_reward": [-1.529], "policy_red_v21_reward": [-1.0039999999999998, -0.8843067621838304, -1.5039999999999558], "policy_red_v9_reward": [-1.007], "policy_red_v30_reward": [0.4926932378161716], "policy_red_v3_reward": [-1.0179999999999998], "policy_red_v19_reward": [0.44684375], "policy_red_v12_reward": [1.4786932378161717, 3.3946463628161725], "policy_red_v4_reward": [-1.0259999999999996, -2.009], "policy_red_v35_reward": [1.4896932378161714]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8085729411464488, "mean_inference_ms": 7.782792004669615, "mean_action_processing_ms": 0.29427640779018427, "mean_env_wait_ms": 0.38860410672105233, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10418236255645752, "StateBufferConnector_ms": 0.004292130470275879, "ViewRequirementAgentConnector_ms": 0.11912453174591064}}, "episode_reward_max": 4.446792725632342, "episode_reward_min": -3.084171874999964, "episode_reward_mean": 2.285284548356558, "episode_len_mean": 162.7, "episodes_this_iter": 33, "policy_reward_min": {"red_v14": 1.971828125, "red": -7.325000000000047, "blue": -2.0219999999999994, "red_v25": -1.0069999999999997, "red_v29": -1.084999999999994, "red_v5": -1.0349999999999986, "red_v16": -1.0149999999999997, "red_v20": -1.0019999999999998, "red_v24": -1.0329999999999968, "red_v10": -1.0059999999999996, "red_v2": -2.0069999999999997, "red_v13": 0.44162500000000005, "red_v34": 0.4851030335440556, "red_v23": -1.226999999999988, "red_v11": 0.48769323781520385, "red_v6": -2.0109999999999992, "red_v22": -2.0169999999999995, "red_v8": -1.529, "red_v21": -1.5039999999999558, "red_v9": -1.007, "red_v30": 0.4926932378161716, "red_v3": -1.0179999999999998, "red_v19": 0.44684375, "red_v12": 1.4786932378161717, "red_v4": -2.009, "red_v35": 1.4896932378161714}, "policy_reward_max": {"red_v14": 1.971828125, "red": 3.99192761281617, "blue": 4.240828125000009, "red_v25": -0.6330000000000001, "red_v29": 1.481693237816171, "red_v5": 1.9437031249999999, "red_v16": -1.0149999999999997, "red_v20": 1.768740112816172, "red_v24": 0.49369323781617, "red_v10": 1.976421875, "red_v2": -2.0069999999999997, "red_v13": 2.414265625, "red_v34": 0.4851030335440556, "red_v23": 0.49, "red_v11": 3.4032244878152067, "red_v6": 2.29321875, "red_v22": 2.340724487816171, "red_v8": -1.529, "red_v21": -0.8843067621838304, "red_v9": -1.007, "red_v30": 0.4926932378161716, "red_v3": -1.0179999999999998, "red_v19": 0.44684375, "red_v12": 3.3946463628161725, "red_v4": -1.0259999999999996, "red_v35": 1.4896932378161714}, "policy_reward_mean": {"red_v14": 1.971828125, "red": 2.560744954913277, "blue": -0.7504554020212745, "red_v25": -0.7683333333333332, "red_v29": 0.5060259426895117, "red_v5": 0.5923490907040432, "red_v16": -1.0149999999999997, "red_v20": 0.2608583376580865, "red_v24": -0.11934105239460346, "red_v10": 0.4852109375000002, "red_v2": -2.0069999999999997, "red_v13": 1.4279453125000001, "red_v34": 0.4851030335440556, "red_v23": -0.2479656554853111, "red_v11": 1.9546079918768038, "red_v6": -0.43844531249999963, "red_v22": 0.16559149593872388, "red_v8": -1.529, "red_v21": -1.1307689207279286, "red_v9": -1.007, "red_v30": 0.4926932378161716, "red_v3": -1.0179999999999998, "red_v19": 0.44684375, "red_v12": 2.436669800316172, "red_v4": -1.5174999999999996, "red_v35": 1.4896932378161714}, "hist_stats": {"episode_reward": [1.9765213628161704, 2.4113651128161706, 1.5545994878161844, 2.310661987816177, 1.9453956677729414, 2.4498338628161704, 2.3473338628161744, 3.3301151128161703, 2.068724487816179, 1.2492557378161742, 0.8125057378161733, 2.975118658544055, 2.4221776128161725, 1.932583862816172, 2.1148807378161827, 1.9831151128161704, 2.26443335063235, 2.862189855, 1.9664588628161708, 2.405958862816173, 3.9315306463602275, 2.075615112816185, 2.4014901128161723, 2.3131018428162022, 3.413443237815206, 1.6512531250000002, 3.404917725631378, 0.8564554800000012, 2.0005369878161896, 2.421927612816172, 4.440198975632343, 1.4646776128161707, 4.410480225632343, 1.4673807378161707, 2.317417725632348, 3.464458862816171, 2.4076776128161725, 2.9545369878161707, 3.8048708506323505, 0.9251533644425932, 2.6259901128161833, 2.4170682378161725, 1.0962687500000001, 0.9162939894425931, 1.96767761281617, 2.4604588628161705, 2.316583862816178, -1.5236192621837992, 2.379221105, 2.47589636281617, 2.3582869878161747, 2.4438338628161715, 1.867596105000001, 2.4645682378161706, 0.6992401128162058, 1.9785271006324296, 3.9522771006323403, 2.5130896006324015, 1.4306151128161715, 2.3937557378161722, 0.950536987816172, 4.400152100632344, 1.0408338628161817, 2.4253182378161724, 2.478708862815204, 3.655649487816171, 0.6026932378161804, 3.3953396006323433, 1.8773304800000004, 2.4698182378161704, 1.9851151128161701, 1.8661898550000005, 0.4226932378161944, 1.922075239442594, 3.943714600631374, 2.3217869878161728, 1.9282687500000089, -3.084171874999964, 4.446792725632342, 2.38453064636023, 2.469271362816171, 2.9258494878161723, 2.952755737816171, 2.4883331677729417, 4.116227612816172, 2.433130737816172, 2.4571619878161712, 0.9165596144425932, 3.942652100632341, 3.9209489756313776, 2.485040533544055, 2.4718963628161705, 1.9763026128161705, 1.4694588628161704, 2.475786987815204, 1.9698651128161702, 2.3804744878161723, 1.9849276128161701, 4.062101842816185, 2.4523494878161713], "episode_lengths": [23, 73, 350, 138, 63, 51, 147, 25, 502, 588, 188, 27, 69, 67, 708, 25, 209, 30, 43, 75, 53, 249, 97, 408, 80, 31, 86, 41, 370, 85, 60, 37, 98, 36, 182, 43, 101, 50, 133, 58, 257, 72, 58, 45, 37, 43, 131, 1188, 20, 31, 130, 51, 28, 40, 625, 1011, 67, 575, 57, 108, 50, 107, 371, 56, 27, 30, 1280, 111, 17, 24, 25, 30, 1280, 51, 55, 162, 186, 727, 62, 117, 39, 78, 44, 19, 69, 52, 42, 56, 75, 76, 20, 31, 29, 43, 34, 41, 134, 21, 280, 46], "policy_red_v14_reward": [1.971828125], "policy_blue_reward": [-1.0249999999999984, -1.0419999999999965, 2.813812500000001, -0.004, -1.0199999999999987, -0.5189999999999998, 0.2479999999999999, -0.006, -1.0259999999999976, 0.48, -2.0069999999999997, -1.5079999999999998, -1.106999999999992, -1.022999999999998, -2.012999999999999, -0.014000000000000005, -1.51, -0.6199999999999994, -1.0279999999999982, -2.005, -1.0149999999999995, -1.0439999999999978, 2.19100000000002, -1.003, -1.0339999999999976, -1.0169999999999995, -2.0089999999999995, 0.38254687499999984, -2.0219999999999994, -1.596, -1.0069999999999997, -1.3429999999999696, -2.006, -2.0049999999999994, -0.518, -1.0419999999999967, 4.240828125000009, -1.010999999999999, -0.01800000000000001, -1.003, -1.0129999999999995, -2.009, -2.0089999999999995, -1.0279999999999978, -2.0069999999999997, 1.6274086050000007, -1.018999999999999], "policy_red_v25_reward": [-0.6330000000000001, -0.665, -1.0069999999999997], "policy_red_v29_reward": [-1.084999999999994, 1.481693237816171, 0.49669323781617625, 1.1580500000000014, 0.4786932378152041], "policy_red_v5_reward": [1.9437031249999999, 1.4776932378161713, -0.017000000000000005, -1.0349999999999986], "policy_red_v16_reward": [-1.0149999999999997], "policy_red_v20_reward": [-0.1559999999999998, 1.768740112816172, -1.0019999999999998, 0.43269323781617386], "policy_red_v24_reward": [-1.0329999999999968, 0.1812836050000164, 0.49369323781617], "policy_red_v10_reward": [1.976421875, -1.0059999999999996], "policy_red_v2_reward": [-2.0069999999999997], "policy_red_v13_reward": [2.414265625, 0.44162500000000005], "policy_red_v34_reward": [0.4851030335440556], "policy_red_v23_reward": [-1.226999999999988, 0.49, -0.006896966455945175], "policy_red_v11_reward": [3.4032244878152067, 1.97290625, 0.48769323781520385], "policy_red_v6_reward": [-2.0109999999999992, -1.0179999999999996, 2.29321875, -1.0179999999999993], "policy_red_v22_reward": [2.340724487816171, -2.0169999999999995, 0.17305000000000026], "policy_red_v8_reward": [-1.529], "policy_red_v21_reward": [-1.0039999999999998, -0.8843067621838304, -1.5039999999999558], "policy_red_v9_reward": [-1.007], "policy_red_v30_reward": [0.4926932378161716], "policy_red_v3_reward": [-1.0179999999999998], "policy_red_v19_reward": [0.44684375], "policy_red_v12_reward": [1.4786932378161717, 3.3946463628161725], "policy_red_v4_reward": [-1.0259999999999996, -2.009], "policy_red_v35_reward": [1.4896932378161714]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8085729411464488, "mean_inference_ms": 7.782792004669615, "mean_action_processing_ms": 0.29427640779018427, "mean_env_wait_ms": 0.38860410672105233, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10418236255645752, "StateBufferConnector_ms": 0.004292130470275879, "ViewRequirementAgentConnector_ms": 0.11912453174591064}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 552000, "num_agent_steps_trained": 552000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.21108231939564, "num_env_steps_trained_throughput_per_sec": 200.21108231939564, "timesteps_total": 276000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 552000, "timers": {"training_iteration_time_ms": 20126.48, "sample_time_ms": 1183.269, "learn_time_ms": 18860.843, "learn_throughput": 212.08, "synch_weights_time_ms": 79.772}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 552000, "num_agent_steps_trained": 552000}, "done": false, "episodes_total": 679, "training_iteration": 69, "trial_id": "a9680_00000", "date": "2023-09-24_03-00-53", "timestamp": 1695538853, "time_this_iter_s": 19.989903211593628, "time_total_s": 1375.0349292755127, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b341f4df0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b341cc670>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b341cc700>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1375.0349292755127, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 5.209375, "ram_util_percent": 20.971875}, "win_rate": 0.66, "league_size": 39}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4140130980561176, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.016632550939903012, "policy_loss": -0.05848844157444546, "vf_loss": 0.13840324299720427, "vf_explained_var": 0.8222871455053489, "kl": 0.017681055791102025, "entropy": 2.037103580807646, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 66720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "sampler_results": {"episode_reward_max": 4.469448975631375, "episode_reward_min": -3.084171874999964, "episode_reward_mean": 2.2861332323638077, "episode_len_mean": 159.1, "episode_media": {}, "episodes_this_iter": 36, "policy_reward_min": {"red_v20": -2.0189999999999992, "red": -7.325000000000047, "blue": -2.0219999999999994, "red_v22": -2.0169999999999995, "red_v8": -1.529, "red_v21": -1.5039999999999558, "red_v9": -1.007, "red_v30": 0.4926932378161716, "red_v29": 0.4786932378152041, "red_v3": -2.0119999999999996, "red_v19": 0.44684375, "red_v12": 0.1680500000000006, "red_v4": -2.009, "red_v6": -1.0179999999999996, "red_v11": 0.46969323781520417, "red_v35": -1.012999999999999, "red_v23": -1.6560000000000001, "red_v5": -1.0349999999999986, "red_v13": 0.44162500000000005, "red_v24": 0.49369323781617, "red_v25": -1.0069999999999997, "red_v10": -1.0059999999999996, "red_v16": -1.021999999999999, "red_v28": 0.4786932378161699, "red_v14": -2.008, "red_v26": -0.5730000000000001, "red_v36": 3.3983807378161726, "red_v32": 0.5061030335440552, "red_v1": -0.007}, "policy_reward_max": {"red_v20": 0.43269323781617386, "red": 3.9967401128152034, "blue": 4.240828125000009, "red_v22": 0.7416925427729428, "red_v8": -1.015, "red_v21": -0.8843067621838304, "red_v9": 0.4193437500000001, "red_v30": 0.4926932378161716, "red_v29": 1.1580500000000014, "red_v3": -1.0179999999999998, "red_v19": 0.44684375, "red_v12": 3.3946463628161725, "red_v4": -1.0259999999999996, "red_v6": 2.29321875, "red_v11": 1.97290625, "red_v35": 1.4896932378161714, "red_v23": 0.3932836050000005, "red_v5": -0.017000000000000005, "red_v13": 0.44162500000000005, "red_v24": 1.4946932378152042, "red_v25": 0.4476932378161729, "red_v10": -1.0059999999999996, "red_v16": -1.021999999999999, "red_v28": 0.4786932378161699, "red_v14": -2.008, "red_v26": -0.5089999999999998, "red_v36": 3.3983807378161726, "red_v32": 0.5061030335440552, "red_v1": -0.007}, "policy_reward_mean": {"red_v20": -0.8627689207279418, "red": 2.7861660336928082, "blue": -0.9530198465957431, "red_v22": -0.36741915240901873, "red_v8": -1.2719999999999998, "red_v21": -1.1307689207279286, "red_v9": -0.2938281249999999, "red_v30": 0.4926932378161716, "red_v29": 0.7111454918771273, "red_v3": -1.5149999999999997, "red_v19": 0.44684375, "red_v12": 1.3809333376580863, "red_v4": -1.5174999999999996, "red_v6": 0.08573958333333365, "red_v11": 0.9767642418768028, "red_v35": 0.23834661890808617, "red_v23": -0.4232044538186483, "red_v5": -0.5259999999999992, "red_v13": 0.44162500000000005, "red_v24": 0.9941932378156871, "red_v25": -0.2796533810919134, "red_v10": -1.0059999999999996, "red_v16": -1.021999999999999, "red_v28": 0.4786932378161699, "red_v14": -2.008, "red_v26": -0.5409999999999999, "red_v36": 3.3983807378161726, "red_v32": 0.5061030335440552, "red_v1": -0.007}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.4076776128161725, 2.9545369878161707, 3.8048708506323505, 0.9251533644425932, 2.6259901128161833, 2.4170682378161725, 1.0962687500000001, 0.9162939894425931, 1.96767761281617, 2.4604588628161705, 2.316583862816178, -1.5236192621837992, 2.379221105, 2.47589636281617, 2.3582869878161747, 2.4438338628161715, 1.867596105000001, 2.4645682378161706, 0.6992401128162058, 1.9785271006324296, 3.9522771006323403, 2.5130896006324015, 1.4306151128161715, 2.3937557378161722, 0.950536987816172, 4.400152100632344, 1.0408338628161817, 2.4253182378161724, 2.478708862815204, 3.655649487816171, 0.6026932378161804, 3.3953396006323433, 1.8773304800000004, 2.4698182378161704, 1.9851151128161701, 1.8661898550000005, 0.4226932378161944, 1.922075239442594, 3.943714600631374, 2.3217869878161728, 1.9282687500000089, -3.084171874999964, 4.446792725632342, 2.38453064636023, 2.469271362816171, 2.9258494878161723, 2.952755737816171, 2.4883331677729417, 4.116227612816172, 2.433130737816172, 2.4571619878161712, 0.9165596144425932, 3.942652100632341, 3.9209489756313776, 2.485040533544055, 2.4718963628161705, 1.9763026128161705, 1.4694588628161704, 2.475786987815204, 1.9698651128161702, 2.3804744878161723, 1.9849276128161701, 4.062101842816185, 2.4523494878161713, 2.4399119878161715, 2.6239768428162393, 3.8806955928161706, 2.4757124085440547, 1.960536987816171, 3.889823975632345, 1.9655682378161707, 1.990740112815204, 1.10553698781617, 2.452536987816171, 1.48170886281617, 2.66439375, 2.485337408544055, 2.887396362816172, 1.4543494878161711, -1.6625312499999905, 1.9636776128161708, 1.9793857805891693, 3.915542725631377, 2.4715682378161707, 2.4563494878161705, 0.9110369878161706, 3.4000739756323437, 2.981927612815204, 1.4730838628161707, 3.8887303885440545, 1.4773026128161706, 1.471708862815204, 2.8312557378161767, 1.9301776128161714, 2.45627136281617, 2.9737869878161707, 0.8756273550000004, 3.648430737816171, 3.831902100632349, 4.469448975631375], "episode_lengths": [101, 50, 133, 58, 257, 72, 58, 45, 37, 43, 131, 1188, 20, 31, 130, 51, 28, 40, 625, 1011, 67, 575, 57, 108, 50, 107, 371, 56, 27, 30, 1280, 111, 17, 24, 25, 30, 1280, 51, 55, 162, 186, 727, 62, 117, 39, 78, 44, 19, 69, 52, 42, 56, 75, 76, 20, 31, 29, 43, 34, 41, 134, 21, 280, 46, 58, 1280, 26, 29, 50, 116, 40, 17, 306, 50, 27, 18, 21, 63, 46, 554, 37, 1280, 78, 40, 46, 82, 100, 21, 35, 18, 29, 27, 140, 69, 39, 34, 18, 36, 123, 44], "policy_red_v20_reward": [-1.0019999999999998, 0.43269323781617386, -2.0189999999999992], "policy_blue_reward": [-0.014000000000000005, -1.51, -0.6199999999999994, -1.0279999999999982, -2.005, -1.0149999999999995, -1.0439999999999978, 2.19100000000002, -1.003, -1.0339999999999976, -1.0169999999999995, -2.0089999999999995, 0.38254687499999984, -2.0219999999999994, -1.596, -1.0069999999999997, -1.3429999999999696, -2.006, -2.0049999999999994, -0.518, -1.0419999999999967, 4.240828125000009, -1.010999999999999, -0.01800000000000001, -1.003, -1.0129999999999995, -2.009, -2.0089999999999995, -1.0279999999999978, -2.0069999999999997, 1.6274086050000007, -1.018999999999999, 0.5332836050000005, -1.0069999999999997, -2.0089999999999995, -2.0059999999999993, -1.0129999999999997, -2.0069999999999997, -0.003, -1.0069999999999997, -2.0169999999999995, -0.6580000000000001, -2.017999999999999, -1.0089999999999997, -2.0059999999999993, -2.0069999999999992, -0.04500000000000003], "policy_red_v22_reward": [-2.0169999999999995, 0.17305000000000026, 0.7416925427729428], "policy_red_v8_reward": [-1.529, -1.015], "policy_red_v21_reward": [-1.0039999999999998, -0.8843067621838304, -1.5039999999999558], "policy_red_v9_reward": [-1.007, 0.4193437500000001], "policy_red_v30_reward": [0.4926932378161716], "policy_red_v29_reward": [0.49669323781617625, 1.1580500000000014, 0.4786932378152041], "policy_red_v3_reward": [-1.0179999999999998, -2.0119999999999996], "policy_red_v19_reward": [0.44684375], "policy_red_v12_reward": [1.4786932378161717, 3.3946463628161725, 0.48234375000000007, 0.1680500000000006], "policy_red_v4_reward": [-1.0259999999999996, -2.009], "policy_red_v6_reward": [-1.0179999999999996, 2.29321875, -1.0179999999999993], "policy_red_v11_reward": [1.97290625, 0.48769323781520385, 0.46969323781520417], "policy_red_v35_reward": [1.4896932378161714, -1.012999999999999], "policy_red_v23_reward": [-0.006896966455945175, 0.3932836050000005, -1.6560000000000001], "policy_red_v5_reward": [-0.017000000000000005, -1.0349999999999986], "policy_red_v13_reward": [0.44162500000000005], "policy_red_v24_reward": [0.49369323781617, 1.4946932378152042], "policy_red_v25_reward": [-1.0069999999999997, 0.4476932378161729], "policy_red_v10_reward": [-1.0059999999999996], "policy_red_v16_reward": [-1.021999999999999], "policy_red_v28_reward": [0.4786932378161699], "policy_red_v14_reward": [-2.008], "policy_red_v26_reward": [-0.5730000000000001, -0.5089999999999998], "policy_red_v36_reward": [3.3983807378161726], "policy_red_v32_reward": [0.5061030335440552], "policy_red_v1_reward": [-0.007]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8091562165653066, "mean_inference_ms": 7.769722712749244, "mean_action_processing_ms": 0.29440439326755247, "mean_env_wait_ms": 0.38906030722382257, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1034773588180542, "StateBufferConnector_ms": 0.004242300987243652, "ViewRequirementAgentConnector_ms": 0.11847090721130371}}, "episode_reward_max": 4.469448975631375, "episode_reward_min": -3.084171874999964, "episode_reward_mean": 2.2861332323638077, "episode_len_mean": 159.1, "episodes_this_iter": 36, "policy_reward_min": {"red_v20": -2.0189999999999992, "red": -7.325000000000047, "blue": -2.0219999999999994, "red_v22": -2.0169999999999995, "red_v8": -1.529, "red_v21": -1.5039999999999558, "red_v9": -1.007, "red_v30": 0.4926932378161716, "red_v29": 0.4786932378152041, "red_v3": -2.0119999999999996, "red_v19": 0.44684375, "red_v12": 0.1680500000000006, "red_v4": -2.009, "red_v6": -1.0179999999999996, "red_v11": 0.46969323781520417, "red_v35": -1.012999999999999, "red_v23": -1.6560000000000001, "red_v5": -1.0349999999999986, "red_v13": 0.44162500000000005, "red_v24": 0.49369323781617, "red_v25": -1.0069999999999997, "red_v10": -1.0059999999999996, "red_v16": -1.021999999999999, "red_v28": 0.4786932378161699, "red_v14": -2.008, "red_v26": -0.5730000000000001, "red_v36": 3.3983807378161726, "red_v32": 0.5061030335440552, "red_v1": -0.007}, "policy_reward_max": {"red_v20": 0.43269323781617386, "red": 3.9967401128152034, "blue": 4.240828125000009, "red_v22": 0.7416925427729428, "red_v8": -1.015, "red_v21": -0.8843067621838304, "red_v9": 0.4193437500000001, "red_v30": 0.4926932378161716, "red_v29": 1.1580500000000014, "red_v3": -1.0179999999999998, "red_v19": 0.44684375, "red_v12": 3.3946463628161725, "red_v4": -1.0259999999999996, "red_v6": 2.29321875, "red_v11": 1.97290625, "red_v35": 1.4896932378161714, "red_v23": 0.3932836050000005, "red_v5": -0.017000000000000005, "red_v13": 0.44162500000000005, "red_v24": 1.4946932378152042, "red_v25": 0.4476932378161729, "red_v10": -1.0059999999999996, "red_v16": -1.021999999999999, "red_v28": 0.4786932378161699, "red_v14": -2.008, "red_v26": -0.5089999999999998, "red_v36": 3.3983807378161726, "red_v32": 0.5061030335440552, "red_v1": -0.007}, "policy_reward_mean": {"red_v20": -0.8627689207279418, "red": 2.7861660336928082, "blue": -0.9530198465957431, "red_v22": -0.36741915240901873, "red_v8": -1.2719999999999998, "red_v21": -1.1307689207279286, "red_v9": -0.2938281249999999, "red_v30": 0.4926932378161716, "red_v29": 0.7111454918771273, "red_v3": -1.5149999999999997, "red_v19": 0.44684375, "red_v12": 1.3809333376580863, "red_v4": -1.5174999999999996, "red_v6": 0.08573958333333365, "red_v11": 0.9767642418768028, "red_v35": 0.23834661890808617, "red_v23": -0.4232044538186483, "red_v5": -0.5259999999999992, "red_v13": 0.44162500000000005, "red_v24": 0.9941932378156871, "red_v25": -0.2796533810919134, "red_v10": -1.0059999999999996, "red_v16": -1.021999999999999, "red_v28": 0.4786932378161699, "red_v14": -2.008, "red_v26": -0.5409999999999999, "red_v36": 3.3983807378161726, "red_v32": 0.5061030335440552, "red_v1": -0.007}, "hist_stats": {"episode_reward": [2.4076776128161725, 2.9545369878161707, 3.8048708506323505, 0.9251533644425932, 2.6259901128161833, 2.4170682378161725, 1.0962687500000001, 0.9162939894425931, 1.96767761281617, 2.4604588628161705, 2.316583862816178, -1.5236192621837992, 2.379221105, 2.47589636281617, 2.3582869878161747, 2.4438338628161715, 1.867596105000001, 2.4645682378161706, 0.6992401128162058, 1.9785271006324296, 3.9522771006323403, 2.5130896006324015, 1.4306151128161715, 2.3937557378161722, 0.950536987816172, 4.400152100632344, 1.0408338628161817, 2.4253182378161724, 2.478708862815204, 3.655649487816171, 0.6026932378161804, 3.3953396006323433, 1.8773304800000004, 2.4698182378161704, 1.9851151128161701, 1.8661898550000005, 0.4226932378161944, 1.922075239442594, 3.943714600631374, 2.3217869878161728, 1.9282687500000089, -3.084171874999964, 4.446792725632342, 2.38453064636023, 2.469271362816171, 2.9258494878161723, 2.952755737816171, 2.4883331677729417, 4.116227612816172, 2.433130737816172, 2.4571619878161712, 0.9165596144425932, 3.942652100632341, 3.9209489756313776, 2.485040533544055, 2.4718963628161705, 1.9763026128161705, 1.4694588628161704, 2.475786987815204, 1.9698651128161702, 2.3804744878161723, 1.9849276128161701, 4.062101842816185, 2.4523494878161713, 2.4399119878161715, 2.6239768428162393, 3.8806955928161706, 2.4757124085440547, 1.960536987816171, 3.889823975632345, 1.9655682378161707, 1.990740112815204, 1.10553698781617, 2.452536987816171, 1.48170886281617, 2.66439375, 2.485337408544055, 2.887396362816172, 1.4543494878161711, -1.6625312499999905, 1.9636776128161708, 1.9793857805891693, 3.915542725631377, 2.4715682378161707, 2.4563494878161705, 0.9110369878161706, 3.4000739756323437, 2.981927612815204, 1.4730838628161707, 3.8887303885440545, 1.4773026128161706, 1.471708862815204, 2.8312557378161767, 1.9301776128161714, 2.45627136281617, 2.9737869878161707, 0.8756273550000004, 3.648430737816171, 3.831902100632349, 4.469448975631375], "episode_lengths": [101, 50, 133, 58, 257, 72, 58, 45, 37, 43, 131, 1188, 20, 31, 130, 51, 28, 40, 625, 1011, 67, 575, 57, 108, 50, 107, 371, 56, 27, 30, 1280, 111, 17, 24, 25, 30, 1280, 51, 55, 162, 186, 727, 62, 117, 39, 78, 44, 19, 69, 52, 42, 56, 75, 76, 20, 31, 29, 43, 34, 41, 134, 21, 280, 46, 58, 1280, 26, 29, 50, 116, 40, 17, 306, 50, 27, 18, 21, 63, 46, 554, 37, 1280, 78, 40, 46, 82, 100, 21, 35, 18, 29, 27, 140, 69, 39, 34, 18, 36, 123, 44], "policy_red_v20_reward": [-1.0019999999999998, 0.43269323781617386, -2.0189999999999992], "policy_blue_reward": [-0.014000000000000005, -1.51, -0.6199999999999994, -1.0279999999999982, -2.005, -1.0149999999999995, -1.0439999999999978, 2.19100000000002, -1.003, -1.0339999999999976, -1.0169999999999995, -2.0089999999999995, 0.38254687499999984, -2.0219999999999994, -1.596, -1.0069999999999997, -1.3429999999999696, -2.006, -2.0049999999999994, -0.518, -1.0419999999999967, 4.240828125000009, -1.010999999999999, -0.01800000000000001, -1.003, -1.0129999999999995, -2.009, -2.0089999999999995, -1.0279999999999978, -2.0069999999999997, 1.6274086050000007, -1.018999999999999, 0.5332836050000005, -1.0069999999999997, -2.0089999999999995, -2.0059999999999993, -1.0129999999999997, -2.0069999999999997, -0.003, -1.0069999999999997, -2.0169999999999995, -0.6580000000000001, -2.017999999999999, -1.0089999999999997, -2.0059999999999993, -2.0069999999999992, -0.04500000000000003], "policy_red_v22_reward": [-2.0169999999999995, 0.17305000000000026, 0.7416925427729428], "policy_red_v8_reward": [-1.529, -1.015], "policy_red_v21_reward": [-1.0039999999999998, -0.8843067621838304, -1.5039999999999558], "policy_red_v9_reward": [-1.007, 0.4193437500000001], "policy_red_v30_reward": [0.4926932378161716], "policy_red_v29_reward": [0.49669323781617625, 1.1580500000000014, 0.4786932378152041], "policy_red_v3_reward": [-1.0179999999999998, -2.0119999999999996], "policy_red_v19_reward": [0.44684375], "policy_red_v12_reward": [1.4786932378161717, 3.3946463628161725, 0.48234375000000007, 0.1680500000000006], "policy_red_v4_reward": [-1.0259999999999996, -2.009], "policy_red_v6_reward": [-1.0179999999999996, 2.29321875, -1.0179999999999993], "policy_red_v11_reward": [1.97290625, 0.48769323781520385, 0.46969323781520417], "policy_red_v35_reward": [1.4896932378161714, -1.012999999999999], "policy_red_v23_reward": [-0.006896966455945175, 0.3932836050000005, -1.6560000000000001], "policy_red_v5_reward": [-0.017000000000000005, -1.0349999999999986], "policy_red_v13_reward": [0.44162500000000005], "policy_red_v24_reward": [0.49369323781617, 1.4946932378152042], "policy_red_v25_reward": [-1.0069999999999997, 0.4476932378161729], "policy_red_v10_reward": [-1.0059999999999996], "policy_red_v16_reward": [-1.021999999999999], "policy_red_v28_reward": [0.4786932378161699], "policy_red_v14_reward": [-2.008], "policy_red_v26_reward": [-0.5730000000000001, -0.5089999999999998], "policy_red_v36_reward": [3.3983807378161726], "policy_red_v32_reward": [0.5061030335440552], "policy_red_v1_reward": [-0.007]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8091562165653066, "mean_inference_ms": 7.769722712749244, "mean_action_processing_ms": 0.29440439326755247, "mean_env_wait_ms": 0.38906030722382257, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1034773588180542, "StateBufferConnector_ms": 0.004242300987243652, "ViewRequirementAgentConnector_ms": 0.11847090721130371}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.63932586343373, "num_env_steps_trained_throughput_per_sec": 199.63932586343373, "timesteps_total": 280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 20127.997, "sample_time_ms": 1175.761, "learn_time_ms": 18869.518, "learn_throughput": 211.982, "synch_weights_time_ms": 80.147}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "episodes_total": 715, "training_iteration": 70, "trial_id": "a9680_00000", "date": "2023-09-24_03-01-16", "timestamp": 1695538876, "time_this_iter_s": 20.047117948532104, "time_total_s": 1395.0820472240448, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b341f59f0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b341ccd30>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b341ccdc0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1395.0820472240448, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 5.35, "ram_util_percent": 21.078125}, "win_rate": 0.69, "league_size": 40}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5964064850161472, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.05123524371398768, "policy_loss": -0.05639965542213758, "vf_loss": 0.20468940971574437, "vf_explained_var": 0.766146440928181, "kl": 0.016297118305154377, "entropy": 2.043508319556713, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 67680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 568000, "num_agent_steps_trained": 568000}, "sampler_results": {"episode_reward_max": 4.469448975631375, "episode_reward_min": -2.9121874999999853, "episode_reward_mean": 2.229617182156708, "episode_len_mean": 119.97, "episode_media": {}, "episodes_this_iter": 45, "policy_reward_min": {"blue": -2.017999999999999, "red": -3.8141875000000147, "red_v5": -1.0349999999999986, "red_v29": 0.4786932378152041, "red_v6": -2.0059999999999993, "red_v13": 0.44162500000000005, "red_v24": 0.49369323781617, "red_v25": -1.0069999999999997, "red_v10": -1.0059999999999996, "red_v4": -2.009, "red_v16": -1.5269999999999997, "red_v23": -1.6560000000000001, "red_v28": 0.4786932378161699, "red_v14": -2.008, "red_v26": -2.036999999999998, "red_v22": 0.7416925427729428, "red_v11": 0.46969323781520417, "red_v35": -1.012999999999999, "red_v9": -2.0039999999999996, "red_v36": 0.17705000000000015, "red_v32": -0.5639999999999998, "red_v3": -2.0119999999999996, "red_v20": -2.0189999999999992, "red_v8": -1.015, "red_v1": -0.007, "red_v12": -2.009, "red_v19": -0.004, "red_v31": 0.47350000000000003, "red_v37": 1.9805312499999999, "red_v27": 0.39628360500000037, "red_v34": 0.48969323781617, "red_v18": -1.005}, "policy_reward_max": {"blue": 1.857234375, "red": 3.9967401128152034, "red_v5": -0.017000000000000005, "red_v29": 1.1580500000000014, "red_v6": -1.0179999999999993, "red_v13": 0.44162500000000005, "red_v24": 1.4946932378152042, "red_v25": 0.4476932378161729, "red_v10": -1.0059999999999996, "red_v4": -2.009, "red_v16": -1.021999999999999, "red_v23": 0.3932836050000005, "red_v28": 1.8999971144425922, "red_v14": 0.46693461444259227, "red_v26": 1.944296875, "red_v22": 0.7416925427729428, "red_v11": 0.46969323781520417, "red_v35": -1.012999999999999, "red_v9": 0.4193437500000001, "red_v36": 3.3983807378161726, "red_v32": 0.5061030335440552, "red_v3": -2.005, "red_v20": -2.0189999999999992, "red_v8": -0.09981249999999953, "red_v1": -0.007, "red_v12": 0.48234375000000007, "red_v19": -0.004, "red_v31": 1.8370937500000002, "red_v37": 1.9805312499999999, "red_v27": 0.39628360500000037, "red_v34": 1.98575, "red_v18": -1.005}, "policy_reward_mean": {"blue": -1.0251335758888873, "red": 2.792616861001258, "red_v5": -0.5259999999999992, "red_v29": 0.8183716189076027, "red_v6": -1.3516666666666655, "red_v13": 0.44162500000000005, "red_v24": 0.9941932378156871, "red_v25": -0.2796533810919134, "red_v10": -1.0059999999999996, "red_v4": -2.009, "red_v16": -1.2744999999999993, "red_v23": -0.6313581974999998, "red_v28": 1.1893451761293812, "red_v14": -0.3994573825804089, "red_v26": -0.2936757812499995, "red_v22": 0.7416925427729428, "red_v11": 0.46969323781520417, "red_v35": -1.012999999999999, "red_v9": -1.0325520833333328, "red_v36": 1.7877153689080862, "red_v32": -0.028948483227972333, "red_v3": -2.0084999999999997, "red_v20": -2.0189999999999992, "red_v8": -0.5574062499999997, "red_v1": -0.007, "red_v12": -0.34065156249999984, "red_v19": -0.004, "red_v31": 1.1552968750000001, "red_v37": 1.9805312499999999, "red_v27": 0.39628360500000037, "red_v34": 1.2377216189080849, "red_v18": -1.005}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.9258494878161723, 2.952755737816171, 2.4883331677729417, 4.116227612816172, 2.433130737816172, 2.4571619878161712, 0.9165596144425932, 3.942652100632341, 3.9209489756313776, 2.485040533544055, 2.4718963628161705, 1.9763026128161705, 1.4694588628161704, 2.475786987815204, 1.9698651128161702, 2.3804744878161723, 1.9849276128161701, 4.062101842816185, 2.4523494878161713, 2.4399119878161715, 2.6239768428162393, 3.8806955928161706, 2.4757124085440547, 1.960536987816171, 3.889823975632345, 1.9655682378161707, 1.990740112815204, 1.10553698781617, 2.452536987816171, 1.48170886281617, 2.66439375, 2.485337408544055, 2.887396362816172, 1.4543494878161711, -1.6625312499999905, 1.9636776128161708, 1.9793857805891693, 3.915542725631377, 2.4715682378161707, 2.4563494878161705, 0.9110369878161706, 3.4000739756323437, 2.981927612815204, 1.4730838628161707, 3.8887303885440545, 1.4773026128161706, 1.471708862815204, 2.8312557378161767, 1.9301776128161714, 2.45627136281617, 2.9737869878161707, 0.8756273550000004, 3.648430737816171, 3.831902100632349, 4.469448975631375, 2.360536987816174, 1.478040533544055, 2.1648000000000005, 2.98089636281617, 2.97749011281617, 0.6286932378162176, 0.9801932378161702, 1.98822448781617, -0.20211926218382992, 0.918740112816172, 2.467271362816171, 2.946208862816171, 1.8946903522587641, 2.48622448781617, 1.8509276128161738, 2.478114417772942, 3.9101591022587643, 3.6677936585440554, 3.2393304800000005, 1.9736776128161706, 1.9469901128161706, 1.8759242300000005, 2.4508338628161708, 2.4022244878161736, 1.4924425427729422, -2.9121874999999853, 1.960161987815205, 0.9673807378161707, 2.9005057378161716, 1.9810050427729418, 0.6747557378162279, 2.426552612816172, 1.4669432378161704, 2.4563083506323617, 1.1726718750000003, 2.472278364442592, 2.925474487816172, 1.4825213628152043, 1.895958167772946, 1.9430994878161716, 0.9706776128161707, 1.6658000000000004, 1.8427869878161744, 3.9623396006323417, 1.9635682378161712], "episode_lengths": [78, 44, 19, 69, 52, 42, 56, 75, 76, 20, 31, 29, 43, 34, 41, 134, 21, 280, 46, 58, 1280, 26, 29, 50, 116, 40, 17, 306, 50, 27, 18, 21, 63, 46, 554, 37, 1280, 78, 40, 46, 82, 100, 21, 35, 18, 29, 27, 140, 69, 39, 34, 18, 36, 123, 44, 114, 20, 16, 31, 33, 1280, 32, 22, 708, 81, 39, 59, 108, 22, 149, 25, 86, 19, 17, 37, 65, 19, 51, 86, 16, 316, 42, 36, 60, 28, 876, 77, 48, 505, 137, 18, 70, 23, 75, 62, 37, 16, 162, 47, 40], "policy_blue_reward": [-0.01800000000000001, -1.003, -1.0129999999999995, -2.009, -2.0089999999999995, -1.0279999999999978, -2.0069999999999997, 1.6274086050000007, -1.018999999999999, 0.5332836050000005, -1.0069999999999997, -2.0089999999999995, -2.0059999999999993, -1.0129999999999997, -2.0069999999999997, -0.003, -1.0069999999999997, -2.0169999999999995, -0.6580000000000001, -2.017999999999999, -1.0089999999999997, -2.0059999999999993, -2.0069999999999992, -0.04500000000000003, -1.0399999999999985, -2.0129999999999995, -1.0049999999999997, -1.3499999999999668, -1.0099999999999993, -0.013000000000000005, -1.0059999999999996, 1.857234375, -1.009, -1.0169999999999995, 0.9020000000000044, -2.0109999999999992, -2.006, 0.4830625000000053, -1.021999999999998, -0.5489999999999998, -0.02100000000000001, -2.007999999999999, -2.0179999999999985, -1.51, -2.007999999999999], "policy_red_v5_reward": [-0.017000000000000005, -1.0349999999999986], "policy_red_v29_reward": [1.1580500000000014, 0.4786932378152041], "policy_red_v6_reward": [-1.0179999999999993, -1.0309999999999975, -2.0059999999999993], "policy_red_v13_reward": [0.44162500000000005], "policy_red_v24_reward": [0.49369323781617, 1.4946932378152042], "policy_red_v25_reward": [-1.0069999999999997, 0.4476932378161729], "policy_red_v10_reward": [-1.0059999999999996], "policy_red_v4_reward": [-2.009], "policy_red_v16_reward": [-1.021999999999999, -1.5269999999999997], "policy_red_v23_reward": [0.3932836050000005, -1.6560000000000001], "policy_red_v28_reward": [0.4786932378161699, 1.8999971144425922], "policy_red_v14_reward": [-2.008, 0.46693461444259227, 0.3426932378161809], "policy_red_v26_reward": [-0.5730000000000001, -0.5089999999999998, 1.944296875, -2.036999999999998], "policy_red_v22_reward": [0.7416925427729428], "policy_red_v11_reward": [0.46969323781520417], "policy_red_v35_reward": [-1.012999999999999], "policy_red_v9_reward": [0.4193437500000001, -1.512999999999999, -2.0039999999999996], "policy_red_v36_reward": [3.3983807378161726, 0.17705000000000015], "policy_red_v32_reward": [0.5061030335440552, -0.5639999999999998], "policy_red_v3_reward": [-2.0119999999999996, -2.005], "policy_red_v20_reward": [-2.0189999999999992], "policy_red_v8_reward": [-1.015, -0.09981249999999953], "policy_red_v1_reward": [-0.007], "policy_red_v12_reward": [0.48234375000000007, 0.1680500000000006, -0.004, -2.009], "policy_red_v19_reward": [-0.004], "policy_red_v31_reward": [0.47350000000000003, 1.8370937500000002], "policy_red_v37_reward": [1.9805312499999999], "policy_red_v27_reward": [0.39628360500000037], "policy_red_v34_reward": [1.98575, 0.48969323781617], "policy_red_v18_reward": [-1.005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8088401539353385, "mean_inference_ms": 7.748617403315831, "mean_action_processing_ms": 0.29328398820791696, "mean_env_wait_ms": 0.3882458414289549, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10096323490142822, "StateBufferConnector_ms": 0.004129528999328613, "ViewRequirementAgentConnector_ms": 0.1159048080444336}}, "episode_reward_max": 4.469448975631375, "episode_reward_min": -2.9121874999999853, "episode_reward_mean": 2.229617182156708, "episode_len_mean": 119.97, "episodes_this_iter": 45, "policy_reward_min": {"blue": -2.017999999999999, "red": -3.8141875000000147, "red_v5": -1.0349999999999986, "red_v29": 0.4786932378152041, "red_v6": -2.0059999999999993, "red_v13": 0.44162500000000005, "red_v24": 0.49369323781617, "red_v25": -1.0069999999999997, "red_v10": -1.0059999999999996, "red_v4": -2.009, "red_v16": -1.5269999999999997, "red_v23": -1.6560000000000001, "red_v28": 0.4786932378161699, "red_v14": -2.008, "red_v26": -2.036999999999998, "red_v22": 0.7416925427729428, "red_v11": 0.46969323781520417, "red_v35": -1.012999999999999, "red_v9": -2.0039999999999996, "red_v36": 0.17705000000000015, "red_v32": -0.5639999999999998, "red_v3": -2.0119999999999996, "red_v20": -2.0189999999999992, "red_v8": -1.015, "red_v1": -0.007, "red_v12": -2.009, "red_v19": -0.004, "red_v31": 0.47350000000000003, "red_v37": 1.9805312499999999, "red_v27": 0.39628360500000037, "red_v34": 0.48969323781617, "red_v18": -1.005}, "policy_reward_max": {"blue": 1.857234375, "red": 3.9967401128152034, "red_v5": -0.017000000000000005, "red_v29": 1.1580500000000014, "red_v6": -1.0179999999999993, "red_v13": 0.44162500000000005, "red_v24": 1.4946932378152042, "red_v25": 0.4476932378161729, "red_v10": -1.0059999999999996, "red_v4": -2.009, "red_v16": -1.021999999999999, "red_v23": 0.3932836050000005, "red_v28": 1.8999971144425922, "red_v14": 0.46693461444259227, "red_v26": 1.944296875, "red_v22": 0.7416925427729428, "red_v11": 0.46969323781520417, "red_v35": -1.012999999999999, "red_v9": 0.4193437500000001, "red_v36": 3.3983807378161726, "red_v32": 0.5061030335440552, "red_v3": -2.005, "red_v20": -2.0189999999999992, "red_v8": -0.09981249999999953, "red_v1": -0.007, "red_v12": 0.48234375000000007, "red_v19": -0.004, "red_v31": 1.8370937500000002, "red_v37": 1.9805312499999999, "red_v27": 0.39628360500000037, "red_v34": 1.98575, "red_v18": -1.005}, "policy_reward_mean": {"blue": -1.0251335758888873, "red": 2.792616861001258, "red_v5": -0.5259999999999992, "red_v29": 0.8183716189076027, "red_v6": -1.3516666666666655, "red_v13": 0.44162500000000005, "red_v24": 0.9941932378156871, "red_v25": -0.2796533810919134, "red_v10": -1.0059999999999996, "red_v4": -2.009, "red_v16": -1.2744999999999993, "red_v23": -0.6313581974999998, "red_v28": 1.1893451761293812, "red_v14": -0.3994573825804089, "red_v26": -0.2936757812499995, "red_v22": 0.7416925427729428, "red_v11": 0.46969323781520417, "red_v35": -1.012999999999999, "red_v9": -1.0325520833333328, "red_v36": 1.7877153689080862, "red_v32": -0.028948483227972333, "red_v3": -2.0084999999999997, "red_v20": -2.0189999999999992, "red_v8": -0.5574062499999997, "red_v1": -0.007, "red_v12": -0.34065156249999984, "red_v19": -0.004, "red_v31": 1.1552968750000001, "red_v37": 1.9805312499999999, "red_v27": 0.39628360500000037, "red_v34": 1.2377216189080849, "red_v18": -1.005}, "hist_stats": {"episode_reward": [2.9258494878161723, 2.952755737816171, 2.4883331677729417, 4.116227612816172, 2.433130737816172, 2.4571619878161712, 0.9165596144425932, 3.942652100632341, 3.9209489756313776, 2.485040533544055, 2.4718963628161705, 1.9763026128161705, 1.4694588628161704, 2.475786987815204, 1.9698651128161702, 2.3804744878161723, 1.9849276128161701, 4.062101842816185, 2.4523494878161713, 2.4399119878161715, 2.6239768428162393, 3.8806955928161706, 2.4757124085440547, 1.960536987816171, 3.889823975632345, 1.9655682378161707, 1.990740112815204, 1.10553698781617, 2.452536987816171, 1.48170886281617, 2.66439375, 2.485337408544055, 2.887396362816172, 1.4543494878161711, -1.6625312499999905, 1.9636776128161708, 1.9793857805891693, 3.915542725631377, 2.4715682378161707, 2.4563494878161705, 0.9110369878161706, 3.4000739756323437, 2.981927612815204, 1.4730838628161707, 3.8887303885440545, 1.4773026128161706, 1.471708862815204, 2.8312557378161767, 1.9301776128161714, 2.45627136281617, 2.9737869878161707, 0.8756273550000004, 3.648430737816171, 3.831902100632349, 4.469448975631375, 2.360536987816174, 1.478040533544055, 2.1648000000000005, 2.98089636281617, 2.97749011281617, 0.6286932378162176, 0.9801932378161702, 1.98822448781617, -0.20211926218382992, 0.918740112816172, 2.467271362816171, 2.946208862816171, 1.8946903522587641, 2.48622448781617, 1.8509276128161738, 2.478114417772942, 3.9101591022587643, 3.6677936585440554, 3.2393304800000005, 1.9736776128161706, 1.9469901128161706, 1.8759242300000005, 2.4508338628161708, 2.4022244878161736, 1.4924425427729422, -2.9121874999999853, 1.960161987815205, 0.9673807378161707, 2.9005057378161716, 1.9810050427729418, 0.6747557378162279, 2.426552612816172, 1.4669432378161704, 2.4563083506323617, 1.1726718750000003, 2.472278364442592, 2.925474487816172, 1.4825213628152043, 1.895958167772946, 1.9430994878161716, 0.9706776128161707, 1.6658000000000004, 1.8427869878161744, 3.9623396006323417, 1.9635682378161712], "episode_lengths": [78, 44, 19, 69, 52, 42, 56, 75, 76, 20, 31, 29, 43, 34, 41, 134, 21, 280, 46, 58, 1280, 26, 29, 50, 116, 40, 17, 306, 50, 27, 18, 21, 63, 46, 554, 37, 1280, 78, 40, 46, 82, 100, 21, 35, 18, 29, 27, 140, 69, 39, 34, 18, 36, 123, 44, 114, 20, 16, 31, 33, 1280, 32, 22, 708, 81, 39, 59, 108, 22, 149, 25, 86, 19, 17, 37, 65, 19, 51, 86, 16, 316, 42, 36, 60, 28, 876, 77, 48, 505, 137, 18, 70, 23, 75, 62, 37, 16, 162, 47, 40], "policy_blue_reward": [-0.01800000000000001, -1.003, -1.0129999999999995, -2.009, -2.0089999999999995, -1.0279999999999978, -2.0069999999999997, 1.6274086050000007, -1.018999999999999, 0.5332836050000005, -1.0069999999999997, -2.0089999999999995, -2.0059999999999993, -1.0129999999999997, -2.0069999999999997, -0.003, -1.0069999999999997, -2.0169999999999995, -0.6580000000000001, -2.017999999999999, -1.0089999999999997, -2.0059999999999993, -2.0069999999999992, -0.04500000000000003, -1.0399999999999985, -2.0129999999999995, -1.0049999999999997, -1.3499999999999668, -1.0099999999999993, -0.013000000000000005, -1.0059999999999996, 1.857234375, -1.009, -1.0169999999999995, 0.9020000000000044, -2.0109999999999992, -2.006, 0.4830625000000053, -1.021999999999998, -0.5489999999999998, -0.02100000000000001, -2.007999999999999, -2.0179999999999985, -1.51, -2.007999999999999], "policy_red_v5_reward": [-0.017000000000000005, -1.0349999999999986], "policy_red_v29_reward": [1.1580500000000014, 0.4786932378152041], "policy_red_v6_reward": [-1.0179999999999993, -1.0309999999999975, -2.0059999999999993], "policy_red_v13_reward": [0.44162500000000005], "policy_red_v24_reward": [0.49369323781617, 1.4946932378152042], "policy_red_v25_reward": [-1.0069999999999997, 0.4476932378161729], "policy_red_v10_reward": [-1.0059999999999996], "policy_red_v4_reward": [-2.009], "policy_red_v16_reward": [-1.021999999999999, -1.5269999999999997], "policy_red_v23_reward": [0.3932836050000005, -1.6560000000000001], "policy_red_v28_reward": [0.4786932378161699, 1.8999971144425922], "policy_red_v14_reward": [-2.008, 0.46693461444259227, 0.3426932378161809], "policy_red_v26_reward": [-0.5730000000000001, -0.5089999999999998, 1.944296875, -2.036999999999998], "policy_red_v22_reward": [0.7416925427729428], "policy_red_v11_reward": [0.46969323781520417], "policy_red_v35_reward": [-1.012999999999999], "policy_red_v9_reward": [0.4193437500000001, -1.512999999999999, -2.0039999999999996], "policy_red_v36_reward": [3.3983807378161726, 0.17705000000000015], "policy_red_v32_reward": [0.5061030335440552, -0.5639999999999998], "policy_red_v3_reward": [-2.0119999999999996, -2.005], "policy_red_v20_reward": [-2.0189999999999992], "policy_red_v8_reward": [-1.015, -0.09981249999999953], "policy_red_v1_reward": [-0.007], "policy_red_v12_reward": [0.48234375000000007, 0.1680500000000006, -0.004, -2.009], "policy_red_v19_reward": [-0.004], "policy_red_v31_reward": [0.47350000000000003, 1.8370937500000002], "policy_red_v37_reward": [1.9805312499999999], "policy_red_v27_reward": [0.39628360500000037], "policy_red_v34_reward": [1.98575, 0.48969323781617], "policy_red_v18_reward": [-1.005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8088401539353385, "mean_inference_ms": 7.748617403315831, "mean_action_processing_ms": 0.29328398820791696, "mean_env_wait_ms": 0.3882458414289549, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10096323490142822, "StateBufferConnector_ms": 0.004129528999328613, "ViewRequirementAgentConnector_ms": 0.1159048080444336}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 568000, "num_agent_steps_trained": 568000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 197.5189318522779, "num_env_steps_trained_throughput_per_sec": 197.5189318522779, "timesteps_total": 284000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 568000, "timers": {"training_iteration_time_ms": 20154.945, "sample_time_ms": 1163.739, "learn_time_ms": 18910.249, "learn_throughput": 211.526, "synch_weights_time_ms": 78.385}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 568000, "num_agent_steps_trained": 568000}, "done": false, "episodes_total": 760, "training_iteration": 71, "trial_id": "a9680_00000", "date": "2023-09-24_03-01-41", "timestamp": 1695538901, "time_this_iter_s": 20.261937618255615, "time_total_s": 1415.3439848423004, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b341f4490>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b341cdcf0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b341cdc60>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1415.3439848423004, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 4.937142857142858, "ram_util_percent": 21.26571428571428}, "win_rate": 0.69, "league_size": 41}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.446168312927087, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.03490242195451477, "policy_loss": -0.06036664050673911, "vf_loss": 0.17850967159029096, "vf_explained_var": 0.7815847820291917, "kl": 0.017797773410855675, "entropy": 1.9947713548938433, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 68640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "sampler_results": {"episode_reward_max": 4.469448975631375, "episode_reward_min": -2.9121874999999853, "episode_reward_mean": 2.0735235158473118, "episode_len_mean": 132.86, "episode_media": {}, "episodes_this_iter": 36, "policy_reward_min": {"red_v22": 0.7416925427729428, "red": -6.178806762183833, "red_v11": 0.46969323781520417, "blue": -2.0179999999999985, "red_v35": -1.012999999999999, "red_v9": -2.0039999999999996, "red_v36": 0.17705000000000015, "red_v26": -2.036999999999998, "red_v32": -0.5639999999999998, "red_v3": -2.0119999999999996, "red_v20": -2.0189999999999992, "red_v8": -1.015, "red_v1": -2.0069999999999997, "red_v12": -2.009, "red_v25": 0.4476932378161729, "red_v24": 1.4946932378152042, "red_v19": -0.004, "red_v31": 0.47350000000000003, "red_v37": 0.4360000000000004, "red_v16": -1.5269999999999997, "red_v28": -0.562, "red_v14": 0.3426932378161809, "red_v27": 0.39628360500000037, "red_v6": -2.0059999999999993, "red_v34": -1.0209999999999988, "red_v18": -1.005, "red_v4": -0.5579999999999999, "red_v17": -0.13971639499999788, "red_v10": -1.0209999999999992, "red_v23": -1.682, "red_v7": -0.5079999999999993}, "policy_reward_max": {"red_v22": 1.9469531249999998, "red": 3.9913338628152037, "red_v11": 1.4886932378161704, "blue": 3.599999999999945, "red_v35": -1.012999999999999, "red_v9": 0.4193437500000001, "red_v36": 3.3983807378161726, "red_v26": 1.944296875, "red_v32": 0.5061030335440552, "red_v3": -0.40100000000000025, "red_v20": -2.0189999999999992, "red_v8": -0.004, "red_v1": -0.007, "red_v12": 0.48234375000000007, "red_v25": 0.4476932378161729, "red_v24": 1.4946932378152042, "red_v19": -0.004, "red_v31": 1.8370937500000002, "red_v37": 1.9805312499999999, "red_v16": -1.5269999999999997, "red_v28": 1.8999971144425922, "red_v14": 0.46693461444259227, "red_v27": 2.9307713628161705, "red_v6": -1.0309999999999975, "red_v34": 1.98575, "red_v18": -1.005, "red_v4": -0.010000000000000002, "red_v17": -0.13971639499999788, "red_v10": -1.0209999999999992, "red_v23": -1.682, "red_v7": -0.5079999999999993}, "policy_reward_mean": {"red_v22": 1.3443228338864714, "red": 2.5527591219136907, "red_v11": 0.9791932378156872, "blue": -1.0592786458333332, "red_v35": -1.012999999999999, "red_v9": -1.0325520833333328, "red_v36": 1.7877153689080862, "red_v26": -0.10691328124999949, "red_v32": 0.11393209045340942, "red_v3": -1.4726666666666663, "red_v20": -2.0189999999999992, "red_v8": -0.37293749999999976, "red_v1": -1.048999999999996, "red_v12": -0.34065156249999984, "red_v25": 0.4476932378161729, "red_v24": 1.4946932378152042, "red_v19": -0.004, "red_v31": 0.9364289959387234, "red_v37": 1.2082656250000001, "red_v16": -1.5269999999999997, "red_v28": 0.6689985572212961, "red_v14": 0.4048139261293866, "red_v27": 1.6635274839080854, "red_v6": -1.5184999999999984, "red_v34": 0.4848144126053903, "red_v18": -1.005, "red_v4": -0.284, "red_v17": -0.13971639499999788, "red_v10": -1.0209999999999992, "red_v23": -1.682, "red_v7": -0.5079999999999993}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.9793857805891693, 3.915542725631377, 2.4715682378161707, 2.4563494878161705, 0.9110369878161706, 3.4000739756323437, 2.981927612815204, 1.4730838628161707, 3.8887303885440545, 1.4773026128161706, 1.471708862815204, 2.8312557378161767, 1.9301776128161714, 2.45627136281617, 2.9737869878161707, 0.8756273550000004, 3.648430737816171, 3.831902100632349, 4.469448975631375, 2.360536987816174, 1.478040533544055, 2.1648000000000005, 2.98089636281617, 2.97749011281617, 0.6286932378162176, 0.9801932378161702, 1.98822448781617, -0.20211926218382992, 0.918740112816172, 2.467271362816171, 2.946208862816171, 1.8946903522587641, 2.48622448781617, 1.8509276128161738, 2.478114417772942, 3.9101591022587643, 3.6677936585440554, 3.2393304800000005, 1.9736776128161706, 1.9469901128161706, 1.8759242300000005, 2.4508338628161708, 2.4022244878161736, 1.4924425427729422, -2.9121874999999853, 1.960161987815205, 0.9673807378161707, 2.9005057378161716, 1.9810050427729418, 0.6747557378162279, 2.426552612816172, 1.4669432378161704, 2.4563083506323617, 1.1726718750000003, 2.472278364442592, 2.925474487816172, 1.4825213628152043, 1.895958167772946, 1.9430994878161716, 0.9706776128161707, 1.6658000000000004, 1.8427869878161744, 3.9623396006323417, 1.9635682378161712, 1.984333862815204, 1.48041198781617, 1.4851151128161701, 1.46767761281617, 2.9783374085440553, 1.4831151128161704, 1.939646362816172, 2.917677612816171, 1.9787088628161702, 2.307867467816175, 2.4728651128161703, 3.656649487816171, 2.4204744878161737, 2.482926917772942, 2.4618963628161707, -0.5352812499999999, 0.9366932378161699, 1.9760057378161702, 1.483926917772942, 4.458527100632342, 1.90809375, 2.4643807378161706, -2.578806762183821, 2.4800057378161697, 0.9730838628161698, 0.7566932378162139, 0.5501307378161729, 0.963693237816219, 2.92759948781617, 2.9788963628161698, 2.413333862816172, 1.9690838628161704, 3.95298022563234, 0.8670023550000001, 2.0898213628161733, 3.7782614756323523], "episode_lengths": [1280, 78, 40, 46, 82, 100, 21, 35, 18, 29, 27, 140, 69, 39, 34, 18, 36, 123, 44, 114, 20, 16, 31, 33, 1280, 32, 22, 708, 81, 39, 59, 108, 22, 149, 25, 86, 19, 17, 37, 65, 19, 51, 86, 16, 316, 42, 36, 60, 28, 876, 77, 48, 505, 137, 18, 70, 23, 75, 62, 37, 16, 162, 47, 40, 19, 26, 25, 37, 21, 25, 47, 37, 27, 67, 41, 30, 70, 21, 31, 26, 64, 28, 21, 51, 34, 36, 928, 28, 35, 1280, 372, 1280, 30, 31, 83, 35, 66, 26, 71, 168], "policy_red_v22_reward": [0.7416925427729428, 1.9469531249999998], "policy_red_v11_reward": [0.46969323781520417, 1.4886932378161704], "policy_blue_reward": [-1.0089999999999997, -2.0059999999999993, -2.0069999999999992, -0.04500000000000003, -1.0399999999999985, -2.0129999999999995, -1.0049999999999997, -1.3499999999999668, -1.0099999999999993, -0.013000000000000005, -1.0059999999999996, 1.857234375, -1.009, -1.0169999999999995, 0.9020000000000044, -2.0109999999999992, -2.006, 0.4830625000000053, -1.021999999999998, -0.5489999999999998, -0.02100000000000001, -2.007999999999999, -2.0179999999999985, -1.51, -2.007999999999999, -2.0069999999999997, -2.008, -2.0039999999999996, -2.0149999999999997, -2.0089999999999995, -1.0059999999999993, -1.0039999999999998, -1.505, -2.0069999999999997, -2.005, -0.012, -1.013, 3.599999999999945, -1.0079999999999998, -1.51, -1.0279999999999987, -1.5079999999999998], "policy_red_v35_reward": [-1.012999999999999], "policy_red_v9_reward": [0.4193437500000001, -1.512999999999999, -2.0039999999999996], "policy_red_v36_reward": [3.3983807378161726, 0.17705000000000015], "policy_red_v26_reward": [-0.5089999999999998, 1.944296875, -2.036999999999998, 0.17405000000000004], "policy_red_v32_reward": [0.5061030335440552, -0.5639999999999998, 0.39969323781617294], "policy_red_v3_reward": [-2.0119999999999996, -2.005, -0.40100000000000025], "policy_red_v20_reward": [-2.0189999999999992], "policy_red_v8_reward": [-1.015, -0.09981249999999953, -0.004], "policy_red_v1_reward": [-0.007, -2.0069999999999997, -1.1329999999999882], "policy_red_v12_reward": [0.48234375000000007, 0.1680500000000006, -0.004, -2.009], "policy_red_v25_reward": [0.4476932378161729], "policy_red_v24_reward": [1.4946932378152042], "policy_red_v19_reward": [-0.004], "policy_red_v31_reward": [0.47350000000000003, 1.8370937500000002, 0.4986932378161699], "policy_red_v37_reward": [1.9805312499999999, 0.4360000000000004], "policy_red_v16_reward": [-1.5269999999999997], "policy_red_v28_reward": [1.8999971144425922, -0.562], "policy_red_v14_reward": [0.46693461444259227, 0.3426932378161809], "policy_red_v27_reward": [0.39628360500000037, 2.9307713628161705], "policy_red_v6_reward": [-1.0309999999999975, -2.0059999999999993], "policy_red_v34_reward": [1.98575, 0.48969323781617, -1.0209999999999988], "policy_red_v18_reward": [-1.005], "policy_red_v4_reward": [-0.010000000000000002, -0.5579999999999999], "policy_red_v17_reward": [-0.13971639499999788], "policy_red_v10_reward": [-1.0209999999999992], "policy_red_v23_reward": [-1.682], "policy_red_v7_reward": [-0.5079999999999993]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8085895327793047, "mean_inference_ms": 7.738398526806464, "mean_action_processing_ms": 0.29221879798845385, "mean_env_wait_ms": 0.3875191486940793, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09840500354766846, "StateBufferConnector_ms": 0.004072070121765137, "ViewRequirementAgentConnector_ms": 0.11391007900238037}}, "episode_reward_max": 4.469448975631375, "episode_reward_min": -2.9121874999999853, "episode_reward_mean": 2.0735235158473118, "episode_len_mean": 132.86, "episodes_this_iter": 36, "policy_reward_min": {"red_v22": 0.7416925427729428, "red": -6.178806762183833, "red_v11": 0.46969323781520417, "blue": -2.0179999999999985, "red_v35": -1.012999999999999, "red_v9": -2.0039999999999996, "red_v36": 0.17705000000000015, "red_v26": -2.036999999999998, "red_v32": -0.5639999999999998, "red_v3": -2.0119999999999996, "red_v20": -2.0189999999999992, "red_v8": -1.015, "red_v1": -2.0069999999999997, "red_v12": -2.009, "red_v25": 0.4476932378161729, "red_v24": 1.4946932378152042, "red_v19": -0.004, "red_v31": 0.47350000000000003, "red_v37": 0.4360000000000004, "red_v16": -1.5269999999999997, "red_v28": -0.562, "red_v14": 0.3426932378161809, "red_v27": 0.39628360500000037, "red_v6": -2.0059999999999993, "red_v34": -1.0209999999999988, "red_v18": -1.005, "red_v4": -0.5579999999999999, "red_v17": -0.13971639499999788, "red_v10": -1.0209999999999992, "red_v23": -1.682, "red_v7": -0.5079999999999993}, "policy_reward_max": {"red_v22": 1.9469531249999998, "red": 3.9913338628152037, "red_v11": 1.4886932378161704, "blue": 3.599999999999945, "red_v35": -1.012999999999999, "red_v9": 0.4193437500000001, "red_v36": 3.3983807378161726, "red_v26": 1.944296875, "red_v32": 0.5061030335440552, "red_v3": -0.40100000000000025, "red_v20": -2.0189999999999992, "red_v8": -0.004, "red_v1": -0.007, "red_v12": 0.48234375000000007, "red_v25": 0.4476932378161729, "red_v24": 1.4946932378152042, "red_v19": -0.004, "red_v31": 1.8370937500000002, "red_v37": 1.9805312499999999, "red_v16": -1.5269999999999997, "red_v28": 1.8999971144425922, "red_v14": 0.46693461444259227, "red_v27": 2.9307713628161705, "red_v6": -1.0309999999999975, "red_v34": 1.98575, "red_v18": -1.005, "red_v4": -0.010000000000000002, "red_v17": -0.13971639499999788, "red_v10": -1.0209999999999992, "red_v23": -1.682, "red_v7": -0.5079999999999993}, "policy_reward_mean": {"red_v22": 1.3443228338864714, "red": 2.5527591219136907, "red_v11": 0.9791932378156872, "blue": -1.0592786458333332, "red_v35": -1.012999999999999, "red_v9": -1.0325520833333328, "red_v36": 1.7877153689080862, "red_v26": -0.10691328124999949, "red_v32": 0.11393209045340942, "red_v3": -1.4726666666666663, "red_v20": -2.0189999999999992, "red_v8": -0.37293749999999976, "red_v1": -1.048999999999996, "red_v12": -0.34065156249999984, "red_v25": 0.4476932378161729, "red_v24": 1.4946932378152042, "red_v19": -0.004, "red_v31": 0.9364289959387234, "red_v37": 1.2082656250000001, "red_v16": -1.5269999999999997, "red_v28": 0.6689985572212961, "red_v14": 0.4048139261293866, "red_v27": 1.6635274839080854, "red_v6": -1.5184999999999984, "red_v34": 0.4848144126053903, "red_v18": -1.005, "red_v4": -0.284, "red_v17": -0.13971639499999788, "red_v10": -1.0209999999999992, "red_v23": -1.682, "red_v7": -0.5079999999999993}, "hist_stats": {"episode_reward": [1.9793857805891693, 3.915542725631377, 2.4715682378161707, 2.4563494878161705, 0.9110369878161706, 3.4000739756323437, 2.981927612815204, 1.4730838628161707, 3.8887303885440545, 1.4773026128161706, 1.471708862815204, 2.8312557378161767, 1.9301776128161714, 2.45627136281617, 2.9737869878161707, 0.8756273550000004, 3.648430737816171, 3.831902100632349, 4.469448975631375, 2.360536987816174, 1.478040533544055, 2.1648000000000005, 2.98089636281617, 2.97749011281617, 0.6286932378162176, 0.9801932378161702, 1.98822448781617, -0.20211926218382992, 0.918740112816172, 2.467271362816171, 2.946208862816171, 1.8946903522587641, 2.48622448781617, 1.8509276128161738, 2.478114417772942, 3.9101591022587643, 3.6677936585440554, 3.2393304800000005, 1.9736776128161706, 1.9469901128161706, 1.8759242300000005, 2.4508338628161708, 2.4022244878161736, 1.4924425427729422, -2.9121874999999853, 1.960161987815205, 0.9673807378161707, 2.9005057378161716, 1.9810050427729418, 0.6747557378162279, 2.426552612816172, 1.4669432378161704, 2.4563083506323617, 1.1726718750000003, 2.472278364442592, 2.925474487816172, 1.4825213628152043, 1.895958167772946, 1.9430994878161716, 0.9706776128161707, 1.6658000000000004, 1.8427869878161744, 3.9623396006323417, 1.9635682378161712, 1.984333862815204, 1.48041198781617, 1.4851151128161701, 1.46767761281617, 2.9783374085440553, 1.4831151128161704, 1.939646362816172, 2.917677612816171, 1.9787088628161702, 2.307867467816175, 2.4728651128161703, 3.656649487816171, 2.4204744878161737, 2.482926917772942, 2.4618963628161707, -0.5352812499999999, 0.9366932378161699, 1.9760057378161702, 1.483926917772942, 4.458527100632342, 1.90809375, 2.4643807378161706, -2.578806762183821, 2.4800057378161697, 0.9730838628161698, 0.7566932378162139, 0.5501307378161729, 0.963693237816219, 2.92759948781617, 2.9788963628161698, 2.413333862816172, 1.9690838628161704, 3.95298022563234, 0.8670023550000001, 2.0898213628161733, 3.7782614756323523], "episode_lengths": [1280, 78, 40, 46, 82, 100, 21, 35, 18, 29, 27, 140, 69, 39, 34, 18, 36, 123, 44, 114, 20, 16, 31, 33, 1280, 32, 22, 708, 81, 39, 59, 108, 22, 149, 25, 86, 19, 17, 37, 65, 19, 51, 86, 16, 316, 42, 36, 60, 28, 876, 77, 48, 505, 137, 18, 70, 23, 75, 62, 37, 16, 162, 47, 40, 19, 26, 25, 37, 21, 25, 47, 37, 27, 67, 41, 30, 70, 21, 31, 26, 64, 28, 21, 51, 34, 36, 928, 28, 35, 1280, 372, 1280, 30, 31, 83, 35, 66, 26, 71, 168], "policy_red_v22_reward": [0.7416925427729428, 1.9469531249999998], "policy_red_v11_reward": [0.46969323781520417, 1.4886932378161704], "policy_blue_reward": [-1.0089999999999997, -2.0059999999999993, -2.0069999999999992, -0.04500000000000003, -1.0399999999999985, -2.0129999999999995, -1.0049999999999997, -1.3499999999999668, -1.0099999999999993, -0.013000000000000005, -1.0059999999999996, 1.857234375, -1.009, -1.0169999999999995, 0.9020000000000044, -2.0109999999999992, -2.006, 0.4830625000000053, -1.021999999999998, -0.5489999999999998, -0.02100000000000001, -2.007999999999999, -2.0179999999999985, -1.51, -2.007999999999999, -2.0069999999999997, -2.008, -2.0039999999999996, -2.0149999999999997, -2.0089999999999995, -1.0059999999999993, -1.0039999999999998, -1.505, -2.0069999999999997, -2.005, -0.012, -1.013, 3.599999999999945, -1.0079999999999998, -1.51, -1.0279999999999987, -1.5079999999999998], "policy_red_v35_reward": [-1.012999999999999], "policy_red_v9_reward": [0.4193437500000001, -1.512999999999999, -2.0039999999999996], "policy_red_v36_reward": [3.3983807378161726, 0.17705000000000015], "policy_red_v26_reward": [-0.5089999999999998, 1.944296875, -2.036999999999998, 0.17405000000000004], "policy_red_v32_reward": [0.5061030335440552, -0.5639999999999998, 0.39969323781617294], "policy_red_v3_reward": [-2.0119999999999996, -2.005, -0.40100000000000025], "policy_red_v20_reward": [-2.0189999999999992], "policy_red_v8_reward": [-1.015, -0.09981249999999953, -0.004], "policy_red_v1_reward": [-0.007, -2.0069999999999997, -1.1329999999999882], "policy_red_v12_reward": [0.48234375000000007, 0.1680500000000006, -0.004, -2.009], "policy_red_v25_reward": [0.4476932378161729], "policy_red_v24_reward": [1.4946932378152042], "policy_red_v19_reward": [-0.004], "policy_red_v31_reward": [0.47350000000000003, 1.8370937500000002, 0.4986932378161699], "policy_red_v37_reward": [1.9805312499999999, 0.4360000000000004], "policy_red_v16_reward": [-1.5269999999999997], "policy_red_v28_reward": [1.8999971144425922, -0.562], "policy_red_v14_reward": [0.46693461444259227, 0.3426932378161809], "policy_red_v27_reward": [0.39628360500000037, 2.9307713628161705], "policy_red_v6_reward": [-1.0309999999999975, -2.0059999999999993], "policy_red_v34_reward": [1.98575, 0.48969323781617, -1.0209999999999988], "policy_red_v18_reward": [-1.005], "policy_red_v4_reward": [-0.010000000000000002, -0.5579999999999999], "policy_red_v17_reward": [-0.13971639499999788], "policy_red_v10_reward": [-1.0209999999999992], "policy_red_v23_reward": [-1.682], "policy_red_v7_reward": [-0.5079999999999993]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8085895327793047, "mean_inference_ms": 7.738398526806464, "mean_action_processing_ms": 0.29221879798845385, "mean_env_wait_ms": 0.3875191486940793, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09840500354766846, "StateBufferConnector_ms": 0.004072070121765137, "ViewRequirementAgentConnector_ms": 0.11391007900238037}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.7363774897038, "num_env_steps_trained_throughput_per_sec": 201.7363774897038, "timesteps_total": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 20161.197, "sample_time_ms": 1167.826, "learn_time_ms": 18912.322, "learn_throughput": 211.502, "synch_weights_time_ms": 78.404}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "episodes_total": 796, "training_iteration": 72, "trial_id": "a9680_00000", "date": "2023-09-24_03-02-03", "timestamp": 1695538923, "time_this_iter_s": 19.837169647216797, "time_total_s": 1435.1811544895172, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b341f5fc0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b342cc8b0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b342ccd30>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1435.1811544895172, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 5.30967741935484, "ram_util_percent": 21.380645161290314}, "win_rate": 0.69, "league_size": 42}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.413809203232328, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.022555813088304906, "policy_loss": -0.061417782702483235, "vf_loss": 0.15660825006198137, "vf_explained_var": 0.7757690398643414, "kl": 0.017010314828318465, "entropy": 1.9851708276818196, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 69600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 584000, "num_agent_steps_trained": 584000}, "sampler_results": {"episode_reward_max": 4.458527100632342, "episode_reward_min": -2.9121874999999853, "episode_reward_mean": 2.0473892206040514, "episode_len_mean": 105.16, "episode_media": {}, "episodes_this_iter": 35, "policy_reward_min": {"red_v14": 0.3426932378161809, "red": -6.178806762183833, "red_v36": 0.17705000000000015, "red_v27": 0.39628360500000037, "red_v3": -2.005, "red_v26": -2.036999999999998, "red_v12": -2.009, "blue": -2.0179999999999985, "red_v6": -2.0059999999999993, "red_v34": -1.0209999999999988, "red_v9": -2.0039999999999996, "red_v32": -0.5639999999999998, "red_v18": -1.005, "red_v31": 0.4986932378161699, "red_v4": -0.5579999999999999, "red_v1": -2.0069999999999997, "red_v22": -2.0089999999999995, "red_v28": -0.562, "red_v17": -0.13971639499999788, "red_v10": -1.0209999999999992, "red_v37": 0.4360000000000004, "red_v11": 1.4886932378161704, "red_v23": -1.682, "red_v8": -0.5359999999999998, "red_v7": -0.5079999999999993, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": -2.0069999999999997, "red_v25": -1.564}, "policy_reward_max": {"red_v14": 0.46693461444259227, "red": 3.9913338628152037, "red_v36": 0.17705000000000015, "red_v27": 2.9307713628161705, "red_v3": -0.40100000000000025, "red_v26": 1.944296875, "red_v12": -2.009, "blue": 3.599999999999945, "red_v6": -1.0309999999999975, "red_v34": 1.98575, "red_v9": -0.5169999999999999, "red_v32": 0.39969323781617294, "red_v18": -1.005, "red_v31": 1.8370937500000002, "red_v4": -0.010000000000000002, "red_v1": -0.595, "red_v22": 1.9469531249999998, "red_v28": -0.5549999999999998, "red_v17": 1.3902836050000003, "red_v10": 0.49869323781520397, "red_v37": 0.4360000000000004, "red_v11": 1.4886932378161704, "red_v23": -1.682, "red_v8": -0.004, "red_v7": -0.5079999999999993, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": -0.16799999999999982, "red_v25": -1.564}, "policy_reward_mean": {"red_v14": 0.4048139261293866, "red": 2.79895084478434, "red_v36": 0.17705000000000015, "red_v27": 1.6635274839080854, "red_v3": -1.203, "red_v26": 0.2483796875000005, "red_v12": -2.009, "blue": -1.2087946428571434, "red_v6": -1.5184999999999984, "red_v34": 0.4848144126053903, "red_v9": -1.3446666666666662, "red_v32": -0.08215338109191345, "red_v18": -1.005, "red_v31": 1.167893493908085, "red_v4": -0.284, "red_v1": -1.2449999999999959, "red_v22": -0.031023437499999806, "red_v28": -0.5585, "red_v17": 0.6252836050000012, "red_v10": -0.6400766905461984, "red_v37": 0.4360000000000004, "red_v11": 1.4886932378161704, "red_v23": -1.682, "red_v8": -0.2699999999999999, "red_v7": -0.5079999999999993, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": -1.0874999999999997, "red_v25": -1.564}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.9101591022587643, 3.6677936585440554, 3.2393304800000005, 1.9736776128161706, 1.9469901128161706, 1.8759242300000005, 2.4508338628161708, 2.4022244878161736, 1.4924425427729422, -2.9121874999999853, 1.960161987815205, 0.9673807378161707, 2.9005057378161716, 1.9810050427729418, 0.6747557378162279, 2.426552612816172, 1.4669432378161704, 2.4563083506323617, 1.1726718750000003, 2.472278364442592, 2.925474487816172, 1.4825213628152043, 1.895958167772946, 1.9430994878161716, 0.9706776128161707, 1.6658000000000004, 1.8427869878161744, 3.9623396006323417, 1.9635682378161712, 1.984333862815204, 1.48041198781617, 1.4851151128161701, 1.46767761281617, 2.9783374085440553, 1.4831151128161704, 1.939646362816172, 2.917677612816171, 1.9787088628161702, 2.307867467816175, 2.4728651128161703, 3.656649487816171, 2.4204744878161737, 2.482926917772942, 2.4618963628161707, -0.5352812499999999, 0.9366932378161699, 1.9760057378161702, 1.483926917772942, 4.458527100632342, 1.90809375, 2.4643807378161706, -2.578806762183821, 2.4800057378161697, 0.9730838628161698, 0.7566932378162139, 0.5501307378161729, 0.963693237816219, 2.92759948781617, 2.9788963628161698, 2.413333862816172, 1.9690838628161704, 3.95298022563234, 0.8670023550000001, 2.0898213628161733, 3.7782614756323523, 2.7876776128161795, 0.9808182378161706, 4.37739871781617, 2.9249901128161726, 1.9710838628161704, 2.4514276128161714, 1.4438338628161715, 2.4722783644425923, 0.18610937499999958, 2.4811151128161697, 1.4158651128161708, 3.909917725632344, 1.4787088628161702, 1.2642088628161718, 0.9660526128161705, 2.959865112816171, 1.4675752394425925, 1.1639093750000002, 3.983698975631374, 1.97530261281617, 1.4699744878161702, 1.7854086050000015, 2.3545057378161753, 2.4546221144425933, 2.4537244878161713, 2.374583862816171, 3.289021362816172, 1.4794119878161702, 1.9836342835440548, 2.65076875, 2.93411511281617, 2.4456151128161716, 1.483223792772942, 2.4569432378161706, 2.951724487816171], "episode_lengths": [86, 19, 17, 37, 65, 19, 51, 86, 16, 316, 42, 36, 60, 28, 876, 77, 48, 505, 137, 18, 70, 23, 75, 62, 37, 16, 162, 47, 40, 19, 26, 25, 37, 21, 25, 47, 37, 27, 67, 41, 30, 70, 21, 31, 26, 64, 28, 21, 51, 34, 36, 928, 28, 35, 1280, 372, 1280, 30, 31, 83, 35, 66, 26, 71, 168, 165, 24, 25, 65, 35, 53, 51, 18, 445, 25, 41, 86, 27, 251, 45, 41, 19, 13, 28, 29, 38, 88, 124, 36, 54, 67, 55, 26, 22, 26, 25, 57, 22, 48, 54], "policy_red_v14_reward": [0.46693461444259227, 0.3426932378161809], "policy_red_v36_reward": [0.17705000000000015], "policy_red_v27_reward": [0.39628360500000037, 2.9307713628161705], "policy_red_v3_reward": [-2.005, -0.40100000000000025], "policy_red_v26_reward": [1.944296875, -2.036999999999998, 0.17405000000000004, 0.9121718750000001], "policy_red_v12_reward": [-2.009], "policy_blue_reward": [-1.0169999999999995, 0.9020000000000044, -2.0109999999999992, -2.006, 0.4830625000000053, -1.021999999999998, -0.5489999999999998, -0.02100000000000001, -2.007999999999999, -2.0179999999999985, -1.51, -2.007999999999999, -2.0069999999999997, -2.008, -2.0039999999999996, -2.0149999999999997, -2.0089999999999995, -1.0059999999999993, -1.0039999999999998, -1.505, -2.0069999999999997, -2.005, -0.012, -1.013, 3.599999999999945, -1.0079999999999998, -1.51, -1.0279999999999987, -1.5079999999999998, -1.5099999999999998, -2.0169999999999986, -1.005, -1.133, -1.0069999999999997, -2.008, -1.0579999999999998, -0.011000000000000003, -2.009, -2.0089999999999995, -2.0119999999999996, -0.5309999999999999, -1.0349999999999975, -1.0069999999999995, -1.0149999999999988, -2.008, -2.002, -0.006, -2.005, -1.0089999999999997], "policy_red_v6_reward": [-1.0309999999999975, -2.0059999999999993], "policy_red_v34_reward": [1.98575, 0.48969323781617, -1.0209999999999988], "policy_red_v9_reward": [-1.512999999999999, -2.0039999999999996, -0.5169999999999999], "policy_red_v32_reward": [-0.5639999999999998, 0.39969323781617294], "policy_red_v18_reward": [-1.005], "policy_red_v31_reward": [1.8370937500000002, 0.4986932378161699], "policy_red_v4_reward": [-0.010000000000000002, -0.5579999999999999], "policy_red_v1_reward": [-2.0069999999999997, -1.1329999999999882, -0.595], "policy_red_v22_reward": [1.9469531249999998, -2.0089999999999995], "policy_red_v28_reward": [-0.562, -0.5549999999999998], "policy_red_v17_reward": [-0.13971639499999788, 1.3902836050000003], "policy_red_v10_reward": [-1.0209999999999992, -1.0179999999999987, 0.49869323781520397, -1.0199999999999998], "policy_red_v37_reward": [0.4360000000000004], "policy_red_v11_reward": [1.4886932378161704], "policy_red_v23_reward": [-1.682], "policy_red_v8_reward": [-0.004, -0.5359999999999998], "policy_red_v7_reward": [-0.5079999999999993], "policy_red_v16_reward": [0.4746932378161717], "policy_red_v5_reward": [-1.5059999999999998], "policy_red_v2_reward": [-2.0069999999999997, -0.16799999999999982], "policy_red_v25_reward": [-1.564]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8092712435829094, "mean_inference_ms": 7.730089357939757, "mean_action_processing_ms": 0.29208466310210635, "mean_env_wait_ms": 0.3875478573716928, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10000205039978027, "StateBufferConnector_ms": 0.004204750061035156, "ViewRequirementAgentConnector_ms": 0.11704361438751221}}, "episode_reward_max": 4.458527100632342, "episode_reward_min": -2.9121874999999853, "episode_reward_mean": 2.0473892206040514, "episode_len_mean": 105.16, "episodes_this_iter": 35, "policy_reward_min": {"red_v14": 0.3426932378161809, "red": -6.178806762183833, "red_v36": 0.17705000000000015, "red_v27": 0.39628360500000037, "red_v3": -2.005, "red_v26": -2.036999999999998, "red_v12": -2.009, "blue": -2.0179999999999985, "red_v6": -2.0059999999999993, "red_v34": -1.0209999999999988, "red_v9": -2.0039999999999996, "red_v32": -0.5639999999999998, "red_v18": -1.005, "red_v31": 0.4986932378161699, "red_v4": -0.5579999999999999, "red_v1": -2.0069999999999997, "red_v22": -2.0089999999999995, "red_v28": -0.562, "red_v17": -0.13971639499999788, "red_v10": -1.0209999999999992, "red_v37": 0.4360000000000004, "red_v11": 1.4886932378161704, "red_v23": -1.682, "red_v8": -0.5359999999999998, "red_v7": -0.5079999999999993, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": -2.0069999999999997, "red_v25": -1.564}, "policy_reward_max": {"red_v14": 0.46693461444259227, "red": 3.9913338628152037, "red_v36": 0.17705000000000015, "red_v27": 2.9307713628161705, "red_v3": -0.40100000000000025, "red_v26": 1.944296875, "red_v12": -2.009, "blue": 3.599999999999945, "red_v6": -1.0309999999999975, "red_v34": 1.98575, "red_v9": -0.5169999999999999, "red_v32": 0.39969323781617294, "red_v18": -1.005, "red_v31": 1.8370937500000002, "red_v4": -0.010000000000000002, "red_v1": -0.595, "red_v22": 1.9469531249999998, "red_v28": -0.5549999999999998, "red_v17": 1.3902836050000003, "red_v10": 0.49869323781520397, "red_v37": 0.4360000000000004, "red_v11": 1.4886932378161704, "red_v23": -1.682, "red_v8": -0.004, "red_v7": -0.5079999999999993, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": -0.16799999999999982, "red_v25": -1.564}, "policy_reward_mean": {"red_v14": 0.4048139261293866, "red": 2.79895084478434, "red_v36": 0.17705000000000015, "red_v27": 1.6635274839080854, "red_v3": -1.203, "red_v26": 0.2483796875000005, "red_v12": -2.009, "blue": -1.2087946428571434, "red_v6": -1.5184999999999984, "red_v34": 0.4848144126053903, "red_v9": -1.3446666666666662, "red_v32": -0.08215338109191345, "red_v18": -1.005, "red_v31": 1.167893493908085, "red_v4": -0.284, "red_v1": -1.2449999999999959, "red_v22": -0.031023437499999806, "red_v28": -0.5585, "red_v17": 0.6252836050000012, "red_v10": -0.6400766905461984, "red_v37": 0.4360000000000004, "red_v11": 1.4886932378161704, "red_v23": -1.682, "red_v8": -0.2699999999999999, "red_v7": -0.5079999999999993, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": -1.0874999999999997, "red_v25": -1.564}, "hist_stats": {"episode_reward": [3.9101591022587643, 3.6677936585440554, 3.2393304800000005, 1.9736776128161706, 1.9469901128161706, 1.8759242300000005, 2.4508338628161708, 2.4022244878161736, 1.4924425427729422, -2.9121874999999853, 1.960161987815205, 0.9673807378161707, 2.9005057378161716, 1.9810050427729418, 0.6747557378162279, 2.426552612816172, 1.4669432378161704, 2.4563083506323617, 1.1726718750000003, 2.472278364442592, 2.925474487816172, 1.4825213628152043, 1.895958167772946, 1.9430994878161716, 0.9706776128161707, 1.6658000000000004, 1.8427869878161744, 3.9623396006323417, 1.9635682378161712, 1.984333862815204, 1.48041198781617, 1.4851151128161701, 1.46767761281617, 2.9783374085440553, 1.4831151128161704, 1.939646362816172, 2.917677612816171, 1.9787088628161702, 2.307867467816175, 2.4728651128161703, 3.656649487816171, 2.4204744878161737, 2.482926917772942, 2.4618963628161707, -0.5352812499999999, 0.9366932378161699, 1.9760057378161702, 1.483926917772942, 4.458527100632342, 1.90809375, 2.4643807378161706, -2.578806762183821, 2.4800057378161697, 0.9730838628161698, 0.7566932378162139, 0.5501307378161729, 0.963693237816219, 2.92759948781617, 2.9788963628161698, 2.413333862816172, 1.9690838628161704, 3.95298022563234, 0.8670023550000001, 2.0898213628161733, 3.7782614756323523, 2.7876776128161795, 0.9808182378161706, 4.37739871781617, 2.9249901128161726, 1.9710838628161704, 2.4514276128161714, 1.4438338628161715, 2.4722783644425923, 0.18610937499999958, 2.4811151128161697, 1.4158651128161708, 3.909917725632344, 1.4787088628161702, 1.2642088628161718, 0.9660526128161705, 2.959865112816171, 1.4675752394425925, 1.1639093750000002, 3.983698975631374, 1.97530261281617, 1.4699744878161702, 1.7854086050000015, 2.3545057378161753, 2.4546221144425933, 2.4537244878161713, 2.374583862816171, 3.289021362816172, 1.4794119878161702, 1.9836342835440548, 2.65076875, 2.93411511281617, 2.4456151128161716, 1.483223792772942, 2.4569432378161706, 2.951724487816171], "episode_lengths": [86, 19, 17, 37, 65, 19, 51, 86, 16, 316, 42, 36, 60, 28, 876, 77, 48, 505, 137, 18, 70, 23, 75, 62, 37, 16, 162, 47, 40, 19, 26, 25, 37, 21, 25, 47, 37, 27, 67, 41, 30, 70, 21, 31, 26, 64, 28, 21, 51, 34, 36, 928, 28, 35, 1280, 372, 1280, 30, 31, 83, 35, 66, 26, 71, 168, 165, 24, 25, 65, 35, 53, 51, 18, 445, 25, 41, 86, 27, 251, 45, 41, 19, 13, 28, 29, 38, 88, 124, 36, 54, 67, 55, 26, 22, 26, 25, 57, 22, 48, 54], "policy_red_v14_reward": [0.46693461444259227, 0.3426932378161809], "policy_red_v36_reward": [0.17705000000000015], "policy_red_v27_reward": [0.39628360500000037, 2.9307713628161705], "policy_red_v3_reward": [-2.005, -0.40100000000000025], "policy_red_v26_reward": [1.944296875, -2.036999999999998, 0.17405000000000004, 0.9121718750000001], "policy_red_v12_reward": [-2.009], "policy_blue_reward": [-1.0169999999999995, 0.9020000000000044, -2.0109999999999992, -2.006, 0.4830625000000053, -1.021999999999998, -0.5489999999999998, -0.02100000000000001, -2.007999999999999, -2.0179999999999985, -1.51, -2.007999999999999, -2.0069999999999997, -2.008, -2.0039999999999996, -2.0149999999999997, -2.0089999999999995, -1.0059999999999993, -1.0039999999999998, -1.505, -2.0069999999999997, -2.005, -0.012, -1.013, 3.599999999999945, -1.0079999999999998, -1.51, -1.0279999999999987, -1.5079999999999998, -1.5099999999999998, -2.0169999999999986, -1.005, -1.133, -1.0069999999999997, -2.008, -1.0579999999999998, -0.011000000000000003, -2.009, -2.0089999999999995, -2.0119999999999996, -0.5309999999999999, -1.0349999999999975, -1.0069999999999995, -1.0149999999999988, -2.008, -2.002, -0.006, -2.005, -1.0089999999999997], "policy_red_v6_reward": [-1.0309999999999975, -2.0059999999999993], "policy_red_v34_reward": [1.98575, 0.48969323781617, -1.0209999999999988], "policy_red_v9_reward": [-1.512999999999999, -2.0039999999999996, -0.5169999999999999], "policy_red_v32_reward": [-0.5639999999999998, 0.39969323781617294], "policy_red_v18_reward": [-1.005], "policy_red_v31_reward": [1.8370937500000002, 0.4986932378161699], "policy_red_v4_reward": [-0.010000000000000002, -0.5579999999999999], "policy_red_v1_reward": [-2.0069999999999997, -1.1329999999999882, -0.595], "policy_red_v22_reward": [1.9469531249999998, -2.0089999999999995], "policy_red_v28_reward": [-0.562, -0.5549999999999998], "policy_red_v17_reward": [-0.13971639499999788, 1.3902836050000003], "policy_red_v10_reward": [-1.0209999999999992, -1.0179999999999987, 0.49869323781520397, -1.0199999999999998], "policy_red_v37_reward": [0.4360000000000004], "policy_red_v11_reward": [1.4886932378161704], "policy_red_v23_reward": [-1.682], "policy_red_v8_reward": [-0.004, -0.5359999999999998], "policy_red_v7_reward": [-0.5079999999999993], "policy_red_v16_reward": [0.4746932378161717], "policy_red_v5_reward": [-1.5059999999999998], "policy_red_v2_reward": [-2.0069999999999997, -0.16799999999999982], "policy_red_v25_reward": [-1.564]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8092712435829094, "mean_inference_ms": 7.730089357939757, "mean_action_processing_ms": 0.29208466310210635, "mean_env_wait_ms": 0.3875478573716928, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10000205039978027, "StateBufferConnector_ms": 0.004204750061035156, "ViewRequirementAgentConnector_ms": 0.11704361438751221}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 584000, "num_agent_steps_trained": 584000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 198.17895060700425, "num_env_steps_trained_throughput_per_sec": 198.17895060700425, "timesteps_total": 292000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 584000, "timers": {"training_iteration_time_ms": 20148.193, "sample_time_ms": 1162.921, "learn_time_ms": 18903.582, "learn_throughput": 211.6, "synch_weights_time_ms": 79.014}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 584000, "num_agent_steps_trained": 584000}, "done": false, "episodes_total": 831, "training_iteration": 73, "trial_id": "a9680_00000", "date": "2023-09-24_03-02-26", "timestamp": 1695538946, "time_this_iter_s": 20.19346332550049, "time_total_s": 1455.3746178150177, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b341f7d90>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b341ce5f0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b341ce680>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1455.3746178150177, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 5.045454545454546, "ram_util_percent": 21.47272727272727}, "win_rate": 0.78, "league_size": 43}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2861586576948563, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01823451506861602, "policy_loss": -0.059688724709364274, "vf_loss": 0.07081041738080482, "vf_explained_var": 0.8444243054836988, "kl": 0.018086446488944863, "entropy": 2.0898999699701863, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 70560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "sampler_results": {"episode_reward_max": 4.458527100632342, "episode_reward_min": -2.578806762183821, "episode_reward_mean": 2.142630327524092, "episode_len_mean": 96.42, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"red_v6": -2.0059999999999993, "red": -6.178806762183833, "red_v14": 0.3426932378161809, "blue": -2.0179999999999985, "red_v18": -1.005, "red_v26": -2.036999999999998, "red_v9": -2.0039999999999996, "red_v31": 0.4986932378161699, "red_v34": -1.0209999999999988, "red_v4": -1.008999999999999, "red_v1": -2.0069999999999997, "red_v22": -2.0089999999999995, "red_v28": -0.562, "red_v17": -0.13971639499999788, "red_v10": -1.0209999999999992, "red_v37": 0.4360000000000004, "red_v11": 1.4886932378161704, "red_v3": -0.40100000000000025, "red_v23": -1.682, "red_v8": -0.5359999999999998, "red_v7": -0.5079999999999993, "red_v27": 2.9307713628161705, "red_v32": 0.39969323781617294, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": -2.0069999999999997, "red_v25": -1.564, "red_v38": -0.687, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v36": -0.509}, "policy_reward_max": {"red_v6": -2.0059999999999993, "red": 3.9913338628152037, "red_v14": 0.3426932378161809, "blue": 3.599999999999945, "red_v18": -1.005, "red_v26": 0.9121718750000001, "red_v9": -0.5169999999999999, "red_v31": 1.8370937500000002, "red_v34": 0.48969323781617, "red_v4": -0.010000000000000002, "red_v1": -0.595, "red_v22": 1.9469531249999998, "red_v28": -0.5549999999999998, "red_v17": 1.3902836050000003, "red_v10": 0.49869323781520397, "red_v37": 0.4360000000000004, "red_v11": 1.4886932378161704, "red_v3": -0.40100000000000025, "red_v23": -1.682, "red_v8": -0.004, "red_v7": -0.5079999999999993, "red_v27": 2.9307713628161705, "red_v32": 0.39969323781617294, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": 0.492, "red_v25": -1.564, "red_v38": -0.687, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v36": -0.509}, "policy_reward_mean": {"red_v6": -2.0059999999999993, "red": 2.9295036669779257, "red_v14": 0.3426932378161809, "blue": -1.2583529411764711, "red_v18": -1.005, "red_v26": -0.316926041666666, "red_v9": -1.2604999999999997, "red_v31": 1.167893493908085, "red_v34": -0.2656533810919144, "red_v4": -0.5256666666666664, "red_v1": -1.2449999999999959, "red_v22": -0.35501562499999983, "red_v28": -0.5585, "red_v17": 0.6252836050000012, "red_v10": -0.5138613524369587, "red_v37": 0.4360000000000004, "red_v11": 1.4886932378161704, "red_v3": -0.40100000000000025, "red_v23": -1.682, "red_v8": -0.2699999999999999, "red_v7": -0.5079999999999993, "red_v27": 2.9307713628161705, "red_v32": 0.39969323781617294, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": -0.5609999999999998, "red_v25": -1.564, "red_v38": -0.687, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v36": -0.509}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.4669432378161704, 2.4563083506323617, 1.1726718750000003, 2.472278364442592, 2.925474487816172, 1.4825213628152043, 1.895958167772946, 1.9430994878161716, 0.9706776128161707, 1.6658000000000004, 1.8427869878161744, 3.9623396006323417, 1.9635682378161712, 1.984333862815204, 1.48041198781617, 1.4851151128161701, 1.46767761281617, 2.9783374085440553, 1.4831151128161704, 1.939646362816172, 2.917677612816171, 1.9787088628161702, 2.307867467816175, 2.4728651128161703, 3.656649487816171, 2.4204744878161737, 2.482926917772942, 2.4618963628161707, -0.5352812499999999, 0.9366932378161699, 1.9760057378161702, 1.483926917772942, 4.458527100632342, 1.90809375, 2.4643807378161706, -2.578806762183821, 2.4800057378161697, 0.9730838628161698, 0.7566932378162139, 0.5501307378161729, 0.963693237816219, 2.92759948781617, 2.9788963628161698, 2.413333862816172, 1.9690838628161704, 3.95298022563234, 0.8670023550000001, 2.0898213628161733, 3.7782614756323523, 2.7876776128161795, 0.9808182378161706, 4.37739871781617, 2.9249901128161726, 1.9710838628161704, 2.4514276128161714, 1.4438338628161715, 2.4722783644425923, 0.18610937499999958, 2.4811151128161697, 1.4158651128161708, 3.909917725632344, 1.4787088628161702, 1.2642088628161718, 0.9660526128161705, 2.959865112816171, 1.4675752394425925, 1.1639093750000002, 3.983698975631374, 1.97530261281617, 1.4699744878161702, 1.7854086050000015, 2.3545057378161753, 2.4546221144425933, 2.4537244878161713, 2.374583862816171, 3.289021362816172, 1.4794119878161702, 1.9836342835440548, 2.65076875, 2.93411511281617, 2.4456151128161716, 1.483223792772942, 2.4569432378161706, 2.951724487816171, 3.4670526128161705, 1.3783182378161731, 1.9686776128161707, 1.6613937500000002, 3.466568237816171, 3.053411987816181, 1.906578125, 2.368705480000001, 1.4831151128161704, 2.9748963628161706, 3.987702521360225, 4.441499396360226, 1.4829276128152036, 2.438615112816172, 2.48470886281617, 1.9174901128161719], "episode_lengths": [48, 505, 137, 18, 70, 23, 75, 62, 37, 16, 162, 47, 40, 19, 26, 25, 37, 21, 25, 47, 37, 27, 67, 41, 30, 70, 21, 31, 26, 64, 28, 21, 51, 34, 36, 928, 28, 35, 1280, 372, 1280, 30, 31, 83, 35, 66, 26, 71, 168, 165, 24, 25, 65, 35, 53, 51, 18, 445, 25, 41, 86, 27, 251, 45, 41, 19, 13, 28, 29, 38, 88, 124, 36, 54, 67, 55, 26, 22, 26, 25, 57, 22, 48, 54, 45, 120, 37, 18, 40, 282, 39, 25, 25, 31, 30, 63, 21, 57, 27, 97], "policy_red_v6_reward": [-2.0059999999999993], "policy_red_v14_reward": [0.3426932378161809], "policy_blue_reward": [-0.5489999999999998, -0.02100000000000001, -2.007999999999999, -2.0179999999999985, -1.51, -2.007999999999999, -2.0069999999999997, -2.008, -2.0039999999999996, -2.0149999999999997, -2.0089999999999995, -1.0059999999999993, -1.0039999999999998, -1.505, -2.0069999999999997, -2.005, -0.012, -1.013, 3.599999999999945, -1.0079999999999998, -1.51, -1.0279999999999987, -1.5079999999999998, -1.5099999999999998, -2.0169999999999986, -1.005, -1.133, -1.0069999999999997, -2.008, -1.0579999999999998, -0.011000000000000003, -2.009, -2.0089999999999995, -2.0119999999999996, -0.5309999999999999, -1.0349999999999975, -1.0069999999999995, -1.0149999999999988, -2.008, -2.002, -0.006, -2.005, -1.0089999999999997, -1.0430000000000001, -2.006, -2.0089999999999995, 0.49, -0.013000000000000001, -2.0039999999999996, -2.008, -1.0229999999999995], "policy_red_v18_reward": [-1.005], "policy_red_v26_reward": [-2.036999999999998, 0.17405000000000004, 0.9121718750000001], "policy_red_v9_reward": [-2.0039999999999996, -0.5169999999999999], "policy_red_v31_reward": [1.8370937500000002, 0.4986932378161699], "policy_red_v34_reward": [0.48969323781617, -1.0209999999999988], "policy_red_v4_reward": [-0.010000000000000002, -0.5579999999999999, -1.008999999999999], "policy_red_v1_reward": [-2.0069999999999997, -1.1329999999999882, -0.595], "policy_red_v22_reward": [1.9469531249999998, -2.0089999999999995, -1.003], "policy_red_v28_reward": [-0.562, -0.5549999999999998], "policy_red_v17_reward": [-0.13971639499999788, 1.3902836050000003], "policy_red_v10_reward": [-1.0209999999999992, -1.0179999999999987, 0.49869323781520397, -1.0199999999999998, -0.009000000000000001], "policy_red_v37_reward": [0.4360000000000004], "policy_red_v11_reward": [1.4886932378161704], "policy_red_v3_reward": [-0.40100000000000025], "policy_red_v23_reward": [-1.682], "policy_red_v8_reward": [-0.004, -0.5359999999999998], "policy_red_v7_reward": [-0.5079999999999993], "policy_red_v27_reward": [2.9307713628161705], "policy_red_v32_reward": [0.39969323781617294], "policy_red_v16_reward": [0.4746932378161717], "policy_red_v5_reward": [-1.5059999999999998], "policy_red_v2_reward": [-2.0069999999999997, -0.16799999999999982, 0.492], "policy_red_v25_reward": [-1.564], "policy_red_v38_reward": [-0.687], "policy_red_v21_reward": [0.501103033544055], "policy_red_v12_reward": [1.486103033544055], "policy_red_v36_reward": [-0.509]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.809787565134931, "mean_inference_ms": 7.735277166374568, "mean_action_processing_ms": 0.2922176490401517, "mean_env_wait_ms": 0.3878138852356027, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10022199153900146, "StateBufferConnector_ms": 0.004212379455566406, "ViewRequirementAgentConnector_ms": 0.11724388599395752}}, "episode_reward_max": 4.458527100632342, "episode_reward_min": -2.578806762183821, "episode_reward_mean": 2.142630327524092, "episode_len_mean": 96.42, "episodes_this_iter": 16, "policy_reward_min": {"red_v6": -2.0059999999999993, "red": -6.178806762183833, "red_v14": 0.3426932378161809, "blue": -2.0179999999999985, "red_v18": -1.005, "red_v26": -2.036999999999998, "red_v9": -2.0039999999999996, "red_v31": 0.4986932378161699, "red_v34": -1.0209999999999988, "red_v4": -1.008999999999999, "red_v1": -2.0069999999999997, "red_v22": -2.0089999999999995, "red_v28": -0.562, "red_v17": -0.13971639499999788, "red_v10": -1.0209999999999992, "red_v37": 0.4360000000000004, "red_v11": 1.4886932378161704, "red_v3": -0.40100000000000025, "red_v23": -1.682, "red_v8": -0.5359999999999998, "red_v7": -0.5079999999999993, "red_v27": 2.9307713628161705, "red_v32": 0.39969323781617294, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": -2.0069999999999997, "red_v25": -1.564, "red_v38": -0.687, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v36": -0.509}, "policy_reward_max": {"red_v6": -2.0059999999999993, "red": 3.9913338628152037, "red_v14": 0.3426932378161809, "blue": 3.599999999999945, "red_v18": -1.005, "red_v26": 0.9121718750000001, "red_v9": -0.5169999999999999, "red_v31": 1.8370937500000002, "red_v34": 0.48969323781617, "red_v4": -0.010000000000000002, "red_v1": -0.595, "red_v22": 1.9469531249999998, "red_v28": -0.5549999999999998, "red_v17": 1.3902836050000003, "red_v10": 0.49869323781520397, "red_v37": 0.4360000000000004, "red_v11": 1.4886932378161704, "red_v3": -0.40100000000000025, "red_v23": -1.682, "red_v8": -0.004, "red_v7": -0.5079999999999993, "red_v27": 2.9307713628161705, "red_v32": 0.39969323781617294, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": 0.492, "red_v25": -1.564, "red_v38": -0.687, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v36": -0.509}, "policy_reward_mean": {"red_v6": -2.0059999999999993, "red": 2.9295036669779257, "red_v14": 0.3426932378161809, "blue": -1.2583529411764711, "red_v18": -1.005, "red_v26": -0.316926041666666, "red_v9": -1.2604999999999997, "red_v31": 1.167893493908085, "red_v34": -0.2656533810919144, "red_v4": -0.5256666666666664, "red_v1": -1.2449999999999959, "red_v22": -0.35501562499999983, "red_v28": -0.5585, "red_v17": 0.6252836050000012, "red_v10": -0.5138613524369587, "red_v37": 0.4360000000000004, "red_v11": 1.4886932378161704, "red_v3": -0.40100000000000025, "red_v23": -1.682, "red_v8": -0.2699999999999999, "red_v7": -0.5079999999999993, "red_v27": 2.9307713628161705, "red_v32": 0.39969323781617294, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": -0.5609999999999998, "red_v25": -1.564, "red_v38": -0.687, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v36": -0.509}, "hist_stats": {"episode_reward": [1.4669432378161704, 2.4563083506323617, 1.1726718750000003, 2.472278364442592, 2.925474487816172, 1.4825213628152043, 1.895958167772946, 1.9430994878161716, 0.9706776128161707, 1.6658000000000004, 1.8427869878161744, 3.9623396006323417, 1.9635682378161712, 1.984333862815204, 1.48041198781617, 1.4851151128161701, 1.46767761281617, 2.9783374085440553, 1.4831151128161704, 1.939646362816172, 2.917677612816171, 1.9787088628161702, 2.307867467816175, 2.4728651128161703, 3.656649487816171, 2.4204744878161737, 2.482926917772942, 2.4618963628161707, -0.5352812499999999, 0.9366932378161699, 1.9760057378161702, 1.483926917772942, 4.458527100632342, 1.90809375, 2.4643807378161706, -2.578806762183821, 2.4800057378161697, 0.9730838628161698, 0.7566932378162139, 0.5501307378161729, 0.963693237816219, 2.92759948781617, 2.9788963628161698, 2.413333862816172, 1.9690838628161704, 3.95298022563234, 0.8670023550000001, 2.0898213628161733, 3.7782614756323523, 2.7876776128161795, 0.9808182378161706, 4.37739871781617, 2.9249901128161726, 1.9710838628161704, 2.4514276128161714, 1.4438338628161715, 2.4722783644425923, 0.18610937499999958, 2.4811151128161697, 1.4158651128161708, 3.909917725632344, 1.4787088628161702, 1.2642088628161718, 0.9660526128161705, 2.959865112816171, 1.4675752394425925, 1.1639093750000002, 3.983698975631374, 1.97530261281617, 1.4699744878161702, 1.7854086050000015, 2.3545057378161753, 2.4546221144425933, 2.4537244878161713, 2.374583862816171, 3.289021362816172, 1.4794119878161702, 1.9836342835440548, 2.65076875, 2.93411511281617, 2.4456151128161716, 1.483223792772942, 2.4569432378161706, 2.951724487816171, 3.4670526128161705, 1.3783182378161731, 1.9686776128161707, 1.6613937500000002, 3.466568237816171, 3.053411987816181, 1.906578125, 2.368705480000001, 1.4831151128161704, 2.9748963628161706, 3.987702521360225, 4.441499396360226, 1.4829276128152036, 2.438615112816172, 2.48470886281617, 1.9174901128161719], "episode_lengths": [48, 505, 137, 18, 70, 23, 75, 62, 37, 16, 162, 47, 40, 19, 26, 25, 37, 21, 25, 47, 37, 27, 67, 41, 30, 70, 21, 31, 26, 64, 28, 21, 51, 34, 36, 928, 28, 35, 1280, 372, 1280, 30, 31, 83, 35, 66, 26, 71, 168, 165, 24, 25, 65, 35, 53, 51, 18, 445, 25, 41, 86, 27, 251, 45, 41, 19, 13, 28, 29, 38, 88, 124, 36, 54, 67, 55, 26, 22, 26, 25, 57, 22, 48, 54, 45, 120, 37, 18, 40, 282, 39, 25, 25, 31, 30, 63, 21, 57, 27, 97], "policy_red_v6_reward": [-2.0059999999999993], "policy_red_v14_reward": [0.3426932378161809], "policy_blue_reward": [-0.5489999999999998, -0.02100000000000001, -2.007999999999999, -2.0179999999999985, -1.51, -2.007999999999999, -2.0069999999999997, -2.008, -2.0039999999999996, -2.0149999999999997, -2.0089999999999995, -1.0059999999999993, -1.0039999999999998, -1.505, -2.0069999999999997, -2.005, -0.012, -1.013, 3.599999999999945, -1.0079999999999998, -1.51, -1.0279999999999987, -1.5079999999999998, -1.5099999999999998, -2.0169999999999986, -1.005, -1.133, -1.0069999999999997, -2.008, -1.0579999999999998, -0.011000000000000003, -2.009, -2.0089999999999995, -2.0119999999999996, -0.5309999999999999, -1.0349999999999975, -1.0069999999999995, -1.0149999999999988, -2.008, -2.002, -0.006, -2.005, -1.0089999999999997, -1.0430000000000001, -2.006, -2.0089999999999995, 0.49, -0.013000000000000001, -2.0039999999999996, -2.008, -1.0229999999999995], "policy_red_v18_reward": [-1.005], "policy_red_v26_reward": [-2.036999999999998, 0.17405000000000004, 0.9121718750000001], "policy_red_v9_reward": [-2.0039999999999996, -0.5169999999999999], "policy_red_v31_reward": [1.8370937500000002, 0.4986932378161699], "policy_red_v34_reward": [0.48969323781617, -1.0209999999999988], "policy_red_v4_reward": [-0.010000000000000002, -0.5579999999999999, -1.008999999999999], "policy_red_v1_reward": [-2.0069999999999997, -1.1329999999999882, -0.595], "policy_red_v22_reward": [1.9469531249999998, -2.0089999999999995, -1.003], "policy_red_v28_reward": [-0.562, -0.5549999999999998], "policy_red_v17_reward": [-0.13971639499999788, 1.3902836050000003], "policy_red_v10_reward": [-1.0209999999999992, -1.0179999999999987, 0.49869323781520397, -1.0199999999999998, -0.009000000000000001], "policy_red_v37_reward": [0.4360000000000004], "policy_red_v11_reward": [1.4886932378161704], "policy_red_v3_reward": [-0.40100000000000025], "policy_red_v23_reward": [-1.682], "policy_red_v8_reward": [-0.004, -0.5359999999999998], "policy_red_v7_reward": [-0.5079999999999993], "policy_red_v27_reward": [2.9307713628161705], "policy_red_v32_reward": [0.39969323781617294], "policy_red_v16_reward": [0.4746932378161717], "policy_red_v5_reward": [-1.5059999999999998], "policy_red_v2_reward": [-2.0069999999999997, -0.16799999999999982, 0.492], "policy_red_v25_reward": [-1.564], "policy_red_v38_reward": [-0.687], "policy_red_v21_reward": [0.501103033544055], "policy_red_v12_reward": [1.486103033544055], "policy_red_v36_reward": [-0.509]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.809787565134931, "mean_inference_ms": 7.735277166374568, "mean_action_processing_ms": 0.2922176490401517, "mean_env_wait_ms": 0.3878138852356027, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10022199153900146, "StateBufferConnector_ms": 0.004212379455566406, "ViewRequirementAgentConnector_ms": 0.11724388599395752}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 198.54740484592864, "num_env_steps_trained_throughput_per_sec": 198.54740484592864, "timesteps_total": 296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 20121.645, "sample_time_ms": 1156.964, "learn_time_ms": 18882.74, "learn_throughput": 211.834, "synch_weights_time_ms": 79.182}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "episodes_total": 847, "training_iteration": 74, "trial_id": "a9680_00000", "date": "2023-09-24_03-02-49", "timestamp": 1695538969, "time_this_iter_s": 20.155670881271362, "time_total_s": 1475.530288696289, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b343708b0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b341ccaf0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b341cc550>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1475.530288696289, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 5.240625, "ram_util_percent": 21.578125}, "win_rate": 0.81, "league_size": 44}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1703563272953033, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.018057351059299738, "policy_loss": -0.05773766705145438, "vf_loss": 0.06702848264443068, "vf_explained_var": 0.8521935179829597, "kl": 0.018432735327094937, "entropy": 2.1286555141210557, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 71520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 600000, "num_agent_steps_trained": 600000}, "sampler_results": {"episode_reward_max": 4.458527100632342, "episode_reward_min": -2.578806762183821, "episode_reward_mean": 2.149964857172568, "episode_len_mean": 96.21, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"red_v28": -0.562, "red": -6.178806762183833, "blue": -2.0169999999999986, "red_v17": -0.13971639499999788, "red_v26": 0.17405000000000004, "red_v10": -1.0209999999999992, "red_v34": -1.0209999999999988, "red_v37": 0.4360000000000004, "red_v11": 1.4886932378161704, "red_v3": -0.40100000000000025, "red_v23": -1.682, "red_v1": -1.1329999999999882, "red_v4": -1.008999999999999, "red_v8": -0.5359999999999998, "red_v7": -0.5079999999999993, "red_v31": 0.4986932378161699, "red_v27": 2.9307713628161705, "red_v32": 0.39969323781617294, "red_v22": -2.0089999999999995, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": -2.0069999999999997, "red_v25": -1.564, "red_v9": -0.5169999999999999, "red_v38": -0.687, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v36": -0.509, "red_v13": -1.5189999999999986, "red_v30": -1.0089999999999997, "red_v19": 1.448693237816175, "red_v20": -0.019999999999999907}, "policy_reward_max": {"red_v28": -0.5549999999999998, "red": 3.9877088628161697, "blue": 3.599999999999945, "red_v17": 1.3902836050000003, "red_v26": 0.9121718750000001, "red_v10": 0.49869323781520397, "red_v34": -1.0209999999999988, "red_v37": 0.4360000000000004, "red_v11": 1.4886932378161704, "red_v3": -0.40100000000000025, "red_v23": -1.682, "red_v1": -0.595, "red_v4": -0.5579999999999999, "red_v8": -0.004, "red_v7": -0.5079999999999993, "red_v31": 0.4986932378161699, "red_v27": 2.9307713628161705, "red_v32": 0.39969323781617294, "red_v22": -1.003, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": 0.492, "red_v25": -1.564, "red_v9": -0.5169999999999999, "red_v38": -0.687, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v36": -0.509, "red_v13": -1.5189999999999986, "red_v30": -1.0089999999999997, "red_v19": 1.448693237816175, "red_v20": -0.019999999999999907}, "policy_reward_mean": {"red_v28": -0.5585, "red": 2.888219347754563, "blue": -1.0990066964285723, "red_v17": 0.6252836050000012, "red_v26": 0.5431109375000001, "red_v10": -0.5138613524369587, "red_v34": -1.0209999999999988, "red_v37": 0.4360000000000004, "red_v11": 1.4886932378161704, "red_v3": -0.40100000000000025, "red_v23": -1.682, "red_v1": -0.8639999999999941, "red_v4": -0.7834999999999994, "red_v8": -0.2699999999999999, "red_v7": -0.5079999999999993, "red_v31": 0.4986932378161699, "red_v27": 2.9307713628161705, "red_v32": 0.39969323781617294, "red_v22": -1.5059999999999998, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": -0.7014999999999998, "red_v25": -1.564, "red_v9": -0.5169999999999999, "red_v38": -0.687, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v36": -0.509, "red_v13": -1.5189999999999986, "red_v30": -1.0089999999999997, "red_v19": 1.448693237816175, "red_v20": -0.019999999999999907}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.917677612816171, 1.9787088628161702, 2.307867467816175, 2.4728651128161703, 3.656649487816171, 2.4204744878161737, 2.482926917772942, 2.4618963628161707, -0.5352812499999999, 0.9366932378161699, 1.9760057378161702, 1.483926917772942, 4.458527100632342, 1.90809375, 2.4643807378161706, -2.578806762183821, 2.4800057378161697, 0.9730838628161698, 0.7566932378162139, 0.5501307378161729, 0.963693237816219, 2.92759948781617, 2.9788963628161698, 2.413333862816172, 1.9690838628161704, 3.95298022563234, 0.8670023550000001, 2.0898213628161733, 3.7782614756323523, 2.7876776128161795, 0.9808182378161706, 4.37739871781617, 2.9249901128161726, 1.9710838628161704, 2.4514276128161714, 1.4438338628161715, 2.4722783644425923, 0.18610937499999958, 2.4811151128161697, 1.4158651128161708, 3.909917725632344, 1.4787088628161702, 1.2642088628161718, 0.9660526128161705, 2.959865112816171, 1.4675752394425925, 1.1639093750000002, 3.983698975631374, 1.97530261281617, 1.4699744878161702, 1.7854086050000015, 2.3545057378161753, 2.4546221144425933, 2.4537244878161713, 2.374583862816171, 3.289021362816172, 1.4794119878161702, 1.9836342835440548, 2.65076875, 2.93411511281617, 2.4456151128161716, 1.483223792772942, 2.4569432378161706, 2.951724487816171, 3.4670526128161705, 1.3783182378161731, 1.9686776128161707, 1.6613937500000002, 3.466568237816171, 3.053411987816181, 1.906578125, 2.368705480000001, 1.4831151128161704, 2.9748963628161706, 3.987702521360225, 4.441499396360226, 1.4829276128152036, 2.438615112816172, 2.48470886281617, 1.9174901128161719, 0.8040213628161774, 1.558625000000006, 2.4686846144425925, 2.4735994878161702, 1.4800057378161706, 4.186664342816181, 1.48692761281617, 2.4749814894425923, 2.9818182378152036, 1.9574588628161715, 2.4748963628161706, 2.4207783644425924, 1.485630737815204, 1.290693237816174, 1.9279375, 1.4827088628161702, 1.2433963628161764, 1.6577687500000002, 1.4853374085440554, 2.430583862816171], "episode_lengths": [37, 27, 67, 41, 30, 70, 21, 31, 26, 64, 28, 21, 51, 34, 36, 928, 28, 35, 1280, 372, 1280, 30, 31, 83, 35, 66, 26, 71, 168, 165, 24, 25, 65, 35, 53, 51, 18, 445, 25, 41, 86, 27, 251, 45, 41, 19, 13, 28, 29, 38, 88, 124, 36, 54, 67, 55, 26, 22, 26, 25, 57, 22, 48, 54, 45, 120, 37, 18, 40, 282, 39, 25, 25, 31, 30, 63, 21, 57, 27, 97, 183, 248, 16, 30, 28, 164, 21, 17, 24, 43, 31, 50, 20, 192, 20, 27, 191, 26, 21, 67], "policy_red_v28_reward": [-0.562, -0.5549999999999998], "policy_blue_reward": [-2.0089999999999995, -1.0059999999999993, -1.0039999999999998, -1.505, -2.0069999999999997, -2.005, -0.012, -1.013, 3.599999999999945, -1.0079999999999998, -1.51, -1.0279999999999987, -1.5079999999999998, -1.5099999999999998, -2.0169999999999986, -1.005, -1.133, -1.0069999999999997, -2.008, -1.0579999999999998, -0.011000000000000003, -2.009, -2.0089999999999995, -2.0119999999999996, -0.5309999999999999, -1.0349999999999975, -1.0069999999999995, -1.0149999999999988, -2.008, -2.002, -0.006, -2.005, -1.0089999999999997, -1.0430000000000001, -2.006, -2.0089999999999995, 0.49, -0.013000000000000001, -2.0039999999999996, -2.008, -1.0229999999999995, 2.2516249999999998, -1.0059999999999996, -2.0059999999999993, -2.0069999999999997, -1.001, -0.007, -2.0129999999999995, -1.0079999999999996, -1.0149999999999992, -2.005, 2.319, -0.004, -2.0049999999999994, -2.005, -2.005], "policy_red_v17_reward": [-0.13971639499999788, 1.3902836050000003], "policy_red_v26_reward": [0.17405000000000004, 0.9121718750000001], "policy_red_v10_reward": [-1.0209999999999992, -1.0179999999999987, 0.49869323781520397, -1.0199999999999998, -0.009000000000000001], "policy_red_v34_reward": [-1.0209999999999988], "policy_red_v37_reward": [0.4360000000000004], "policy_red_v11_reward": [1.4886932378161704], "policy_red_v3_reward": [-0.40100000000000025], "policy_red_v23_reward": [-1.682], "policy_red_v1_reward": [-1.1329999999999882, -0.595], "policy_red_v4_reward": [-0.5579999999999999, -1.008999999999999], "policy_red_v8_reward": [-0.004, -0.5359999999999998], "policy_red_v7_reward": [-0.5079999999999993], "policy_red_v31_reward": [0.4986932378161699], "policy_red_v27_reward": [2.9307713628161705], "policy_red_v32_reward": [0.39969323781617294], "policy_red_v22_reward": [-2.0089999999999995, -1.003], "policy_red_v16_reward": [0.4746932378161717], "policy_red_v5_reward": [-1.5059999999999998], "policy_red_v2_reward": [-2.0069999999999997, -0.16799999999999982, 0.492, -1.123], "policy_red_v25_reward": [-1.564], "policy_red_v9_reward": [-0.5169999999999999], "policy_red_v38_reward": [-0.687], "policy_red_v21_reward": [0.501103033544055], "policy_red_v12_reward": [1.486103033544055], "policy_red_v36_reward": [-0.509], "policy_red_v13_reward": [-1.5189999999999986], "policy_red_v30_reward": [-1.0089999999999997], "policy_red_v19_reward": [1.448693237816175], "policy_red_v20_reward": [-0.019999999999999907]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8105069798968139, "mean_inference_ms": 7.743777991513068, "mean_action_processing_ms": 0.29201774506220246, "mean_env_wait_ms": 0.38844236311316815, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09826290607452393, "StateBufferConnector_ms": 0.00415956974029541, "ViewRequirementAgentConnector_ms": 0.11497831344604492}}, "episode_reward_max": 4.458527100632342, "episode_reward_min": -2.578806762183821, "episode_reward_mean": 2.149964857172568, "episode_len_mean": 96.21, "episodes_this_iter": 20, "policy_reward_min": {"red_v28": -0.562, "red": -6.178806762183833, "blue": -2.0169999999999986, "red_v17": -0.13971639499999788, "red_v26": 0.17405000000000004, "red_v10": -1.0209999999999992, "red_v34": -1.0209999999999988, "red_v37": 0.4360000000000004, "red_v11": 1.4886932378161704, "red_v3": -0.40100000000000025, "red_v23": -1.682, "red_v1": -1.1329999999999882, "red_v4": -1.008999999999999, "red_v8": -0.5359999999999998, "red_v7": -0.5079999999999993, "red_v31": 0.4986932378161699, "red_v27": 2.9307713628161705, "red_v32": 0.39969323781617294, "red_v22": -2.0089999999999995, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": -2.0069999999999997, "red_v25": -1.564, "red_v9": -0.5169999999999999, "red_v38": -0.687, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v36": -0.509, "red_v13": -1.5189999999999986, "red_v30": -1.0089999999999997, "red_v19": 1.448693237816175, "red_v20": -0.019999999999999907}, "policy_reward_max": {"red_v28": -0.5549999999999998, "red": 3.9877088628161697, "blue": 3.599999999999945, "red_v17": 1.3902836050000003, "red_v26": 0.9121718750000001, "red_v10": 0.49869323781520397, "red_v34": -1.0209999999999988, "red_v37": 0.4360000000000004, "red_v11": 1.4886932378161704, "red_v3": -0.40100000000000025, "red_v23": -1.682, "red_v1": -0.595, "red_v4": -0.5579999999999999, "red_v8": -0.004, "red_v7": -0.5079999999999993, "red_v31": 0.4986932378161699, "red_v27": 2.9307713628161705, "red_v32": 0.39969323781617294, "red_v22": -1.003, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": 0.492, "red_v25": -1.564, "red_v9": -0.5169999999999999, "red_v38": -0.687, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v36": -0.509, "red_v13": -1.5189999999999986, "red_v30": -1.0089999999999997, "red_v19": 1.448693237816175, "red_v20": -0.019999999999999907}, "policy_reward_mean": {"red_v28": -0.5585, "red": 2.888219347754563, "blue": -1.0990066964285723, "red_v17": 0.6252836050000012, "red_v26": 0.5431109375000001, "red_v10": -0.5138613524369587, "red_v34": -1.0209999999999988, "red_v37": 0.4360000000000004, "red_v11": 1.4886932378161704, "red_v3": -0.40100000000000025, "red_v23": -1.682, "red_v1": -0.8639999999999941, "red_v4": -0.7834999999999994, "red_v8": -0.2699999999999999, "red_v7": -0.5079999999999993, "red_v31": 0.4986932378161699, "red_v27": 2.9307713628161705, "red_v32": 0.39969323781617294, "red_v22": -1.5059999999999998, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": -0.7014999999999998, "red_v25": -1.564, "red_v9": -0.5169999999999999, "red_v38": -0.687, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v36": -0.509, "red_v13": -1.5189999999999986, "red_v30": -1.0089999999999997, "red_v19": 1.448693237816175, "red_v20": -0.019999999999999907}, "hist_stats": {"episode_reward": [2.917677612816171, 1.9787088628161702, 2.307867467816175, 2.4728651128161703, 3.656649487816171, 2.4204744878161737, 2.482926917772942, 2.4618963628161707, -0.5352812499999999, 0.9366932378161699, 1.9760057378161702, 1.483926917772942, 4.458527100632342, 1.90809375, 2.4643807378161706, -2.578806762183821, 2.4800057378161697, 0.9730838628161698, 0.7566932378162139, 0.5501307378161729, 0.963693237816219, 2.92759948781617, 2.9788963628161698, 2.413333862816172, 1.9690838628161704, 3.95298022563234, 0.8670023550000001, 2.0898213628161733, 3.7782614756323523, 2.7876776128161795, 0.9808182378161706, 4.37739871781617, 2.9249901128161726, 1.9710838628161704, 2.4514276128161714, 1.4438338628161715, 2.4722783644425923, 0.18610937499999958, 2.4811151128161697, 1.4158651128161708, 3.909917725632344, 1.4787088628161702, 1.2642088628161718, 0.9660526128161705, 2.959865112816171, 1.4675752394425925, 1.1639093750000002, 3.983698975631374, 1.97530261281617, 1.4699744878161702, 1.7854086050000015, 2.3545057378161753, 2.4546221144425933, 2.4537244878161713, 2.374583862816171, 3.289021362816172, 1.4794119878161702, 1.9836342835440548, 2.65076875, 2.93411511281617, 2.4456151128161716, 1.483223792772942, 2.4569432378161706, 2.951724487816171, 3.4670526128161705, 1.3783182378161731, 1.9686776128161707, 1.6613937500000002, 3.466568237816171, 3.053411987816181, 1.906578125, 2.368705480000001, 1.4831151128161704, 2.9748963628161706, 3.987702521360225, 4.441499396360226, 1.4829276128152036, 2.438615112816172, 2.48470886281617, 1.9174901128161719, 0.8040213628161774, 1.558625000000006, 2.4686846144425925, 2.4735994878161702, 1.4800057378161706, 4.186664342816181, 1.48692761281617, 2.4749814894425923, 2.9818182378152036, 1.9574588628161715, 2.4748963628161706, 2.4207783644425924, 1.485630737815204, 1.290693237816174, 1.9279375, 1.4827088628161702, 1.2433963628161764, 1.6577687500000002, 1.4853374085440554, 2.430583862816171], "episode_lengths": [37, 27, 67, 41, 30, 70, 21, 31, 26, 64, 28, 21, 51, 34, 36, 928, 28, 35, 1280, 372, 1280, 30, 31, 83, 35, 66, 26, 71, 168, 165, 24, 25, 65, 35, 53, 51, 18, 445, 25, 41, 86, 27, 251, 45, 41, 19, 13, 28, 29, 38, 88, 124, 36, 54, 67, 55, 26, 22, 26, 25, 57, 22, 48, 54, 45, 120, 37, 18, 40, 282, 39, 25, 25, 31, 30, 63, 21, 57, 27, 97, 183, 248, 16, 30, 28, 164, 21, 17, 24, 43, 31, 50, 20, 192, 20, 27, 191, 26, 21, 67], "policy_red_v28_reward": [-0.562, -0.5549999999999998], "policy_blue_reward": [-2.0089999999999995, -1.0059999999999993, -1.0039999999999998, -1.505, -2.0069999999999997, -2.005, -0.012, -1.013, 3.599999999999945, -1.0079999999999998, -1.51, -1.0279999999999987, -1.5079999999999998, -1.5099999999999998, -2.0169999999999986, -1.005, -1.133, -1.0069999999999997, -2.008, -1.0579999999999998, -0.011000000000000003, -2.009, -2.0089999999999995, -2.0119999999999996, -0.5309999999999999, -1.0349999999999975, -1.0069999999999995, -1.0149999999999988, -2.008, -2.002, -0.006, -2.005, -1.0089999999999997, -1.0430000000000001, -2.006, -2.0089999999999995, 0.49, -0.013000000000000001, -2.0039999999999996, -2.008, -1.0229999999999995, 2.2516249999999998, -1.0059999999999996, -2.0059999999999993, -2.0069999999999997, -1.001, -0.007, -2.0129999999999995, -1.0079999999999996, -1.0149999999999992, -2.005, 2.319, -0.004, -2.0049999999999994, -2.005, -2.005], "policy_red_v17_reward": [-0.13971639499999788, 1.3902836050000003], "policy_red_v26_reward": [0.17405000000000004, 0.9121718750000001], "policy_red_v10_reward": [-1.0209999999999992, -1.0179999999999987, 0.49869323781520397, -1.0199999999999998, -0.009000000000000001], "policy_red_v34_reward": [-1.0209999999999988], "policy_red_v37_reward": [0.4360000000000004], "policy_red_v11_reward": [1.4886932378161704], "policy_red_v3_reward": [-0.40100000000000025], "policy_red_v23_reward": [-1.682], "policy_red_v1_reward": [-1.1329999999999882, -0.595], "policy_red_v4_reward": [-0.5579999999999999, -1.008999999999999], "policy_red_v8_reward": [-0.004, -0.5359999999999998], "policy_red_v7_reward": [-0.5079999999999993], "policy_red_v31_reward": [0.4986932378161699], "policy_red_v27_reward": [2.9307713628161705], "policy_red_v32_reward": [0.39969323781617294], "policy_red_v22_reward": [-2.0089999999999995, -1.003], "policy_red_v16_reward": [0.4746932378161717], "policy_red_v5_reward": [-1.5059999999999998], "policy_red_v2_reward": [-2.0069999999999997, -0.16799999999999982, 0.492, -1.123], "policy_red_v25_reward": [-1.564], "policy_red_v9_reward": [-0.5169999999999999], "policy_red_v38_reward": [-0.687], "policy_red_v21_reward": [0.501103033544055], "policy_red_v12_reward": [1.486103033544055], "policy_red_v36_reward": [-0.509], "policy_red_v13_reward": [-1.5189999999999986], "policy_red_v30_reward": [-1.0089999999999997], "policy_red_v19_reward": [1.448693237816175], "policy_red_v20_reward": [-0.019999999999999907]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8105069798968139, "mean_inference_ms": 7.743777991513068, "mean_action_processing_ms": 0.29201774506220246, "mean_env_wait_ms": 0.38844236311316815, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09826290607452393, "StateBufferConnector_ms": 0.00415956974029541, "ViewRequirementAgentConnector_ms": 0.11497831344604492}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 600000, "num_agent_steps_trained": 600000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 202.7907599435423, "num_env_steps_trained_throughput_per_sec": 202.7907599435423, "timesteps_total": 300000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 600000, "timers": {"training_iteration_time_ms": 20060.569, "sample_time_ms": 1147.584, "learn_time_ms": 18830.675, "learn_throughput": 212.419, "synch_weights_time_ms": 79.525}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 600000, "num_agent_steps_trained": 600000}, "done": false, "episodes_total": 867, "training_iteration": 75, "trial_id": "a9680_00000", "date": "2023-09-24_03-03-11", "timestamp": 1695538991, "time_this_iter_s": 19.735785722732544, "time_total_s": 1495.2660744190216, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b3426c4f0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3441a710>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3441b010>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1495.2660744190216, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 5.18125, "ram_util_percent": 21.684375000000003}, "win_rate": 0.82, "league_size": 45}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1004997598628203, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.020356800925704497, "policy_loss": -0.05812544367363444, "vf_loss": 0.06253591378141815, "vf_explained_var": 0.8609797870119412, "kl": 0.019086197621606037, "entropy": 2.0881026864051817, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 72480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "sampler_results": {"episode_reward_max": 4.475182655588147, "episode_reward_min": 0.18610937499999958, "episode_reward_mean": 2.221463000165335, "episode_len_mean": 100.83, "episode_media": {}, "episodes_this_iter": 22, "policy_reward_min": {"red_v8": -2.0119999999999996, "red": -1.0283067621838298, "blue": -2.0169999999999986, "red_v7": -0.5079999999999993, "red_v31": 0.4986932378161699, "red_v27": 2.9307713628161705, "red_v32": 0.39969323781617294, "red_v1": -0.595, "red_v17": 1.3902836050000003, "red_v22": -2.0089999999999995, "red_v10": -1.0199999999999998, "red_v26": -1.2059999999999815, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": -2.0069999999999997, "red_v25": -1.564, "red_v28": -0.5549999999999998, "red_v9": -0.5169999999999999, "red_v38": -0.687, "red_v4": -1.008999999999999, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v36": -0.509, "red_v13": -1.5189999999999986, "red_v30": -1.0089999999999997, "red_v19": -1.009, "red_v20": -0.019999999999999907, "red_v35": -1.0139999999999996, "red_v15": -1.0139999999999998, "red_v6": 0.4329218750000011, "red_v23": 1.483934614442592, "red_v39": 1.4956932378152046}, "policy_reward_max": {"red_v8": -0.004, "red": 3.9856342835440546, "blue": 2.319, "red_v7": -0.5079999999999993, "red_v31": 0.4986932378161699, "red_v27": 2.9307713628161705, "red_v32": 0.39969323781617294, "red_v1": -0.595, "red_v17": 1.3902836050000003, "red_v22": -1.003, "red_v10": 0.49869323781520397, "red_v26": 0.9121718750000001, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": 0.492, "red_v25": -1.564, "red_v28": -0.5549999999999998, "red_v9": -0.5169999999999999, "red_v38": -0.687, "red_v4": -1.008999999999999, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v36": -0.509, "red_v13": -1.5189999999999986, "red_v30": -1.0089999999999997, "red_v19": 1.448693237816175, "red_v20": -0.019999999999999907, "red_v35": 0.4859346144425925, "red_v15": -1.0139999999999998, "red_v6": 0.4329218750000011, "red_v23": 1.483934614442592, "red_v39": 1.4956932378152046}, "policy_reward_mean": {"red_v8": -0.6417499999999999, "red": 2.965219790758488, "blue": -1.1755624999999987, "red_v7": -0.5079999999999993, "red_v31": 0.4986932378161699, "red_v27": 2.9307713628161705, "red_v32": 0.39969323781617294, "red_v1": -0.595, "red_v17": 1.3902836050000003, "red_v22": -1.5059999999999998, "red_v10": -0.3870766905461986, "red_v26": -0.14691406249999073, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": -0.7014999999999998, "red_v25": -1.564, "red_v28": -0.5549999999999998, "red_v9": -0.5169999999999999, "red_v38": -0.687, "red_v4": -1.008999999999999, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v36": -0.509, "red_v13": -1.5189999999999986, "red_v30": -1.0089999999999997, "red_v19": -0.04439885243676409, "red_v20": -0.019999999999999907, "red_v35": -0.26403269277870356, "red_v15": -1.0139999999999998, "red_v6": 0.4329218750000011, "red_v23": 1.483934614442592, "red_v39": 1.4956932378152046}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.9788963628161698, 2.413333862816172, 1.9690838628161704, 3.95298022563234, 0.8670023550000001, 2.0898213628161733, 3.7782614756323523, 2.7876776128161795, 0.9808182378161706, 4.37739871781617, 2.9249901128161726, 1.9710838628161704, 2.4514276128161714, 1.4438338628161715, 2.4722783644425923, 0.18610937499999958, 2.4811151128161697, 1.4158651128161708, 3.909917725632344, 1.4787088628161702, 1.2642088628161718, 0.9660526128161705, 2.959865112816171, 1.4675752394425925, 1.1639093750000002, 3.983698975631374, 1.97530261281617, 1.4699744878161702, 1.7854086050000015, 2.3545057378161753, 2.4546221144425933, 2.4537244878161713, 2.374583862816171, 3.289021362816172, 1.4794119878161702, 1.9836342835440548, 2.65076875, 2.93411511281617, 2.4456151128161716, 1.483223792772942, 2.4569432378161706, 2.951724487816171, 3.4670526128161705, 1.3783182378161731, 1.9686776128161707, 1.6613937500000002, 3.466568237816171, 3.053411987816181, 1.906578125, 2.368705480000001, 1.4831151128161704, 2.9748963628161706, 3.987702521360225, 4.441499396360226, 1.4829276128152036, 2.438615112816172, 2.48470886281617, 1.9174901128161719, 0.8040213628161774, 1.558625000000006, 2.4686846144425925, 2.4735994878161702, 1.4800057378161706, 4.186664342816181, 1.48692761281617, 2.4749814894425923, 2.9818182378152036, 1.9574588628161715, 2.4748963628161706, 2.4207783644425924, 1.485630737815204, 1.290693237816174, 1.9279375, 1.4827088628161702, 1.2433963628161764, 1.6577687500000002, 1.4853374085440554, 2.430583862816171, 1.3469711050000006, 2.4459901128161707, 2.4790057378161703, 2.4755213628152037, 0.7416932378162148, 1.8882401128161972, 1.6696125000000004, 3.3256846144425927, 2.923333862816172, 2.4743026128161705, 0.9128564894425937, 2.4606619878161915, 1.4865206677729415, 4.4745646572155335, 2.4719744878161705, 2.97181823781617, 0.39739636281620183, 0.5273026128161706, 2.4784119878161706, 0.6798564894425919, 4.475182655588147, 1.5067244878161719], "episode_lengths": [31, 83, 35, 66, 26, 71, 168, 165, 24, 25, 65, 35, 53, 51, 18, 445, 25, 41, 86, 27, 251, 45, 41, 19, 13, 28, 29, 38, 88, 124, 36, 54, 67, 55, 26, 22, 26, 25, 57, 22, 48, 54, 45, 120, 37, 18, 40, 282, 39, 25, 25, 31, 30, 63, 21, 57, 27, 97, 183, 248, 16, 30, 28, 164, 21, 17, 24, 43, 31, 50, 20, 192, 20, 27, 191, 26, 21, 67, 36, 65, 28, 23, 1280, 433, 12, 16, 83, 29, 57, 394, 23, 20, 38, 24, 639, 349, 26, 633, 33, 758], "policy_red_v8_reward": [-0.004, -0.5359999999999998, -2.0119999999999996, -0.015000000000000001], "policy_blue_reward": [-1.0279999999999987, -1.5079999999999998, -1.5099999999999998, -2.0169999999999986, -1.005, -1.133, -1.0069999999999997, -2.008, -1.0579999999999998, -0.011000000000000003, -2.009, -2.0089999999999995, -2.0119999999999996, -0.5309999999999999, -1.0349999999999975, -1.0069999999999995, -1.0149999999999988, -2.008, -2.002, -0.006, -2.005, -1.0089999999999997, -1.0430000000000001, -2.006, -2.0089999999999995, 0.49, -0.013000000000000001, -2.0039999999999996, -2.008, -1.0229999999999995, 2.2516249999999998, -1.0059999999999996, -2.0059999999999993, -2.0069999999999997, -1.001, -0.007, -2.0129999999999995, -1.0079999999999996, -1.0149999999999992, -2.005, 2.319, -0.004, -2.0049999999999994, -2.005, -2.005, -1.3379999999999677, -2.005, -0.021000000000000005, -1.0119999999999998, -1.1629999999999971, -2.0029999999999997, -1.008999999999999, -1.6640000000000001, -1.1999999999999815], "policy_red_v7_reward": [-0.5079999999999993], "policy_red_v31_reward": [0.4986932378161699], "policy_red_v27_reward": [2.9307713628161705], "policy_red_v32_reward": [0.39969323781617294], "policy_red_v1_reward": [-0.595], "policy_red_v17_reward": [1.3902836050000003], "policy_red_v22_reward": [-2.0089999999999995, -1.003], "policy_red_v10_reward": [-1.0179999999999987, 0.49869323781520397, -1.0199999999999998, -0.009000000000000001], "policy_red_v26_reward": [0.9121718750000001, -1.2059999999999815], "policy_red_v16_reward": [0.4746932378161717], "policy_red_v5_reward": [-1.5059999999999998], "policy_red_v2_reward": [-2.0069999999999997, -0.16799999999999982, 0.492, -1.123], "policy_red_v25_reward": [-1.564], "policy_red_v28_reward": [-0.5549999999999998], "policy_red_v9_reward": [-0.5169999999999999], "policy_red_v38_reward": [-0.687], "policy_red_v4_reward": [-1.008999999999999], "policy_red_v21_reward": [0.501103033544055], "policy_red_v12_reward": [1.486103033544055], "policy_red_v36_reward": [-0.509], "policy_red_v13_reward": [-1.5189999999999986], "policy_red_v30_reward": [-1.0089999999999997], "policy_red_v19_reward": [1.448693237816175, -1.0069999999999995, 0.24570312500000402, 0.09960937499999989, -1.009], "policy_red_v20_reward": [-0.019999999999999907], "policy_red_v35_reward": [-1.0139999999999996, 0.4859346144425925], "policy_red_v15_reward": [-1.0139999999999998], "policy_red_v6_reward": [0.4329218750000011], "policy_red_v23_reward": [1.483934614442592], "policy_red_v39_reward": [1.4956932378152046]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.810972929899276, "mean_inference_ms": 7.744315239074724, "mean_action_processing_ms": 0.2926086103469998, "mean_env_wait_ms": 0.38911854183372263, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09832048416137695, "StateBufferConnector_ms": 0.004136204719543457, "ViewRequirementAgentConnector_ms": 0.11475121974945068}}, "episode_reward_max": 4.475182655588147, "episode_reward_min": 0.18610937499999958, "episode_reward_mean": 2.221463000165335, "episode_len_mean": 100.83, "episodes_this_iter": 22, "policy_reward_min": {"red_v8": -2.0119999999999996, "red": -1.0283067621838298, "blue": -2.0169999999999986, "red_v7": -0.5079999999999993, "red_v31": 0.4986932378161699, "red_v27": 2.9307713628161705, "red_v32": 0.39969323781617294, "red_v1": -0.595, "red_v17": 1.3902836050000003, "red_v22": -2.0089999999999995, "red_v10": -1.0199999999999998, "red_v26": -1.2059999999999815, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": -2.0069999999999997, "red_v25": -1.564, "red_v28": -0.5549999999999998, "red_v9": -0.5169999999999999, "red_v38": -0.687, "red_v4": -1.008999999999999, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v36": -0.509, "red_v13": -1.5189999999999986, "red_v30": -1.0089999999999997, "red_v19": -1.009, "red_v20": -0.019999999999999907, "red_v35": -1.0139999999999996, "red_v15": -1.0139999999999998, "red_v6": 0.4329218750000011, "red_v23": 1.483934614442592, "red_v39": 1.4956932378152046}, "policy_reward_max": {"red_v8": -0.004, "red": 3.9856342835440546, "blue": 2.319, "red_v7": -0.5079999999999993, "red_v31": 0.4986932378161699, "red_v27": 2.9307713628161705, "red_v32": 0.39969323781617294, "red_v1": -0.595, "red_v17": 1.3902836050000003, "red_v22": -1.003, "red_v10": 0.49869323781520397, "red_v26": 0.9121718750000001, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": 0.492, "red_v25": -1.564, "red_v28": -0.5549999999999998, "red_v9": -0.5169999999999999, "red_v38": -0.687, "red_v4": -1.008999999999999, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v36": -0.509, "red_v13": -1.5189999999999986, "red_v30": -1.0089999999999997, "red_v19": 1.448693237816175, "red_v20": -0.019999999999999907, "red_v35": 0.4859346144425925, "red_v15": -1.0139999999999998, "red_v6": 0.4329218750000011, "red_v23": 1.483934614442592, "red_v39": 1.4956932378152046}, "policy_reward_mean": {"red_v8": -0.6417499999999999, "red": 2.965219790758488, "blue": -1.1755624999999987, "red_v7": -0.5079999999999993, "red_v31": 0.4986932378161699, "red_v27": 2.9307713628161705, "red_v32": 0.39969323781617294, "red_v1": -0.595, "red_v17": 1.3902836050000003, "red_v22": -1.5059999999999998, "red_v10": -0.3870766905461986, "red_v26": -0.14691406249999073, "red_v16": 0.4746932378161717, "red_v5": -1.5059999999999998, "red_v2": -0.7014999999999998, "red_v25": -1.564, "red_v28": -0.5549999999999998, "red_v9": -0.5169999999999999, "red_v38": -0.687, "red_v4": -1.008999999999999, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v36": -0.509, "red_v13": -1.5189999999999986, "red_v30": -1.0089999999999997, "red_v19": -0.04439885243676409, "red_v20": -0.019999999999999907, "red_v35": -0.26403269277870356, "red_v15": -1.0139999999999998, "red_v6": 0.4329218750000011, "red_v23": 1.483934614442592, "red_v39": 1.4956932378152046}, "hist_stats": {"episode_reward": [2.9788963628161698, 2.413333862816172, 1.9690838628161704, 3.95298022563234, 0.8670023550000001, 2.0898213628161733, 3.7782614756323523, 2.7876776128161795, 0.9808182378161706, 4.37739871781617, 2.9249901128161726, 1.9710838628161704, 2.4514276128161714, 1.4438338628161715, 2.4722783644425923, 0.18610937499999958, 2.4811151128161697, 1.4158651128161708, 3.909917725632344, 1.4787088628161702, 1.2642088628161718, 0.9660526128161705, 2.959865112816171, 1.4675752394425925, 1.1639093750000002, 3.983698975631374, 1.97530261281617, 1.4699744878161702, 1.7854086050000015, 2.3545057378161753, 2.4546221144425933, 2.4537244878161713, 2.374583862816171, 3.289021362816172, 1.4794119878161702, 1.9836342835440548, 2.65076875, 2.93411511281617, 2.4456151128161716, 1.483223792772942, 2.4569432378161706, 2.951724487816171, 3.4670526128161705, 1.3783182378161731, 1.9686776128161707, 1.6613937500000002, 3.466568237816171, 3.053411987816181, 1.906578125, 2.368705480000001, 1.4831151128161704, 2.9748963628161706, 3.987702521360225, 4.441499396360226, 1.4829276128152036, 2.438615112816172, 2.48470886281617, 1.9174901128161719, 0.8040213628161774, 1.558625000000006, 2.4686846144425925, 2.4735994878161702, 1.4800057378161706, 4.186664342816181, 1.48692761281617, 2.4749814894425923, 2.9818182378152036, 1.9574588628161715, 2.4748963628161706, 2.4207783644425924, 1.485630737815204, 1.290693237816174, 1.9279375, 1.4827088628161702, 1.2433963628161764, 1.6577687500000002, 1.4853374085440554, 2.430583862816171, 1.3469711050000006, 2.4459901128161707, 2.4790057378161703, 2.4755213628152037, 0.7416932378162148, 1.8882401128161972, 1.6696125000000004, 3.3256846144425927, 2.923333862816172, 2.4743026128161705, 0.9128564894425937, 2.4606619878161915, 1.4865206677729415, 4.4745646572155335, 2.4719744878161705, 2.97181823781617, 0.39739636281620183, 0.5273026128161706, 2.4784119878161706, 0.6798564894425919, 4.475182655588147, 1.5067244878161719], "episode_lengths": [31, 83, 35, 66, 26, 71, 168, 165, 24, 25, 65, 35, 53, 51, 18, 445, 25, 41, 86, 27, 251, 45, 41, 19, 13, 28, 29, 38, 88, 124, 36, 54, 67, 55, 26, 22, 26, 25, 57, 22, 48, 54, 45, 120, 37, 18, 40, 282, 39, 25, 25, 31, 30, 63, 21, 57, 27, 97, 183, 248, 16, 30, 28, 164, 21, 17, 24, 43, 31, 50, 20, 192, 20, 27, 191, 26, 21, 67, 36, 65, 28, 23, 1280, 433, 12, 16, 83, 29, 57, 394, 23, 20, 38, 24, 639, 349, 26, 633, 33, 758], "policy_red_v8_reward": [-0.004, -0.5359999999999998, -2.0119999999999996, -0.015000000000000001], "policy_blue_reward": [-1.0279999999999987, -1.5079999999999998, -1.5099999999999998, -2.0169999999999986, -1.005, -1.133, -1.0069999999999997, -2.008, -1.0579999999999998, -0.011000000000000003, -2.009, -2.0089999999999995, -2.0119999999999996, -0.5309999999999999, -1.0349999999999975, -1.0069999999999995, -1.0149999999999988, -2.008, -2.002, -0.006, -2.005, -1.0089999999999997, -1.0430000000000001, -2.006, -2.0089999999999995, 0.49, -0.013000000000000001, -2.0039999999999996, -2.008, -1.0229999999999995, 2.2516249999999998, -1.0059999999999996, -2.0059999999999993, -2.0069999999999997, -1.001, -0.007, -2.0129999999999995, -1.0079999999999996, -1.0149999999999992, -2.005, 2.319, -0.004, -2.0049999999999994, -2.005, -2.005, -1.3379999999999677, -2.005, -0.021000000000000005, -1.0119999999999998, -1.1629999999999971, -2.0029999999999997, -1.008999999999999, -1.6640000000000001, -1.1999999999999815], "policy_red_v7_reward": [-0.5079999999999993], "policy_red_v31_reward": [0.4986932378161699], "policy_red_v27_reward": [2.9307713628161705], "policy_red_v32_reward": [0.39969323781617294], "policy_red_v1_reward": [-0.595], "policy_red_v17_reward": [1.3902836050000003], "policy_red_v22_reward": [-2.0089999999999995, -1.003], "policy_red_v10_reward": [-1.0179999999999987, 0.49869323781520397, -1.0199999999999998, -0.009000000000000001], "policy_red_v26_reward": [0.9121718750000001, -1.2059999999999815], "policy_red_v16_reward": [0.4746932378161717], "policy_red_v5_reward": [-1.5059999999999998], "policy_red_v2_reward": [-2.0069999999999997, -0.16799999999999982, 0.492, -1.123], "policy_red_v25_reward": [-1.564], "policy_red_v28_reward": [-0.5549999999999998], "policy_red_v9_reward": [-0.5169999999999999], "policy_red_v38_reward": [-0.687], "policy_red_v4_reward": [-1.008999999999999], "policy_red_v21_reward": [0.501103033544055], "policy_red_v12_reward": [1.486103033544055], "policy_red_v36_reward": [-0.509], "policy_red_v13_reward": [-1.5189999999999986], "policy_red_v30_reward": [-1.0089999999999997], "policy_red_v19_reward": [1.448693237816175, -1.0069999999999995, 0.24570312500000402, 0.09960937499999989, -1.009], "policy_red_v20_reward": [-0.019999999999999907], "policy_red_v35_reward": [-1.0139999999999996, 0.4859346144425925], "policy_red_v15_reward": [-1.0139999999999998], "policy_red_v6_reward": [0.4329218750000011], "policy_red_v23_reward": [1.483934614442592], "policy_red_v39_reward": [1.4956932378152046]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.810972929899276, "mean_inference_ms": 7.744315239074724, "mean_action_processing_ms": 0.2926086103469998, "mean_env_wait_ms": 0.38911854183372263, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09832048416137695, "StateBufferConnector_ms": 0.004136204719543457, "ViewRequirementAgentConnector_ms": 0.11475121974945068}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.53157095081866, "num_env_steps_trained_throughput_per_sec": 200.53157095081866, "timesteps_total": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 20025.183, "sample_time_ms": 1144.632, "learn_time_ms": 18798.518, "learn_throughput": 212.783, "synch_weights_time_ms": 79.147}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "episodes_total": 889, "training_iteration": 76, "trial_id": "a9680_00000", "date": "2023-09-24_03-03-34", "timestamp": 1695539014, "time_this_iter_s": 19.958788633346558, "time_total_s": 1515.2248630523682, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b3426f4f0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b342843a0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34284430>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1515.2248630523682, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 5.534375, "ram_util_percent": 21.790625}, "win_rate": 0.8, "league_size": 46}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.080254378914833, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.007364597183186561, "policy_loss": -0.061876495628772926, "vf_loss": 0.09659734497157237, "vf_explained_var": 0.7736786335706711, "kl": 0.018323692724050034, "entropy": 2.032436044762532, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 73440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 616000, "num_agent_steps_trained": 616000}, "sampler_results": {"episode_reward_max": 4.475182655588147, "episode_reward_min": -1.6063848871838224, "episode_reward_mean": 2.1682990710453987, "episode_len_mean": 120.51, "episode_media": {}, "episodes_this_iter": 23, "policy_reward_min": {"blue": -2.0129999999999995, "red": -1.9583848871838263, "red_v2": -2.0069999999999997, "red_v10": -1.0199999999999998, "red_v25": -1.564, "red_v28": -0.5549999999999998, "red_v9": -0.5169999999999999, "red_v38": -0.687, "red_v4": -1.008999999999999, "red_v21": 0.501103033544055, "red_v12": -1.0069999999999995, "red_v22": -1.003, "red_v36": -1.0059999999999998, "red_v13": -1.5189999999999986, "red_v30": -1.0089999999999997, "red_v19": -1.009, "red_v20": -0.019999999999999907, "red_v8": -2.0119999999999996, "red_v35": -1.0139999999999996, "red_v15": -1.0139999999999998, "red_v26": -1.2059999999999815, "red_v6": 0.4329218750000011, "red_v23": 1.483934614442592, "red_v39": 0.1770500000000006, "red_v31": -0.19830676218383003, "red_v16": -2.0039999999999996, "red_v34": 0.39428360500000026, "red_v1": -1.1609999999999872}, "policy_reward_max": {"blue": 2.319, "red": 3.9856342835440546, "red_v2": 0.492, "red_v10": 0.49869323781520397, "red_v25": -1.564, "red_v28": -0.5549999999999998, "red_v9": -0.5169999999999999, "red_v38": -0.687, "red_v4": -1.008999999999999, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v22": -1.003, "red_v36": -0.509, "red_v13": -1.5189999999999986, "red_v30": -1.0089999999999997, "red_v19": 1.448693237816175, "red_v20": -0.019999999999999907, "red_v8": -0.015000000000000001, "red_v35": 0.4859346144425925, "red_v15": -1.0139999999999998, "red_v26": -1.2059999999999815, "red_v6": 0.4329218750000011, "red_v23": 1.483934614442592, "red_v39": 1.4956932378152046, "red_v31": 0.47569323781617023, "red_v16": -2.0039999999999996, "red_v34": 0.39428360500000026, "red_v1": -1.1609999999999872}, "policy_reward_mean": {"blue": -1.0939976165254224, "red": 2.9703065701448748, "red_v2": -0.7014999999999998, "red_v10": -0.17676892072826525, "red_v25": -1.564, "red_v28": -0.5549999999999998, "red_v9": -0.5169999999999999, "red_v38": -0.687, "red_v4": -1.008999999999999, "red_v21": 0.501103033544055, "red_v12": 0.2395515167720278, "red_v22": -1.003, "red_v36": -0.7574999999999998, "red_v13": -1.5189999999999986, "red_v30": -1.0089999999999997, "red_v19": -0.04439885243676409, "red_v20": -0.019999999999999907, "red_v8": -1.0134999999999998, "red_v35": -0.26403269277870356, "red_v15": -1.0139999999999998, "red_v26": -1.2059999999999815, "red_v6": 0.4329218750000011, "red_v23": 1.483934614442592, "red_v39": 0.8363716189076026, "red_v31": 0.1386932378161701, "red_v16": -2.0039999999999996, "red_v34": 0.39428360500000026, "red_v1": -1.1609999999999872}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.4675752394425925, 1.1639093750000002, 3.983698975631374, 1.97530261281617, 1.4699744878161702, 1.7854086050000015, 2.3545057378161753, 2.4546221144425933, 2.4537244878161713, 2.374583862816171, 3.289021362816172, 1.4794119878161702, 1.9836342835440548, 2.65076875, 2.93411511281617, 2.4456151128161716, 1.483223792772942, 2.4569432378161706, 2.951724487816171, 3.4670526128161705, 1.3783182378161731, 1.9686776128161707, 1.6613937500000002, 3.466568237816171, 3.053411987816181, 1.906578125, 2.368705480000001, 1.4831151128161704, 2.9748963628161706, 3.987702521360225, 4.441499396360226, 1.4829276128152036, 2.438615112816172, 2.48470886281617, 1.9174901128161719, 0.8040213628161774, 1.558625000000006, 2.4686846144425925, 2.4735994878161702, 1.4800057378161706, 4.186664342816181, 1.48692761281617, 2.4749814894425923, 2.9818182378152036, 1.9574588628161715, 2.4748963628161706, 2.4207783644425924, 1.485630737815204, 1.290693237816174, 1.9279375, 1.4827088628161702, 1.2433963628161764, 1.6577687500000002, 1.4853374085440554, 2.430583862816171, 1.3469711050000006, 2.4459901128161707, 2.4790057378161703, 2.4755213628152037, 0.7416932378162148, 1.8882401128161972, 1.6696125000000004, 3.3256846144425927, 2.923333862816172, 2.4743026128161705, 0.9128564894425937, 2.4606619878161915, 1.4865206677729415, 4.4745646572155335, 2.4719744878161705, 2.97181823781617, 0.39739636281620183, 0.5273026128161706, 2.4784119878161706, 0.6798564894425919, 4.475182655588147, 1.5067244878161719, 0.7260057378161759, 0.8122905335440737, 1.921214600632364, 3.661946362816171, 1.4722783644425925, 1.4780057378161704, 2.881627355, 2.4748963628152043, -1.6063848871838224, 2.9638651128161713, 2.4768217835440556, 2.48341198781617, 0.9223338628161719, 2.4842244878161703, 2.463052612816171, 2.3773304800000004, 1.6689093750000001, 2.6712088628161963, 1.8759242300000005, 0.88702136281617, 3.8896174678161697, 3.9359021006323434, 1.8828338628161967], "episode_lengths": [19, 13, 28, 29, 38, 88, 124, 36, 54, 67, 55, 26, 22, 26, 25, 57, 22, 48, 54, 45, 120, 37, 18, 40, 282, 39, 25, 25, 31, 30, 63, 21, 57, 27, 97, 183, 248, 16, 30, 28, 164, 21, 17, 24, 43, 31, 50, 20, 192, 20, 27, 191, 26, 21, 67, 36, 65, 28, 23, 1280, 433, 12, 16, 83, 29, 57, 394, 23, 20, 38, 24, 639, 349, 26, 633, 33, 758, 284, 836, 535, 31, 18, 28, 18, 31, 569, 41, 26, 26, 83, 22, 45, 17, 13, 571, 19, 119, 19, 59, 435], "policy_blue_reward": [-2.009, -2.0089999999999995, -2.0119999999999996, -0.5309999999999999, -1.0349999999999975, -1.0069999999999995, -1.0149999999999988, -2.008, -2.002, -0.006, -2.005, -1.0089999999999997, -1.0430000000000001, -2.006, -2.0089999999999995, 0.49, -0.013000000000000001, -2.0039999999999996, -2.008, -1.0229999999999995, 2.2516249999999998, -1.0059999999999996, -2.0059999999999993, -2.0069999999999997, -1.001, -0.007, -2.0129999999999995, -1.0079999999999996, -1.0149999999999992, -2.005, 2.319, -0.004, -2.0049999999999994, -2.005, -2.005, -1.3379999999999677, -2.005, -0.021000000000000005, -1.0119999999999998, -1.1629999999999971, -2.0029999999999997, -1.008999999999999, -1.6640000000000001, -1.1999999999999815, -1.578, -0.7890000000000001, -2.0039999999999996, -2.0069999999999997, -0.004, -1.0089999999999995, 0.3520000000000052, -0.009000000000000001, -1.0119999999999991, -1.0049999999999997, -1.024, -1.009, 1.2875156250000028, -2.008, -1.532], "policy_red_v2_reward": [-2.0069999999999997, -0.16799999999999982, 0.492, -1.123], "policy_red_v10_reward": [0.49869323781520397, -1.0199999999999998, -0.009000000000000001], "policy_red_v25_reward": [-1.564], "policy_red_v28_reward": [-0.5549999999999998], "policy_red_v9_reward": [-0.5169999999999999], "policy_red_v38_reward": [-0.687], "policy_red_v4_reward": [-1.008999999999999], "policy_red_v21_reward": [0.501103033544055], "policy_red_v12_reward": [1.486103033544055, -1.0069999999999995], "policy_red_v22_reward": [-1.003], "policy_red_v36_reward": [-0.509, -1.0059999999999998], "policy_red_v13_reward": [-1.5189999999999986], "policy_red_v30_reward": [-1.0089999999999997], "policy_red_v19_reward": [1.448693237816175, -1.0069999999999995, 0.24570312500000402, 0.09960937499999989, -1.009], "policy_red_v20_reward": [-0.019999999999999907], "policy_red_v8_reward": [-2.0119999999999996, -0.015000000000000001], "policy_red_v35_reward": [-1.0139999999999996, 0.4859346144425925], "policy_red_v15_reward": [-1.0139999999999998], "policy_red_v26_reward": [-1.2059999999999815], "policy_red_v6_reward": [0.4329218750000011], "policy_red_v23_reward": [1.483934614442592], "policy_red_v39_reward": [1.4956932378152046, 0.1770500000000006], "policy_red_v31_reward": [-0.19830676218383003, 0.47569323781617023], "policy_red_v16_reward": [-2.0039999999999996], "policy_red_v34_reward": [0.39428360500000026], "policy_red_v1_reward": [-1.1609999999999872]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8117166294614624, "mean_inference_ms": 7.770036423951277, "mean_action_processing_ms": 0.2937787378361454, "mean_env_wait_ms": 0.3894744326954767, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09795427322387695, "StateBufferConnector_ms": 0.004106760025024414, "ViewRequirementAgentConnector_ms": 0.11366069316864014}}, "episode_reward_max": 4.475182655588147, "episode_reward_min": -1.6063848871838224, "episode_reward_mean": 2.1682990710453987, "episode_len_mean": 120.51, "episodes_this_iter": 23, "policy_reward_min": {"blue": -2.0129999999999995, "red": -1.9583848871838263, "red_v2": -2.0069999999999997, "red_v10": -1.0199999999999998, "red_v25": -1.564, "red_v28": -0.5549999999999998, "red_v9": -0.5169999999999999, "red_v38": -0.687, "red_v4": -1.008999999999999, "red_v21": 0.501103033544055, "red_v12": -1.0069999999999995, "red_v22": -1.003, "red_v36": -1.0059999999999998, "red_v13": -1.5189999999999986, "red_v30": -1.0089999999999997, "red_v19": -1.009, "red_v20": -0.019999999999999907, "red_v8": -2.0119999999999996, "red_v35": -1.0139999999999996, "red_v15": -1.0139999999999998, "red_v26": -1.2059999999999815, "red_v6": 0.4329218750000011, "red_v23": 1.483934614442592, "red_v39": 0.1770500000000006, "red_v31": -0.19830676218383003, "red_v16": -2.0039999999999996, "red_v34": 0.39428360500000026, "red_v1": -1.1609999999999872}, "policy_reward_max": {"blue": 2.319, "red": 3.9856342835440546, "red_v2": 0.492, "red_v10": 0.49869323781520397, "red_v25": -1.564, "red_v28": -0.5549999999999998, "red_v9": -0.5169999999999999, "red_v38": -0.687, "red_v4": -1.008999999999999, "red_v21": 0.501103033544055, "red_v12": 1.486103033544055, "red_v22": -1.003, "red_v36": -0.509, "red_v13": -1.5189999999999986, "red_v30": -1.0089999999999997, "red_v19": 1.448693237816175, "red_v20": -0.019999999999999907, "red_v8": -0.015000000000000001, "red_v35": 0.4859346144425925, "red_v15": -1.0139999999999998, "red_v26": -1.2059999999999815, "red_v6": 0.4329218750000011, "red_v23": 1.483934614442592, "red_v39": 1.4956932378152046, "red_v31": 0.47569323781617023, "red_v16": -2.0039999999999996, "red_v34": 0.39428360500000026, "red_v1": -1.1609999999999872}, "policy_reward_mean": {"blue": -1.0939976165254224, "red": 2.9703065701448748, "red_v2": -0.7014999999999998, "red_v10": -0.17676892072826525, "red_v25": -1.564, "red_v28": -0.5549999999999998, "red_v9": -0.5169999999999999, "red_v38": -0.687, "red_v4": -1.008999999999999, "red_v21": 0.501103033544055, "red_v12": 0.2395515167720278, "red_v22": -1.003, "red_v36": -0.7574999999999998, "red_v13": -1.5189999999999986, "red_v30": -1.0089999999999997, "red_v19": -0.04439885243676409, "red_v20": -0.019999999999999907, "red_v8": -1.0134999999999998, "red_v35": -0.26403269277870356, "red_v15": -1.0139999999999998, "red_v26": -1.2059999999999815, "red_v6": 0.4329218750000011, "red_v23": 1.483934614442592, "red_v39": 0.8363716189076026, "red_v31": 0.1386932378161701, "red_v16": -2.0039999999999996, "red_v34": 0.39428360500000026, "red_v1": -1.1609999999999872}, "hist_stats": {"episode_reward": [1.4675752394425925, 1.1639093750000002, 3.983698975631374, 1.97530261281617, 1.4699744878161702, 1.7854086050000015, 2.3545057378161753, 2.4546221144425933, 2.4537244878161713, 2.374583862816171, 3.289021362816172, 1.4794119878161702, 1.9836342835440548, 2.65076875, 2.93411511281617, 2.4456151128161716, 1.483223792772942, 2.4569432378161706, 2.951724487816171, 3.4670526128161705, 1.3783182378161731, 1.9686776128161707, 1.6613937500000002, 3.466568237816171, 3.053411987816181, 1.906578125, 2.368705480000001, 1.4831151128161704, 2.9748963628161706, 3.987702521360225, 4.441499396360226, 1.4829276128152036, 2.438615112816172, 2.48470886281617, 1.9174901128161719, 0.8040213628161774, 1.558625000000006, 2.4686846144425925, 2.4735994878161702, 1.4800057378161706, 4.186664342816181, 1.48692761281617, 2.4749814894425923, 2.9818182378152036, 1.9574588628161715, 2.4748963628161706, 2.4207783644425924, 1.485630737815204, 1.290693237816174, 1.9279375, 1.4827088628161702, 1.2433963628161764, 1.6577687500000002, 1.4853374085440554, 2.430583862816171, 1.3469711050000006, 2.4459901128161707, 2.4790057378161703, 2.4755213628152037, 0.7416932378162148, 1.8882401128161972, 1.6696125000000004, 3.3256846144425927, 2.923333862816172, 2.4743026128161705, 0.9128564894425937, 2.4606619878161915, 1.4865206677729415, 4.4745646572155335, 2.4719744878161705, 2.97181823781617, 0.39739636281620183, 0.5273026128161706, 2.4784119878161706, 0.6798564894425919, 4.475182655588147, 1.5067244878161719, 0.7260057378161759, 0.8122905335440737, 1.921214600632364, 3.661946362816171, 1.4722783644425925, 1.4780057378161704, 2.881627355, 2.4748963628152043, -1.6063848871838224, 2.9638651128161713, 2.4768217835440556, 2.48341198781617, 0.9223338628161719, 2.4842244878161703, 2.463052612816171, 2.3773304800000004, 1.6689093750000001, 2.6712088628161963, 1.8759242300000005, 0.88702136281617, 3.8896174678161697, 3.9359021006323434, 1.8828338628161967], "episode_lengths": [19, 13, 28, 29, 38, 88, 124, 36, 54, 67, 55, 26, 22, 26, 25, 57, 22, 48, 54, 45, 120, 37, 18, 40, 282, 39, 25, 25, 31, 30, 63, 21, 57, 27, 97, 183, 248, 16, 30, 28, 164, 21, 17, 24, 43, 31, 50, 20, 192, 20, 27, 191, 26, 21, 67, 36, 65, 28, 23, 1280, 433, 12, 16, 83, 29, 57, 394, 23, 20, 38, 24, 639, 349, 26, 633, 33, 758, 284, 836, 535, 31, 18, 28, 18, 31, 569, 41, 26, 26, 83, 22, 45, 17, 13, 571, 19, 119, 19, 59, 435], "policy_blue_reward": [-2.009, -2.0089999999999995, -2.0119999999999996, -0.5309999999999999, -1.0349999999999975, -1.0069999999999995, -1.0149999999999988, -2.008, -2.002, -0.006, -2.005, -1.0089999999999997, -1.0430000000000001, -2.006, -2.0089999999999995, 0.49, -0.013000000000000001, -2.0039999999999996, -2.008, -1.0229999999999995, 2.2516249999999998, -1.0059999999999996, -2.0059999999999993, -2.0069999999999997, -1.001, -0.007, -2.0129999999999995, -1.0079999999999996, -1.0149999999999992, -2.005, 2.319, -0.004, -2.0049999999999994, -2.005, -2.005, -1.3379999999999677, -2.005, -0.021000000000000005, -1.0119999999999998, -1.1629999999999971, -2.0029999999999997, -1.008999999999999, -1.6640000000000001, -1.1999999999999815, -1.578, -0.7890000000000001, -2.0039999999999996, -2.0069999999999997, -0.004, -1.0089999999999995, 0.3520000000000052, -0.009000000000000001, -1.0119999999999991, -1.0049999999999997, -1.024, -1.009, 1.2875156250000028, -2.008, -1.532], "policy_red_v2_reward": [-2.0069999999999997, -0.16799999999999982, 0.492, -1.123], "policy_red_v10_reward": [0.49869323781520397, -1.0199999999999998, -0.009000000000000001], "policy_red_v25_reward": [-1.564], "policy_red_v28_reward": [-0.5549999999999998], "policy_red_v9_reward": [-0.5169999999999999], "policy_red_v38_reward": [-0.687], "policy_red_v4_reward": [-1.008999999999999], "policy_red_v21_reward": [0.501103033544055], "policy_red_v12_reward": [1.486103033544055, -1.0069999999999995], "policy_red_v22_reward": [-1.003], "policy_red_v36_reward": [-0.509, -1.0059999999999998], "policy_red_v13_reward": [-1.5189999999999986], "policy_red_v30_reward": [-1.0089999999999997], "policy_red_v19_reward": [1.448693237816175, -1.0069999999999995, 0.24570312500000402, 0.09960937499999989, -1.009], "policy_red_v20_reward": [-0.019999999999999907], "policy_red_v8_reward": [-2.0119999999999996, -0.015000000000000001], "policy_red_v35_reward": [-1.0139999999999996, 0.4859346144425925], "policy_red_v15_reward": [-1.0139999999999998], "policy_red_v26_reward": [-1.2059999999999815], "policy_red_v6_reward": [0.4329218750000011], "policy_red_v23_reward": [1.483934614442592], "policy_red_v39_reward": [1.4956932378152046, 0.1770500000000006], "policy_red_v31_reward": [-0.19830676218383003, 0.47569323781617023], "policy_red_v16_reward": [-2.0039999999999996], "policy_red_v34_reward": [0.39428360500000026], "policy_red_v1_reward": [-1.1609999999999872]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8117166294614624, "mean_inference_ms": 7.770036423951277, "mean_action_processing_ms": 0.2937787378361454, "mean_env_wait_ms": 0.3894744326954767, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09795427322387695, "StateBufferConnector_ms": 0.004106760025024414, "ViewRequirementAgentConnector_ms": 0.11366069316864014}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 616000, "num_agent_steps_trained": 616000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.13294763427206, "num_env_steps_trained_throughput_per_sec": 201.13294763427206, "timesteps_total": 308000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 616000, "timers": {"training_iteration_time_ms": 20004.262, "sample_time_ms": 1140.721, "learn_time_ms": 18781.435, "learn_throughput": 212.976, "synch_weights_time_ms": 79.234}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 616000, "num_agent_steps_trained": 616000}, "done": false, "episodes_total": 912, "training_iteration": 77, "trial_id": "a9680_00000", "date": "2023-09-24_03-03-57", "timestamp": 1695539037, "time_this_iter_s": 19.89962124824524, "time_total_s": 1535.1244843006134, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b3426cdc0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b342845e0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34284670>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1535.1244843006134, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 5.142424242424242, "ram_util_percent": 21.972727272727273}, "win_rate": 0.81, "league_size": 47}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3292632492880028, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.013417036902198257, "policy_loss": -0.05781429664251239, "vf_loss": 0.1313032188763221, "vf_explained_var": 0.8164240305622419, "kl": 0.016546615182414827, "entropy": 1.8662522739420335, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 74400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "sampler_results": {"episode_reward_max": 4.475182655588147, "episode_reward_min": -1.6063848871838224, "episode_reward_mean": 2.1448216625003, "episode_len_mean": 164.24, "episode_media": {}, "episodes_this_iter": 37, "policy_reward_min": {"red_v30": -1.0089999999999997, "red": -1.9583848871838263, "blue": -2.013, "red_v19": -1.009, "red_v2": -1.123, "red_v20": -0.019999999999999907, "red_v8": -2.0119999999999996, "red_v35": -1.0139999999999996, "red_v15": -1.0139999999999998, "red_v26": -1.2059999999999815, "red_v6": 0.4329218750000011, "red_v23": 1.483934614442592, "red_v39": 0.1770500000000006, "red_v31": -0.19830676218383003, "red_v12": -1.0069999999999995, "red_v36": -1.0059999999999998, "red_v16": -2.0039999999999996, "red_v34": 0.39428360500000026, "red_v1": -1.1609999999999872, "red_v44": 1.9424843749999998, "red_v17": -0.1499999999999997, "red_v25": -0.006, "red_v24": 3.4071689894425945, "red_v21": -2.0039999999999996, "red_v40": -2.0339999999999976, "red_v27": 0.4966932378161699, "red_v33": -0.019000000000000006, "red_v18": -1.025, "red_v4": -1.0069999999999995, "red_v42": 0.481, "red_v13": -0.012000000000000004}, "policy_reward_max": {"red_v30": -1.0089999999999997, "red": 3.995740112815204, "blue": 2.319, "red_v19": 1.448693237816175, "red_v2": -1.123, "red_v20": -0.019999999999999907, "red_v8": -0.015000000000000001, "red_v35": 0.4859346144425925, "red_v15": -0.56530676218383, "red_v26": 1.8500596144425923, "red_v6": 0.4329218750000011, "red_v23": 1.483934614442592, "red_v39": 1.4956932378152046, "red_v31": 0.47569323781617023, "red_v12": -1.0069999999999995, "red_v36": -1.0059999999999998, "red_v16": -2.0039999999999996, "red_v34": 0.39428360500000026, "red_v1": -1.1609999999999872, "red_v44": 1.9424843749999998, "red_v17": -0.1499999999999997, "red_v25": -0.006, "red_v24": 3.4071689894425945, "red_v21": -2.0039999999999996, "red_v40": -1.001, "red_v27": 0.4966932378161699, "red_v33": -0.019000000000000006, "red_v18": -1.025, "red_v4": -1.0069999999999995, "red_v42": 0.481, "red_v13": -0.012000000000000004}, "policy_reward_mean": {"red_v30": -1.0089999999999997, "red": 2.8627046889592083, "blue": -1.0916646012931008, "red_v19": -0.04439885243676409, "red_v2": -1.123, "red_v20": -0.019999999999999907, "red_v8": -1.087999999999994, "red_v35": -0.017043590371605005, "red_v15": -0.7896533810919149, "red_v26": 0.32202980722130536, "red_v6": 0.4329218750000011, "red_v23": 1.483934614442592, "red_v39": 0.8363716189076026, "red_v31": 0.1386932378161701, "red_v12": -1.0069999999999995, "red_v36": -1.0059999999999998, "red_v16": -2.0039999999999996, "red_v34": 0.39428360500000026, "red_v1": -1.1609999999999872, "red_v44": 1.9424843749999998, "red_v17": -0.1499999999999997, "red_v25": -0.006, "red_v24": 3.4071689894425945, "red_v21": -2.0039999999999996, "red_v40": -1.5174999999999987, "red_v27": 0.4966932378161699, "red_v33": -0.019000000000000006, "red_v18": -1.025, "red_v4": -1.0069999999999995, "red_v42": 0.481, "red_v13": -0.012000000000000004}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.4686846144425925, 2.4735994878161702, 1.4800057378161706, 4.186664342816181, 1.48692761281617, 2.4749814894425923, 2.9818182378152036, 1.9574588628161715, 2.4748963628161706, 2.4207783644425924, 1.485630737815204, 1.290693237816174, 1.9279375, 1.4827088628161702, 1.2433963628161764, 1.6577687500000002, 1.4853374085440554, 2.430583862816171, 1.3469711050000006, 2.4459901128161707, 2.4790057378161703, 2.4755213628152037, 0.7416932378162148, 1.8882401128161972, 1.6696125000000004, 3.3256846144425927, 2.923333862816172, 2.4743026128161705, 0.9128564894425937, 2.4606619878161915, 1.4865206677729415, 4.4745646572155335, 2.4719744878161705, 2.97181823781617, 0.39739636281620183, 0.5273026128161706, 2.4784119878161706, 0.6798564894425919, 4.475182655588147, 1.5067244878161719, 0.7260057378161759, 0.8122905335440737, 1.921214600632364, 3.661946362816171, 1.4722783644425925, 1.4780057378161704, 2.881627355, 2.4748963628152043, -1.6063848871838224, 2.9638651128161713, 2.4768217835440556, 2.48341198781617, 0.9223338628161719, 2.4842244878161703, 2.463052612816171, 2.3773304800000004, 1.6689093750000001, 2.6712088628161963, 1.8759242300000005, 0.88702136281617, 3.8896174678161697, 3.9359021006323434, 1.8828338628161967, 3.9474716022587635, 2.4767088628161704, 1.948177612816171, 1.4893338628161699, 0.9346221144425924, 3.3464425427729414, 2.9829276128161704, 2.47889636281617, 0.8497713628152047, 2.3865213628161706, 1.622786987816186, 2.4658963628161703, 2.9723877394425924, 3.414862227258764, 0.12469323781617148, 1.6658000000000004, 3.2126677256323557, 2.8705179800000002, 1.489743658544055, 2.4600526128161704, 2.4762783644425923, 1.6127557378161883, 2.4699744878161702, 2.4714155335440555, 3.9685271006323415, 2.9600838628161714, 2.2977528522578052, 2.418365112816172, 1.5076307378161955, 2.466490112816171, 1.2156307378161715, 1.989740112815204, 1.48822448781617, 3.435286987816172, 2.955458862816172, 0.6446932378162156, 2.1357401128161877], "episode_lengths": [16, 30, 28, 164, 21, 17, 24, 43, 31, 50, 20, 192, 20, 27, 191, 26, 21, 67, 36, 65, 28, 23, 1280, 433, 12, 16, 83, 29, 57, 394, 23, 20, 38, 24, 639, 349, 26, 633, 33, 758, 284, 836, 535, 31, 18, 28, 18, 31, 569, 41, 26, 26, 83, 22, 45, 17, 13, 571, 19, 119, 19, 59, 435, 50, 27, 69, 19, 36, 16, 21, 31, 135, 87, 290, 31, 15, 85, 1280, 16, 230, 21, 19, 45, 18, 300, 38, 28, 51, 35, 152, 73, 660, 33, 980, 17, 22, 66, 43, 1280, 273], "policy_red_v30_reward": [-1.0089999999999997], "policy_blue_reward": [-1.0059999999999996, -2.0059999999999993, -2.0069999999999997, -1.001, -0.007, -2.0129999999999995, -1.0079999999999996, -1.0149999999999992, -2.005, 2.319, -0.004, -2.0049999999999994, -2.005, -2.005, -1.3379999999999677, -2.005, -0.021000000000000005, -1.0119999999999998, -1.1629999999999971, -2.0029999999999997, -1.008999999999999, -1.6640000000000001, -1.1999999999999815, -1.578, -0.7890000000000001, -2.0039999999999996, -2.0069999999999997, -0.004, -1.0089999999999995, 0.3520000000000052, -0.009000000000000001, -1.0119999999999991, -1.0049999999999997, -1.024, -1.009, 1.2875156250000028, -2.008, -1.532, -1.0119999999999993, -2.005, -2.013, -0.009000000000000001, -1.0049999999999997, -1.5399999999999991, -1.025999999999999, -1.5809999999999982, -1.0129999999999992, -0.009000000000000001, -2.0029999999999997, -1.013999999999999, -1.0089999999999995, -1.0079999999999998, 1.1989374999999998, -1.2959999999999743, -2.0059999999999993, -2.0039999999999996, -1.3499999999999657, -1.0789999999999969], "policy_red_v19_reward": [1.448693237816175, -1.0069999999999995, 0.24570312500000402, 0.09960937499999989, -1.009], "policy_red_v2_reward": [-1.123], "policy_red_v20_reward": [-0.019999999999999907], "policy_red_v8_reward": [-2.0119999999999996, -0.015000000000000001, -1.2369999999999823], "policy_red_v35_reward": [-1.0139999999999996, 0.4859346144425925, 0.4769346144425921], "policy_red_v15_reward": [-1.0139999999999998, -0.56530676218383], "policy_red_v26_reward": [-1.2059999999999815, 1.8500596144425923], "policy_red_v6_reward": [0.4329218750000011], "policy_red_v23_reward": [1.483934614442592], "policy_red_v39_reward": [1.4956932378152046, 0.1770500000000006], "policy_red_v31_reward": [-0.19830676218383003, 0.47569323781617023], "policy_red_v12_reward": [-1.0069999999999995], "policy_red_v36_reward": [-1.0059999999999998], "policy_red_v16_reward": [-2.0039999999999996], "policy_red_v34_reward": [0.39428360500000026], "policy_red_v1_reward": [-1.1609999999999872], "policy_red_v44_reward": [1.9424843749999998], "policy_red_v17_reward": [-0.1499999999999997], "policy_red_v25_reward": [-0.006], "policy_red_v24_reward": [3.4071689894425945], "policy_red_v21_reward": [-2.0039999999999996], "policy_red_v40_reward": [-1.001, -2.0339999999999976], "policy_red_v27_reward": [0.4966932378161699], "policy_red_v33_reward": [-0.019000000000000006], "policy_red_v18_reward": [-1.025], "policy_red_v4_reward": [-1.0069999999999995], "policy_red_v42_reward": [0.481], "policy_red_v13_reward": [-0.012000000000000004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8125618266836335, "mean_inference_ms": 7.7924551935049555, "mean_action_processing_ms": 0.29455106931245933, "mean_env_wait_ms": 0.3896316645073202, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09668231010437012, "StateBufferConnector_ms": 0.004032611846923828, "ViewRequirementAgentConnector_ms": 0.11198937892913818}}, "episode_reward_max": 4.475182655588147, "episode_reward_min": -1.6063848871838224, "episode_reward_mean": 2.1448216625003, "episode_len_mean": 164.24, "episodes_this_iter": 37, "policy_reward_min": {"red_v30": -1.0089999999999997, "red": -1.9583848871838263, "blue": -2.013, "red_v19": -1.009, "red_v2": -1.123, "red_v20": -0.019999999999999907, "red_v8": -2.0119999999999996, "red_v35": -1.0139999999999996, "red_v15": -1.0139999999999998, "red_v26": -1.2059999999999815, "red_v6": 0.4329218750000011, "red_v23": 1.483934614442592, "red_v39": 0.1770500000000006, "red_v31": -0.19830676218383003, "red_v12": -1.0069999999999995, "red_v36": -1.0059999999999998, "red_v16": -2.0039999999999996, "red_v34": 0.39428360500000026, "red_v1": -1.1609999999999872, "red_v44": 1.9424843749999998, "red_v17": -0.1499999999999997, "red_v25": -0.006, "red_v24": 3.4071689894425945, "red_v21": -2.0039999999999996, "red_v40": -2.0339999999999976, "red_v27": 0.4966932378161699, "red_v33": -0.019000000000000006, "red_v18": -1.025, "red_v4": -1.0069999999999995, "red_v42": 0.481, "red_v13": -0.012000000000000004}, "policy_reward_max": {"red_v30": -1.0089999999999997, "red": 3.995740112815204, "blue": 2.319, "red_v19": 1.448693237816175, "red_v2": -1.123, "red_v20": -0.019999999999999907, "red_v8": -0.015000000000000001, "red_v35": 0.4859346144425925, "red_v15": -0.56530676218383, "red_v26": 1.8500596144425923, "red_v6": 0.4329218750000011, "red_v23": 1.483934614442592, "red_v39": 1.4956932378152046, "red_v31": 0.47569323781617023, "red_v12": -1.0069999999999995, "red_v36": -1.0059999999999998, "red_v16": -2.0039999999999996, "red_v34": 0.39428360500000026, "red_v1": -1.1609999999999872, "red_v44": 1.9424843749999998, "red_v17": -0.1499999999999997, "red_v25": -0.006, "red_v24": 3.4071689894425945, "red_v21": -2.0039999999999996, "red_v40": -1.001, "red_v27": 0.4966932378161699, "red_v33": -0.019000000000000006, "red_v18": -1.025, "red_v4": -1.0069999999999995, "red_v42": 0.481, "red_v13": -0.012000000000000004}, "policy_reward_mean": {"red_v30": -1.0089999999999997, "red": 2.8627046889592083, "blue": -1.0916646012931008, "red_v19": -0.04439885243676409, "red_v2": -1.123, "red_v20": -0.019999999999999907, "red_v8": -1.087999999999994, "red_v35": -0.017043590371605005, "red_v15": -0.7896533810919149, "red_v26": 0.32202980722130536, "red_v6": 0.4329218750000011, "red_v23": 1.483934614442592, "red_v39": 0.8363716189076026, "red_v31": 0.1386932378161701, "red_v12": -1.0069999999999995, "red_v36": -1.0059999999999998, "red_v16": -2.0039999999999996, "red_v34": 0.39428360500000026, "red_v1": -1.1609999999999872, "red_v44": 1.9424843749999998, "red_v17": -0.1499999999999997, "red_v25": -0.006, "red_v24": 3.4071689894425945, "red_v21": -2.0039999999999996, "red_v40": -1.5174999999999987, "red_v27": 0.4966932378161699, "red_v33": -0.019000000000000006, "red_v18": -1.025, "red_v4": -1.0069999999999995, "red_v42": 0.481, "red_v13": -0.012000000000000004}, "hist_stats": {"episode_reward": [2.4686846144425925, 2.4735994878161702, 1.4800057378161706, 4.186664342816181, 1.48692761281617, 2.4749814894425923, 2.9818182378152036, 1.9574588628161715, 2.4748963628161706, 2.4207783644425924, 1.485630737815204, 1.290693237816174, 1.9279375, 1.4827088628161702, 1.2433963628161764, 1.6577687500000002, 1.4853374085440554, 2.430583862816171, 1.3469711050000006, 2.4459901128161707, 2.4790057378161703, 2.4755213628152037, 0.7416932378162148, 1.8882401128161972, 1.6696125000000004, 3.3256846144425927, 2.923333862816172, 2.4743026128161705, 0.9128564894425937, 2.4606619878161915, 1.4865206677729415, 4.4745646572155335, 2.4719744878161705, 2.97181823781617, 0.39739636281620183, 0.5273026128161706, 2.4784119878161706, 0.6798564894425919, 4.475182655588147, 1.5067244878161719, 0.7260057378161759, 0.8122905335440737, 1.921214600632364, 3.661946362816171, 1.4722783644425925, 1.4780057378161704, 2.881627355, 2.4748963628152043, -1.6063848871838224, 2.9638651128161713, 2.4768217835440556, 2.48341198781617, 0.9223338628161719, 2.4842244878161703, 2.463052612816171, 2.3773304800000004, 1.6689093750000001, 2.6712088628161963, 1.8759242300000005, 0.88702136281617, 3.8896174678161697, 3.9359021006323434, 1.8828338628161967, 3.9474716022587635, 2.4767088628161704, 1.948177612816171, 1.4893338628161699, 0.9346221144425924, 3.3464425427729414, 2.9829276128161704, 2.47889636281617, 0.8497713628152047, 2.3865213628161706, 1.622786987816186, 2.4658963628161703, 2.9723877394425924, 3.414862227258764, 0.12469323781617148, 1.6658000000000004, 3.2126677256323557, 2.8705179800000002, 1.489743658544055, 2.4600526128161704, 2.4762783644425923, 1.6127557378161883, 2.4699744878161702, 2.4714155335440555, 3.9685271006323415, 2.9600838628161714, 2.2977528522578052, 2.418365112816172, 1.5076307378161955, 2.466490112816171, 1.2156307378161715, 1.989740112815204, 1.48822448781617, 3.435286987816172, 2.955458862816172, 0.6446932378162156, 2.1357401128161877], "episode_lengths": [16, 30, 28, 164, 21, 17, 24, 43, 31, 50, 20, 192, 20, 27, 191, 26, 21, 67, 36, 65, 28, 23, 1280, 433, 12, 16, 83, 29, 57, 394, 23, 20, 38, 24, 639, 349, 26, 633, 33, 758, 284, 836, 535, 31, 18, 28, 18, 31, 569, 41, 26, 26, 83, 22, 45, 17, 13, 571, 19, 119, 19, 59, 435, 50, 27, 69, 19, 36, 16, 21, 31, 135, 87, 290, 31, 15, 85, 1280, 16, 230, 21, 19, 45, 18, 300, 38, 28, 51, 35, 152, 73, 660, 33, 980, 17, 22, 66, 43, 1280, 273], "policy_red_v30_reward": [-1.0089999999999997], "policy_blue_reward": [-1.0059999999999996, -2.0059999999999993, -2.0069999999999997, -1.001, -0.007, -2.0129999999999995, -1.0079999999999996, -1.0149999999999992, -2.005, 2.319, -0.004, -2.0049999999999994, -2.005, -2.005, -1.3379999999999677, -2.005, -0.021000000000000005, -1.0119999999999998, -1.1629999999999971, -2.0029999999999997, -1.008999999999999, -1.6640000000000001, -1.1999999999999815, -1.578, -0.7890000000000001, -2.0039999999999996, -2.0069999999999997, -0.004, -1.0089999999999995, 0.3520000000000052, -0.009000000000000001, -1.0119999999999991, -1.0049999999999997, -1.024, -1.009, 1.2875156250000028, -2.008, -1.532, -1.0119999999999993, -2.005, -2.013, -0.009000000000000001, -1.0049999999999997, -1.5399999999999991, -1.025999999999999, -1.5809999999999982, -1.0129999999999992, -0.009000000000000001, -2.0029999999999997, -1.013999999999999, -1.0089999999999995, -1.0079999999999998, 1.1989374999999998, -1.2959999999999743, -2.0059999999999993, -2.0039999999999996, -1.3499999999999657, -1.0789999999999969], "policy_red_v19_reward": [1.448693237816175, -1.0069999999999995, 0.24570312500000402, 0.09960937499999989, -1.009], "policy_red_v2_reward": [-1.123], "policy_red_v20_reward": [-0.019999999999999907], "policy_red_v8_reward": [-2.0119999999999996, -0.015000000000000001, -1.2369999999999823], "policy_red_v35_reward": [-1.0139999999999996, 0.4859346144425925, 0.4769346144425921], "policy_red_v15_reward": [-1.0139999999999998, -0.56530676218383], "policy_red_v26_reward": [-1.2059999999999815, 1.8500596144425923], "policy_red_v6_reward": [0.4329218750000011], "policy_red_v23_reward": [1.483934614442592], "policy_red_v39_reward": [1.4956932378152046, 0.1770500000000006], "policy_red_v31_reward": [-0.19830676218383003, 0.47569323781617023], "policy_red_v12_reward": [-1.0069999999999995], "policy_red_v36_reward": [-1.0059999999999998], "policy_red_v16_reward": [-2.0039999999999996], "policy_red_v34_reward": [0.39428360500000026], "policy_red_v1_reward": [-1.1609999999999872], "policy_red_v44_reward": [1.9424843749999998], "policy_red_v17_reward": [-0.1499999999999997], "policy_red_v25_reward": [-0.006], "policy_red_v24_reward": [3.4071689894425945], "policy_red_v21_reward": [-2.0039999999999996], "policy_red_v40_reward": [-1.001, -2.0339999999999976], "policy_red_v27_reward": [0.4966932378161699], "policy_red_v33_reward": [-0.019000000000000006], "policy_red_v18_reward": [-1.025], "policy_red_v4_reward": [-1.0069999999999995], "policy_red_v42_reward": [0.481], "policy_red_v13_reward": [-0.012000000000000004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8125618266836335, "mean_inference_ms": 7.7924551935049555, "mean_action_processing_ms": 0.29455106931245933, "mean_env_wait_ms": 0.3896316645073202, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09668231010437012, "StateBufferConnector_ms": 0.004032611846923828, "ViewRequirementAgentConnector_ms": 0.11198937892913818}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.00678323862928, "num_env_steps_trained_throughput_per_sec": 200.00678323862928, "timesteps_total": 312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 19998.224, "sample_time_ms": 1140.35, "learn_time_ms": 18774.851, "learn_throughput": 213.051, "synch_weights_time_ms": 80.033}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "episodes_total": 949, "training_iteration": 78, "trial_id": "a9680_00000", "date": "2023-09-24_03-04-20", "timestamp": 1695539060, "time_this_iter_s": 20.009174346923828, "time_total_s": 1555.1336586475372, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b3426e500>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b3441a4d0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b341cf7f0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1555.1336586475372, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 5.240625, "ram_util_percent": 22.08125}, "win_rate": 0.8, "league_size": 48}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9627643048763277, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.11299571647553724, "policy_loss": -0.03546849627649256, "vf_loss": 0.2889271395513788, "vf_explained_var": 0.4384469484910369, "kl": 0.013006088939270436, "entropy": 1.8520972325156133, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 75360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 632000, "num_agent_steps_trained": 632000}, "sampler_results": {"episode_reward_max": 4.495921271360225, "episode_reward_min": -1.6063848871838224, "episode_reward_mean": 2.1515573620276753, "episode_len_mean": 169.76, "episode_media": {}, "episodes_this_iter": 41, "policy_reward_min": {"blue": -2.013, "red": -1.9583848871838263, "red_v31": -1.5189999999999997, "red_v39": 0.1770500000000006, "red_v12": -1.0069999999999995, "red_v36": -1.0059999999999998, "red_v16": -2.0039999999999996, "red_v34": 0.39428360500000026, "red_v1": -1.1609999999999872, "red_v35": 0.4769346144425921, "red_v44": 1.9424843749999998, "red_v17": -0.1499999999999997, "red_v25": -0.006, "red_v24": -2.0159999999999987, "red_v8": -1.2369999999999823, "red_v21": -2.0039999999999996, "red_v15": -0.56530676218383, "red_v40": -2.0339999999999976, "red_v27": 0.4966932378161699, "red_v33": -0.019000000000000006, "red_v26": 1.8500596144425923, "red_v18": -1.025, "red_v4": -2.01, "red_v42": 0.481, "red_v13": -0.012000000000000004, "red_v2": 1.6564502394425924, "red_v30": -2.008999999999999, "red_v32": 0.182103033544057, "red_v45": -2.0429999999999966, "red_v7": -1.0099999999999993, "red_v22": -2.0139999999999993, "red_v14": 2.437328125, "red_v10": 1.89190625, "red_v5": -0.007, "red_v19": -0.1549999999999998, "red_v43": -0.5039999999999998}, "policy_reward_max": {"blue": 1.9963156250000265, "red": 3.995740112815204, "red_v31": 0.47569323781617023, "red_v39": 0.1770500000000006, "red_v12": -1.0069999999999995, "red_v36": -1.0059999999999998, "red_v16": -2.0039999999999996, "red_v34": 0.39428360500000026, "red_v1": -1.1609999999999872, "red_v35": 3.295705480000003, "red_v44": 1.9424843749999998, "red_v17": -0.1499999999999997, "red_v25": -0.006, "red_v24": 3.4071689894425945, "red_v8": -0.007, "red_v21": -2.0039999999999996, "red_v15": -0.56530676218383, "red_v40": -1.001, "red_v27": 0.4966932378161699, "red_v33": 1.8533026128161898, "red_v26": 1.8500596144425923, "red_v18": -1.025, "red_v4": -1.0069999999999995, "red_v42": 0.481, "red_v13": -0.012000000000000004, "red_v2": 1.6564502394425924, "red_v30": -2.008999999999999, "red_v32": 0.182103033544057, "red_v45": -2.0429999999999966, "red_v7": -1.0099999999999993, "red_v22": 1.5066932378161697, "red_v14": 2.437328125, "red_v10": 1.89190625, "red_v5": 0.437, "red_v19": 1.5601776128161713, "red_v43": -0.5039999999999998}, "policy_reward_mean": {"blue": -1.0571894675925901, "red": 2.764675467117397, "red_v31": -0.41387117478921986, "red_v39": 0.1770500000000006, "red_v12": -1.0069999999999995, "red_v36": -1.0059999999999998, "red_v16": -2.0039999999999996, "red_v34": 0.39428360500000026, "red_v1": -1.1609999999999872, "red_v35": 1.8863200472212975, "red_v44": 1.9424843749999998, "red_v17": -0.1499999999999997, "red_v25": -0.006, "red_v24": 0.6955844947212979, "red_v8": -0.6219999999999911, "red_v21": -2.0039999999999996, "red_v15": -0.56530676218383, "red_v40": -1.5174999999999987, "red_v27": 0.4966932378161699, "red_v33": 0.917151306408095, "red_v26": 1.8500596144425923, "red_v18": -1.025, "red_v4": -1.3439999999999996, "red_v42": 0.481, "red_v13": -0.012000000000000004, "red_v2": 1.6564502394425924, "red_v30": -2.008999999999999, "red_v32": 0.182103033544057, "red_v45": -2.0429999999999966, "red_v7": -1.0099999999999993, "red_v22": -0.2536533810919148, "red_v14": 2.437328125, "red_v10": 1.89190625, "red_v5": 0.215, "red_v19": 0.7025888064080857, "red_v43": -0.5039999999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.8122905335440737, 1.921214600632364, 3.661946362816171, 1.4722783644425925, 1.4780057378161704, 2.881627355, 2.4748963628152043, -1.6063848871838224, 2.9638651128161713, 2.4768217835440556, 2.48341198781617, 0.9223338628161719, 2.4842244878161703, 2.463052612816171, 2.3773304800000004, 1.6689093750000001, 2.6712088628161963, 1.8759242300000005, 0.88702136281617, 3.8896174678161697, 3.9359021006323434, 1.8828338628161967, 3.9474716022587635, 2.4767088628161704, 1.948177612816171, 1.4893338628161699, 0.9346221144425924, 3.3464425427729414, 2.9829276128161704, 2.47889636281617, 0.8497713628152047, 2.3865213628161706, 1.622786987816186, 2.4658963628161703, 2.9723877394425924, 3.414862227258764, 0.12469323781617148, 1.6658000000000004, 3.2126677256323557, 2.8705179800000002, 1.489743658544055, 2.4600526128161704, 2.4762783644425923, 1.6127557378161883, 2.4699744878161702, 2.4714155335440555, 3.9685271006323415, 2.9600838628161714, 2.2977528522578052, 2.418365112816172, 1.5076307378161955, 2.466490112816171, 1.2156307378161715, 1.989740112815204, 1.48822448781617, 3.435286987816172, 2.955458862816172, 0.6446932378162156, 2.1357401128161877, 2.9835213628161705, 2.863143477258763, 1.416828125, 1.4352557378161717, 0.1837401128161784, 2.48692761281617, 2.4777088628161703, 1.8709242300000006, 2.472899908544055, 2.4828182378161703, 1.4954432378161697, 1.48711511281617, 2.3978182378161716, 1.3004212713603147, 1.4889269177729418, 1.3736932378161733, 1.4741932378161708, 2.468786987816171, 1.3671117300000004, 2.443021362816172, 1.7711898550000003, 2.6726125, 2.9770057378161705, 1.960755737815205, 1.3762211050000002, 3.3022679800000003, 3.3003987178161744, 2.193995850632378, 1.8752211050000003, 0.8311463628161703, 1.856870850632372, 2.16639375, 3.3300057378161703, 1.4625682378161715, 1.9612401128161707, 2.470278364442593, 4.495921271360225, 2.4731151128161706, 1.6705213628162077, 2.9840362927729416, 0.32100886281620267], "episode_lengths": [836, 535, 31, 18, 28, 18, 31, 569, 41, 26, 26, 83, 22, 45, 17, 13, 571, 19, 119, 19, 59, 435, 50, 27, 69, 19, 36, 16, 21, 31, 135, 87, 290, 31, 15, 85, 1280, 16, 230, 21, 19, 45, 18, 300, 38, 28, 51, 35, 152, 73, 660, 33, 980, 17, 22, 66, 43, 1280, 273, 23, 379, 23, 76, 721, 21, 27, 19, 33, 24, 16, 25, 88, 1272, 21, 128, 32, 34, 23, 55, 94, 12, 28, 44, 20, 37, 89, 669, 20, 207, 517, 18, 28, 40, 49, 18, 24, 25, 599, 18, 1227], "policy_blue_reward": [-0.7890000000000001, -2.0039999999999996, -2.0069999999999997, -0.004, -1.0089999999999995, 0.3520000000000052, -0.009000000000000001, -1.0119999999999991, -1.0049999999999997, -1.024, -1.009, 1.2875156250000028, -2.008, -1.532, -1.0119999999999993, -2.005, -2.013, -0.009000000000000001, -1.0049999999999997, -1.5399999999999991, -1.025999999999999, -1.5809999999999982, -1.0129999999999992, -0.009000000000000001, -2.0029999999999997, -1.013999999999999, -1.0089999999999995, -1.0079999999999998, 1.1989374999999998, -1.2959999999999743, -2.0059999999999993, -2.0039999999999996, -1.3499999999999657, -1.0789999999999969, -1.0089999999999997, -1.2060000000000002, -1.007, -1.0089999999999995, -2.0069999999999997, -1.0079999999999993, -1.0069999999999995, -2.002, -2.0029999999999997, -1.0299999999999974, -2.003, -2.0109999999999997, -0.002, -0.006, -2.004, -2.005, -1.0019999999999998, -1.0049999999999997, -1.2029999999999814, 1.9963156250000265], "policy_red_v31_reward": [-0.19830676218383003, 0.47569323781617023, -1.5189999999999997], "policy_red_v39_reward": [0.1770500000000006], "policy_red_v12_reward": [-1.0069999999999995], "policy_red_v36_reward": [-1.0059999999999998], "policy_red_v16_reward": [-2.0039999999999996], "policy_red_v34_reward": [0.39428360500000026], "policy_red_v1_reward": [-1.1609999999999872], "policy_red_v35_reward": [0.4769346144425921, 3.295705480000003], "policy_red_v44_reward": [1.9424843749999998], "policy_red_v17_reward": [-0.1499999999999997], "policy_red_v25_reward": [-0.006], "policy_red_v24_reward": [3.4071689894425945, -2.0159999999999987], "policy_red_v8_reward": [-1.2369999999999823, -0.007], "policy_red_v21_reward": [-2.0039999999999996], "policy_red_v15_reward": [-0.56530676218383], "policy_red_v40_reward": [-1.001, -2.0339999999999976], "policy_red_v27_reward": [0.4966932378161699], "policy_red_v33_reward": [-0.019000000000000006, 1.8533026128161898], "policy_red_v26_reward": [1.8500596144425923], "policy_red_v18_reward": [-1.025], "policy_red_v4_reward": [-1.0069999999999995, -2.01, -1.0149999999999995], "policy_red_v42_reward": [0.481], "policy_red_v13_reward": [-0.012000000000000004], "policy_red_v2_reward": [1.6564502394425924], "policy_red_v30_reward": [-2.008999999999999], "policy_red_v32_reward": [0.182103033544057], "policy_red_v45_reward": [-2.0429999999999966], "policy_red_v7_reward": [-1.0099999999999993], "policy_red_v22_reward": [-2.0139999999999993, 1.5066932378161697], "policy_red_v14_reward": [2.437328125], "policy_red_v10_reward": [1.89190625], "policy_red_v5_reward": [0.437, -0.007], "policy_red_v19_reward": [1.5601776128161713, -0.1549999999999998], "policy_red_v43_reward": [-0.5039999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8124756662271786, "mean_inference_ms": 7.779854703677837, "mean_action_processing_ms": 0.29460565969854896, "mean_env_wait_ms": 0.38886797297117764, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09656965732574463, "StateBufferConnector_ms": 0.004070401191711426, "ViewRequirementAgentConnector_ms": 0.11284458637237549}}, "episode_reward_max": 4.495921271360225, "episode_reward_min": -1.6063848871838224, "episode_reward_mean": 2.1515573620276753, "episode_len_mean": 169.76, "episodes_this_iter": 41, "policy_reward_min": {"blue": -2.013, "red": -1.9583848871838263, "red_v31": -1.5189999999999997, "red_v39": 0.1770500000000006, "red_v12": -1.0069999999999995, "red_v36": -1.0059999999999998, "red_v16": -2.0039999999999996, "red_v34": 0.39428360500000026, "red_v1": -1.1609999999999872, "red_v35": 0.4769346144425921, "red_v44": 1.9424843749999998, "red_v17": -0.1499999999999997, "red_v25": -0.006, "red_v24": -2.0159999999999987, "red_v8": -1.2369999999999823, "red_v21": -2.0039999999999996, "red_v15": -0.56530676218383, "red_v40": -2.0339999999999976, "red_v27": 0.4966932378161699, "red_v33": -0.019000000000000006, "red_v26": 1.8500596144425923, "red_v18": -1.025, "red_v4": -2.01, "red_v42": 0.481, "red_v13": -0.012000000000000004, "red_v2": 1.6564502394425924, "red_v30": -2.008999999999999, "red_v32": 0.182103033544057, "red_v45": -2.0429999999999966, "red_v7": -1.0099999999999993, "red_v22": -2.0139999999999993, "red_v14": 2.437328125, "red_v10": 1.89190625, "red_v5": -0.007, "red_v19": -0.1549999999999998, "red_v43": -0.5039999999999998}, "policy_reward_max": {"blue": 1.9963156250000265, "red": 3.995740112815204, "red_v31": 0.47569323781617023, "red_v39": 0.1770500000000006, "red_v12": -1.0069999999999995, "red_v36": -1.0059999999999998, "red_v16": -2.0039999999999996, "red_v34": 0.39428360500000026, "red_v1": -1.1609999999999872, "red_v35": 3.295705480000003, "red_v44": 1.9424843749999998, "red_v17": -0.1499999999999997, "red_v25": -0.006, "red_v24": 3.4071689894425945, "red_v8": -0.007, "red_v21": -2.0039999999999996, "red_v15": -0.56530676218383, "red_v40": -1.001, "red_v27": 0.4966932378161699, "red_v33": 1.8533026128161898, "red_v26": 1.8500596144425923, "red_v18": -1.025, "red_v4": -1.0069999999999995, "red_v42": 0.481, "red_v13": -0.012000000000000004, "red_v2": 1.6564502394425924, "red_v30": -2.008999999999999, "red_v32": 0.182103033544057, "red_v45": -2.0429999999999966, "red_v7": -1.0099999999999993, "red_v22": 1.5066932378161697, "red_v14": 2.437328125, "red_v10": 1.89190625, "red_v5": 0.437, "red_v19": 1.5601776128161713, "red_v43": -0.5039999999999998}, "policy_reward_mean": {"blue": -1.0571894675925901, "red": 2.764675467117397, "red_v31": -0.41387117478921986, "red_v39": 0.1770500000000006, "red_v12": -1.0069999999999995, "red_v36": -1.0059999999999998, "red_v16": -2.0039999999999996, "red_v34": 0.39428360500000026, "red_v1": -1.1609999999999872, "red_v35": 1.8863200472212975, "red_v44": 1.9424843749999998, "red_v17": -0.1499999999999997, "red_v25": -0.006, "red_v24": 0.6955844947212979, "red_v8": -0.6219999999999911, "red_v21": -2.0039999999999996, "red_v15": -0.56530676218383, "red_v40": -1.5174999999999987, "red_v27": 0.4966932378161699, "red_v33": 0.917151306408095, "red_v26": 1.8500596144425923, "red_v18": -1.025, "red_v4": -1.3439999999999996, "red_v42": 0.481, "red_v13": -0.012000000000000004, "red_v2": 1.6564502394425924, "red_v30": -2.008999999999999, "red_v32": 0.182103033544057, "red_v45": -2.0429999999999966, "red_v7": -1.0099999999999993, "red_v22": -0.2536533810919148, "red_v14": 2.437328125, "red_v10": 1.89190625, "red_v5": 0.215, "red_v19": 0.7025888064080857, "red_v43": -0.5039999999999998}, "hist_stats": {"episode_reward": [0.8122905335440737, 1.921214600632364, 3.661946362816171, 1.4722783644425925, 1.4780057378161704, 2.881627355, 2.4748963628152043, -1.6063848871838224, 2.9638651128161713, 2.4768217835440556, 2.48341198781617, 0.9223338628161719, 2.4842244878161703, 2.463052612816171, 2.3773304800000004, 1.6689093750000001, 2.6712088628161963, 1.8759242300000005, 0.88702136281617, 3.8896174678161697, 3.9359021006323434, 1.8828338628161967, 3.9474716022587635, 2.4767088628161704, 1.948177612816171, 1.4893338628161699, 0.9346221144425924, 3.3464425427729414, 2.9829276128161704, 2.47889636281617, 0.8497713628152047, 2.3865213628161706, 1.622786987816186, 2.4658963628161703, 2.9723877394425924, 3.414862227258764, 0.12469323781617148, 1.6658000000000004, 3.2126677256323557, 2.8705179800000002, 1.489743658544055, 2.4600526128161704, 2.4762783644425923, 1.6127557378161883, 2.4699744878161702, 2.4714155335440555, 3.9685271006323415, 2.9600838628161714, 2.2977528522578052, 2.418365112816172, 1.5076307378161955, 2.466490112816171, 1.2156307378161715, 1.989740112815204, 1.48822448781617, 3.435286987816172, 2.955458862816172, 0.6446932378162156, 2.1357401128161877, 2.9835213628161705, 2.863143477258763, 1.416828125, 1.4352557378161717, 0.1837401128161784, 2.48692761281617, 2.4777088628161703, 1.8709242300000006, 2.472899908544055, 2.4828182378161703, 1.4954432378161697, 1.48711511281617, 2.3978182378161716, 1.3004212713603147, 1.4889269177729418, 1.3736932378161733, 1.4741932378161708, 2.468786987816171, 1.3671117300000004, 2.443021362816172, 1.7711898550000003, 2.6726125, 2.9770057378161705, 1.960755737815205, 1.3762211050000002, 3.3022679800000003, 3.3003987178161744, 2.193995850632378, 1.8752211050000003, 0.8311463628161703, 1.856870850632372, 2.16639375, 3.3300057378161703, 1.4625682378161715, 1.9612401128161707, 2.470278364442593, 4.495921271360225, 2.4731151128161706, 1.6705213628162077, 2.9840362927729416, 0.32100886281620267], "episode_lengths": [836, 535, 31, 18, 28, 18, 31, 569, 41, 26, 26, 83, 22, 45, 17, 13, 571, 19, 119, 19, 59, 435, 50, 27, 69, 19, 36, 16, 21, 31, 135, 87, 290, 31, 15, 85, 1280, 16, 230, 21, 19, 45, 18, 300, 38, 28, 51, 35, 152, 73, 660, 33, 980, 17, 22, 66, 43, 1280, 273, 23, 379, 23, 76, 721, 21, 27, 19, 33, 24, 16, 25, 88, 1272, 21, 128, 32, 34, 23, 55, 94, 12, 28, 44, 20, 37, 89, 669, 20, 207, 517, 18, 28, 40, 49, 18, 24, 25, 599, 18, 1227], "policy_blue_reward": [-0.7890000000000001, -2.0039999999999996, -2.0069999999999997, -0.004, -1.0089999999999995, 0.3520000000000052, -0.009000000000000001, -1.0119999999999991, -1.0049999999999997, -1.024, -1.009, 1.2875156250000028, -2.008, -1.532, -1.0119999999999993, -2.005, -2.013, -0.009000000000000001, -1.0049999999999997, -1.5399999999999991, -1.025999999999999, -1.5809999999999982, -1.0129999999999992, -0.009000000000000001, -2.0029999999999997, -1.013999999999999, -1.0089999999999995, -1.0079999999999998, 1.1989374999999998, -1.2959999999999743, -2.0059999999999993, -2.0039999999999996, -1.3499999999999657, -1.0789999999999969, -1.0089999999999997, -1.2060000000000002, -1.007, -1.0089999999999995, -2.0069999999999997, -1.0079999999999993, -1.0069999999999995, -2.002, -2.0029999999999997, -1.0299999999999974, -2.003, -2.0109999999999997, -0.002, -0.006, -2.004, -2.005, -1.0019999999999998, -1.0049999999999997, -1.2029999999999814, 1.9963156250000265], "policy_red_v31_reward": [-0.19830676218383003, 0.47569323781617023, -1.5189999999999997], "policy_red_v39_reward": [0.1770500000000006], "policy_red_v12_reward": [-1.0069999999999995], "policy_red_v36_reward": [-1.0059999999999998], "policy_red_v16_reward": [-2.0039999999999996], "policy_red_v34_reward": [0.39428360500000026], "policy_red_v1_reward": [-1.1609999999999872], "policy_red_v35_reward": [0.4769346144425921, 3.295705480000003], "policy_red_v44_reward": [1.9424843749999998], "policy_red_v17_reward": [-0.1499999999999997], "policy_red_v25_reward": [-0.006], "policy_red_v24_reward": [3.4071689894425945, -2.0159999999999987], "policy_red_v8_reward": [-1.2369999999999823, -0.007], "policy_red_v21_reward": [-2.0039999999999996], "policy_red_v15_reward": [-0.56530676218383], "policy_red_v40_reward": [-1.001, -2.0339999999999976], "policy_red_v27_reward": [0.4966932378161699], "policy_red_v33_reward": [-0.019000000000000006, 1.8533026128161898], "policy_red_v26_reward": [1.8500596144425923], "policy_red_v18_reward": [-1.025], "policy_red_v4_reward": [-1.0069999999999995, -2.01, -1.0149999999999995], "policy_red_v42_reward": [0.481], "policy_red_v13_reward": [-0.012000000000000004], "policy_red_v2_reward": [1.6564502394425924], "policy_red_v30_reward": [-2.008999999999999], "policy_red_v32_reward": [0.182103033544057], "policy_red_v45_reward": [-2.0429999999999966], "policy_red_v7_reward": [-1.0099999999999993], "policy_red_v22_reward": [-2.0139999999999993, 1.5066932378161697], "policy_red_v14_reward": [2.437328125], "policy_red_v10_reward": [1.89190625], "policy_red_v5_reward": [0.437, -0.007], "policy_red_v19_reward": [1.5601776128161713, -0.1549999999999998], "policy_red_v43_reward": [-0.5039999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8124756662271786, "mean_inference_ms": 7.779854703677837, "mean_action_processing_ms": 0.29460565969854896, "mean_env_wait_ms": 0.38886797297117764, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09656965732574463, "StateBufferConnector_ms": 0.004070401191711426, "ViewRequirementAgentConnector_ms": 0.11284458637237549}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 632000, "num_agent_steps_trained": 632000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 198.85970239251324, "num_env_steps_trained_throughput_per_sec": 198.85970239251324, "timesteps_total": 316000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 632000, "timers": {"training_iteration_time_ms": 20011.801, "sample_time_ms": 1139.815, "learn_time_ms": 18788.978, "learn_throughput": 212.891, "synch_weights_time_ms": 80.041}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 632000, "num_agent_steps_trained": 632000}, "done": false, "episodes_total": 990, "training_iteration": 79, "trial_id": "a9680_00000", "date": "2023-09-24_03-04-43", "timestamp": 1695539083, "time_this_iter_s": 20.124286890029907, "time_total_s": 1575.2579455375671, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b342ae020>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34286560>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b342865f0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1575.2579455375671, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 5.206060606060605, "ram_util_percent": 22.178787878787883}, "win_rate": 0.78, "league_size": 49}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3362576585263013, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.01415876663547048, "policy_loss": -0.052904779079350796, "vf_loss": 0.12190582517165846, "vf_explained_var": 0.8459157157689333, "kl": 0.01759735015536774, "entropy": 1.8081740569323301, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 76320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "sampler_results": {"episode_reward_max": 4.495921271360225, "episode_reward_min": -0.2786661371838298, "episode_reward_mean": 2.217478254595021, "episode_len_mean": 154.71, "episode_media": {}, "episodes_this_iter": 35, "policy_reward_min": {"red_v24": -2.0159999999999987, "red": -1.675306762183828, "red_v8": -1.2369999999999823, "red_v21": -2.0039999999999996, "red_v15": -2.0169999999999995, "blue": -2.0479999999999965, "red_v40": -2.0339999999999976, "red_v27": 0.4966932378161699, "red_v33": -2.0139999999999985, "red_v26": 1.8500596144425923, "red_v18": -1.025, "red_v4": -2.01, "red_v42": 0.481, "red_v13": -0.012000000000000004, "red_v2": 1.6564502394425924, "red_v30": -2.008999999999999, "red_v32": 0.182103033544057, "red_v45": -2.0429999999999966, "red_v7": -1.0099999999999993, "red_v22": -2.0139999999999993, "red_v14": 2.437328125, "red_v10": 1.89190625, "red_v5": -0.007, "red_v35": 3.295705480000003, "red_v31": -1.5189999999999997, "red_v19": -0.1549999999999998, "red_v43": -0.5039999999999998, "red_v16": -1.0099999999999998, "red_v12": -2.0089999999999995, "red_v44": -0.5559999999999998, "red_v11": 0.433, "red_v20": 1.48969323781617}, "policy_reward_max": {"red_v24": 3.4071689894425945, "red": 3.995740112815204, "red_v8": -0.007, "red_v21": -2.0039999999999996, "red_v15": -0.56530676218383, "blue": 1.9963156250000265, "red_v40": -1.001, "red_v27": 0.4966932378161699, "red_v33": 1.8533026128161898, "red_v26": 1.8500596144425923, "red_v18": -1.025, "red_v4": -1.004, "red_v42": 0.481, "red_v13": 0.3933906250000002, "red_v2": 1.6564502394425924, "red_v30": 0.5036932378161697, "red_v32": 0.182103033544057, "red_v45": -2.0429999999999966, "red_v7": -1.0099999999999993, "red_v22": 1.5066932378161697, "red_v14": 2.437328125, "red_v10": 1.89190625, "red_v5": 0.437, "red_v35": 3.295705480000003, "red_v31": -1.5189999999999997, "red_v19": 1.5601776128161713, "red_v43": -0.5039999999999998, "red_v16": -1.0099999999999998, "red_v12": 0.49869323781617014, "red_v44": -0.5559999999999998, "red_v11": 0.433, "red_v20": 1.48969323781617}, "policy_reward_mean": {"red_v24": 0.6170345346283964, "red": 2.8769724508565817, "red_v8": -0.6013333333333274, "red_v21": -2.0039999999999996, "red_v15": -1.2911533810919147, "blue": -1.1362499387254879, "red_v40": -1.5174999999999987, "red_v27": 0.4966932378161699, "red_v33": -0.15551419054595206, "red_v26": 1.8500596144425923, "red_v18": -1.025, "red_v4": -1.259, "red_v42": 0.481, "red_v13": 0.1906953125000001, "red_v2": 1.6564502394425924, "red_v30": -0.7526533810919147, "red_v32": 0.182103033544057, "red_v45": -2.0429999999999966, "red_v7": -1.0099999999999993, "red_v22": -0.2536533810919148, "red_v14": 2.437328125, "red_v10": 1.89190625, "red_v5": 0.215, "red_v35": 3.295705480000003, "red_v31": -1.5189999999999997, "red_v19": 0.7025888064080857, "red_v43": -0.5039999999999998, "red_v16": -1.0099999999999998, "red_v12": -0.5064355873946097, "red_v44": -0.5559999999999998, "red_v11": 0.433, "red_v20": 1.48969323781617}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.414862227258764, 0.12469323781617148, 1.6658000000000004, 3.2126677256323557, 2.8705179800000002, 1.489743658544055, 2.4600526128161704, 2.4762783644425923, 1.6127557378161883, 2.4699744878161702, 2.4714155335440555, 3.9685271006323415, 2.9600838628161714, 2.2977528522578052, 2.418365112816172, 1.5076307378161955, 2.466490112816171, 1.2156307378161715, 1.989740112815204, 1.48822448781617, 3.435286987816172, 2.955458862816172, 0.6446932378162156, 2.1357401128161877, 2.9835213628161705, 2.863143477258763, 1.416828125, 1.4352557378161717, 0.1837401128161784, 2.48692761281617, 2.4777088628161703, 1.8709242300000006, 2.472899908544055, 2.4828182378161703, 1.4954432378161697, 1.48711511281617, 2.3978182378161716, 1.3004212713603147, 1.4889269177729418, 1.3736932378161733, 1.4741932378161708, 2.468786987816171, 1.3671117300000004, 2.443021362816172, 1.7711898550000003, 2.6726125, 2.9770057378161705, 1.960755737815205, 1.3762211050000002, 3.3022679800000003, 3.3003987178161744, 2.193995850632378, 1.8752211050000003, 0.8311463628161703, 1.856870850632372, 2.16639375, 3.3300057378161703, 1.4625682378161715, 1.9612401128161707, 2.470278364442593, 4.495921271360225, 2.4731151128161706, 1.6705213628162077, 2.9840362927729416, 0.32100886281620267, 0.8970838628161706, 2.9525369878161714, 2.480630737815204, 2.4743807378161704, 1.9797088628152044, 1.980411292772942, 1.2987557378161778, 3.99321460063234, 1.9751186585440554, 2.4628651128161705, 2.0461932378161904, 2.962603033544055, 2.9826307378161703, 2.966865112816171, 2.9356307378152033, 1.471599487816171, -0.2786661371838298, 3.421005737816171, 2.9258963628161703, 1.46756823781617, 2.9879276128161703, 2.4890362927729415, 3.926955977258765, 0.837046875, 3.9776677256323403, 1.4699814894425924, 2.4821144177729417, 2.4697627394425927, 2.4831151128161704, 1.9249588628161725, 4.465042725632341, 2.4634588628161707, 1.3756273550000004, 1.344927612816171, 2.4787088628161706], "episode_lengths": [85, 1280, 16, 230, 21, 19, 45, 18, 300, 38, 28, 51, 35, 152, 73, 660, 33, 980, 17, 22, 66, 43, 1280, 273, 23, 379, 23, 76, 721, 21, 27, 19, 33, 24, 16, 25, 88, 1272, 21, 128, 32, 34, 23, 55, 94, 12, 28, 44, 20, 37, 89, 669, 20, 207, 517, 18, 28, 40, 49, 18, 24, 25, 599, 18, 1227, 99, 50, 20, 36, 27, 26, 172, 23, 27, 41, 352, 32, 20, 41, 20, 30, 1171, 28, 31, 40, 21, 18, 55, 17, 38, 17, 25, 23, 25, 75, 46, 43, 18, 149, 27], "policy_red_v24_reward": [3.4071689894425945, -2.0159999999999987, 0.4599346144425932], "policy_red_v8_reward": [-1.2369999999999823, -0.007, -0.56], "policy_red_v21_reward": [-2.0039999999999996], "policy_red_v15_reward": [-0.56530676218383, -2.0169999999999995], "policy_blue_reward": [-0.009000000000000001, -2.0029999999999997, -1.013999999999999, -1.0089999999999995, -1.0079999999999998, 1.1989374999999998, -1.2959999999999743, -2.0059999999999993, -2.0039999999999996, -1.3499999999999657, -1.0789999999999969, -1.0089999999999997, -1.2060000000000002, -1.007, -1.0089999999999995, -2.0069999999999997, -1.0079999999999993, -1.0069999999999995, -2.002, -2.0029999999999997, -1.0299999999999974, -2.003, -2.0109999999999997, -0.002, -0.006, -2.004, -2.005, -1.0019999999999998, -1.0049999999999997, -1.2029999999999814, 1.9963156250000265, -0.015000000000000006, -1.0079999999999993, -2.0089999999999995, -2.0479999999999965, -2.0079999999999996, -1.0119999999999993, -1.094999999999991, -0.008, -0.010000000000000002, -2.0119999999999996, -0.005, -2.001, -2.006, -1.007, -1.0039999999999998, -1.0079999999999996, -1.0109999999999995, -2.006, -1.555, -1.0089999999999997], "policy_red_v40_reward": [-1.001, -2.0339999999999976], "policy_red_v27_reward": [0.4966932378161699], "policy_red_v33_reward": [-0.019000000000000006, 1.8533026128161898, -2.0139999999999985, -0.44235937499999967], "policy_red_v26_reward": [1.8500596144425923], "policy_red_v18_reward": [-1.025], "policy_red_v4_reward": [-1.0069999999999995, -2.01, -1.0149999999999995, -1.004], "policy_red_v42_reward": [0.481], "policy_red_v13_reward": [-0.012000000000000004, 0.3933906250000002], "policy_red_v2_reward": [1.6564502394425924], "policy_red_v30_reward": [-2.008999999999999, 0.5036932378161697], "policy_red_v32_reward": [0.182103033544057], "policy_red_v45_reward": [-2.0429999999999966], "policy_red_v7_reward": [-1.0099999999999993], "policy_red_v22_reward": [-2.0139999999999993, 1.5066932378161697], "policy_red_v14_reward": [2.437328125], "policy_red_v10_reward": [1.89190625], "policy_red_v5_reward": [0.437, -0.007], "policy_red_v35_reward": [3.295705480000003], "policy_red_v31_reward": [-1.5189999999999997], "policy_red_v19_reward": [1.5601776128161713, -0.1549999999999998], "policy_red_v43_reward": [-0.5039999999999998], "policy_red_v16_reward": [-1.0099999999999998], "policy_red_v12_reward": [-2.0089999999999995, -0.009000000000000001, 0.49869323781617014], "policy_red_v44_reward": [-0.5559999999999998], "policy_red_v11_reward": [0.433], "policy_red_v20_reward": [1.48969323781617]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8118368420494548, "mean_inference_ms": 7.72816417657285, "mean_action_processing_ms": 0.29329525010973084, "mean_env_wait_ms": 0.38842384329913543, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0982445478439331, "StateBufferConnector_ms": 0.004130840301513672, "ViewRequirementAgentConnector_ms": 0.11515593528747559}}, "episode_reward_max": 4.495921271360225, "episode_reward_min": -0.2786661371838298, "episode_reward_mean": 2.217478254595021, "episode_len_mean": 154.71, "episodes_this_iter": 35, "policy_reward_min": {"red_v24": -2.0159999999999987, "red": -1.675306762183828, "red_v8": -1.2369999999999823, "red_v21": -2.0039999999999996, "red_v15": -2.0169999999999995, "blue": -2.0479999999999965, "red_v40": -2.0339999999999976, "red_v27": 0.4966932378161699, "red_v33": -2.0139999999999985, "red_v26": 1.8500596144425923, "red_v18": -1.025, "red_v4": -2.01, "red_v42": 0.481, "red_v13": -0.012000000000000004, "red_v2": 1.6564502394425924, "red_v30": -2.008999999999999, "red_v32": 0.182103033544057, "red_v45": -2.0429999999999966, "red_v7": -1.0099999999999993, "red_v22": -2.0139999999999993, "red_v14": 2.437328125, "red_v10": 1.89190625, "red_v5": -0.007, "red_v35": 3.295705480000003, "red_v31": -1.5189999999999997, "red_v19": -0.1549999999999998, "red_v43": -0.5039999999999998, "red_v16": -1.0099999999999998, "red_v12": -2.0089999999999995, "red_v44": -0.5559999999999998, "red_v11": 0.433, "red_v20": 1.48969323781617}, "policy_reward_max": {"red_v24": 3.4071689894425945, "red": 3.995740112815204, "red_v8": -0.007, "red_v21": -2.0039999999999996, "red_v15": -0.56530676218383, "blue": 1.9963156250000265, "red_v40": -1.001, "red_v27": 0.4966932378161699, "red_v33": 1.8533026128161898, "red_v26": 1.8500596144425923, "red_v18": -1.025, "red_v4": -1.004, "red_v42": 0.481, "red_v13": 0.3933906250000002, "red_v2": 1.6564502394425924, "red_v30": 0.5036932378161697, "red_v32": 0.182103033544057, "red_v45": -2.0429999999999966, "red_v7": -1.0099999999999993, "red_v22": 1.5066932378161697, "red_v14": 2.437328125, "red_v10": 1.89190625, "red_v5": 0.437, "red_v35": 3.295705480000003, "red_v31": -1.5189999999999997, "red_v19": 1.5601776128161713, "red_v43": -0.5039999999999998, "red_v16": -1.0099999999999998, "red_v12": 0.49869323781617014, "red_v44": -0.5559999999999998, "red_v11": 0.433, "red_v20": 1.48969323781617}, "policy_reward_mean": {"red_v24": 0.6170345346283964, "red": 2.8769724508565817, "red_v8": -0.6013333333333274, "red_v21": -2.0039999999999996, "red_v15": -1.2911533810919147, "blue": -1.1362499387254879, "red_v40": -1.5174999999999987, "red_v27": 0.4966932378161699, "red_v33": -0.15551419054595206, "red_v26": 1.8500596144425923, "red_v18": -1.025, "red_v4": -1.259, "red_v42": 0.481, "red_v13": 0.1906953125000001, "red_v2": 1.6564502394425924, "red_v30": -0.7526533810919147, "red_v32": 0.182103033544057, "red_v45": -2.0429999999999966, "red_v7": -1.0099999999999993, "red_v22": -0.2536533810919148, "red_v14": 2.437328125, "red_v10": 1.89190625, "red_v5": 0.215, "red_v35": 3.295705480000003, "red_v31": -1.5189999999999997, "red_v19": 0.7025888064080857, "red_v43": -0.5039999999999998, "red_v16": -1.0099999999999998, "red_v12": -0.5064355873946097, "red_v44": -0.5559999999999998, "red_v11": 0.433, "red_v20": 1.48969323781617}, "hist_stats": {"episode_reward": [3.414862227258764, 0.12469323781617148, 1.6658000000000004, 3.2126677256323557, 2.8705179800000002, 1.489743658544055, 2.4600526128161704, 2.4762783644425923, 1.6127557378161883, 2.4699744878161702, 2.4714155335440555, 3.9685271006323415, 2.9600838628161714, 2.2977528522578052, 2.418365112816172, 1.5076307378161955, 2.466490112816171, 1.2156307378161715, 1.989740112815204, 1.48822448781617, 3.435286987816172, 2.955458862816172, 0.6446932378162156, 2.1357401128161877, 2.9835213628161705, 2.863143477258763, 1.416828125, 1.4352557378161717, 0.1837401128161784, 2.48692761281617, 2.4777088628161703, 1.8709242300000006, 2.472899908544055, 2.4828182378161703, 1.4954432378161697, 1.48711511281617, 2.3978182378161716, 1.3004212713603147, 1.4889269177729418, 1.3736932378161733, 1.4741932378161708, 2.468786987816171, 1.3671117300000004, 2.443021362816172, 1.7711898550000003, 2.6726125, 2.9770057378161705, 1.960755737815205, 1.3762211050000002, 3.3022679800000003, 3.3003987178161744, 2.193995850632378, 1.8752211050000003, 0.8311463628161703, 1.856870850632372, 2.16639375, 3.3300057378161703, 1.4625682378161715, 1.9612401128161707, 2.470278364442593, 4.495921271360225, 2.4731151128161706, 1.6705213628162077, 2.9840362927729416, 0.32100886281620267, 0.8970838628161706, 2.9525369878161714, 2.480630737815204, 2.4743807378161704, 1.9797088628152044, 1.980411292772942, 1.2987557378161778, 3.99321460063234, 1.9751186585440554, 2.4628651128161705, 2.0461932378161904, 2.962603033544055, 2.9826307378161703, 2.966865112816171, 2.9356307378152033, 1.471599487816171, -0.2786661371838298, 3.421005737816171, 2.9258963628161703, 1.46756823781617, 2.9879276128161703, 2.4890362927729415, 3.926955977258765, 0.837046875, 3.9776677256323403, 1.4699814894425924, 2.4821144177729417, 2.4697627394425927, 2.4831151128161704, 1.9249588628161725, 4.465042725632341, 2.4634588628161707, 1.3756273550000004, 1.344927612816171, 2.4787088628161706], "episode_lengths": [85, 1280, 16, 230, 21, 19, 45, 18, 300, 38, 28, 51, 35, 152, 73, 660, 33, 980, 17, 22, 66, 43, 1280, 273, 23, 379, 23, 76, 721, 21, 27, 19, 33, 24, 16, 25, 88, 1272, 21, 128, 32, 34, 23, 55, 94, 12, 28, 44, 20, 37, 89, 669, 20, 207, 517, 18, 28, 40, 49, 18, 24, 25, 599, 18, 1227, 99, 50, 20, 36, 27, 26, 172, 23, 27, 41, 352, 32, 20, 41, 20, 30, 1171, 28, 31, 40, 21, 18, 55, 17, 38, 17, 25, 23, 25, 75, 46, 43, 18, 149, 27], "policy_red_v24_reward": [3.4071689894425945, -2.0159999999999987, 0.4599346144425932], "policy_red_v8_reward": [-1.2369999999999823, -0.007, -0.56], "policy_red_v21_reward": [-2.0039999999999996], "policy_red_v15_reward": [-0.56530676218383, -2.0169999999999995], "policy_blue_reward": [-0.009000000000000001, -2.0029999999999997, -1.013999999999999, -1.0089999999999995, -1.0079999999999998, 1.1989374999999998, -1.2959999999999743, -2.0059999999999993, -2.0039999999999996, -1.3499999999999657, -1.0789999999999969, -1.0089999999999997, -1.2060000000000002, -1.007, -1.0089999999999995, -2.0069999999999997, -1.0079999999999993, -1.0069999999999995, -2.002, -2.0029999999999997, -1.0299999999999974, -2.003, -2.0109999999999997, -0.002, -0.006, -2.004, -2.005, -1.0019999999999998, -1.0049999999999997, -1.2029999999999814, 1.9963156250000265, -0.015000000000000006, -1.0079999999999993, -2.0089999999999995, -2.0479999999999965, -2.0079999999999996, -1.0119999999999993, -1.094999999999991, -0.008, -0.010000000000000002, -2.0119999999999996, -0.005, -2.001, -2.006, -1.007, -1.0039999999999998, -1.0079999999999996, -1.0109999999999995, -2.006, -1.555, -1.0089999999999997], "policy_red_v40_reward": [-1.001, -2.0339999999999976], "policy_red_v27_reward": [0.4966932378161699], "policy_red_v33_reward": [-0.019000000000000006, 1.8533026128161898, -2.0139999999999985, -0.44235937499999967], "policy_red_v26_reward": [1.8500596144425923], "policy_red_v18_reward": [-1.025], "policy_red_v4_reward": [-1.0069999999999995, -2.01, -1.0149999999999995, -1.004], "policy_red_v42_reward": [0.481], "policy_red_v13_reward": [-0.012000000000000004, 0.3933906250000002], "policy_red_v2_reward": [1.6564502394425924], "policy_red_v30_reward": [-2.008999999999999, 0.5036932378161697], "policy_red_v32_reward": [0.182103033544057], "policy_red_v45_reward": [-2.0429999999999966], "policy_red_v7_reward": [-1.0099999999999993], "policy_red_v22_reward": [-2.0139999999999993, 1.5066932378161697], "policy_red_v14_reward": [2.437328125], "policy_red_v10_reward": [1.89190625], "policy_red_v5_reward": [0.437, -0.007], "policy_red_v35_reward": [3.295705480000003], "policy_red_v31_reward": [-1.5189999999999997], "policy_red_v19_reward": [1.5601776128161713, -0.1549999999999998], "policy_red_v43_reward": [-0.5039999999999998], "policy_red_v16_reward": [-1.0099999999999998], "policy_red_v12_reward": [-2.0089999999999995, -0.009000000000000001, 0.49869323781617014], "policy_red_v44_reward": [-0.5559999999999998], "policy_red_v11_reward": [0.433], "policy_red_v20_reward": [1.48969323781617]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8118368420494548, "mean_inference_ms": 7.72816417657285, "mean_action_processing_ms": 0.29329525010973084, "mean_env_wait_ms": 0.38842384329913543, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0982445478439331, "StateBufferConnector_ms": 0.004130840301513672, "ViewRequirementAgentConnector_ms": 0.11515593528747559}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 197.99711917133496, "num_env_steps_trained_throughput_per_sec": 197.99711917133496, "timesteps_total": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 20028.419, "sample_time_ms": 1140.555, "learn_time_ms": 18804.749, "learn_throughput": 212.712, "synch_weights_time_ms": 80.113}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "episodes_total": 1025, "training_iteration": 80, "trial_id": "a9680_00000", "date": "2023-09-24_03-05-06", "timestamp": 1695539106, "time_this_iter_s": 20.212836265563965, "time_total_s": 1595.470781803131, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b342af220>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34286dd0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34286e60>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1595.470781803131, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 5.196969696969697, "ram_util_percent": 22.284848484848485}, "win_rate": 0.79, "league_size": 50}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6017561433836818, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.09722714776435168, "policy_loss": -0.03550679319499371, "vf_loss": 0.2566640047589317, "vf_explained_var": 0.3905650246888399, "kl": 0.013922854688704927, "entropy": 1.8633454735080401, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 77280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 648000, "num_agent_steps_trained": 648000}, "sampler_results": {"episode_reward_max": 4.497323280588145, "episode_reward_min": -0.2786661371838298, "episode_reward_mean": 2.1810615738031576, "episode_len_mean": 115.73, "episode_media": {}, "episodes_this_iter": 28, "policy_reward_min": {"blue": -2.0479999999999965, "red": -1.675306762183828, "red_v32": 0.182103033544057, "red_v45": -2.0429999999999966, "red_v7": -1.0099999999999993, "red_v22": -2.0139999999999993, "red_v14": -0.006, "red_v10": 1.89190625, "red_v4": -2.01, "red_v5": -0.014000000000000005, "red_v35": 3.295705480000003, "red_v33": -2.0139999999999985, "red_v31": -1.5189999999999997, "red_v19": -0.1549999999999998, "red_v24": -2.0159999999999987, "red_v43": -1.0089999999999997, "red_v13": 0.3933906250000002, "red_v16": -1.0099999999999998, "red_v12": -2.0089999999999995, "red_v30": 0.5036932378161697, "red_v44": -0.5559999999999998, "red_v11": -1.0219999999999996, "red_v8": -0.56, "red_v15": -2.0169999999999995, "red_v20": 1.48969323781617, "red_v27": -0.2713067621838299, "red_v29": 1.5056932378152037, "red_v1": -2.008, "red_v41": -1.537, "red_v2": -0.016000000000000007, "red_v47": -1.005, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": -2.0139999999999993}, "policy_reward_max": {"blue": 1.9963156250000265, "red": 3.9894112927729424, "red_v32": 0.182103033544057, "red_v45": -2.0429999999999966, "red_v7": -1.0099999999999993, "red_v22": 1.5066932378161697, "red_v14": 2.437328125, "red_v10": 1.89190625, "red_v4": -1.004, "red_v5": 0.437, "red_v35": 3.295705480000003, "red_v33": 1.8533026128161898, "red_v31": -1.5189999999999997, "red_v19": 1.5601776128161713, "red_v24": 0.4599346144425932, "red_v43": -0.5039999999999998, "red_v13": 0.3933906250000002, "red_v16": -1.0099999999999998, "red_v12": 0.49869323781617014, "red_v30": 1.8410937500000002, "red_v44": -0.5559999999999998, "red_v11": 0.433, "red_v8": -0.56, "red_v15": -2.0169999999999995, "red_v20": 1.48969323781617, "red_v27": -0.2713067621838299, "red_v29": 1.5056932378152037, "red_v1": -2.008, "red_v41": 0.5046925427729418, "red_v2": -0.016000000000000007, "red_v47": -1.005, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": -2.0139999999999993}, "policy_reward_mean": {"blue": -1.1974643995098024, "red": 2.8978971955702764, "red_v32": 0.182103033544057, "red_v45": -2.0429999999999966, "red_v7": -1.0099999999999993, "red_v22": -0.2536533810919148, "red_v14": 1.2156640625000001, "red_v10": 1.89190625, "red_v4": -1.3857499999999998, "red_v5": 0.13866666666666666, "red_v35": 3.295705480000003, "red_v33": -0.20101892072793612, "red_v31": -1.5189999999999997, "red_v19": 0.7025888064080857, "red_v24": -0.7780326927787027, "red_v43": -0.7564999999999997, "red_v13": 0.3933906250000002, "red_v16": -1.0099999999999998, "red_v12": -0.5064355873946097, "red_v30": 1.172393493908085, "red_v44": -0.5559999999999998, "red_v11": -0.29449999999999976, "red_v8": -0.56, "red_v15": -2.0169999999999995, "red_v20": 1.48969323781617, "red_v27": -0.2713067621838299, "red_v29": 1.5056932378152037, "red_v1": -2.008, "red_v41": -0.516153728613529, "red_v2": -0.016000000000000007, "red_v47": -1.005, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": -2.0139999999999993}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.1837401128161784, 2.48692761281617, 2.4777088628161703, 1.8709242300000006, 2.472899908544055, 2.4828182378161703, 1.4954432378161697, 1.48711511281617, 2.3978182378161716, 1.3004212713603147, 1.4889269177729418, 1.3736932378161733, 1.4741932378161708, 2.468786987816171, 1.3671117300000004, 2.443021362816172, 1.7711898550000003, 2.6726125, 2.9770057378161705, 1.960755737815205, 1.3762211050000002, 3.3022679800000003, 3.3003987178161744, 2.193995850632378, 1.8752211050000003, 0.8311463628161703, 1.856870850632372, 2.16639375, 3.3300057378161703, 1.4625682378161715, 1.9612401128161707, 2.470278364442593, 4.495921271360225, 2.4731151128161706, 1.6705213628162077, 2.9840362927729416, 0.32100886281620267, 0.8970838628161706, 2.9525369878161714, 2.480630737815204, 2.4743807378161704, 1.9797088628152044, 1.980411292772942, 1.2987557378161778, 3.99321460063234, 1.9751186585440554, 2.4628651128161705, 2.0461932378161904, 2.962603033544055, 2.9826307378161703, 2.966865112816171, 2.9356307378152033, 1.471599487816171, -0.2786661371838298, 3.421005737816171, 2.9258963628161703, 1.46756823781617, 2.9879276128161703, 2.4890362927729415, 3.926955977258765, 0.837046875, 3.9776677256323403, 1.4699814894425924, 2.4821144177729417, 2.4697627394425927, 2.4831151128161704, 1.9249588628161725, 4.465042725632341, 2.4634588628161707, 1.3756273550000004, 1.344927612816171, 2.4787088628161706, 1.9430994878161716, 1.9678721144425926, 1.4701151128152041, 2.987739417772942, 2.2220739756324197, 4.497323280588145, 2.9765994878161703, 1.4659744878161707, 2.4500526128161715, 1.4828182378161698, 3.990104530589112, 2.9420994878161717, 2.1559875000000006, 1.4153125000000002, 2.966490112816171, 1.8374531250000001, 0.8104744878161704, 2.66620625, 2.4199901128161727, 1.4767088628161704, 0.9597905335440555, 2.168224487816183, 1.4800369878152042, 2.4821151128161705, 1.8457869878161741, 1.9781932378161704, 0.7877401128161701, 0.9630838628161719], "episode_lengths": [721, 21, 27, 19, 33, 24, 16, 25, 88, 1272, 21, 128, 32, 34, 23, 55, 94, 12, 28, 44, 20, 37, 89, 669, 20, 207, 517, 18, 28, 40, 49, 18, 24, 25, 599, 18, 1227, 99, 50, 20, 36, 27, 26, 172, 23, 27, 41, 352, 32, 20, 41, 20, 30, 1171, 28, 31, 40, 21, 18, 55, 17, 38, 17, 25, 23, 25, 75, 46, 43, 18, 149, 27, 62, 20, 25, 17, 804, 20, 30, 38, 45, 24, 26, 62, 20, 28, 33, 15, 198, 14, 65, 27, 36, 278, 18, 25, 162, 32, 209, 35], "policy_blue_reward": [-1.2060000000000002, -1.007, -1.0089999999999995, -2.0069999999999997, -1.0079999999999993, -1.0069999999999995, -2.002, -2.0029999999999997, -1.0299999999999974, -2.003, -2.0109999999999997, -0.002, -0.006, -2.004, -2.005, -1.0019999999999998, -1.0049999999999997, -1.2029999999999814, 1.9963156250000265, -0.015000000000000006, -1.0079999999999993, -2.0089999999999995, -2.0479999999999965, -2.0079999999999996, -1.0119999999999993, -1.094999999999991, -0.008, -0.010000000000000002, -2.0119999999999996, -0.005, -2.001, -2.006, -1.007, -1.0039999999999998, -1.0079999999999996, -1.0109999999999995, -2.006, -1.555, -1.0089999999999997, -2.015999999999999, -0.5029999999999999, -2.01, -0.008, -2.0149999999999997, -1.0099999999999996, -1.0069999999999995, -1.5479999999999998, -0.004, -2.0109999999999992, -1.5709999999999968, -2.0069999999999992], "policy_red_v32_reward": [0.182103033544057], "policy_red_v45_reward": [-2.0429999999999966], "policy_red_v7_reward": [-1.0099999999999993], "policy_red_v22_reward": [-2.0139999999999993, 1.5066932378161697], "policy_red_v14_reward": [2.437328125, -0.006], "policy_red_v10_reward": [1.89190625], "policy_red_v4_reward": [-2.01, -1.0149999999999995, -1.004, -1.5139999999999998], "policy_red_v5_reward": [0.437, -0.007, -0.014000000000000005], "policy_red_v35_reward": [3.295705480000003], "policy_red_v33_reward": [1.8533026128161898, -2.0139999999999985, -0.44235937499999967], "policy_red_v31_reward": [-1.5189999999999997], "policy_red_v19_reward": [1.5601776128161713, -0.1549999999999998], "policy_red_v24_reward": [-2.0159999999999987, 0.4599346144425932], "policy_red_v43_reward": [-0.5039999999999998, -1.0089999999999997], "policy_red_v13_reward": [0.3933906250000002], "policy_red_v16_reward": [-1.0099999999999998], "policy_red_v12_reward": [-2.0089999999999995, -0.009000000000000001, 0.49869323781617014], "policy_red_v30_reward": [0.5036932378161697, 1.8410937500000002], "policy_red_v44_reward": [-0.5559999999999998], "policy_red_v11_reward": [0.433, -1.0219999999999996], "policy_red_v8_reward": [-0.56], "policy_red_v15_reward": [-2.0169999999999995], "policy_red_v20_reward": [1.48969323781617], "policy_red_v27_reward": [-0.2713067621838299], "policy_red_v29_reward": [1.5056932378152037], "policy_red_v1_reward": [-2.008], "policy_red_v41_reward": [0.5046925427729418, -1.537], "policy_red_v2_reward": [-0.016000000000000007], "policy_red_v47_reward": [-1.005], "policy_red_v28_reward": [0.46499999999999997], "policy_red_v39_reward": [0.45868750000000014], "policy_red_v38_reward": [-2.0139999999999993]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8142937756166506, "mean_inference_ms": 7.758801493583132, "mean_action_processing_ms": 0.294621085545131, "mean_env_wait_ms": 0.390296834277856, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09924852848052979, "StateBufferConnector_ms": 0.004150748252868652, "ViewRequirementAgentConnector_ms": 0.11559915542602539}}, "episode_reward_max": 4.497323280588145, "episode_reward_min": -0.2786661371838298, "episode_reward_mean": 2.1810615738031576, "episode_len_mean": 115.73, "episodes_this_iter": 28, "policy_reward_min": {"blue": -2.0479999999999965, "red": -1.675306762183828, "red_v32": 0.182103033544057, "red_v45": -2.0429999999999966, "red_v7": -1.0099999999999993, "red_v22": -2.0139999999999993, "red_v14": -0.006, "red_v10": 1.89190625, "red_v4": -2.01, "red_v5": -0.014000000000000005, "red_v35": 3.295705480000003, "red_v33": -2.0139999999999985, "red_v31": -1.5189999999999997, "red_v19": -0.1549999999999998, "red_v24": -2.0159999999999987, "red_v43": -1.0089999999999997, "red_v13": 0.3933906250000002, "red_v16": -1.0099999999999998, "red_v12": -2.0089999999999995, "red_v30": 0.5036932378161697, "red_v44": -0.5559999999999998, "red_v11": -1.0219999999999996, "red_v8": -0.56, "red_v15": -2.0169999999999995, "red_v20": 1.48969323781617, "red_v27": -0.2713067621838299, "red_v29": 1.5056932378152037, "red_v1": -2.008, "red_v41": -1.537, "red_v2": -0.016000000000000007, "red_v47": -1.005, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": -2.0139999999999993}, "policy_reward_max": {"blue": 1.9963156250000265, "red": 3.9894112927729424, "red_v32": 0.182103033544057, "red_v45": -2.0429999999999966, "red_v7": -1.0099999999999993, "red_v22": 1.5066932378161697, "red_v14": 2.437328125, "red_v10": 1.89190625, "red_v4": -1.004, "red_v5": 0.437, "red_v35": 3.295705480000003, "red_v33": 1.8533026128161898, "red_v31": -1.5189999999999997, "red_v19": 1.5601776128161713, "red_v24": 0.4599346144425932, "red_v43": -0.5039999999999998, "red_v13": 0.3933906250000002, "red_v16": -1.0099999999999998, "red_v12": 0.49869323781617014, "red_v30": 1.8410937500000002, "red_v44": -0.5559999999999998, "red_v11": 0.433, "red_v8": -0.56, "red_v15": -2.0169999999999995, "red_v20": 1.48969323781617, "red_v27": -0.2713067621838299, "red_v29": 1.5056932378152037, "red_v1": -2.008, "red_v41": 0.5046925427729418, "red_v2": -0.016000000000000007, "red_v47": -1.005, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": -2.0139999999999993}, "policy_reward_mean": {"blue": -1.1974643995098024, "red": 2.8978971955702764, "red_v32": 0.182103033544057, "red_v45": -2.0429999999999966, "red_v7": -1.0099999999999993, "red_v22": -0.2536533810919148, "red_v14": 1.2156640625000001, "red_v10": 1.89190625, "red_v4": -1.3857499999999998, "red_v5": 0.13866666666666666, "red_v35": 3.295705480000003, "red_v33": -0.20101892072793612, "red_v31": -1.5189999999999997, "red_v19": 0.7025888064080857, "red_v24": -0.7780326927787027, "red_v43": -0.7564999999999997, "red_v13": 0.3933906250000002, "red_v16": -1.0099999999999998, "red_v12": -0.5064355873946097, "red_v30": 1.172393493908085, "red_v44": -0.5559999999999998, "red_v11": -0.29449999999999976, "red_v8": -0.56, "red_v15": -2.0169999999999995, "red_v20": 1.48969323781617, "red_v27": -0.2713067621838299, "red_v29": 1.5056932378152037, "red_v1": -2.008, "red_v41": -0.516153728613529, "red_v2": -0.016000000000000007, "red_v47": -1.005, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": -2.0139999999999993}, "hist_stats": {"episode_reward": [0.1837401128161784, 2.48692761281617, 2.4777088628161703, 1.8709242300000006, 2.472899908544055, 2.4828182378161703, 1.4954432378161697, 1.48711511281617, 2.3978182378161716, 1.3004212713603147, 1.4889269177729418, 1.3736932378161733, 1.4741932378161708, 2.468786987816171, 1.3671117300000004, 2.443021362816172, 1.7711898550000003, 2.6726125, 2.9770057378161705, 1.960755737815205, 1.3762211050000002, 3.3022679800000003, 3.3003987178161744, 2.193995850632378, 1.8752211050000003, 0.8311463628161703, 1.856870850632372, 2.16639375, 3.3300057378161703, 1.4625682378161715, 1.9612401128161707, 2.470278364442593, 4.495921271360225, 2.4731151128161706, 1.6705213628162077, 2.9840362927729416, 0.32100886281620267, 0.8970838628161706, 2.9525369878161714, 2.480630737815204, 2.4743807378161704, 1.9797088628152044, 1.980411292772942, 1.2987557378161778, 3.99321460063234, 1.9751186585440554, 2.4628651128161705, 2.0461932378161904, 2.962603033544055, 2.9826307378161703, 2.966865112816171, 2.9356307378152033, 1.471599487816171, -0.2786661371838298, 3.421005737816171, 2.9258963628161703, 1.46756823781617, 2.9879276128161703, 2.4890362927729415, 3.926955977258765, 0.837046875, 3.9776677256323403, 1.4699814894425924, 2.4821144177729417, 2.4697627394425927, 2.4831151128161704, 1.9249588628161725, 4.465042725632341, 2.4634588628161707, 1.3756273550000004, 1.344927612816171, 2.4787088628161706, 1.9430994878161716, 1.9678721144425926, 1.4701151128152041, 2.987739417772942, 2.2220739756324197, 4.497323280588145, 2.9765994878161703, 1.4659744878161707, 2.4500526128161715, 1.4828182378161698, 3.990104530589112, 2.9420994878161717, 2.1559875000000006, 1.4153125000000002, 2.966490112816171, 1.8374531250000001, 0.8104744878161704, 2.66620625, 2.4199901128161727, 1.4767088628161704, 0.9597905335440555, 2.168224487816183, 1.4800369878152042, 2.4821151128161705, 1.8457869878161741, 1.9781932378161704, 0.7877401128161701, 0.9630838628161719], "episode_lengths": [721, 21, 27, 19, 33, 24, 16, 25, 88, 1272, 21, 128, 32, 34, 23, 55, 94, 12, 28, 44, 20, 37, 89, 669, 20, 207, 517, 18, 28, 40, 49, 18, 24, 25, 599, 18, 1227, 99, 50, 20, 36, 27, 26, 172, 23, 27, 41, 352, 32, 20, 41, 20, 30, 1171, 28, 31, 40, 21, 18, 55, 17, 38, 17, 25, 23, 25, 75, 46, 43, 18, 149, 27, 62, 20, 25, 17, 804, 20, 30, 38, 45, 24, 26, 62, 20, 28, 33, 15, 198, 14, 65, 27, 36, 278, 18, 25, 162, 32, 209, 35], "policy_blue_reward": [-1.2060000000000002, -1.007, -1.0089999999999995, -2.0069999999999997, -1.0079999999999993, -1.0069999999999995, -2.002, -2.0029999999999997, -1.0299999999999974, -2.003, -2.0109999999999997, -0.002, -0.006, -2.004, -2.005, -1.0019999999999998, -1.0049999999999997, -1.2029999999999814, 1.9963156250000265, -0.015000000000000006, -1.0079999999999993, -2.0089999999999995, -2.0479999999999965, -2.0079999999999996, -1.0119999999999993, -1.094999999999991, -0.008, -0.010000000000000002, -2.0119999999999996, -0.005, -2.001, -2.006, -1.007, -1.0039999999999998, -1.0079999999999996, -1.0109999999999995, -2.006, -1.555, -1.0089999999999997, -2.015999999999999, -0.5029999999999999, -2.01, -0.008, -2.0149999999999997, -1.0099999999999996, -1.0069999999999995, -1.5479999999999998, -0.004, -2.0109999999999992, -1.5709999999999968, -2.0069999999999992], "policy_red_v32_reward": [0.182103033544057], "policy_red_v45_reward": [-2.0429999999999966], "policy_red_v7_reward": [-1.0099999999999993], "policy_red_v22_reward": [-2.0139999999999993, 1.5066932378161697], "policy_red_v14_reward": [2.437328125, -0.006], "policy_red_v10_reward": [1.89190625], "policy_red_v4_reward": [-2.01, -1.0149999999999995, -1.004, -1.5139999999999998], "policy_red_v5_reward": [0.437, -0.007, -0.014000000000000005], "policy_red_v35_reward": [3.295705480000003], "policy_red_v33_reward": [1.8533026128161898, -2.0139999999999985, -0.44235937499999967], "policy_red_v31_reward": [-1.5189999999999997], "policy_red_v19_reward": [1.5601776128161713, -0.1549999999999998], "policy_red_v24_reward": [-2.0159999999999987, 0.4599346144425932], "policy_red_v43_reward": [-0.5039999999999998, -1.0089999999999997], "policy_red_v13_reward": [0.3933906250000002], "policy_red_v16_reward": [-1.0099999999999998], "policy_red_v12_reward": [-2.0089999999999995, -0.009000000000000001, 0.49869323781617014], "policy_red_v30_reward": [0.5036932378161697, 1.8410937500000002], "policy_red_v44_reward": [-0.5559999999999998], "policy_red_v11_reward": [0.433, -1.0219999999999996], "policy_red_v8_reward": [-0.56], "policy_red_v15_reward": [-2.0169999999999995], "policy_red_v20_reward": [1.48969323781617], "policy_red_v27_reward": [-0.2713067621838299], "policy_red_v29_reward": [1.5056932378152037], "policy_red_v1_reward": [-2.008], "policy_red_v41_reward": [0.5046925427729418, -1.537], "policy_red_v2_reward": [-0.016000000000000007], "policy_red_v47_reward": [-1.005], "policy_red_v28_reward": [0.46499999999999997], "policy_red_v39_reward": [0.45868750000000014], "policy_red_v38_reward": [-2.0139999999999993]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8142937756166506, "mean_inference_ms": 7.758801493583132, "mean_action_processing_ms": 0.294621085545131, "mean_env_wait_ms": 0.390296834277856, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09924852848052979, "StateBufferConnector_ms": 0.004150748252868652, "ViewRequirementAgentConnector_ms": 0.11559915542602539}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 648000, "num_agent_steps_trained": 648000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 204.82211988885078, "num_env_steps_trained_throughput_per_sec": 204.82211988885078, "timesteps_total": 324000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 648000, "timers": {"training_iteration_time_ms": 19956.21, "sample_time_ms": 1138.375, "learn_time_ms": 18733.307, "learn_throughput": 213.523, "synch_weights_time_ms": 81.474}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 648000, "num_agent_steps_trained": 648000}, "done": false, "episodes_total": 1053, "training_iteration": 81, "trial_id": "a9680_00000", "date": "2023-09-24_03-05-32", "timestamp": 1695539132, "time_this_iter_s": 19.53930950164795, "time_total_s": 1615.010091304779, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1df3c100>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b342875b0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34287640>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1615.010091304779, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 5.033333333333334, "ram_util_percent": 22.388888888888886}, "win_rate": 0.8, "league_size": 51}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.082396381100019, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0005051081767305732, "policy_loss": -0.055155413348499376, "vf_loss": 0.09987767881248147, "vf_explained_var": 0.7330787921324372, "kl": 0.016979445314056343, "entropy": 1.91906796519955, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 78240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "sampler_results": {"episode_reward_max": 4.497323280588145, "episode_reward_min": -0.2786661371838298, "episode_reward_mean": 2.197247680144922, "episode_len_mean": 110.31, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"blue": -2.0479999999999965, "red": -1.675306762183828, "red_v5": -0.014000000000000005, "red_v35": 3.295705480000003, "red_v33": -2.0139999999999985, "red_v31": -1.5189999999999997, "red_v19": -0.1549999999999998, "red_v24": -2.0159999999999987, "red_v43": -1.0089999999999997, "red_v22": 1.5066932378161697, "red_v4": -1.5139999999999998, "red_v13": -2.014999999999999, "red_v16": -1.0099999999999998, "red_v12": -2.0089999999999995, "red_v30": 0.5036932378161697, "red_v44": -0.5559999999999998, "red_v11": -1.0219999999999996, "red_v8": -0.56, "red_v15": -2.0169999999999995, "red_v20": 1.48969323781617, "red_v14": -0.006, "red_v27": -0.2713067621838299, "red_v29": 1.5056932378152037, "red_v1": -2.008, "red_v41": -1.537, "red_v2": -0.016000000000000007, "red_v47": -1.006, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": -2.0139999999999993, "red_v40": 0.5006932378161698, "red_v17": -2.0299999999999994, "red_v9": -2.0119999999999996, "red_v10": 1.3592836050000003, "red_v25": -2.0089999999999995}, "policy_reward_max": {"blue": 1.9963156250000265, "red": 3.9894112927729424, "red_v5": 0.47350000000000003, "red_v35": 3.295705480000003, "red_v33": 1.8533026128161898, "red_v31": -1.5189999999999997, "red_v19": 1.5601776128161713, "red_v24": 0.4599346144425932, "red_v43": -0.5039999999999998, "red_v22": 1.5066932378161697, "red_v4": -1.004, "red_v13": 0.3933906250000002, "red_v16": -1.0099999999999998, "red_v12": 0.49869323781617014, "red_v30": 1.8410937500000002, "red_v44": -0.5559999999999998, "red_v11": 0.433, "red_v8": -0.56, "red_v15": -2.0169999999999995, "red_v20": 1.48969323781617, "red_v14": -0.006, "red_v27": -0.2713067621838299, "red_v29": 1.5056932378152037, "red_v1": 0.84, "red_v41": 0.5046925427729418, "red_v2": -0.016000000000000007, "red_v47": -1.005, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": -2.0139999999999993, "red_v40": 1.5046932378161697, "red_v17": -2.0299999999999994, "red_v9": -2.0119999999999996, "red_v10": 1.3592836050000003, "red_v25": -0.56}, "policy_reward_mean": {"blue": -1.2115583559782597, "red": 2.894644975191157, "red_v5": 0.222375, "red_v35": 3.295705480000003, "red_v33": -0.20101892072793612, "red_v31": -1.5189999999999997, "red_v19": 0.7025888064080857, "red_v24": -0.7780326927787027, "red_v43": -0.7564999999999997, "red_v22": 1.5066932378161697, "red_v4": -1.1349999999999998, "red_v13": -0.8108046874999992, "red_v16": -1.0099999999999998, "red_v12": -0.5064355873946097, "red_v30": 1.172393493908085, "red_v44": -0.5559999999999998, "red_v11": -0.29449999999999976, "red_v8": -0.56, "red_v15": -2.0169999999999995, "red_v20": 1.48969323781617, "red_v14": -0.006, "red_v27": -0.2713067621838299, "red_v29": 1.5056932378152037, "red_v1": -0.5840000000000001, "red_v41": -0.516153728613529, "red_v2": -0.016000000000000007, "red_v47": -1.0055, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": -2.0139999999999993, "red_v40": 1.0026932378161697, "red_v17": -2.0299999999999994, "red_v9": -2.0119999999999996, "red_v10": 1.3592836050000003, "red_v25": -1.2844999999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.3762211050000002, 3.3022679800000003, 3.3003987178161744, 2.193995850632378, 1.8752211050000003, 0.8311463628161703, 1.856870850632372, 2.16639375, 3.3300057378161703, 1.4625682378161715, 1.9612401128161707, 2.470278364442593, 4.495921271360225, 2.4731151128161706, 1.6705213628162077, 2.9840362927729416, 0.32100886281620267, 0.8970838628161706, 2.9525369878161714, 2.480630737815204, 2.4743807378161704, 1.9797088628152044, 1.980411292772942, 1.2987557378161778, 3.99321460063234, 1.9751186585440554, 2.4628651128161705, 2.0461932378161904, 2.962603033544055, 2.9826307378161703, 2.966865112816171, 2.9356307378152033, 1.471599487816171, -0.2786661371838298, 3.421005737816171, 2.9258963628161703, 1.46756823781617, 2.9879276128161703, 2.4890362927729415, 3.926955977258765, 0.837046875, 3.9776677256323403, 1.4699814894425924, 2.4821144177729417, 2.4697627394425927, 2.4831151128161704, 1.9249588628161725, 4.465042725632341, 2.4634588628161707, 1.3756273550000004, 1.344927612816171, 2.4787088628161706, 1.9430994878161716, 1.9678721144425926, 1.4701151128152041, 2.987739417772942, 2.2220739756324197, 4.497323280588145, 2.9765994878161703, 1.4659744878161707, 2.4500526128161715, 1.4828182378161698, 3.990104530589112, 2.9420994878161717, 2.1559875000000006, 1.4153125000000002, 2.966490112816171, 1.8374531250000001, 0.8104744878161704, 2.66620625, 2.4199901128161727, 1.4767088628161704, 0.9597905335440555, 2.168224487816183, 1.4800369878152042, 2.4821151128161705, 1.8457869878161741, 1.9781932378161704, 0.7877401128161701, 0.9630838628161719, 1.0867869878161804, 0.9787088628161702, 4.487183350632341, 1.4474588628161715, 1.4767088628161704, 3.97966772563234, 3.1741273550000013, 0.8677836050000003, 3.812458862816171, 2.47708386281617, 0.8759242300000005, 2.4838182378161706, 2.477193237816171, 2.9205682378161706, 2.450317542772942, -0.08596301218382829, 1.4695682378161705, 1.4472088628161712, 1.4853338628152044, 0.9597869878161698], "episode_lengths": [20, 37, 89, 669, 20, 207, 517, 18, 28, 40, 49, 18, 24, 25, 599, 18, 1227, 99, 50, 20, 36, 27, 26, 172, 23, 27, 41, 352, 32, 20, 41, 20, 30, 1171, 28, 31, 40, 21, 18, 55, 17, 38, 17, 25, 23, 25, 75, 46, 43, 18, 149, 27, 62, 20, 25, 17, 804, 20, 30, 38, 45, 24, 26, 62, 20, 28, 33, 15, 198, 14, 65, 27, 36, 278, 18, 25, 162, 32, 209, 35, 418, 27, 33, 43, 27, 38, 114, 32, 43, 35, 19, 24, 32, 40, 56, 1042, 40, 59, 19, 34], "policy_blue_reward": [-2.004, -2.005, -1.0019999999999998, -1.0049999999999997, -1.2029999999999814, 1.9963156250000265, -0.015000000000000006, -1.0079999999999993, -2.0089999999999995, -2.0479999999999965, -2.0079999999999996, -1.0119999999999993, -1.094999999999991, -0.008, -0.010000000000000002, -2.0119999999999996, -0.005, -2.001, -2.006, -1.007, -1.0039999999999998, -1.0079999999999996, -1.0109999999999995, -2.006, -1.555, -1.0089999999999997, -2.015999999999999, -0.5029999999999999, -2.01, -0.008, -2.0149999999999997, -1.0099999999999996, -1.0069999999999995, -1.5479999999999998, -0.004, -2.0109999999999992, -1.5709999999999968, -2.0069999999999992, -1.115, -1.5089999999999995, -1.503, -1.0079999999999996, -1.0079999999999991, -1.3010000000000002, -2.0089999999999995, -1.509], "policy_red_v5_reward": [0.437, -0.007, -0.014000000000000005, 0.47350000000000003], "policy_red_v35_reward": [3.295705480000003], "policy_red_v33_reward": [1.8533026128161898, -2.0139999999999985, -0.44235937499999967], "policy_red_v31_reward": [-1.5189999999999997], "policy_red_v19_reward": [1.5601776128161713, -0.1549999999999998], "policy_red_v24_reward": [-2.0159999999999987, 0.4599346144425932], "policy_red_v43_reward": [-0.5039999999999998, -1.0089999999999997], "policy_red_v22_reward": [1.5066932378161697], "policy_red_v4_reward": [-1.0149999999999995, -1.004, -1.5139999999999998, -1.0069999999999997], "policy_red_v13_reward": [0.3933906250000002, -2.014999999999999], "policy_red_v16_reward": [-1.0099999999999998], "policy_red_v12_reward": [-2.0089999999999995, -0.009000000000000001, 0.49869323781617014], "policy_red_v30_reward": [0.5036932378161697, 1.8410937500000002], "policy_red_v44_reward": [-0.5559999999999998], "policy_red_v11_reward": [0.433, -1.0219999999999996], "policy_red_v8_reward": [-0.56], "policy_red_v15_reward": [-2.0169999999999995], "policy_red_v20_reward": [1.48969323781617], "policy_red_v14_reward": [-0.006], "policy_red_v27_reward": [-0.2713067621838299], "policy_red_v29_reward": [1.5056932378152037], "policy_red_v1_reward": [-2.008, 0.84], "policy_red_v41_reward": [0.5046925427729418, -1.537], "policy_red_v2_reward": [-0.016000000000000007], "policy_red_v47_reward": [-1.005, -1.006], "policy_red_v28_reward": [0.46499999999999997], "policy_red_v39_reward": [0.45868750000000014], "policy_red_v38_reward": [-2.0139999999999993], "policy_red_v40_reward": [1.5046932378161697, 0.5006932378161698], "policy_red_v17_reward": [-2.0299999999999994], "policy_red_v9_reward": [-2.0119999999999996], "policy_red_v10_reward": [1.3592836050000003], "policy_red_v25_reward": [-0.56, -2.0089999999999995]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.814492609146218, "mean_inference_ms": 7.758836731038716, "mean_action_processing_ms": 0.29466769626149375, "mean_env_wait_ms": 0.3910799561159342, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10191667079925537, "StateBufferConnector_ms": 0.004233837127685547, "ViewRequirementAgentConnector_ms": 0.1177988052368164}}, "episode_reward_max": 4.497323280588145, "episode_reward_min": -0.2786661371838298, "episode_reward_mean": 2.197247680144922, "episode_len_mean": 110.31, "episodes_this_iter": 20, "policy_reward_min": {"blue": -2.0479999999999965, "red": -1.675306762183828, "red_v5": -0.014000000000000005, "red_v35": 3.295705480000003, "red_v33": -2.0139999999999985, "red_v31": -1.5189999999999997, "red_v19": -0.1549999999999998, "red_v24": -2.0159999999999987, "red_v43": -1.0089999999999997, "red_v22": 1.5066932378161697, "red_v4": -1.5139999999999998, "red_v13": -2.014999999999999, "red_v16": -1.0099999999999998, "red_v12": -2.0089999999999995, "red_v30": 0.5036932378161697, "red_v44": -0.5559999999999998, "red_v11": -1.0219999999999996, "red_v8": -0.56, "red_v15": -2.0169999999999995, "red_v20": 1.48969323781617, "red_v14": -0.006, "red_v27": -0.2713067621838299, "red_v29": 1.5056932378152037, "red_v1": -2.008, "red_v41": -1.537, "red_v2": -0.016000000000000007, "red_v47": -1.006, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": -2.0139999999999993, "red_v40": 0.5006932378161698, "red_v17": -2.0299999999999994, "red_v9": -2.0119999999999996, "red_v10": 1.3592836050000003, "red_v25": -2.0089999999999995}, "policy_reward_max": {"blue": 1.9963156250000265, "red": 3.9894112927729424, "red_v5": 0.47350000000000003, "red_v35": 3.295705480000003, "red_v33": 1.8533026128161898, "red_v31": -1.5189999999999997, "red_v19": 1.5601776128161713, "red_v24": 0.4599346144425932, "red_v43": -0.5039999999999998, "red_v22": 1.5066932378161697, "red_v4": -1.004, "red_v13": 0.3933906250000002, "red_v16": -1.0099999999999998, "red_v12": 0.49869323781617014, "red_v30": 1.8410937500000002, "red_v44": -0.5559999999999998, "red_v11": 0.433, "red_v8": -0.56, "red_v15": -2.0169999999999995, "red_v20": 1.48969323781617, "red_v14": -0.006, "red_v27": -0.2713067621838299, "red_v29": 1.5056932378152037, "red_v1": 0.84, "red_v41": 0.5046925427729418, "red_v2": -0.016000000000000007, "red_v47": -1.005, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": -2.0139999999999993, "red_v40": 1.5046932378161697, "red_v17": -2.0299999999999994, "red_v9": -2.0119999999999996, "red_v10": 1.3592836050000003, "red_v25": -0.56}, "policy_reward_mean": {"blue": -1.2115583559782597, "red": 2.894644975191157, "red_v5": 0.222375, "red_v35": 3.295705480000003, "red_v33": -0.20101892072793612, "red_v31": -1.5189999999999997, "red_v19": 0.7025888064080857, "red_v24": -0.7780326927787027, "red_v43": -0.7564999999999997, "red_v22": 1.5066932378161697, "red_v4": -1.1349999999999998, "red_v13": -0.8108046874999992, "red_v16": -1.0099999999999998, "red_v12": -0.5064355873946097, "red_v30": 1.172393493908085, "red_v44": -0.5559999999999998, "red_v11": -0.29449999999999976, "red_v8": -0.56, "red_v15": -2.0169999999999995, "red_v20": 1.48969323781617, "red_v14": -0.006, "red_v27": -0.2713067621838299, "red_v29": 1.5056932378152037, "red_v1": -0.5840000000000001, "red_v41": -0.516153728613529, "red_v2": -0.016000000000000007, "red_v47": -1.0055, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": -2.0139999999999993, "red_v40": 1.0026932378161697, "red_v17": -2.0299999999999994, "red_v9": -2.0119999999999996, "red_v10": 1.3592836050000003, "red_v25": -1.2844999999999998}, "hist_stats": {"episode_reward": [1.3762211050000002, 3.3022679800000003, 3.3003987178161744, 2.193995850632378, 1.8752211050000003, 0.8311463628161703, 1.856870850632372, 2.16639375, 3.3300057378161703, 1.4625682378161715, 1.9612401128161707, 2.470278364442593, 4.495921271360225, 2.4731151128161706, 1.6705213628162077, 2.9840362927729416, 0.32100886281620267, 0.8970838628161706, 2.9525369878161714, 2.480630737815204, 2.4743807378161704, 1.9797088628152044, 1.980411292772942, 1.2987557378161778, 3.99321460063234, 1.9751186585440554, 2.4628651128161705, 2.0461932378161904, 2.962603033544055, 2.9826307378161703, 2.966865112816171, 2.9356307378152033, 1.471599487816171, -0.2786661371838298, 3.421005737816171, 2.9258963628161703, 1.46756823781617, 2.9879276128161703, 2.4890362927729415, 3.926955977258765, 0.837046875, 3.9776677256323403, 1.4699814894425924, 2.4821144177729417, 2.4697627394425927, 2.4831151128161704, 1.9249588628161725, 4.465042725632341, 2.4634588628161707, 1.3756273550000004, 1.344927612816171, 2.4787088628161706, 1.9430994878161716, 1.9678721144425926, 1.4701151128152041, 2.987739417772942, 2.2220739756324197, 4.497323280588145, 2.9765994878161703, 1.4659744878161707, 2.4500526128161715, 1.4828182378161698, 3.990104530589112, 2.9420994878161717, 2.1559875000000006, 1.4153125000000002, 2.966490112816171, 1.8374531250000001, 0.8104744878161704, 2.66620625, 2.4199901128161727, 1.4767088628161704, 0.9597905335440555, 2.168224487816183, 1.4800369878152042, 2.4821151128161705, 1.8457869878161741, 1.9781932378161704, 0.7877401128161701, 0.9630838628161719, 1.0867869878161804, 0.9787088628161702, 4.487183350632341, 1.4474588628161715, 1.4767088628161704, 3.97966772563234, 3.1741273550000013, 0.8677836050000003, 3.812458862816171, 2.47708386281617, 0.8759242300000005, 2.4838182378161706, 2.477193237816171, 2.9205682378161706, 2.450317542772942, -0.08596301218382829, 1.4695682378161705, 1.4472088628161712, 1.4853338628152044, 0.9597869878161698], "episode_lengths": [20, 37, 89, 669, 20, 207, 517, 18, 28, 40, 49, 18, 24, 25, 599, 18, 1227, 99, 50, 20, 36, 27, 26, 172, 23, 27, 41, 352, 32, 20, 41, 20, 30, 1171, 28, 31, 40, 21, 18, 55, 17, 38, 17, 25, 23, 25, 75, 46, 43, 18, 149, 27, 62, 20, 25, 17, 804, 20, 30, 38, 45, 24, 26, 62, 20, 28, 33, 15, 198, 14, 65, 27, 36, 278, 18, 25, 162, 32, 209, 35, 418, 27, 33, 43, 27, 38, 114, 32, 43, 35, 19, 24, 32, 40, 56, 1042, 40, 59, 19, 34], "policy_blue_reward": [-2.004, -2.005, -1.0019999999999998, -1.0049999999999997, -1.2029999999999814, 1.9963156250000265, -0.015000000000000006, -1.0079999999999993, -2.0089999999999995, -2.0479999999999965, -2.0079999999999996, -1.0119999999999993, -1.094999999999991, -0.008, -0.010000000000000002, -2.0119999999999996, -0.005, -2.001, -2.006, -1.007, -1.0039999999999998, -1.0079999999999996, -1.0109999999999995, -2.006, -1.555, -1.0089999999999997, -2.015999999999999, -0.5029999999999999, -2.01, -0.008, -2.0149999999999997, -1.0099999999999996, -1.0069999999999995, -1.5479999999999998, -0.004, -2.0109999999999992, -1.5709999999999968, -2.0069999999999992, -1.115, -1.5089999999999995, -1.503, -1.0079999999999996, -1.0079999999999991, -1.3010000000000002, -2.0089999999999995, -1.509], "policy_red_v5_reward": [0.437, -0.007, -0.014000000000000005, 0.47350000000000003], "policy_red_v35_reward": [3.295705480000003], "policy_red_v33_reward": [1.8533026128161898, -2.0139999999999985, -0.44235937499999967], "policy_red_v31_reward": [-1.5189999999999997], "policy_red_v19_reward": [1.5601776128161713, -0.1549999999999998], "policy_red_v24_reward": [-2.0159999999999987, 0.4599346144425932], "policy_red_v43_reward": [-0.5039999999999998, -1.0089999999999997], "policy_red_v22_reward": [1.5066932378161697], "policy_red_v4_reward": [-1.0149999999999995, -1.004, -1.5139999999999998, -1.0069999999999997], "policy_red_v13_reward": [0.3933906250000002, -2.014999999999999], "policy_red_v16_reward": [-1.0099999999999998], "policy_red_v12_reward": [-2.0089999999999995, -0.009000000000000001, 0.49869323781617014], "policy_red_v30_reward": [0.5036932378161697, 1.8410937500000002], "policy_red_v44_reward": [-0.5559999999999998], "policy_red_v11_reward": [0.433, -1.0219999999999996], "policy_red_v8_reward": [-0.56], "policy_red_v15_reward": [-2.0169999999999995], "policy_red_v20_reward": [1.48969323781617], "policy_red_v14_reward": [-0.006], "policy_red_v27_reward": [-0.2713067621838299], "policy_red_v29_reward": [1.5056932378152037], "policy_red_v1_reward": [-2.008, 0.84], "policy_red_v41_reward": [0.5046925427729418, -1.537], "policy_red_v2_reward": [-0.016000000000000007], "policy_red_v47_reward": [-1.005, -1.006], "policy_red_v28_reward": [0.46499999999999997], "policy_red_v39_reward": [0.45868750000000014], "policy_red_v38_reward": [-2.0139999999999993], "policy_red_v40_reward": [1.5046932378161697, 0.5006932378161698], "policy_red_v17_reward": [-2.0299999999999994], "policy_red_v9_reward": [-2.0119999999999996], "policy_red_v10_reward": [1.3592836050000003], "policy_red_v25_reward": [-0.56, -2.0089999999999995]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.814492609146218, "mean_inference_ms": 7.758836731038716, "mean_action_processing_ms": 0.29466769626149375, "mean_env_wait_ms": 0.3910799561159342, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10191667079925537, "StateBufferConnector_ms": 0.004233837127685547, "ViewRequirementAgentConnector_ms": 0.1177988052368164}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.20065005069947, "num_env_steps_trained_throughput_per_sec": 201.20065005069947, "timesteps_total": 328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 19961.49, "sample_time_ms": 1136.156, "learn_time_ms": 18740.695, "learn_throughput": 213.439, "synch_weights_time_ms": 81.618}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "episodes_total": 1073, "training_iteration": 82, "trial_id": "a9680_00000", "date": "2023-09-24_03-05-55", "timestamp": 1695539155, "time_this_iter_s": 19.890995502471924, "time_total_s": 1634.901086807251, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1df3f220>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34287d00>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34287d90>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1634.901086807251, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 5.290909090909092, "ram_util_percent": 22.490909090909092}, "win_rate": 0.78, "league_size": 52}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2180349104106427, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.00544737090410005, "policy_loss": -0.05660181279818062, "vf_loss": 0.0884543701307848, "vf_explained_var": 0.8478002752487858, "kl": 0.019515248272061095, "entropy": 1.8546045621236165, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 79200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 664000, "num_agent_steps_trained": 664000}, "sampler_results": {"episode_reward_max": 4.497323280588145, "episode_reward_min": -12.020150512183776, "episode_reward_mean": 1.8726808181662475, "episode_len_mean": 136.4, "episode_media": {}, "episodes_this_iter": 33, "policy_reward_min": {"red_v33": -0.44235937499999967, "red": -24.13915051218385, "red_v11": -1.0219999999999996, "red_v8": -0.56, "blue": -2.015999999999999, "red_v4": -1.5139999999999998, "red_v24": 0.4599346144425932, "red_v12": 0.49869323781617014, "red_v15": -2.0169999999999995, "red_v20": 0.369693237816179, "red_v14": -0.006, "red_v27": -0.2713067621838299, "red_v29": 1.5056932378152037, "red_v1": -2.008, "red_v41": -1.537, "red_v5": -0.014000000000000005, "red_v2": -0.016000000000000007, "red_v47": -1.006, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": -2.0139999999999993, "red_v43": -2.0089999999999995, "red_v30": 1.8410937500000002, "red_v40": 0.5006932378161698, "red_v17": -2.0299999999999994, "red_v9": -2.0119999999999996, "red_v10": -2.013, "red_v25": -2.0089999999999995, "red_v13": -2.014999999999999, "red_v16": -1.133, "red_v19": -1.003, "red_v42": 12.119000000000023, "red_v49": -1.0079999999999998, "red_v32": -0.7720000000000008, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383}, "policy_reward_max": {"red_v33": -0.44235937499999967, "red": 3.98519323781617, "red_v11": 0.433, "red_v8": -0.56, "blue": -0.004, "red_v4": -1.004, "red_v24": 0.4599346144425932, "red_v12": 0.49869323781617014, "red_v15": -2.0169999999999995, "red_v20": 1.48969323781617, "red_v14": 1.840786987816177, "red_v27": 2.220068237816177, "red_v29": 1.5056932378152037, "red_v1": 0.84, "red_v41": 0.5046925427729418, "red_v5": 0.47350000000000003, "red_v2": -0.016000000000000007, "red_v47": -1.005, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": 10.891956250000032, "red_v43": -1.0089999999999997, "red_v30": 1.8410937500000002, "red_v40": 1.5046932378161697, "red_v17": -2.0299999999999994, "red_v9": -1.679, "red_v10": 1.3592836050000003, "red_v25": -0.56, "red_v13": -2.014999999999999, "red_v16": -1.133, "red_v19": -1.003, "red_v42": 12.119000000000023, "red_v49": -1.0079999999999998, "red_v32": -0.5830653855574073, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383}, "policy_reward_mean": {"red_v33": -0.44235937499999967, "red": 2.476252639489904, "red_v11": -0.38399999999999973, "red_v8": -0.56, "blue": -1.3373958333333331, "red_v4": -1.1749999999999998, "red_v24": 0.4599346144425932, "red_v12": 0.49869323781617014, "red_v15": -2.0169999999999995, "red_v20": 0.9296932378161745, "red_v14": 0.9173934939080884, "red_v27": 0.9743807378161735, "red_v29": 1.5056932378152037, "red_v1": -0.5840000000000001, "red_v41": -0.516153728613529, "red_v5": 0.22975, "red_v2": -0.016000000000000007, "red_v47": -1.0055, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": 4.438978125000016, "red_v43": -1.5089999999999995, "red_v30": 1.8410937500000002, "red_v40": 1.0026932378161697, "red_v17": -2.0299999999999994, "red_v9": -1.8455, "red_v10": -0.3268581974999998, "red_v25": -1.2844999999999998, "red_v13": -2.014999999999999, "red_v16": -1.133, "red_v19": -1.003, "red_v42": 12.119000000000023, "red_v49": -1.0079999999999998, "red_v32": -0.677532692778704, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.2786661371838298, 3.421005737816171, 2.9258963628161703, 1.46756823781617, 2.9879276128161703, 2.4890362927729415, 3.926955977258765, 0.837046875, 3.9776677256323403, 1.4699814894425924, 2.4821144177729417, 2.4697627394425927, 2.4831151128161704, 1.9249588628161725, 4.465042725632341, 2.4634588628161707, 1.3756273550000004, 1.344927612816171, 2.4787088628161706, 1.9430994878161716, 1.9678721144425926, 1.4701151128152041, 2.987739417772942, 2.2220739756324197, 4.497323280588145, 2.9765994878161703, 1.4659744878161707, 2.4500526128161715, 1.4828182378161698, 3.990104530589112, 2.9420994878161717, 2.1559875000000006, 1.4153125000000002, 2.966490112816171, 1.8374531250000001, 0.8104744878161704, 2.66620625, 2.4199901128161727, 1.4767088628161704, 0.9597905335440555, 2.168224487816183, 1.4800369878152042, 2.4821151128161705, 1.8457869878161741, 1.9781932378161704, 0.7877401128161701, 0.9630838628161719, 1.0867869878161804, 0.9787088628161702, 4.487183350632341, 1.4474588628161715, 1.4767088628161704, 3.97966772563234, 3.1741273550000013, 0.8677836050000003, 3.812458862816171, 2.47708386281617, 0.8759242300000005, 2.4838182378161706, 2.477193237816171, 2.9205682378161706, 2.450317542772942, -0.08596301218382829, 1.4695682378161705, 1.4472088628161712, 1.4853338628152044, 0.9597869878161698, 2.8674432378161723, 1.3642869878161723, 2.7167614756323517, 2.4557244878161715, 1.9714901128161706, 0.810052612816194, 1.479743658544055, 2.2154802256323745, 2.9292244878161706, 1.1575031250000005, 1.1896463628161753, 1.4883331677729421, 1.0951463628161726, 2.4790057378161703, 2.6549875000000007, 0.5910369878161698, 2.483524908544055, 2.481818237816171, -12.020150512183776, 2.477193237816171, 0.696693237816226, 2.4482088628161707, 2.38473673, 1.9695682378161707, 3.987511475631373, 3.035245850632361, 2.486630737815204, 0.8384531250000002, 2.6532458506323584, 1.3827367300000004, -7.816350512183837, 3.043112227258782, 1.4767088628161704], "episode_lengths": [1171, 28, 31, 40, 21, 18, 55, 17, 38, 17, 25, 23, 25, 75, 46, 43, 18, 149, 27, 62, 20, 25, 17, 804, 20, 30, 38, 45, 24, 26, 62, 20, 28, 33, 15, 198, 14, 65, 27, 36, 278, 18, 25, 162, 32, 209, 35, 418, 27, 33, 43, 27, 38, 114, 32, 43, 35, 19, 24, 32, 40, 56, 1042, 40, 59, 19, 34, 80, 130, 264, 54, 33, 493, 19, 674, 22, 15, 303, 19, 399, 28, 20, 338, 25, 24, 782, 32, 1280, 59, 15, 40, 24, 397, 20, 15, 269, 15, 926, 389, 27], "policy_red_v33_reward": [-0.44235937499999967], "policy_red_v11_reward": [0.433, -1.0219999999999996, -0.5629999999999997], "policy_red_v8_reward": [-0.56], "policy_blue_reward": [-2.0119999999999996, -0.005, -2.001, -2.006, -1.007, -1.0039999999999998, -1.0079999999999996, -1.0109999999999995, -2.006, -1.555, -1.0089999999999997, -2.015999999999999, -0.5029999999999999, -2.01, -0.008, -2.0149999999999997, -1.0099999999999996, -1.0069999999999995, -1.5479999999999998, -0.004, -2.0109999999999992, -1.5709999999999968, -2.0069999999999992, -1.115, -1.5089999999999995, -1.503, -1.0079999999999996, -1.0079999999999991, -1.3010000000000002, -2.0089999999999995, -1.509, -0.5749999999999998, -1.54, -1.010999999999999, -2.0089999999999995, -2.0089999999999995, -1.576, -2.005, -1.113, -1.0079999999999996, -0.008, -1.0079999999999991, -1.0119999999999993, -1.0019999999999998, -1.0059999999999998, -2.004, -2.003, -2.01], "policy_red_v4_reward": [-1.004, -1.5139999999999998, -1.0069999999999997], "policy_red_v24_reward": [0.4599346144425932], "policy_red_v12_reward": [0.49869323781617014], "policy_red_v15_reward": [-2.0169999999999995], "policy_red_v20_reward": [1.48969323781617, 0.369693237816179], "policy_red_v14_reward": [-0.006, 1.840786987816177], "policy_red_v27_reward": [-0.2713067621838299, 2.220068237816177], "policy_red_v29_reward": [1.5056932378152037], "policy_red_v1_reward": [-2.008, 0.84], "policy_red_v41_reward": [0.5046925427729418, -1.537], "policy_red_v5_reward": [-0.014000000000000005, 0.47350000000000003], "policy_red_v2_reward": [-0.016000000000000007], "policy_red_v47_reward": [-1.005, -1.006], "policy_red_v28_reward": [0.46499999999999997], "policy_red_v39_reward": [0.45868750000000014], "policy_red_v38_reward": [-2.0139999999999993, 10.891956250000032], "policy_red_v43_reward": [-1.0089999999999997, -2.0089999999999995], "policy_red_v30_reward": [1.8410937500000002], "policy_red_v40_reward": [1.5046932378161697, 0.5006932378161698], "policy_red_v17_reward": [-2.0299999999999994], "policy_red_v9_reward": [-2.0119999999999996, -1.679], "policy_red_v10_reward": [1.3592836050000003, -2.013], "policy_red_v25_reward": [-0.56, -2.0089999999999995], "policy_red_v13_reward": [-2.014999999999999], "policy_red_v16_reward": [-1.133], "policy_red_v19_reward": [-1.003], "policy_red_v42_reward": [12.119000000000023], "policy_red_v49_reward": [-1.0079999999999998], "policy_red_v32_reward": [-0.7720000000000008, -0.5830653855574073], "policy_red_v34_reward": [0.4996932378152038], "policy_red_v44_reward": [-0.59630676218383]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8135693783049548, "mean_inference_ms": 7.745965750507093, "mean_action_processing_ms": 0.2936760362519914, "mean_env_wait_ms": 0.38934522102922164, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10101854801177979, "StateBufferConnector_ms": 0.004183769226074219, "ViewRequirementAgentConnector_ms": 0.11568617820739746}}, "episode_reward_max": 4.497323280588145, "episode_reward_min": -12.020150512183776, "episode_reward_mean": 1.8726808181662475, "episode_len_mean": 136.4, "episodes_this_iter": 33, "policy_reward_min": {"red_v33": -0.44235937499999967, "red": -24.13915051218385, "red_v11": -1.0219999999999996, "red_v8": -0.56, "blue": -2.015999999999999, "red_v4": -1.5139999999999998, "red_v24": 0.4599346144425932, "red_v12": 0.49869323781617014, "red_v15": -2.0169999999999995, "red_v20": 0.369693237816179, "red_v14": -0.006, "red_v27": -0.2713067621838299, "red_v29": 1.5056932378152037, "red_v1": -2.008, "red_v41": -1.537, "red_v5": -0.014000000000000005, "red_v2": -0.016000000000000007, "red_v47": -1.006, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": -2.0139999999999993, "red_v43": -2.0089999999999995, "red_v30": 1.8410937500000002, "red_v40": 0.5006932378161698, "red_v17": -2.0299999999999994, "red_v9": -2.0119999999999996, "red_v10": -2.013, "red_v25": -2.0089999999999995, "red_v13": -2.014999999999999, "red_v16": -1.133, "red_v19": -1.003, "red_v42": 12.119000000000023, "red_v49": -1.0079999999999998, "red_v32": -0.7720000000000008, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383}, "policy_reward_max": {"red_v33": -0.44235937499999967, "red": 3.98519323781617, "red_v11": 0.433, "red_v8": -0.56, "blue": -0.004, "red_v4": -1.004, "red_v24": 0.4599346144425932, "red_v12": 0.49869323781617014, "red_v15": -2.0169999999999995, "red_v20": 1.48969323781617, "red_v14": 1.840786987816177, "red_v27": 2.220068237816177, "red_v29": 1.5056932378152037, "red_v1": 0.84, "red_v41": 0.5046925427729418, "red_v5": 0.47350000000000003, "red_v2": -0.016000000000000007, "red_v47": -1.005, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": 10.891956250000032, "red_v43": -1.0089999999999997, "red_v30": 1.8410937500000002, "red_v40": 1.5046932378161697, "red_v17": -2.0299999999999994, "red_v9": -1.679, "red_v10": 1.3592836050000003, "red_v25": -0.56, "red_v13": -2.014999999999999, "red_v16": -1.133, "red_v19": -1.003, "red_v42": 12.119000000000023, "red_v49": -1.0079999999999998, "red_v32": -0.5830653855574073, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383}, "policy_reward_mean": {"red_v33": -0.44235937499999967, "red": 2.476252639489904, "red_v11": -0.38399999999999973, "red_v8": -0.56, "blue": -1.3373958333333331, "red_v4": -1.1749999999999998, "red_v24": 0.4599346144425932, "red_v12": 0.49869323781617014, "red_v15": -2.0169999999999995, "red_v20": 0.9296932378161745, "red_v14": 0.9173934939080884, "red_v27": 0.9743807378161735, "red_v29": 1.5056932378152037, "red_v1": -0.5840000000000001, "red_v41": -0.516153728613529, "red_v5": 0.22975, "red_v2": -0.016000000000000007, "red_v47": -1.0055, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": 4.438978125000016, "red_v43": -1.5089999999999995, "red_v30": 1.8410937500000002, "red_v40": 1.0026932378161697, "red_v17": -2.0299999999999994, "red_v9": -1.8455, "red_v10": -0.3268581974999998, "red_v25": -1.2844999999999998, "red_v13": -2.014999999999999, "red_v16": -1.133, "red_v19": -1.003, "red_v42": 12.119000000000023, "red_v49": -1.0079999999999998, "red_v32": -0.677532692778704, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383}, "hist_stats": {"episode_reward": [-0.2786661371838298, 3.421005737816171, 2.9258963628161703, 1.46756823781617, 2.9879276128161703, 2.4890362927729415, 3.926955977258765, 0.837046875, 3.9776677256323403, 1.4699814894425924, 2.4821144177729417, 2.4697627394425927, 2.4831151128161704, 1.9249588628161725, 4.465042725632341, 2.4634588628161707, 1.3756273550000004, 1.344927612816171, 2.4787088628161706, 1.9430994878161716, 1.9678721144425926, 1.4701151128152041, 2.987739417772942, 2.2220739756324197, 4.497323280588145, 2.9765994878161703, 1.4659744878161707, 2.4500526128161715, 1.4828182378161698, 3.990104530589112, 2.9420994878161717, 2.1559875000000006, 1.4153125000000002, 2.966490112816171, 1.8374531250000001, 0.8104744878161704, 2.66620625, 2.4199901128161727, 1.4767088628161704, 0.9597905335440555, 2.168224487816183, 1.4800369878152042, 2.4821151128161705, 1.8457869878161741, 1.9781932378161704, 0.7877401128161701, 0.9630838628161719, 1.0867869878161804, 0.9787088628161702, 4.487183350632341, 1.4474588628161715, 1.4767088628161704, 3.97966772563234, 3.1741273550000013, 0.8677836050000003, 3.812458862816171, 2.47708386281617, 0.8759242300000005, 2.4838182378161706, 2.477193237816171, 2.9205682378161706, 2.450317542772942, -0.08596301218382829, 1.4695682378161705, 1.4472088628161712, 1.4853338628152044, 0.9597869878161698, 2.8674432378161723, 1.3642869878161723, 2.7167614756323517, 2.4557244878161715, 1.9714901128161706, 0.810052612816194, 1.479743658544055, 2.2154802256323745, 2.9292244878161706, 1.1575031250000005, 1.1896463628161753, 1.4883331677729421, 1.0951463628161726, 2.4790057378161703, 2.6549875000000007, 0.5910369878161698, 2.483524908544055, 2.481818237816171, -12.020150512183776, 2.477193237816171, 0.696693237816226, 2.4482088628161707, 2.38473673, 1.9695682378161707, 3.987511475631373, 3.035245850632361, 2.486630737815204, 0.8384531250000002, 2.6532458506323584, 1.3827367300000004, -7.816350512183837, 3.043112227258782, 1.4767088628161704], "episode_lengths": [1171, 28, 31, 40, 21, 18, 55, 17, 38, 17, 25, 23, 25, 75, 46, 43, 18, 149, 27, 62, 20, 25, 17, 804, 20, 30, 38, 45, 24, 26, 62, 20, 28, 33, 15, 198, 14, 65, 27, 36, 278, 18, 25, 162, 32, 209, 35, 418, 27, 33, 43, 27, 38, 114, 32, 43, 35, 19, 24, 32, 40, 56, 1042, 40, 59, 19, 34, 80, 130, 264, 54, 33, 493, 19, 674, 22, 15, 303, 19, 399, 28, 20, 338, 25, 24, 782, 32, 1280, 59, 15, 40, 24, 397, 20, 15, 269, 15, 926, 389, 27], "policy_red_v33_reward": [-0.44235937499999967], "policy_red_v11_reward": [0.433, -1.0219999999999996, -0.5629999999999997], "policy_red_v8_reward": [-0.56], "policy_blue_reward": [-2.0119999999999996, -0.005, -2.001, -2.006, -1.007, -1.0039999999999998, -1.0079999999999996, -1.0109999999999995, -2.006, -1.555, -1.0089999999999997, -2.015999999999999, -0.5029999999999999, -2.01, -0.008, -2.0149999999999997, -1.0099999999999996, -1.0069999999999995, -1.5479999999999998, -0.004, -2.0109999999999992, -1.5709999999999968, -2.0069999999999992, -1.115, -1.5089999999999995, -1.503, -1.0079999999999996, -1.0079999999999991, -1.3010000000000002, -2.0089999999999995, -1.509, -0.5749999999999998, -1.54, -1.010999999999999, -2.0089999999999995, -2.0089999999999995, -1.576, -2.005, -1.113, -1.0079999999999996, -0.008, -1.0079999999999991, -1.0119999999999993, -1.0019999999999998, -1.0059999999999998, -2.004, -2.003, -2.01], "policy_red_v4_reward": [-1.004, -1.5139999999999998, -1.0069999999999997], "policy_red_v24_reward": [0.4599346144425932], "policy_red_v12_reward": [0.49869323781617014], "policy_red_v15_reward": [-2.0169999999999995], "policy_red_v20_reward": [1.48969323781617, 0.369693237816179], "policy_red_v14_reward": [-0.006, 1.840786987816177], "policy_red_v27_reward": [-0.2713067621838299, 2.220068237816177], "policy_red_v29_reward": [1.5056932378152037], "policy_red_v1_reward": [-2.008, 0.84], "policy_red_v41_reward": [0.5046925427729418, -1.537], "policy_red_v5_reward": [-0.014000000000000005, 0.47350000000000003], "policy_red_v2_reward": [-0.016000000000000007], "policy_red_v47_reward": [-1.005, -1.006], "policy_red_v28_reward": [0.46499999999999997], "policy_red_v39_reward": [0.45868750000000014], "policy_red_v38_reward": [-2.0139999999999993, 10.891956250000032], "policy_red_v43_reward": [-1.0089999999999997, -2.0089999999999995], "policy_red_v30_reward": [1.8410937500000002], "policy_red_v40_reward": [1.5046932378161697, 0.5006932378161698], "policy_red_v17_reward": [-2.0299999999999994], "policy_red_v9_reward": [-2.0119999999999996, -1.679], "policy_red_v10_reward": [1.3592836050000003, -2.013], "policy_red_v25_reward": [-0.56, -2.0089999999999995], "policy_red_v13_reward": [-2.014999999999999], "policy_red_v16_reward": [-1.133], "policy_red_v19_reward": [-1.003], "policy_red_v42_reward": [12.119000000000023], "policy_red_v49_reward": [-1.0079999999999998], "policy_red_v32_reward": [-0.7720000000000008, -0.5830653855574073], "policy_red_v34_reward": [0.4996932378152038], "policy_red_v44_reward": [-0.59630676218383]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8135693783049548, "mean_inference_ms": 7.745965750507093, "mean_action_processing_ms": 0.2936760362519914, "mean_env_wait_ms": 0.38934522102922164, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10101854801177979, "StateBufferConnector_ms": 0.004183769226074219, "ViewRequirementAgentConnector_ms": 0.11568617820739746}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 664000, "num_agent_steps_trained": 664000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 195.52097137325242, "num_env_steps_trained_throughput_per_sec": 195.52097137325242, "timesteps_total": 332000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 664000, "timers": {"training_iteration_time_ms": 19988.929, "sample_time_ms": 1134.336, "learn_time_ms": 18770.051, "learn_throughput": 213.105, "synch_weights_time_ms": 81.459}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 664000, "num_agent_steps_trained": 664000}, "done": false, "episodes_total": 1106, "training_iteration": 83, "trial_id": "a9680_00000", "date": "2023-09-24_03-06-19", "timestamp": 1695539179, "time_this_iter_s": 20.468953132629395, "time_total_s": 1655.3700399398804, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b3426cb20>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34286560>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b342864d0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1655.3700399398804, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 5.957575757575757, "ram_util_percent": 22.67575757575758}, "win_rate": 0.8, "league_size": 53}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.233802189057072, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.009652104604659447, "policy_loss": -0.05844821579230484, "vf_loss": 0.12257816810936978, "vf_explained_var": 0.7880789584790667, "kl": 0.019361251123618358, "entropy": 1.901326886191964, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 80160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "sampler_results": {"episode_reward_max": 4.487183350632341, "episode_reward_min": -12.020150512183776, "episode_reward_mean": 1.853299494075689, "episode_len_mean": 147.04, "episode_media": {}, "episodes_this_iter": 28, "policy_reward_min": {"red_v1": -2.0559999999999965, "red": -24.13915051218385, "red_v41": -1.537, "red_v5": -0.014000000000000005, "blue": -2.0199999999999987, "red_v2": -0.016000000000000007, "red_v47": -1.006, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": -2.0139999999999993, "red_v43": -2.0089999999999995, "red_v30": 1.8410937500000002, "red_v4": -1.5139999999999998, "red_v40": 0.5006932378161698, "red_v17": -2.0299999999999994, "red_v9": -2.0119999999999996, "red_v10": -2.013, "red_v25": -2.0089999999999995, "red_v13": -2.0169999999999986, "red_v27": 2.220068237816177, "red_v16": -1.133, "red_v14": 1.840786987816177, "red_v11": -0.5629999999999997, "red_v19": -1.003, "red_v42": -0.5349999999999997, "red_v49": -1.0079999999999998, "red_v32": -0.7720000000000008, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383, "red_v20": 0.369693237816179, "red_v48": 0.39328360500000037, "red_v8": 0.831546875, "red_v46": -2.0169999999999995, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v21": 1.4736932378161711}, "policy_reward_max": {"red_v1": 0.84, "red": 3.98519323781617, "red_v41": 0.5046925427729418, "red_v5": 0.47350000000000003, "blue": 1.98715625, "red_v2": -0.016000000000000007, "red_v47": -1.005, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": 10.891956250000032, "red_v43": -1.0089999999999997, "red_v30": 1.8410937500000002, "red_v4": -1.0069999999999997, "red_v40": 1.5046932378161697, "red_v17": -2.0299999999999994, "red_v9": -1.679, "red_v10": 1.3592836050000003, "red_v25": -0.56, "red_v13": -2.014999999999999, "red_v27": 2.220068237816177, "red_v16": -1.133, "red_v14": 1.840786987816177, "red_v11": -0.5629999999999997, "red_v19": -1.003, "red_v42": 12.119000000000023, "red_v49": -1.0079999999999998, "red_v32": -0.5830653855574073, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383, "red_v20": 0.369693237816179, "red_v48": 0.39328360500000037, "red_v8": 0.831546875, "red_v46": -1.072, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v21": 1.4736932378161711}, "policy_reward_mean": {"red_v1": -0.8079999999999992, "red": 2.4080110652500846, "red_v41": -0.516153728613529, "red_v5": 0.22975, "blue": -1.1156090561224485, "red_v2": -0.016000000000000007, "red_v47": -1.0055, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": 4.438978125000016, "red_v43": -1.5089999999999995, "red_v30": 1.8410937500000002, "red_v4": -1.2604999999999997, "red_v40": 1.0026932378161697, "red_v17": -2.0299999999999994, "red_v9": -1.8455, "red_v10": -0.3268581974999998, "red_v25": -1.2844999999999998, "red_v13": -2.0159999999999987, "red_v27": 2.220068237816177, "red_v16": -1.133, "red_v14": 1.840786987816177, "red_v11": -0.5629999999999997, "red_v19": -1.003, "red_v42": 5.792000000000011, "red_v49": -1.0079999999999998, "red_v32": -0.677532692778704, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383, "red_v20": 0.369693237816179, "red_v48": 0.39328360500000037, "red_v8": 0.831546875, "red_v46": -1.5444999999999998, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v21": 1.4736932378161711}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.4828182378161698, 3.990104530589112, 2.9420994878161717, 2.1559875000000006, 1.4153125000000002, 2.966490112816171, 1.8374531250000001, 0.8104744878161704, 2.66620625, 2.4199901128161727, 1.4767088628161704, 0.9597905335440555, 2.168224487816183, 1.4800369878152042, 2.4821151128161705, 1.8457869878161741, 1.9781932378161704, 0.7877401128161701, 0.9630838628161719, 1.0867869878161804, 0.9787088628161702, 4.487183350632341, 1.4474588628161715, 1.4767088628161704, 3.97966772563234, 3.1741273550000013, 0.8677836050000003, 3.812458862816171, 2.47708386281617, 0.8759242300000005, 2.4838182378161706, 2.477193237816171, 2.9205682378161706, 2.450317542772942, -0.08596301218382829, 1.4695682378161705, 1.4472088628161712, 1.4853338628152044, 0.9597869878161698, 2.8674432378161723, 1.3642869878161723, 2.7167614756323517, 2.4557244878161715, 1.9714901128161706, 0.810052612816194, 1.479743658544055, 2.2154802256323745, 2.9292244878161706, 1.1575031250000005, 1.1896463628161753, 1.4883331677729421, 1.0951463628161726, 2.4790057378161703, 2.6549875000000007, 0.5910369878161698, 2.483524908544055, 2.481818237816171, -12.020150512183776, 2.477193237816171, 0.696693237816226, 2.4482088628161707, 2.38473673, 1.9695682378161707, 3.987511475631373, 3.035245850632361, 2.486630737815204, 0.8384531250000002, 2.6532458506323584, 1.3827367300000004, -7.816350512183837, 3.043112227258782, 1.4767088628161704, 1.53216198781617, 2.4735994878161707, 1.425224487816172, 3.885616772772942, 1.299240112816174, 1.8637869878161752, 2.5054276128161845, 2.4817088628161703, 2.938802612816172, 1.4658651128161706, 2.9741186585440555, 2.4748963628161706, 2.4736846144425924, 2.45746460063235, 2.4547244878152044, 2.4763026128161703, 2.97470886281617, 0.9917394177729422, 1.9686932378162099, 2.47941198781617, 2.98822448781617, 2.4886300427729413, 1.8824398550000003, 1.464786292772942, 1.9612713628161713, 4.397652100632346, 2.488040533544055, 1.486630737815204], "episode_lengths": [24, 26, 62, 20, 28, 33, 15, 198, 14, 65, 27, 36, 278, 18, 25, 162, 32, 209, 35, 418, 27, 33, 43, 27, 38, 114, 32, 43, 35, 19, 24, 32, 40, 56, 1042, 40, 59, 19, 34, 80, 130, 264, 54, 33, 493, 19, 674, 22, 15, 303, 19, 399, 28, 20, 338, 25, 24, 782, 32, 1280, 59, 15, 40, 24, 397, 20, 15, 269, 15, 926, 389, 27, 618, 30, 86, 19, 177, 98, 437, 27, 61, 41, 27, 31, 16, 647, 54, 29, 27, 17, 1280, 26, 22, 20, 14, 34, 39, 75, 20, 20], "policy_red_v1_reward": [-2.008, 0.84, -2.0559999999999965, -0.008], "policy_red_v41_reward": [0.5046925427729418, -1.537], "policy_red_v5_reward": [-0.014000000000000005, 0.47350000000000003], "policy_blue_reward": [-1.0099999999999996, -1.0069999999999995, -1.5479999999999998, -0.004, -2.0109999999999992, -1.5709999999999968, -2.0069999999999992, -1.115, -1.5089999999999995, -1.503, -1.0079999999999996, -1.0079999999999991, -1.3010000000000002, -2.0089999999999995, -1.509, -0.5749999999999998, -1.54, -1.010999999999999, -2.0089999999999995, -2.0089999999999995, -1.576, -2.005, -1.113, -1.0079999999999996, -0.008, -1.0079999999999991, -1.0119999999999993, -1.0019999999999998, -1.0059999999999998, -2.004, -2.003, -2.01, -1.012, -2.0199999999999987, -1.0069999999999997, -0.012000000000000004, -2.009999999999999, -1.0109999999999992, -1.0039999999999996, 0.489, -1.01, -0.012000000000000004, -1.5039999999999998, 0.5009999999999998, -1.0089999999999997, -0.003, 1.98715625, -1.0049999999999997, -2.004], "policy_red_v2_reward": [-0.016000000000000007], "policy_red_v47_reward": [-1.005, -1.006], "policy_red_v28_reward": [0.46499999999999997], "policy_red_v39_reward": [0.45868750000000014], "policy_red_v38_reward": [-2.0139999999999993, 10.891956250000032], "policy_red_v43_reward": [-1.0089999999999997, -2.0089999999999995], "policy_red_v30_reward": [1.8410937500000002], "policy_red_v4_reward": [-1.5139999999999998, -1.0069999999999997], "policy_red_v40_reward": [1.5046932378161697, 0.5006932378161698], "policy_red_v17_reward": [-2.0299999999999994], "policy_red_v9_reward": [-2.0119999999999996, -1.679], "policy_red_v10_reward": [1.3592836050000003, -2.013], "policy_red_v25_reward": [-0.56, -2.0089999999999995], "policy_red_v13_reward": [-2.014999999999999, -2.0169999999999986], "policy_red_v27_reward": [2.220068237816177], "policy_red_v16_reward": [-1.133], "policy_red_v14_reward": [1.840786987816177], "policy_red_v11_reward": [-0.5629999999999997], "policy_red_v19_reward": [-1.003], "policy_red_v42_reward": [12.119000000000023, -0.5349999999999997], "policy_red_v49_reward": [-1.0079999999999998], "policy_red_v32_reward": [-0.7720000000000008, -0.5830653855574073], "policy_red_v34_reward": [0.4996932378152038], "policy_red_v44_reward": [-0.59630676218383], "policy_red_v20_reward": [0.369693237816179], "policy_red_v48_reward": [0.39328360500000037], "policy_red_v8_reward": [0.831546875], "policy_red_v46_reward": [-1.072, -2.0169999999999995], "policy_red_v35_reward": [0.4296932378161733], "policy_red_v37_reward": [-1.003], "policy_red_v21_reward": [1.4736932378161711]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.814376413715241, "mean_inference_ms": 7.759095840323819, "mean_action_processing_ms": 0.29374079120198654, "mean_env_wait_ms": 0.3894077311963828, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1037822961807251, "StateBufferConnector_ms": 0.0043392181396484375, "ViewRequirementAgentConnector_ms": 0.11918056011199951}}, "episode_reward_max": 4.487183350632341, "episode_reward_min": -12.020150512183776, "episode_reward_mean": 1.853299494075689, "episode_len_mean": 147.04, "episodes_this_iter": 28, "policy_reward_min": {"red_v1": -2.0559999999999965, "red": -24.13915051218385, "red_v41": -1.537, "red_v5": -0.014000000000000005, "blue": -2.0199999999999987, "red_v2": -0.016000000000000007, "red_v47": -1.006, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": -2.0139999999999993, "red_v43": -2.0089999999999995, "red_v30": 1.8410937500000002, "red_v4": -1.5139999999999998, "red_v40": 0.5006932378161698, "red_v17": -2.0299999999999994, "red_v9": -2.0119999999999996, "red_v10": -2.013, "red_v25": -2.0089999999999995, "red_v13": -2.0169999999999986, "red_v27": 2.220068237816177, "red_v16": -1.133, "red_v14": 1.840786987816177, "red_v11": -0.5629999999999997, "red_v19": -1.003, "red_v42": -0.5349999999999997, "red_v49": -1.0079999999999998, "red_v32": -0.7720000000000008, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383, "red_v20": 0.369693237816179, "red_v48": 0.39328360500000037, "red_v8": 0.831546875, "red_v46": -2.0169999999999995, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v21": 1.4736932378161711}, "policy_reward_max": {"red_v1": 0.84, "red": 3.98519323781617, "red_v41": 0.5046925427729418, "red_v5": 0.47350000000000003, "blue": 1.98715625, "red_v2": -0.016000000000000007, "red_v47": -1.005, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": 10.891956250000032, "red_v43": -1.0089999999999997, "red_v30": 1.8410937500000002, "red_v4": -1.0069999999999997, "red_v40": 1.5046932378161697, "red_v17": -2.0299999999999994, "red_v9": -1.679, "red_v10": 1.3592836050000003, "red_v25": -0.56, "red_v13": -2.014999999999999, "red_v27": 2.220068237816177, "red_v16": -1.133, "red_v14": 1.840786987816177, "red_v11": -0.5629999999999997, "red_v19": -1.003, "red_v42": 12.119000000000023, "red_v49": -1.0079999999999998, "red_v32": -0.5830653855574073, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383, "red_v20": 0.369693237816179, "red_v48": 0.39328360500000037, "red_v8": 0.831546875, "red_v46": -1.072, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v21": 1.4736932378161711}, "policy_reward_mean": {"red_v1": -0.8079999999999992, "red": 2.4080110652500846, "red_v41": -0.516153728613529, "red_v5": 0.22975, "blue": -1.1156090561224485, "red_v2": -0.016000000000000007, "red_v47": -1.0055, "red_v28": 0.46499999999999997, "red_v39": 0.45868750000000014, "red_v38": 4.438978125000016, "red_v43": -1.5089999999999995, "red_v30": 1.8410937500000002, "red_v4": -1.2604999999999997, "red_v40": 1.0026932378161697, "red_v17": -2.0299999999999994, "red_v9": -1.8455, "red_v10": -0.3268581974999998, "red_v25": -1.2844999999999998, "red_v13": -2.0159999999999987, "red_v27": 2.220068237816177, "red_v16": -1.133, "red_v14": 1.840786987816177, "red_v11": -0.5629999999999997, "red_v19": -1.003, "red_v42": 5.792000000000011, "red_v49": -1.0079999999999998, "red_v32": -0.677532692778704, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383, "red_v20": 0.369693237816179, "red_v48": 0.39328360500000037, "red_v8": 0.831546875, "red_v46": -1.5444999999999998, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v21": 1.4736932378161711}, "hist_stats": {"episode_reward": [1.4828182378161698, 3.990104530589112, 2.9420994878161717, 2.1559875000000006, 1.4153125000000002, 2.966490112816171, 1.8374531250000001, 0.8104744878161704, 2.66620625, 2.4199901128161727, 1.4767088628161704, 0.9597905335440555, 2.168224487816183, 1.4800369878152042, 2.4821151128161705, 1.8457869878161741, 1.9781932378161704, 0.7877401128161701, 0.9630838628161719, 1.0867869878161804, 0.9787088628161702, 4.487183350632341, 1.4474588628161715, 1.4767088628161704, 3.97966772563234, 3.1741273550000013, 0.8677836050000003, 3.812458862816171, 2.47708386281617, 0.8759242300000005, 2.4838182378161706, 2.477193237816171, 2.9205682378161706, 2.450317542772942, -0.08596301218382829, 1.4695682378161705, 1.4472088628161712, 1.4853338628152044, 0.9597869878161698, 2.8674432378161723, 1.3642869878161723, 2.7167614756323517, 2.4557244878161715, 1.9714901128161706, 0.810052612816194, 1.479743658544055, 2.2154802256323745, 2.9292244878161706, 1.1575031250000005, 1.1896463628161753, 1.4883331677729421, 1.0951463628161726, 2.4790057378161703, 2.6549875000000007, 0.5910369878161698, 2.483524908544055, 2.481818237816171, -12.020150512183776, 2.477193237816171, 0.696693237816226, 2.4482088628161707, 2.38473673, 1.9695682378161707, 3.987511475631373, 3.035245850632361, 2.486630737815204, 0.8384531250000002, 2.6532458506323584, 1.3827367300000004, -7.816350512183837, 3.043112227258782, 1.4767088628161704, 1.53216198781617, 2.4735994878161707, 1.425224487816172, 3.885616772772942, 1.299240112816174, 1.8637869878161752, 2.5054276128161845, 2.4817088628161703, 2.938802612816172, 1.4658651128161706, 2.9741186585440555, 2.4748963628161706, 2.4736846144425924, 2.45746460063235, 2.4547244878152044, 2.4763026128161703, 2.97470886281617, 0.9917394177729422, 1.9686932378162099, 2.47941198781617, 2.98822448781617, 2.4886300427729413, 1.8824398550000003, 1.464786292772942, 1.9612713628161713, 4.397652100632346, 2.488040533544055, 1.486630737815204], "episode_lengths": [24, 26, 62, 20, 28, 33, 15, 198, 14, 65, 27, 36, 278, 18, 25, 162, 32, 209, 35, 418, 27, 33, 43, 27, 38, 114, 32, 43, 35, 19, 24, 32, 40, 56, 1042, 40, 59, 19, 34, 80, 130, 264, 54, 33, 493, 19, 674, 22, 15, 303, 19, 399, 28, 20, 338, 25, 24, 782, 32, 1280, 59, 15, 40, 24, 397, 20, 15, 269, 15, 926, 389, 27, 618, 30, 86, 19, 177, 98, 437, 27, 61, 41, 27, 31, 16, 647, 54, 29, 27, 17, 1280, 26, 22, 20, 14, 34, 39, 75, 20, 20], "policy_red_v1_reward": [-2.008, 0.84, -2.0559999999999965, -0.008], "policy_red_v41_reward": [0.5046925427729418, -1.537], "policy_red_v5_reward": [-0.014000000000000005, 0.47350000000000003], "policy_blue_reward": [-1.0099999999999996, -1.0069999999999995, -1.5479999999999998, -0.004, -2.0109999999999992, -1.5709999999999968, -2.0069999999999992, -1.115, -1.5089999999999995, -1.503, -1.0079999999999996, -1.0079999999999991, -1.3010000000000002, -2.0089999999999995, -1.509, -0.5749999999999998, -1.54, -1.010999999999999, -2.0089999999999995, -2.0089999999999995, -1.576, -2.005, -1.113, -1.0079999999999996, -0.008, -1.0079999999999991, -1.0119999999999993, -1.0019999999999998, -1.0059999999999998, -2.004, -2.003, -2.01, -1.012, -2.0199999999999987, -1.0069999999999997, -0.012000000000000004, -2.009999999999999, -1.0109999999999992, -1.0039999999999996, 0.489, -1.01, -0.012000000000000004, -1.5039999999999998, 0.5009999999999998, -1.0089999999999997, -0.003, 1.98715625, -1.0049999999999997, -2.004], "policy_red_v2_reward": [-0.016000000000000007], "policy_red_v47_reward": [-1.005, -1.006], "policy_red_v28_reward": [0.46499999999999997], "policy_red_v39_reward": [0.45868750000000014], "policy_red_v38_reward": [-2.0139999999999993, 10.891956250000032], "policy_red_v43_reward": [-1.0089999999999997, -2.0089999999999995], "policy_red_v30_reward": [1.8410937500000002], "policy_red_v4_reward": [-1.5139999999999998, -1.0069999999999997], "policy_red_v40_reward": [1.5046932378161697, 0.5006932378161698], "policy_red_v17_reward": [-2.0299999999999994], "policy_red_v9_reward": [-2.0119999999999996, -1.679], "policy_red_v10_reward": [1.3592836050000003, -2.013], "policy_red_v25_reward": [-0.56, -2.0089999999999995], "policy_red_v13_reward": [-2.014999999999999, -2.0169999999999986], "policy_red_v27_reward": [2.220068237816177], "policy_red_v16_reward": [-1.133], "policy_red_v14_reward": [1.840786987816177], "policy_red_v11_reward": [-0.5629999999999997], "policy_red_v19_reward": [-1.003], "policy_red_v42_reward": [12.119000000000023, -0.5349999999999997], "policy_red_v49_reward": [-1.0079999999999998], "policy_red_v32_reward": [-0.7720000000000008, -0.5830653855574073], "policy_red_v34_reward": [0.4996932378152038], "policy_red_v44_reward": [-0.59630676218383], "policy_red_v20_reward": [0.369693237816179], "policy_red_v48_reward": [0.39328360500000037], "policy_red_v8_reward": [0.831546875], "policy_red_v46_reward": [-1.072, -2.0169999999999995], "policy_red_v35_reward": [0.4296932378161733], "policy_red_v37_reward": [-1.003], "policy_red_v21_reward": [1.4736932378161711]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.814376413715241, "mean_inference_ms": 7.759095840323819, "mean_action_processing_ms": 0.29374079120198654, "mean_env_wait_ms": 0.3894077311963828, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1037822961807251, "StateBufferConnector_ms": 0.0043392181396484375, "ViewRequirementAgentConnector_ms": 0.11918056011199951}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 206.66176722273983, "num_env_steps_trained_throughput_per_sec": 206.66176722273983, "timesteps_total": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 19909.827, "sample_time_ms": 1134.648, "learn_time_ms": 18691.817, "learn_throughput": 213.997, "synch_weights_time_ms": 80.318}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "episodes_total": 1134, "training_iteration": 84, "trial_id": "a9680_00000", "date": "2023-09-24_03-06-41", "timestamp": 1695539201, "time_this_iter_s": 19.36499547958374, "time_total_s": 1674.735035419464, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1df3edd0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34285240>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b34284c10>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1674.735035419464, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 5.4468749999999995, "ram_util_percent": 22.778125}, "win_rate": 0.78, "league_size": 54}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0199276405076185, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.003946963152945197, "policy_loss": -0.05047153428992412, "vf_loss": 0.09811325013870373, "vf_explained_var": 0.7466828302790721, "kl": 0.01614979829607819, "entropy": 1.9055363786717257, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 81120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 680000, "num_agent_steps_trained": 680000}, "sampler_results": {"episode_reward_max": 4.397652100632346, "episode_reward_min": -12.020150512183776, "episode_reward_mean": 1.8619565461482583, "episode_len_mean": 155.22, "episode_media": {}, "episodes_this_iter": 23, "policy_reward_min": {"red_v9": -2.0119999999999996, "red": -24.13915051218385, "red_v40": 0.5006932378161698, "red_v10": -2.013, "red_v5": -2.008, "red_v1": -2.0559999999999965, "red_v47": -1.006, "blue": -2.0199999999999987, "red_v25": -2.0089999999999995, "red_v4": -1.0069999999999997, "red_v13": -2.0169999999999986, "red_v27": 2.220068237816177, "red_v16": -1.133, "red_v14": 1.840786987816177, "red_v11": -0.5629999999999997, "red_v19": -1.003, "red_v42": -1.033, "red_v49": -1.0079999999999998, "red_v32": -0.7720000000000008, "red_v43": -2.024999999999998, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383, "red_v20": 0.369693237816179, "red_v38": 10.891956250000032, "red_v48": 0.39328360500000037, "red_v8": 0.831546875, "red_v46": -2.0169999999999995, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v21": 1.4736932378161711, "red_v50": -1.006, "red_v12": 0.46769323781520544, "red_v30": -1.001, "red_v33": -0.6829999999999986}, "policy_reward_max": {"red_v9": -1.679, "red": 3.9804901128161703, "red_v40": 0.5006932378161698, "red_v10": 1.3592836050000003, "red_v5": 0.47350000000000003, "red_v1": 0.84, "red_v47": -1.006, "blue": 1.98715625, "red_v25": -0.5390653855574077, "red_v4": -1.0069999999999997, "red_v13": -0.019703124999984944, "red_v27": 2.220068237816177, "red_v16": -0.8509499999999999, "red_v14": 1.840786987816177, "red_v11": -0.5089999999999997, "red_v19": 1.943765625, "red_v42": 12.119000000000023, "red_v49": -1.0079999999999998, "red_v32": -0.5830653855574073, "red_v43": -2.0089999999999995, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383, "red_v20": 0.369693237816179, "red_v38": 10.891956250000032, "red_v48": 0.39328360500000037, "red_v8": 0.831546875, "red_v46": -1.072, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v21": 1.4736932378161711, "red_v50": -1.006, "red_v12": 0.46769323781520544, "red_v30": 1.9785312499999999, "red_v33": -0.6829999999999986}, "policy_reward_mean": {"red_v9": -1.8455, "red": 2.4068470716059664, "red_v40": 0.5006932378161698, "red_v10": -0.3268581974999998, "red_v5": -0.76725, "red_v1": -0.40799999999999886, "red_v47": -1.006, "blue": -1.0954168749999997, "red_v25": -1.0360217951858024, "red_v4": -1.0069999999999997, "red_v13": -1.3505677083333276, "red_v27": 2.220068237816177, "red_v16": -0.9919749999999999, "red_v14": 1.840786987816177, "red_v11": -0.5359999999999997, "red_v19": 0.4703828125, "red_v42": 3.517000000000008, "red_v49": -1.0079999999999998, "red_v32": -0.677532692778704, "red_v43": -2.0169999999999986, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383, "red_v20": 0.369693237816179, "red_v38": 10.891956250000032, "red_v48": 0.39328360500000037, "red_v8": 0.831546875, "red_v46": -1.5444999999999998, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v21": 1.4736932378161711, "red_v50": -1.006, "red_v12": 0.46769323781520544, "red_v30": 0.488765625, "red_v33": -0.6829999999999986}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.4767088628161704, 3.97966772563234, 3.1741273550000013, 0.8677836050000003, 3.812458862816171, 2.47708386281617, 0.8759242300000005, 2.4838182378161706, 2.477193237816171, 2.9205682378161706, 2.450317542772942, -0.08596301218382829, 1.4695682378161705, 1.4472088628161712, 1.4853338628152044, 0.9597869878161698, 2.8674432378161723, 1.3642869878161723, 2.7167614756323517, 2.4557244878161715, 1.9714901128161706, 0.810052612816194, 1.479743658544055, 2.2154802256323745, 2.9292244878161706, 1.1575031250000005, 1.1896463628161753, 1.4883331677729421, 1.0951463628161726, 2.4790057378161703, 2.6549875000000007, 0.5910369878161698, 2.483524908544055, 2.481818237816171, -12.020150512183776, 2.477193237816171, 0.696693237816226, 2.4482088628161707, 2.38473673, 1.9695682378161707, 3.987511475631373, 3.035245850632361, 2.486630737815204, 0.8384531250000002, 2.6532458506323584, 1.3827367300000004, -7.816350512183837, 3.043112227258782, 1.4767088628161704, 1.53216198781617, 2.4735994878161707, 1.425224487816172, 3.885616772772942, 1.299240112816174, 1.8637869878161752, 2.5054276128161845, 2.4817088628161703, 2.938802612816172, 1.4658651128161706, 2.9741186585440555, 2.4748963628161706, 2.4736846144425924, 2.45746460063235, 2.4547244878152044, 2.4763026128161703, 2.97470886281617, 0.9917394177729422, 1.9686932378162099, 2.47941198781617, 2.98822448781617, 2.4886300427729413, 1.8824398550000003, 1.464786292772942, 1.9612713628161713, 4.397652100632346, 2.488040533544055, 1.486630737815204, 1.4495369878161715, 2.46919323781617, 2.461646362816171, 1.2917869878152128, 3.336221602258769, 1.9763026128161703, 1.4447401128161705, 2.4757869878161705, 2.7737771006313823, 2.9878057378161778, 2.471786987816171, 1.489145667772942, 0.7564062500000035, 1.485333862815204, 2.4764901128161703, 1.98422448781617, 1.9609588628162022, 1.7190526128161765, 2.386439855, 1.9504588628161712, 1.489446783544055, 2.4919276128161703, 0.365990112816196], "episode_lengths": [27, 38, 114, 32, 43, 35, 19, 24, 32, 40, 56, 1042, 40, 59, 19, 34, 80, 130, 264, 54, 33, 493, 19, 674, 22, 15, 303, 19, 399, 28, 20, 338, 25, 24, 782, 32, 1280, 59, 15, 40, 24, 397, 20, 15, 269, 15, 926, 389, 27, 618, 30, 86, 19, 177, 98, 437, 27, 61, 41, 27, 31, 16, 647, 54, 29, 27, 17, 1280, 26, 22, 20, 14, 34, 39, 75, 20, 20, 50, 32, 47, 162, 130, 29, 81, 34, 227, 172, 34, 15, 62, 19, 33, 22, 907, 109, 14, 43, 18, 21, 385], "policy_red_v9_reward": [-2.0119999999999996, -1.679], "policy_red_v40_reward": [0.5006932378161698], "policy_red_v10_reward": [1.3592836050000003, -2.013], "policy_red_v5_reward": [0.47350000000000003, -2.008], "policy_red_v1_reward": [0.84, -2.0559999999999965, -0.008], "policy_red_v47_reward": [-1.006], "policy_blue_reward": [-1.503, -1.0079999999999996, -1.0079999999999991, -1.3010000000000002, -2.0089999999999995, -1.509, -0.5749999999999998, -1.54, -1.010999999999999, -2.0089999999999995, -2.0089999999999995, -1.576, -2.005, -1.113, -1.0079999999999996, -0.008, -1.0079999999999991, -1.0119999999999993, -1.0019999999999998, -1.0059999999999998, -2.004, -2.003, -2.01, -1.012, -2.0199999999999987, -1.0069999999999997, -0.012000000000000004, -2.009999999999999, -1.0109999999999992, -1.0039999999999996, 0.489, -1.01, -0.012000000000000004, -1.5039999999999998, 0.5009999999999998, -1.0089999999999997, -0.003, 1.98715625, -1.0049999999999997, -2.004, -2.0169999999999995, -1.0159999999999996, -1.0099999999999991, -1.0079999999999998, -1.0089999999999997, -2.006, -1.0079999999999993, 0.19199999999999978, -2.005, -1.001], "policy_red_v25_reward": [-0.56, -2.0089999999999995, -0.5390653855574077], "policy_red_v4_reward": [-1.0069999999999997], "policy_red_v13_reward": [-2.014999999999999, -2.0169999999999986, -0.019703124999984944], "policy_red_v27_reward": [2.220068237816177], "policy_red_v16_reward": [-1.133, -0.8509499999999999], "policy_red_v14_reward": [1.840786987816177], "policy_red_v11_reward": [-0.5629999999999997, -0.5089999999999997], "policy_red_v19_reward": [-1.003, 1.943765625], "policy_red_v42_reward": [12.119000000000023, -0.5349999999999997, -1.033], "policy_red_v49_reward": [-1.0079999999999998], "policy_red_v32_reward": [-0.7720000000000008, -0.5830653855574073], "policy_red_v43_reward": [-2.0089999999999995, -2.024999999999998], "policy_red_v34_reward": [0.4996932378152038], "policy_red_v44_reward": [-0.59630676218383], "policy_red_v20_reward": [0.369693237816179], "policy_red_v38_reward": [10.891956250000032], "policy_red_v48_reward": [0.39328360500000037], "policy_red_v8_reward": [0.831546875], "policy_red_v46_reward": [-1.072, -2.0169999999999995], "policy_red_v35_reward": [0.4296932378161733], "policy_red_v37_reward": [-1.003], "policy_red_v21_reward": [1.4736932378161711], "policy_red_v50_reward": [-1.006], "policy_red_v12_reward": [0.46769323781520544], "policy_red_v30_reward": [1.9785312499999999, -1.001], "policy_red_v33_reward": [-0.6829999999999986]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8139377313631138, "mean_inference_ms": 7.750276414149903, "mean_action_processing_ms": 0.29314602110083193, "mean_env_wait_ms": 0.38918129536651697, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10570716857910156, "StateBufferConnector_ms": 0.004453897476196289, "ViewRequirementAgentConnector_ms": 0.12240195274353027}}, "episode_reward_max": 4.397652100632346, "episode_reward_min": -12.020150512183776, "episode_reward_mean": 1.8619565461482583, "episode_len_mean": 155.22, "episodes_this_iter": 23, "policy_reward_min": {"red_v9": -2.0119999999999996, "red": -24.13915051218385, "red_v40": 0.5006932378161698, "red_v10": -2.013, "red_v5": -2.008, "red_v1": -2.0559999999999965, "red_v47": -1.006, "blue": -2.0199999999999987, "red_v25": -2.0089999999999995, "red_v4": -1.0069999999999997, "red_v13": -2.0169999999999986, "red_v27": 2.220068237816177, "red_v16": -1.133, "red_v14": 1.840786987816177, "red_v11": -0.5629999999999997, "red_v19": -1.003, "red_v42": -1.033, "red_v49": -1.0079999999999998, "red_v32": -0.7720000000000008, "red_v43": -2.024999999999998, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383, "red_v20": 0.369693237816179, "red_v38": 10.891956250000032, "red_v48": 0.39328360500000037, "red_v8": 0.831546875, "red_v46": -2.0169999999999995, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v21": 1.4736932378161711, "red_v50": -1.006, "red_v12": 0.46769323781520544, "red_v30": -1.001, "red_v33": -0.6829999999999986}, "policy_reward_max": {"red_v9": -1.679, "red": 3.9804901128161703, "red_v40": 0.5006932378161698, "red_v10": 1.3592836050000003, "red_v5": 0.47350000000000003, "red_v1": 0.84, "red_v47": -1.006, "blue": 1.98715625, "red_v25": -0.5390653855574077, "red_v4": -1.0069999999999997, "red_v13": -0.019703124999984944, "red_v27": 2.220068237816177, "red_v16": -0.8509499999999999, "red_v14": 1.840786987816177, "red_v11": -0.5089999999999997, "red_v19": 1.943765625, "red_v42": 12.119000000000023, "red_v49": -1.0079999999999998, "red_v32": -0.5830653855574073, "red_v43": -2.0089999999999995, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383, "red_v20": 0.369693237816179, "red_v38": 10.891956250000032, "red_v48": 0.39328360500000037, "red_v8": 0.831546875, "red_v46": -1.072, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v21": 1.4736932378161711, "red_v50": -1.006, "red_v12": 0.46769323781520544, "red_v30": 1.9785312499999999, "red_v33": -0.6829999999999986}, "policy_reward_mean": {"red_v9": -1.8455, "red": 2.4068470716059664, "red_v40": 0.5006932378161698, "red_v10": -0.3268581974999998, "red_v5": -0.76725, "red_v1": -0.40799999999999886, "red_v47": -1.006, "blue": -1.0954168749999997, "red_v25": -1.0360217951858024, "red_v4": -1.0069999999999997, "red_v13": -1.3505677083333276, "red_v27": 2.220068237816177, "red_v16": -0.9919749999999999, "red_v14": 1.840786987816177, "red_v11": -0.5359999999999997, "red_v19": 0.4703828125, "red_v42": 3.517000000000008, "red_v49": -1.0079999999999998, "red_v32": -0.677532692778704, "red_v43": -2.0169999999999986, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383, "red_v20": 0.369693237816179, "red_v38": 10.891956250000032, "red_v48": 0.39328360500000037, "red_v8": 0.831546875, "red_v46": -1.5444999999999998, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v21": 1.4736932378161711, "red_v50": -1.006, "red_v12": 0.46769323781520544, "red_v30": 0.488765625, "red_v33": -0.6829999999999986}, "hist_stats": {"episode_reward": [1.4767088628161704, 3.97966772563234, 3.1741273550000013, 0.8677836050000003, 3.812458862816171, 2.47708386281617, 0.8759242300000005, 2.4838182378161706, 2.477193237816171, 2.9205682378161706, 2.450317542772942, -0.08596301218382829, 1.4695682378161705, 1.4472088628161712, 1.4853338628152044, 0.9597869878161698, 2.8674432378161723, 1.3642869878161723, 2.7167614756323517, 2.4557244878161715, 1.9714901128161706, 0.810052612816194, 1.479743658544055, 2.2154802256323745, 2.9292244878161706, 1.1575031250000005, 1.1896463628161753, 1.4883331677729421, 1.0951463628161726, 2.4790057378161703, 2.6549875000000007, 0.5910369878161698, 2.483524908544055, 2.481818237816171, -12.020150512183776, 2.477193237816171, 0.696693237816226, 2.4482088628161707, 2.38473673, 1.9695682378161707, 3.987511475631373, 3.035245850632361, 2.486630737815204, 0.8384531250000002, 2.6532458506323584, 1.3827367300000004, -7.816350512183837, 3.043112227258782, 1.4767088628161704, 1.53216198781617, 2.4735994878161707, 1.425224487816172, 3.885616772772942, 1.299240112816174, 1.8637869878161752, 2.5054276128161845, 2.4817088628161703, 2.938802612816172, 1.4658651128161706, 2.9741186585440555, 2.4748963628161706, 2.4736846144425924, 2.45746460063235, 2.4547244878152044, 2.4763026128161703, 2.97470886281617, 0.9917394177729422, 1.9686932378162099, 2.47941198781617, 2.98822448781617, 2.4886300427729413, 1.8824398550000003, 1.464786292772942, 1.9612713628161713, 4.397652100632346, 2.488040533544055, 1.486630737815204, 1.4495369878161715, 2.46919323781617, 2.461646362816171, 1.2917869878152128, 3.336221602258769, 1.9763026128161703, 1.4447401128161705, 2.4757869878161705, 2.7737771006313823, 2.9878057378161778, 2.471786987816171, 1.489145667772942, 0.7564062500000035, 1.485333862815204, 2.4764901128161703, 1.98422448781617, 1.9609588628162022, 1.7190526128161765, 2.386439855, 1.9504588628161712, 1.489446783544055, 2.4919276128161703, 0.365990112816196], "episode_lengths": [27, 38, 114, 32, 43, 35, 19, 24, 32, 40, 56, 1042, 40, 59, 19, 34, 80, 130, 264, 54, 33, 493, 19, 674, 22, 15, 303, 19, 399, 28, 20, 338, 25, 24, 782, 32, 1280, 59, 15, 40, 24, 397, 20, 15, 269, 15, 926, 389, 27, 618, 30, 86, 19, 177, 98, 437, 27, 61, 41, 27, 31, 16, 647, 54, 29, 27, 17, 1280, 26, 22, 20, 14, 34, 39, 75, 20, 20, 50, 32, 47, 162, 130, 29, 81, 34, 227, 172, 34, 15, 62, 19, 33, 22, 907, 109, 14, 43, 18, 21, 385], "policy_red_v9_reward": [-2.0119999999999996, -1.679], "policy_red_v40_reward": [0.5006932378161698], "policy_red_v10_reward": [1.3592836050000003, -2.013], "policy_red_v5_reward": [0.47350000000000003, -2.008], "policy_red_v1_reward": [0.84, -2.0559999999999965, -0.008], "policy_red_v47_reward": [-1.006], "policy_blue_reward": [-1.503, -1.0079999999999996, -1.0079999999999991, -1.3010000000000002, -2.0089999999999995, -1.509, -0.5749999999999998, -1.54, -1.010999999999999, -2.0089999999999995, -2.0089999999999995, -1.576, -2.005, -1.113, -1.0079999999999996, -0.008, -1.0079999999999991, -1.0119999999999993, -1.0019999999999998, -1.0059999999999998, -2.004, -2.003, -2.01, -1.012, -2.0199999999999987, -1.0069999999999997, -0.012000000000000004, -2.009999999999999, -1.0109999999999992, -1.0039999999999996, 0.489, -1.01, -0.012000000000000004, -1.5039999999999998, 0.5009999999999998, -1.0089999999999997, -0.003, 1.98715625, -1.0049999999999997, -2.004, -2.0169999999999995, -1.0159999999999996, -1.0099999999999991, -1.0079999999999998, -1.0089999999999997, -2.006, -1.0079999999999993, 0.19199999999999978, -2.005, -1.001], "policy_red_v25_reward": [-0.56, -2.0089999999999995, -0.5390653855574077], "policy_red_v4_reward": [-1.0069999999999997], "policy_red_v13_reward": [-2.014999999999999, -2.0169999999999986, -0.019703124999984944], "policy_red_v27_reward": [2.220068237816177], "policy_red_v16_reward": [-1.133, -0.8509499999999999], "policy_red_v14_reward": [1.840786987816177], "policy_red_v11_reward": [-0.5629999999999997, -0.5089999999999997], "policy_red_v19_reward": [-1.003, 1.943765625], "policy_red_v42_reward": [12.119000000000023, -0.5349999999999997, -1.033], "policy_red_v49_reward": [-1.0079999999999998], "policy_red_v32_reward": [-0.7720000000000008, -0.5830653855574073], "policy_red_v43_reward": [-2.0089999999999995, -2.024999999999998], "policy_red_v34_reward": [0.4996932378152038], "policy_red_v44_reward": [-0.59630676218383], "policy_red_v20_reward": [0.369693237816179], "policy_red_v38_reward": [10.891956250000032], "policy_red_v48_reward": [0.39328360500000037], "policy_red_v8_reward": [0.831546875], "policy_red_v46_reward": [-1.072, -2.0169999999999995], "policy_red_v35_reward": [0.4296932378161733], "policy_red_v37_reward": [-1.003], "policy_red_v21_reward": [1.4736932378161711], "policy_red_v50_reward": [-1.006], "policy_red_v12_reward": [0.46769323781520544], "policy_red_v30_reward": [1.9785312499999999, -1.001], "policy_red_v33_reward": [-0.6829999999999986]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8139377313631138, "mean_inference_ms": 7.750276414149903, "mean_action_processing_ms": 0.29314602110083193, "mean_env_wait_ms": 0.38918129536651697, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10570716857910156, "StateBufferConnector_ms": 0.004453897476196289, "ViewRequirementAgentConnector_ms": 0.12240195274353027}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 680000, "num_agent_steps_trained": 680000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.51019549008336, "num_env_steps_trained_throughput_per_sec": 200.51019549008336, "timesteps_total": 340000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 680000, "timers": {"training_iteration_time_ms": 19932.26, "sample_time_ms": 1143.53, "learn_time_ms": 18705.302, "learn_throughput": 213.843, "synch_weights_time_ms": 80.28}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 680000, "num_agent_steps_trained": 680000}, "done": false, "episodes_total": 1157, "training_iteration": 85, "trial_id": "a9680_00000", "date": "2023-09-24_03-07-05", "timestamp": 1695539225, "time_this_iter_s": 19.960019826889038, "time_total_s": 1694.6950552463531, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b3426cbe0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1df4c940>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1df4c9d0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1694.6950552463531, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 5.357575757575758, "ram_util_percent": 22.878787878787875}, "win_rate": 0.79, "league_size": 55}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.359619266912341, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.002418034378691421, "policy_loss": -0.04692573734258379, "vf_loss": 0.08597948996466584, "vf_explained_var": 0.823946583395203, "kl": 0.018278159180836594, "entropy": 1.8711450442671775, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 82080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "sampler_results": {"episode_reward_max": 4.397652100632346, "episode_reward_min": -12.020150512183776, "episode_reward_mean": 1.8981913558529524, "episode_len_mean": 170.35, "episode_media": {}, "episodes_this_iter": 23, "policy_reward_min": {"red_v14": 1.840786987816177, "red": -24.13915051218385, "red_v11": -0.5629999999999997, "red_v10": -2.013, "blue": -2.0199999999999987, "red_v9": -1.679, "red_v19": -1.003, "red_v42": -1.033, "red_v49": -1.0079999999999998, "red_v32": -0.7720000000000008, "red_v43": -2.024999999999998, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383, "red_v20": -1.0479999999999952, "red_v38": 10.891956250000032, "red_v48": 0.39328360500000037, "red_v8": 0.831546875, "red_v1": -2.0559999999999965, "red_v46": -2.0169999999999995, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v13": -2.0169999999999986, "red_v21": 1.4736932378161711, "red_v25": -0.5390653855574077, "red_v50": -1.006, "red_v12": 0.46769323781520544, "red_v16": -0.8509499999999999, "red_v5": -2.008, "red_v30": -1.001, "red_v33": -0.6829999999999986, "red_v28": 1.8910624999999999, "red_v27": -2.0119999999999996, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997}, "policy_reward_max": {"red_v14": 1.840786987816177, "red": 3.9808963628161704, "red_v11": -0.5089999999999997, "red_v10": 0.43429687500000014, "blue": 1.98715625, "red_v9": -1.679, "red_v19": 1.943765625, "red_v42": 12.119000000000023, "red_v49": -1.0079999999999998, "red_v32": -0.5830653855574073, "red_v43": -2.0089999999999995, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383, "red_v20": 0.369693237816179, "red_v38": 10.891956250000032, "red_v48": 0.39328360500000037, "red_v8": 1.9349218750000001, "red_v1": -0.008, "red_v46": -1.072, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v13": -0.019703124999984944, "red_v21": 1.4736932378161711, "red_v25": -0.5390653855574077, "red_v50": -1.006, "red_v12": 2.0239425427729447, "red_v16": -0.8509499999999999, "red_v5": -2.008, "red_v30": 1.9785312499999999, "red_v33": 0.5006932378161699, "red_v28": 1.8910624999999999, "red_v27": -2.0119999999999996, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997}, "policy_reward_mean": {"red_v14": 1.840786987816177, "red": 2.3524743040052014, "red_v11": -0.5359999999999997, "red_v10": -0.7893515624999998, "blue": -1.0672968749999996, "red_v9": -1.679, "red_v19": 0.2531529542720567, "red_v42": 2.4977500000000057, "red_v49": -1.0079999999999998, "red_v32": -0.677532692778704, "red_v43": -2.0169999999999986, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383, "red_v20": -0.33915338109190807, "red_v38": 10.891956250000032, "red_v48": 0.39328360500000037, "red_v8": 1.383234375, "red_v1": -1.0319999999999983, "red_v46": -1.5444999999999998, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v13": -1.0183515624999917, "red_v21": 1.4736932378161711, "red_v25": -0.5390653855574077, "red_v50": -1.006, "red_v12": 1.245817890294075, "red_v16": -0.8509499999999999, "red_v5": -2.008, "red_v30": 0.488765625, "red_v33": -0.09115338109191434, "red_v28": 1.8910624999999999, "red_v27": -2.0119999999999996, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.2154802256323745, 2.9292244878161706, 1.1575031250000005, 1.1896463628161753, 1.4883331677729421, 1.0951463628161726, 2.4790057378161703, 2.6549875000000007, 0.5910369878161698, 2.483524908544055, 2.481818237816171, -12.020150512183776, 2.477193237816171, 0.696693237816226, 2.4482088628161707, 2.38473673, 1.9695682378161707, 3.987511475631373, 3.035245850632361, 2.486630737815204, 0.8384531250000002, 2.6532458506323584, 1.3827367300000004, -7.816350512183837, 3.043112227258782, 1.4767088628161704, 1.53216198781617, 2.4735994878161707, 1.425224487816172, 3.885616772772942, 1.299240112816174, 1.8637869878161752, 2.5054276128161845, 2.4817088628161703, 2.938802612816172, 1.4658651128161706, 2.9741186585440555, 2.4748963628161706, 2.4736846144425924, 2.45746460063235, 2.4547244878152044, 2.4763026128161703, 2.97470886281617, 0.9917394177729422, 1.9686932378162099, 2.47941198781617, 2.98822448781617, 2.4886300427729413, 1.8824398550000003, 1.464786292772942, 1.9612713628161713, 4.397652100632346, 2.488040533544055, 1.486630737815204, 1.4495369878161715, 2.46919323781617, 2.461646362816171, 1.2917869878152128, 3.336221602258769, 1.9763026128161703, 1.4447401128161705, 2.4757869878161705, 2.7737771006313823, 2.9878057378161778, 2.471786987816171, 1.489145667772942, 0.7564062500000035, 1.485333862815204, 2.4764901128161703, 1.98422448781617, 1.9609588628162022, 1.7190526128161765, 2.386439855, 1.9504588628161712, 1.489446783544055, 2.4919276128161703, 0.365990112816196, 1.951693237816211, 2.4759311585440544, 1.8937557378161731, 2.916896362816171, 1.4725994878161708, 1.4493252394425924, 2.44994323781617, 1.9648963628161713, 3.9767458506323394, 0.9429901128161706, 1.3322343750000005, 1.43034375, 1.1658000000000004, 3.988104530589112, 3.7908026128161723, 2.48733386281617, 2.472278364442592, 2.47759948781617, 1.817730225632365, 1.9406151128161713, 1.3758494878162058, 2.321635780589143, 1.4654658644425926], "episode_lengths": [674, 22, 15, 303, 19, 399, 28, 20, 338, 25, 24, 782, 32, 1280, 59, 15, 40, 24, 397, 20, 15, 269, 15, 926, 389, 27, 618, 30, 86, 19, 177, 98, 437, 27, 61, 41, 27, 31, 16, 647, 54, 29, 27, 17, 1280, 26, 22, 20, 14, 34, 39, 75, 20, 20, 50, 32, 47, 162, 130, 29, 81, 34, 227, 172, 34, 15, 62, 19, 33, 22, 907, 109, 14, 43, 18, 21, 385, 1280, 23, 108, 31, 30, 35, 48, 31, 45, 65, 21, 18, 16, 26, 61, 19, 18, 30, 658, 57, 1038, 560, 22], "policy_red_v14_reward": [1.840786987816177], "policy_red_v11_reward": [-0.5629999999999997, -0.5089999999999997], "policy_red_v10_reward": [-2.013, 0.43429687500000014], "policy_blue_reward": [-1.576, -2.005, -1.113, -1.0079999999999996, -0.008, -1.0079999999999991, -1.0119999999999993, -1.0019999999999998, -1.0059999999999998, -2.004, -2.003, -2.01, -1.012, -2.0199999999999987, -1.0069999999999997, -0.012000000000000004, -2.009999999999999, -1.0109999999999992, -1.0039999999999996, 0.489, -1.01, -0.012000000000000004, -1.5039999999999998, 0.5009999999999998, -1.0089999999999997, -0.003, 1.98715625, -1.0049999999999997, -2.004, -2.0169999999999995, -1.0159999999999996, -1.0099999999999991, -1.0079999999999998, -1.0089999999999997, -2.006, -1.0079999999999993, 0.19199999999999978, -2.005, -1.001, 0.4949999999999998, -1.0059999999999998, -1.507, -1.0139999999999991, -2.0159999999999987, -2.0039999999999996, -1.002, -2.005, -1.0059999999999996, -1.003, -2.0079999999999996], "policy_red_v9_reward": [-1.679], "policy_red_v19_reward": [-1.003, 1.943765625, -0.18130676218383002], "policy_red_v42_reward": [12.119000000000023, -0.5349999999999997, -1.033, -0.5599999999999999], "policy_red_v49_reward": [-1.0079999999999998], "policy_red_v32_reward": [-0.7720000000000008, -0.5830653855574073], "policy_red_v43_reward": [-2.0089999999999995, -2.024999999999998], "policy_red_v34_reward": [0.4996932378152038], "policy_red_v44_reward": [-0.59630676218383], "policy_red_v20_reward": [0.369693237816179, -1.0479999999999952], "policy_red_v38_reward": [10.891956250000032], "policy_red_v48_reward": [0.39328360500000037], "policy_red_v8_reward": [0.831546875, 1.9349218750000001], "policy_red_v1_reward": [-2.0559999999999965, -0.008], "policy_red_v46_reward": [-1.072, -2.0169999999999995], "policy_red_v35_reward": [0.4296932378161733], "policy_red_v37_reward": [-1.003], "policy_red_v13_reward": [-2.0169999999999986, -0.019703124999984944], "policy_red_v21_reward": [1.4736932378161711], "policy_red_v25_reward": [-0.5390653855574077], "policy_red_v50_reward": [-1.006], "policy_red_v12_reward": [0.46769323781520544, 2.0239425427729447], "policy_red_v16_reward": [-0.8509499999999999], "policy_red_v5_reward": [-2.008], "policy_red_v30_reward": [1.9785312499999999, -1.001], "policy_red_v33_reward": [-0.6829999999999986, 0.5006932378161699], "policy_red_v28_reward": [1.8910624999999999], "policy_red_v27_reward": [-2.0119999999999996], "policy_red_v23_reward": [0.501692542772942], "policy_red_v51_reward": [0.8300000000000001], "policy_red_v15_reward": [-1.0089999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8128784145368223, "mean_inference_ms": 7.729765824671144, "mean_action_processing_ms": 0.2923059809638781, "mean_env_wait_ms": 0.38773671225351036, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10290718078613281, "StateBufferConnector_ms": 0.004400968551635742, "ViewRequirementAgentConnector_ms": 0.12126457691192627}}, "episode_reward_max": 4.397652100632346, "episode_reward_min": -12.020150512183776, "episode_reward_mean": 1.8981913558529524, "episode_len_mean": 170.35, "episodes_this_iter": 23, "policy_reward_min": {"red_v14": 1.840786987816177, "red": -24.13915051218385, "red_v11": -0.5629999999999997, "red_v10": -2.013, "blue": -2.0199999999999987, "red_v9": -1.679, "red_v19": -1.003, "red_v42": -1.033, "red_v49": -1.0079999999999998, "red_v32": -0.7720000000000008, "red_v43": -2.024999999999998, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383, "red_v20": -1.0479999999999952, "red_v38": 10.891956250000032, "red_v48": 0.39328360500000037, "red_v8": 0.831546875, "red_v1": -2.0559999999999965, "red_v46": -2.0169999999999995, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v13": -2.0169999999999986, "red_v21": 1.4736932378161711, "red_v25": -0.5390653855574077, "red_v50": -1.006, "red_v12": 0.46769323781520544, "red_v16": -0.8509499999999999, "red_v5": -2.008, "red_v30": -1.001, "red_v33": -0.6829999999999986, "red_v28": 1.8910624999999999, "red_v27": -2.0119999999999996, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997}, "policy_reward_max": {"red_v14": 1.840786987816177, "red": 3.9808963628161704, "red_v11": -0.5089999999999997, "red_v10": 0.43429687500000014, "blue": 1.98715625, "red_v9": -1.679, "red_v19": 1.943765625, "red_v42": 12.119000000000023, "red_v49": -1.0079999999999998, "red_v32": -0.5830653855574073, "red_v43": -2.0089999999999995, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383, "red_v20": 0.369693237816179, "red_v38": 10.891956250000032, "red_v48": 0.39328360500000037, "red_v8": 1.9349218750000001, "red_v1": -0.008, "red_v46": -1.072, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v13": -0.019703124999984944, "red_v21": 1.4736932378161711, "red_v25": -0.5390653855574077, "red_v50": -1.006, "red_v12": 2.0239425427729447, "red_v16": -0.8509499999999999, "red_v5": -2.008, "red_v30": 1.9785312499999999, "red_v33": 0.5006932378161699, "red_v28": 1.8910624999999999, "red_v27": -2.0119999999999996, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997}, "policy_reward_mean": {"red_v14": 1.840786987816177, "red": 2.3524743040052014, "red_v11": -0.5359999999999997, "red_v10": -0.7893515624999998, "blue": -1.0672968749999996, "red_v9": -1.679, "red_v19": 0.2531529542720567, "red_v42": 2.4977500000000057, "red_v49": -1.0079999999999998, "red_v32": -0.677532692778704, "red_v43": -2.0169999999999986, "red_v34": 0.4996932378152038, "red_v44": -0.59630676218383, "red_v20": -0.33915338109190807, "red_v38": 10.891956250000032, "red_v48": 0.39328360500000037, "red_v8": 1.383234375, "red_v1": -1.0319999999999983, "red_v46": -1.5444999999999998, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v13": -1.0183515624999917, "red_v21": 1.4736932378161711, "red_v25": -0.5390653855574077, "red_v50": -1.006, "red_v12": 1.245817890294075, "red_v16": -0.8509499999999999, "red_v5": -2.008, "red_v30": 0.488765625, "red_v33": -0.09115338109191434, "red_v28": 1.8910624999999999, "red_v27": -2.0119999999999996, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997}, "hist_stats": {"episode_reward": [2.2154802256323745, 2.9292244878161706, 1.1575031250000005, 1.1896463628161753, 1.4883331677729421, 1.0951463628161726, 2.4790057378161703, 2.6549875000000007, 0.5910369878161698, 2.483524908544055, 2.481818237816171, -12.020150512183776, 2.477193237816171, 0.696693237816226, 2.4482088628161707, 2.38473673, 1.9695682378161707, 3.987511475631373, 3.035245850632361, 2.486630737815204, 0.8384531250000002, 2.6532458506323584, 1.3827367300000004, -7.816350512183837, 3.043112227258782, 1.4767088628161704, 1.53216198781617, 2.4735994878161707, 1.425224487816172, 3.885616772772942, 1.299240112816174, 1.8637869878161752, 2.5054276128161845, 2.4817088628161703, 2.938802612816172, 1.4658651128161706, 2.9741186585440555, 2.4748963628161706, 2.4736846144425924, 2.45746460063235, 2.4547244878152044, 2.4763026128161703, 2.97470886281617, 0.9917394177729422, 1.9686932378162099, 2.47941198781617, 2.98822448781617, 2.4886300427729413, 1.8824398550000003, 1.464786292772942, 1.9612713628161713, 4.397652100632346, 2.488040533544055, 1.486630737815204, 1.4495369878161715, 2.46919323781617, 2.461646362816171, 1.2917869878152128, 3.336221602258769, 1.9763026128161703, 1.4447401128161705, 2.4757869878161705, 2.7737771006313823, 2.9878057378161778, 2.471786987816171, 1.489145667772942, 0.7564062500000035, 1.485333862815204, 2.4764901128161703, 1.98422448781617, 1.9609588628162022, 1.7190526128161765, 2.386439855, 1.9504588628161712, 1.489446783544055, 2.4919276128161703, 0.365990112816196, 1.951693237816211, 2.4759311585440544, 1.8937557378161731, 2.916896362816171, 1.4725994878161708, 1.4493252394425924, 2.44994323781617, 1.9648963628161713, 3.9767458506323394, 0.9429901128161706, 1.3322343750000005, 1.43034375, 1.1658000000000004, 3.988104530589112, 3.7908026128161723, 2.48733386281617, 2.472278364442592, 2.47759948781617, 1.817730225632365, 1.9406151128161713, 1.3758494878162058, 2.321635780589143, 1.4654658644425926], "episode_lengths": [674, 22, 15, 303, 19, 399, 28, 20, 338, 25, 24, 782, 32, 1280, 59, 15, 40, 24, 397, 20, 15, 269, 15, 926, 389, 27, 618, 30, 86, 19, 177, 98, 437, 27, 61, 41, 27, 31, 16, 647, 54, 29, 27, 17, 1280, 26, 22, 20, 14, 34, 39, 75, 20, 20, 50, 32, 47, 162, 130, 29, 81, 34, 227, 172, 34, 15, 62, 19, 33, 22, 907, 109, 14, 43, 18, 21, 385, 1280, 23, 108, 31, 30, 35, 48, 31, 45, 65, 21, 18, 16, 26, 61, 19, 18, 30, 658, 57, 1038, 560, 22], "policy_red_v14_reward": [1.840786987816177], "policy_red_v11_reward": [-0.5629999999999997, -0.5089999999999997], "policy_red_v10_reward": [-2.013, 0.43429687500000014], "policy_blue_reward": [-1.576, -2.005, -1.113, -1.0079999999999996, -0.008, -1.0079999999999991, -1.0119999999999993, -1.0019999999999998, -1.0059999999999998, -2.004, -2.003, -2.01, -1.012, -2.0199999999999987, -1.0069999999999997, -0.012000000000000004, -2.009999999999999, -1.0109999999999992, -1.0039999999999996, 0.489, -1.01, -0.012000000000000004, -1.5039999999999998, 0.5009999999999998, -1.0089999999999997, -0.003, 1.98715625, -1.0049999999999997, -2.004, -2.0169999999999995, -1.0159999999999996, -1.0099999999999991, -1.0079999999999998, -1.0089999999999997, -2.006, -1.0079999999999993, 0.19199999999999978, -2.005, -1.001, 0.4949999999999998, -1.0059999999999998, -1.507, -1.0139999999999991, -2.0159999999999987, -2.0039999999999996, -1.002, -2.005, -1.0059999999999996, -1.003, -2.0079999999999996], "policy_red_v9_reward": [-1.679], "policy_red_v19_reward": [-1.003, 1.943765625, -0.18130676218383002], "policy_red_v42_reward": [12.119000000000023, -0.5349999999999997, -1.033, -0.5599999999999999], "policy_red_v49_reward": [-1.0079999999999998], "policy_red_v32_reward": [-0.7720000000000008, -0.5830653855574073], "policy_red_v43_reward": [-2.0089999999999995, -2.024999999999998], "policy_red_v34_reward": [0.4996932378152038], "policy_red_v44_reward": [-0.59630676218383], "policy_red_v20_reward": [0.369693237816179, -1.0479999999999952], "policy_red_v38_reward": [10.891956250000032], "policy_red_v48_reward": [0.39328360500000037], "policy_red_v8_reward": [0.831546875, 1.9349218750000001], "policy_red_v1_reward": [-2.0559999999999965, -0.008], "policy_red_v46_reward": [-1.072, -2.0169999999999995], "policy_red_v35_reward": [0.4296932378161733], "policy_red_v37_reward": [-1.003], "policy_red_v13_reward": [-2.0169999999999986, -0.019703124999984944], "policy_red_v21_reward": [1.4736932378161711], "policy_red_v25_reward": [-0.5390653855574077], "policy_red_v50_reward": [-1.006], "policy_red_v12_reward": [0.46769323781520544, 2.0239425427729447], "policy_red_v16_reward": [-0.8509499999999999], "policy_red_v5_reward": [-2.008], "policy_red_v30_reward": [1.9785312499999999, -1.001], "policy_red_v33_reward": [-0.6829999999999986, 0.5006932378161699], "policy_red_v28_reward": [1.8910624999999999], "policy_red_v27_reward": [-2.0119999999999996], "policy_red_v23_reward": [0.501692542772942], "policy_red_v51_reward": [0.8300000000000001], "policy_red_v15_reward": [-1.0089999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8128784145368223, "mean_inference_ms": 7.729765824671144, "mean_action_processing_ms": 0.2923059809638781, "mean_env_wait_ms": 0.38773671225351036, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10290718078613281, "StateBufferConnector_ms": 0.004400968551635742, "ViewRequirementAgentConnector_ms": 0.12126457691192627}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 195.3711844011003, "num_env_steps_trained_throughput_per_sec": 195.3711844011003, "timesteps_total": 344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 19984.948, "sample_time_ms": 1147.831, "learn_time_ms": 18752.382, "learn_throughput": 213.306, "synch_weights_time_ms": 81.644}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "episodes_total": 1180, "training_iteration": 86, "trial_id": "a9680_00000", "date": "2023-09-24_03-07-29", "timestamp": 1695539249, "time_this_iter_s": 20.48544716835022, "time_total_s": 1715.1805024147034, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1df3d390>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1df4da20>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1df4dab0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1715.1805024147034, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 5.226470588235294, "ram_util_percent": 22.988235294117647}, "win_rate": 0.76, "league_size": 56}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.413340262820323, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.03970153679983923, "policy_loss": -0.052694085682742295, "vf_loss": 0.17463305894828712, "vf_explained_var": 0.7016843938579161, "kl": 0.015486280268967275, "entropy": 1.8897328529506923, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 83040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 696000, "num_agent_steps_trained": 696000}, "sampler_results": {"episode_reward_max": 4.397652100632346, "episode_reward_min": 0.2529687500000002, "episode_reward_mean": 2.173608412368685, "episode_len_mean": 127.93, "episode_media": {}, "episodes_this_iter": 28, "policy_reward_min": {"blue": -2.0199999999999987, "red": -0.11071639499999919, "red_v48": 0.39328360500000037, "red_v8": 0.831546875, "red_v1": -2.0559999999999965, "red_v46": -2.0169999999999995, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v13": -2.0169999999999986, "red_v21": 1.4736932378161711, "red_v43": -2.024999999999998, "red_v25": -0.5390653855574077, "red_v11": -0.5089999999999997, "red_v50": -1.006, "red_v12": 0.46769323781520544, "red_v16": -0.8509499999999999, "red_v5": -2.008, "red_v42": -1.033, "red_v30": -1.001, "red_v33": -0.6829999999999986, "red_v19": -0.18130676218383002, "red_v28": 1.8910624999999999, "red_v27": -2.0119999999999996, "red_v10": -1.542, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997, "red_v20": -1.0479999999999952, "red_v45": -0.5569999999999999, "red_v14": -2.013999999999999, "red_v3": -1.5259999999999994, "red_v29": -1.0479999999999976, "red_v26": 0.50369323781617, "red_v40": -1.006, "red_v17": -1.588, "red_v7": -2.0149999999999997, "red_v32": 1.94565625}, "policy_reward_max": {"blue": 1.98715625, "red": 3.995739417772942, "red_v48": 0.39328360500000037, "red_v8": 1.9349218750000001, "red_v1": -0.008, "red_v46": -1.072, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v13": -0.019703124999984944, "red_v21": 1.4736932378161711, "red_v43": -2.024999999999998, "red_v25": -0.5390653855574077, "red_v11": 1.46371875, "red_v50": 0.5036925427729418, "red_v12": 2.0239425427729447, "red_v16": 0.473934614442593, "red_v5": -2.008, "red_v42": -0.5599999999999999, "red_v30": 1.9785312499999999, "red_v33": 0.5006932378161699, "red_v19": 1.943765625, "red_v28": 1.8910624999999999, "red_v27": -2.0119999999999996, "red_v10": 0.43429687500000014, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997, "red_v20": -1.0479999999999952, "red_v45": 0.4889346144425923, "red_v14": 0.49710303354405505, "red_v3": -1.5259999999999994, "red_v29": -0.5753067621838303, "red_v26": 0.50369323781617, "red_v40": -1.006, "red_v17": -1.588, "red_v7": -2.0149999999999997, "red_v32": 1.94565625}, "policy_reward_mean": {"blue": -1.0462932180851061, "red": 2.791085298369654, "red_v48": 0.39328360500000037, "red_v8": 1.383234375, "red_v1": -1.0319999999999983, "red_v46": -1.5444999999999998, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v13": -1.0183515624999917, "red_v21": 1.4736932378161711, "red_v43": -2.024999999999998, "red_v25": -0.5390653855574077, "red_v11": 0.3119062500000001, "red_v50": -0.2511537286135291, "red_v12": 1.245817890294075, "red_v16": -0.18850769277870344, "red_v5": -2.008, "red_v42": -0.7965, "red_v30": 0.488765625, "red_v33": -0.09115338109191434, "red_v19": 0.881229431408085, "red_v28": 1.8910624999999999, "red_v27": -2.0119999999999996, "red_v10": -0.5538515625, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997, "red_v20": -1.0479999999999952, "red_v45": -0.03403269277870383, "red_v14": -0.35067398881864786, "red_v3": -1.5259999999999994, "red_v29": -0.811653381091914, "red_v26": 0.50369323781617, "red_v40": -1.006, "red_v17": -1.588, "red_v7": -2.0149999999999997, "red_v32": 1.94565625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.425224487816172, 3.885616772772942, 1.299240112816174, 1.8637869878161752, 2.5054276128161845, 2.4817088628161703, 2.938802612816172, 1.4658651128161706, 2.9741186585440555, 2.4748963628161706, 2.4736846144425924, 2.45746460063235, 2.4547244878152044, 2.4763026128161703, 2.97470886281617, 0.9917394177729422, 1.9686932378162099, 2.47941198781617, 2.98822448781617, 2.4886300427729413, 1.8824398550000003, 1.464786292772942, 1.9612713628161713, 4.397652100632346, 2.488040533544055, 1.486630737815204, 1.4495369878161715, 2.46919323781617, 2.461646362816171, 1.2917869878152128, 3.336221602258769, 1.9763026128161703, 1.4447401128161705, 2.4757869878161705, 2.7737771006313823, 2.9878057378161778, 2.471786987816171, 1.489145667772942, 0.7564062500000035, 1.485333862815204, 2.4764901128161703, 1.98422448781617, 1.9609588628162022, 1.7190526128161765, 2.386439855, 1.9504588628161712, 1.489446783544055, 2.4919276128161703, 0.365990112816196, 1.951693237816211, 2.4759311585440544, 1.8937557378161731, 2.916896362816171, 1.4725994878161708, 1.4493252394425924, 2.44994323781617, 1.9648963628161713, 3.9767458506323394, 0.9429901128161706, 1.3322343750000005, 1.43034375, 1.1658000000000004, 3.988104530589112, 3.7908026128161723, 2.48733386281617, 2.472278364442592, 2.47759948781617, 1.817730225632365, 1.9406151128161713, 1.3758494878162058, 2.321635780589143, 1.4654658644425926, 3.981862227258762, 0.9685682378161702, 0.9917557378161788, 1.4874467835440548, 0.2529687500000002, 2.4760092835440557, 2.417911987816172, 3.9832614756323403, 1.4837436585440553, 1.2810057378161703, 1.4194744878161734, 1.353002355000001, 2.92430261281617, 2.472684614442593, 3.9497997272587635, 2.48081823781617, 0.6827244878161709, 1.7315526128161776, 1.9807394177729423, 2.4773026128161706, 3.1437771006323523, 3.996619460545883, 2.9501307378161705, 0.6019269177729426, 1.4715994878161704, 2.4667869878161706, 1.948349487816171, 3.980593146360226], "episode_lengths": [86, 19, 177, 98, 437, 27, 61, 41, 27, 31, 16, 647, 54, 29, 27, 17, 1280, 26, 22, 20, 14, 34, 39, 75, 20, 20, 50, 32, 47, 162, 130, 29, 81, 34, 227, 172, 34, 15, 62, 19, 33, 22, 907, 109, 14, 43, 18, 21, 385, 1280, 23, 108, 31, 30, 35, 48, 31, 45, 65, 21, 18, 16, 26, 61, 19, 18, 30, 658, 57, 1038, 560, 22, 21, 40, 364, 18, 74, 30, 58, 40, 19, 220, 70, 26, 29, 16, 41, 24, 310, 205, 17, 29, 355, 21, 52, 341, 30, 34, 46, 33], "policy_blue_reward": [-2.0199999999999987, -1.0069999999999997, -0.012000000000000004, -2.009999999999999, -1.0109999999999992, -1.0039999999999996, 0.489, -1.01, -0.012000000000000004, -1.5039999999999998, 0.5009999999999998, -1.0089999999999997, -0.003, 1.98715625, -1.0049999999999997, -2.004, -2.0169999999999995, -1.0159999999999996, -1.0099999999999991, -1.0079999999999998, -1.0089999999999997, -2.006, -1.0079999999999993, 0.19199999999999978, -2.005, -1.001, 0.4949999999999998, -1.0059999999999998, -1.507, -1.0139999999999991, -2.0159999999999987, -2.0039999999999996, -1.002, -2.005, -1.0059999999999996, -1.003, -2.0079999999999996, 0.6400625000000004, -2.005, -1.0079999999999993, -2.008, -1.557, -1.007, -1.6019999999999999, -1.0089999999999995, -2.0089999999999995, -1.0129999999999992], "policy_red_v48_reward": [0.39328360500000037], "policy_red_v8_reward": [0.831546875, 1.9349218750000001], "policy_red_v1_reward": [-2.0559999999999965, -0.008], "policy_red_v46_reward": [-1.072, -2.0169999999999995], "policy_red_v35_reward": [0.4296932378161733], "policy_red_v37_reward": [-1.003], "policy_red_v13_reward": [-2.0169999999999986, -0.019703124999984944], "policy_red_v21_reward": [1.4736932378161711], "policy_red_v43_reward": [-2.024999999999998], "policy_red_v25_reward": [-0.5390653855574077], "policy_red_v11_reward": [-0.5089999999999997, 1.46371875, -0.019000000000000006], "policy_red_v50_reward": [-1.006, 0.5036925427729418], "policy_red_v12_reward": [0.46769323781520544, 2.0239425427729447], "policy_red_v16_reward": [-0.8509499999999999, 0.473934614442593], "policy_red_v5_reward": [-2.008], "policy_red_v42_reward": [-1.033, -0.5599999999999999], "policy_red_v30_reward": [1.9785312499999999, -1.001], "policy_red_v33_reward": [-0.6829999999999986, 0.5006932378161699], "policy_red_v19_reward": [1.943765625, -0.18130676218383002], "policy_red_v28_reward": [1.8910624999999999], "policy_red_v27_reward": [-2.0119999999999996], "policy_red_v10_reward": [0.43429687500000014, -1.542], "policy_red_v23_reward": [0.501692542772942], "policy_red_v51_reward": [0.8300000000000001], "policy_red_v15_reward": [-1.0089999999999997], "policy_red_v20_reward": [-1.0479999999999952], "policy_red_v45_reward": [0.4889346144425923, -0.5569999999999999], "policy_red_v14_reward": [0.46487500000000004, -2.013999999999999, 0.49710303354405505], "policy_red_v3_reward": [-1.5259999999999994], "policy_red_v29_reward": [-1.0479999999999976, -0.5753067621838303], "policy_red_v26_reward": [0.50369323781617], "policy_red_v40_reward": [-1.006], "policy_red_v17_reward": [-1.588], "policy_red_v7_reward": [-2.0149999999999997], "policy_red_v32_reward": [1.94565625]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8123981636309797, "mean_inference_ms": 7.71909927177168, "mean_action_processing_ms": 0.29216248115261295, "mean_env_wait_ms": 0.388403441174721, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10491180419921875, "StateBufferConnector_ms": 0.004415273666381836, "ViewRequirementAgentConnector_ms": 0.12208831310272217}}, "episode_reward_max": 4.397652100632346, "episode_reward_min": 0.2529687500000002, "episode_reward_mean": 2.173608412368685, "episode_len_mean": 127.93, "episodes_this_iter": 28, "policy_reward_min": {"blue": -2.0199999999999987, "red": -0.11071639499999919, "red_v48": 0.39328360500000037, "red_v8": 0.831546875, "red_v1": -2.0559999999999965, "red_v46": -2.0169999999999995, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v13": -2.0169999999999986, "red_v21": 1.4736932378161711, "red_v43": -2.024999999999998, "red_v25": -0.5390653855574077, "red_v11": -0.5089999999999997, "red_v50": -1.006, "red_v12": 0.46769323781520544, "red_v16": -0.8509499999999999, "red_v5": -2.008, "red_v42": -1.033, "red_v30": -1.001, "red_v33": -0.6829999999999986, "red_v19": -0.18130676218383002, "red_v28": 1.8910624999999999, "red_v27": -2.0119999999999996, "red_v10": -1.542, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997, "red_v20": -1.0479999999999952, "red_v45": -0.5569999999999999, "red_v14": -2.013999999999999, "red_v3": -1.5259999999999994, "red_v29": -1.0479999999999976, "red_v26": 0.50369323781617, "red_v40": -1.006, "red_v17": -1.588, "red_v7": -2.0149999999999997, "red_v32": 1.94565625}, "policy_reward_max": {"blue": 1.98715625, "red": 3.995739417772942, "red_v48": 0.39328360500000037, "red_v8": 1.9349218750000001, "red_v1": -0.008, "red_v46": -1.072, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v13": -0.019703124999984944, "red_v21": 1.4736932378161711, "red_v43": -2.024999999999998, "red_v25": -0.5390653855574077, "red_v11": 1.46371875, "red_v50": 0.5036925427729418, "red_v12": 2.0239425427729447, "red_v16": 0.473934614442593, "red_v5": -2.008, "red_v42": -0.5599999999999999, "red_v30": 1.9785312499999999, "red_v33": 0.5006932378161699, "red_v19": 1.943765625, "red_v28": 1.8910624999999999, "red_v27": -2.0119999999999996, "red_v10": 0.43429687500000014, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997, "red_v20": -1.0479999999999952, "red_v45": 0.4889346144425923, "red_v14": 0.49710303354405505, "red_v3": -1.5259999999999994, "red_v29": -0.5753067621838303, "red_v26": 0.50369323781617, "red_v40": -1.006, "red_v17": -1.588, "red_v7": -2.0149999999999997, "red_v32": 1.94565625}, "policy_reward_mean": {"blue": -1.0462932180851061, "red": 2.791085298369654, "red_v48": 0.39328360500000037, "red_v8": 1.383234375, "red_v1": -1.0319999999999983, "red_v46": -1.5444999999999998, "red_v35": 0.4296932378161733, "red_v37": -1.003, "red_v13": -1.0183515624999917, "red_v21": 1.4736932378161711, "red_v43": -2.024999999999998, "red_v25": -0.5390653855574077, "red_v11": 0.3119062500000001, "red_v50": -0.2511537286135291, "red_v12": 1.245817890294075, "red_v16": -0.18850769277870344, "red_v5": -2.008, "red_v42": -0.7965, "red_v30": 0.488765625, "red_v33": -0.09115338109191434, "red_v19": 0.881229431408085, "red_v28": 1.8910624999999999, "red_v27": -2.0119999999999996, "red_v10": -0.5538515625, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997, "red_v20": -1.0479999999999952, "red_v45": -0.03403269277870383, "red_v14": -0.35067398881864786, "red_v3": -1.5259999999999994, "red_v29": -0.811653381091914, "red_v26": 0.50369323781617, "red_v40": -1.006, "red_v17": -1.588, "red_v7": -2.0149999999999997, "red_v32": 1.94565625}, "hist_stats": {"episode_reward": [1.425224487816172, 3.885616772772942, 1.299240112816174, 1.8637869878161752, 2.5054276128161845, 2.4817088628161703, 2.938802612816172, 1.4658651128161706, 2.9741186585440555, 2.4748963628161706, 2.4736846144425924, 2.45746460063235, 2.4547244878152044, 2.4763026128161703, 2.97470886281617, 0.9917394177729422, 1.9686932378162099, 2.47941198781617, 2.98822448781617, 2.4886300427729413, 1.8824398550000003, 1.464786292772942, 1.9612713628161713, 4.397652100632346, 2.488040533544055, 1.486630737815204, 1.4495369878161715, 2.46919323781617, 2.461646362816171, 1.2917869878152128, 3.336221602258769, 1.9763026128161703, 1.4447401128161705, 2.4757869878161705, 2.7737771006313823, 2.9878057378161778, 2.471786987816171, 1.489145667772942, 0.7564062500000035, 1.485333862815204, 2.4764901128161703, 1.98422448781617, 1.9609588628162022, 1.7190526128161765, 2.386439855, 1.9504588628161712, 1.489446783544055, 2.4919276128161703, 0.365990112816196, 1.951693237816211, 2.4759311585440544, 1.8937557378161731, 2.916896362816171, 1.4725994878161708, 1.4493252394425924, 2.44994323781617, 1.9648963628161713, 3.9767458506323394, 0.9429901128161706, 1.3322343750000005, 1.43034375, 1.1658000000000004, 3.988104530589112, 3.7908026128161723, 2.48733386281617, 2.472278364442592, 2.47759948781617, 1.817730225632365, 1.9406151128161713, 1.3758494878162058, 2.321635780589143, 1.4654658644425926, 3.981862227258762, 0.9685682378161702, 0.9917557378161788, 1.4874467835440548, 0.2529687500000002, 2.4760092835440557, 2.417911987816172, 3.9832614756323403, 1.4837436585440553, 1.2810057378161703, 1.4194744878161734, 1.353002355000001, 2.92430261281617, 2.472684614442593, 3.9497997272587635, 2.48081823781617, 0.6827244878161709, 1.7315526128161776, 1.9807394177729423, 2.4773026128161706, 3.1437771006323523, 3.996619460545883, 2.9501307378161705, 0.6019269177729426, 1.4715994878161704, 2.4667869878161706, 1.948349487816171, 3.980593146360226], "episode_lengths": [86, 19, 177, 98, 437, 27, 61, 41, 27, 31, 16, 647, 54, 29, 27, 17, 1280, 26, 22, 20, 14, 34, 39, 75, 20, 20, 50, 32, 47, 162, 130, 29, 81, 34, 227, 172, 34, 15, 62, 19, 33, 22, 907, 109, 14, 43, 18, 21, 385, 1280, 23, 108, 31, 30, 35, 48, 31, 45, 65, 21, 18, 16, 26, 61, 19, 18, 30, 658, 57, 1038, 560, 22, 21, 40, 364, 18, 74, 30, 58, 40, 19, 220, 70, 26, 29, 16, 41, 24, 310, 205, 17, 29, 355, 21, 52, 341, 30, 34, 46, 33], "policy_blue_reward": [-2.0199999999999987, -1.0069999999999997, -0.012000000000000004, -2.009999999999999, -1.0109999999999992, -1.0039999999999996, 0.489, -1.01, -0.012000000000000004, -1.5039999999999998, 0.5009999999999998, -1.0089999999999997, -0.003, 1.98715625, -1.0049999999999997, -2.004, -2.0169999999999995, -1.0159999999999996, -1.0099999999999991, -1.0079999999999998, -1.0089999999999997, -2.006, -1.0079999999999993, 0.19199999999999978, -2.005, -1.001, 0.4949999999999998, -1.0059999999999998, -1.507, -1.0139999999999991, -2.0159999999999987, -2.0039999999999996, -1.002, -2.005, -1.0059999999999996, -1.003, -2.0079999999999996, 0.6400625000000004, -2.005, -1.0079999999999993, -2.008, -1.557, -1.007, -1.6019999999999999, -1.0089999999999995, -2.0089999999999995, -1.0129999999999992], "policy_red_v48_reward": [0.39328360500000037], "policy_red_v8_reward": [0.831546875, 1.9349218750000001], "policy_red_v1_reward": [-2.0559999999999965, -0.008], "policy_red_v46_reward": [-1.072, -2.0169999999999995], "policy_red_v35_reward": [0.4296932378161733], "policy_red_v37_reward": [-1.003], "policy_red_v13_reward": [-2.0169999999999986, -0.019703124999984944], "policy_red_v21_reward": [1.4736932378161711], "policy_red_v43_reward": [-2.024999999999998], "policy_red_v25_reward": [-0.5390653855574077], "policy_red_v11_reward": [-0.5089999999999997, 1.46371875, -0.019000000000000006], "policy_red_v50_reward": [-1.006, 0.5036925427729418], "policy_red_v12_reward": [0.46769323781520544, 2.0239425427729447], "policy_red_v16_reward": [-0.8509499999999999, 0.473934614442593], "policy_red_v5_reward": [-2.008], "policy_red_v42_reward": [-1.033, -0.5599999999999999], "policy_red_v30_reward": [1.9785312499999999, -1.001], "policy_red_v33_reward": [-0.6829999999999986, 0.5006932378161699], "policy_red_v19_reward": [1.943765625, -0.18130676218383002], "policy_red_v28_reward": [1.8910624999999999], "policy_red_v27_reward": [-2.0119999999999996], "policy_red_v10_reward": [0.43429687500000014, -1.542], "policy_red_v23_reward": [0.501692542772942], "policy_red_v51_reward": [0.8300000000000001], "policy_red_v15_reward": [-1.0089999999999997], "policy_red_v20_reward": [-1.0479999999999952], "policy_red_v45_reward": [0.4889346144425923, -0.5569999999999999], "policy_red_v14_reward": [0.46487500000000004, -2.013999999999999, 0.49710303354405505], "policy_red_v3_reward": [-1.5259999999999994], "policy_red_v29_reward": [-1.0479999999999976, -0.5753067621838303], "policy_red_v26_reward": [0.50369323781617], "policy_red_v40_reward": [-1.006], "policy_red_v17_reward": [-1.588], "policy_red_v7_reward": [-2.0149999999999997], "policy_red_v32_reward": [1.94565625]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8123981636309797, "mean_inference_ms": 7.71909927177168, "mean_action_processing_ms": 0.29216248115261295, "mean_env_wait_ms": 0.388403441174721, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10491180419921875, "StateBufferConnector_ms": 0.004415273666381836, "ViewRequirementAgentConnector_ms": 0.12208831310272217}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 696000, "num_agent_steps_trained": 696000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.91380831354527, "num_env_steps_trained_throughput_per_sec": 199.91380831354527, "timesteps_total": 348000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 696000, "timers": {"training_iteration_time_ms": 19997.076, "sample_time_ms": 1145.287, "learn_time_ms": 18766.328, "learn_throughput": 213.148, "synch_weights_time_ms": 82.428}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 696000, "num_agent_steps_trained": 696000}, "done": false, "episodes_total": 1208, "training_iteration": 87, "trial_id": "a9680_00000", "date": "2023-09-24_03-07-52", "timestamp": 1695539272, "time_this_iter_s": 20.02121090888977, "time_total_s": 1735.2017133235931, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dfc2da0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1df4e4d0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1df4e560>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1735.2017133235931, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 5.2727272727272725, "ram_util_percent": 23.090909090909093}, "win_rate": 0.72, "league_size": 57}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3541731640696524, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.02588654705493051, "policy_loss": -0.051549360446612506, "vf_loss": 0.14328002700931391, "vf_explained_var": 0.7374322092160582, "kl": 0.01676753390401361, "entropy": 1.7494957067072392, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 84000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "sampler_results": {"episode_reward_max": 4.483674032215534, "episode_reward_min": -0.0994218750000001, "episode_reward_mean": 2.239592881395991, "episode_len_mean": 130.06, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"blue": -2.0159999999999987, "red": -0.11071639499999919, "red_v43": -2.024999999999998, "red_v25": -0.5390653855574077, "red_v11": -0.5089999999999997, "red_v50": -1.006, "red_v12": 0.46769323781520544, "red_v16": -0.8509499999999999, "red_v5": -2.008, "red_v42": -1.033, "red_v30": -1.001, "red_v33": -0.6829999999999986, "red_v19": -0.6450653855574078, "red_v13": -0.019703124999984944, "red_v28": 0.37228360500000035, "red_v27": -2.0119999999999996, "red_v10": -1.542, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997, "red_v8": 1.9349218750000001, "red_v20": -1.0479999999999952, "red_v45": -0.5569999999999999, "red_v14": -2.013999999999999, "red_v3": -1.5259999999999994, "red_v29": -1.0479999999999976, "red_v26": 0.50369323781617, "red_v40": -1.006, "red_v17": -1.588, "red_v7": -2.0149999999999997, "red_v32": 1.94565625, "red_v39": -1.0159999999999993, "red_v46": -1.005, "red_v18": 3.46656823781617, "red_v31": -0.5129999999999999}, "policy_reward_max": {"blue": 1.3053156250000038, "red": 3.995739417772942, "red_v43": -2.024999999999998, "red_v25": -0.5390653855574077, "red_v11": 1.46371875, "red_v50": 0.5036925427729418, "red_v12": 2.0239425427729447, "red_v16": 0.473934614442593, "red_v5": -1.0239999999999982, "red_v42": 0.48693461444259234, "red_v30": 1.9785312499999999, "red_v33": 0.5006932378161699, "red_v19": 1.943765625, "red_v13": -0.019703124999984944, "red_v28": 1.8910624999999999, "red_v27": -2.0119999999999996, "red_v10": 0.43429687500000014, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997, "red_v8": 1.9349218750000001, "red_v20": -1.0479999999999952, "red_v45": 0.4889346144425923, "red_v14": 0.49710303354405505, "red_v3": -1.5259999999999994, "red_v29": 0.5066932378161699, "red_v26": 0.50369323781617, "red_v40": 1.4899346144425925, "red_v17": 0.4936932378161699, "red_v7": -2.0149999999999997, "red_v32": 1.94565625, "red_v39": 0.6590500000000001, "red_v46": -1.005, "red_v18": 3.46656823781617, "red_v31": -0.5129999999999999}, "policy_reward_mean": {"blue": -1.0977257812499996, "red": 2.7601256142073596, "red_v43": -2.024999999999998, "red_v25": -0.5390653855574077, "red_v11": 0.3119062500000001, "red_v50": -0.2511537286135291, "red_v12": 1.245817890294075, "red_v16": -0.18850769277870344, "red_v5": -1.5159999999999991, "red_v42": -0.36868846185246923, "red_v30": 0.4930748292720568, "red_v33": -0.09115338109191434, "red_v19": 0.3724644924195874, "red_v13": -0.019703124999984944, "red_v28": 1.1316730525, "red_v27": -2.0119999999999996, "red_v10": -0.5538515625, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997, "red_v8": 1.9349218750000001, "red_v20": -1.0479999999999952, "red_v45": -0.03403269277870383, "red_v14": -0.35067398881864786, "red_v3": -1.5259999999999994, "red_v29": -0.3722045081225527, "red_v26": 0.50369323781617, "red_v40": 0.24196730722129622, "red_v17": -0.5471533810919151, "red_v7": -2.0149999999999997, "red_v32": 1.94565625, "red_v39": -0.1784749999999996, "red_v46": -1.005, "red_v18": 3.46656823781617, "red_v31": -0.5129999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.46919323781617, 2.461646362816171, 1.2917869878152128, 3.336221602258769, 1.9763026128161703, 1.4447401128161705, 2.4757869878161705, 2.7737771006313823, 2.9878057378161778, 2.471786987816171, 1.489145667772942, 0.7564062500000035, 1.485333862815204, 2.4764901128161703, 1.98422448781617, 1.9609588628162022, 1.7190526128161765, 2.386439855, 1.9504588628161712, 1.489446783544055, 2.4919276128161703, 0.365990112816196, 1.951693237816211, 2.4759311585440544, 1.8937557378161731, 2.916896362816171, 1.4725994878161708, 1.4493252394425924, 2.44994323781617, 1.9648963628161713, 3.9767458506323394, 0.9429901128161706, 1.3322343750000005, 1.43034375, 1.1658000000000004, 3.988104530589112, 3.7908026128161723, 2.48733386281617, 2.472278364442592, 2.47759948781617, 1.817730225632365, 1.9406151128161713, 1.3758494878162058, 2.321635780589143, 1.4654658644425926, 3.981862227258762, 0.9685682378161702, 0.9917557378161788, 1.4874467835440548, 0.2529687500000002, 2.4760092835440557, 2.417911987816172, 3.9832614756323403, 1.4837436585440553, 1.2810057378161703, 1.4194744878161734, 1.353002355000001, 2.92430261281617, 2.472684614442593, 3.9497997272587635, 2.48081823781617, 0.6827244878161709, 1.7315526128161776, 1.9807394177729423, 2.4773026128161706, 3.1437771006323523, 3.996619460545883, 2.9501307378161705, 0.6019269177729426, 1.4715994878161704, 2.4667869878161706, 1.948349487816171, 3.980593146360226, 1.1594744878161702, 2.47549011281617, 2.4662713628161708, 1.9839276128161702, 2.7208682378161715, 2.441693237816171, 2.961161987816171, 0.909875, 1.9519502394425936, 3.97604272563234, 1.7010088628161912, 3.99540210063234, 1.366734375, 3.9791591022587625, 1.9708963628161704, 4.483674032215534, 2.953755737816171, 3.9729646006323405, 2.447431158544055, 3.849554967816172, 1.1253807378161946, 2.4900369878152038, 3.4702614756323404, 2.661143477258804, -0.0994218750000001, 2.950349487816171, 2.431990112816172], "episode_lengths": [32, 47, 162, 130, 29, 81, 34, 227, 172, 34, 15, 62, 19, 33, 22, 907, 109, 14, 43, 18, 21, 385, 1280, 23, 108, 31, 30, 35, 48, 31, 45, 65, 21, 18, 16, 26, 61, 19, 18, 30, 658, 57, 1038, 560, 22, 21, 40, 364, 18, 74, 30, 58, 40, 19, 220, 70, 26, 29, 16, 41, 24, 310, 205, 17, 29, 355, 21, 52, 341, 30, 34, 46, 33, 326, 33, 39, 21, 600, 64, 42, 40, 27, 46, 395, 27, 53, 22, 31, 17, 44, 39, 55, 39, 804, 18, 40, 635, 39, 46, 65], "policy_blue_reward": [-1.0159999999999996, -1.0099999999999991, -1.0079999999999998, -1.0089999999999997, -2.006, -1.0079999999999993, 0.19199999999999978, -2.005, -1.001, 0.4949999999999998, -1.0059999999999998, -1.507, -1.0139999999999991, -2.0159999999999987, -2.0039999999999996, -1.002, -2.005, -1.0059999999999996, -1.003, -2.0079999999999996, 0.6400625000000004, -2.005, -1.0079999999999993, -2.008, -1.557, -1.007, -1.6019999999999999, -1.0089999999999995, -2.0089999999999995, -1.0129999999999992, -1.604, -1.0069999999999995, -1.013999999999999, -2.0069999999999997, -0.014000000000000005, -0.508, -2.0079999999999996, 1.3053156250000038, -2.0069999999999997, -0.016, -1.0149999999999988, 0.6496874999999998, -1.5110000000000001, -1.0189999999999992], "policy_red_v43_reward": [-2.024999999999998], "policy_red_v25_reward": [-0.5390653855574077], "policy_red_v11_reward": [-0.5089999999999997, 1.46371875, -0.019000000000000006], "policy_red_v50_reward": [-1.006, 0.5036925427729418], "policy_red_v12_reward": [0.46769323781520544, 2.0239425427729447], "policy_red_v16_reward": [-0.8509499999999999, 0.473934614442593], "policy_red_v5_reward": [-2.008, -1.0239999999999982], "policy_red_v42_reward": [-1.033, -0.5599999999999999, 0.48693461444259234], "policy_red_v30_reward": [1.9785312499999999, -1.001, 0.5016932378161705], "policy_red_v33_reward": [-0.6829999999999986, 0.5006932378161699], "policy_red_v19_reward": [1.943765625, -0.18130676218383002, -0.6450653855574078], "policy_red_v13_reward": [-0.019703124999984944], "policy_red_v28_reward": [1.8910624999999999, 0.37228360500000035], "policy_red_v27_reward": [-2.0119999999999996], "policy_red_v10_reward": [0.43429687500000014, -1.542], "policy_red_v23_reward": [0.501692542772942], "policy_red_v51_reward": [0.8300000000000001], "policy_red_v15_reward": [-1.0089999999999997], "policy_red_v8_reward": [1.9349218750000001], "policy_red_v20_reward": [-1.0479999999999952], "policy_red_v45_reward": [0.4889346144425923, -0.5569999999999999], "policy_red_v14_reward": [0.46487500000000004, -2.013999999999999, 0.49710303354405505], "policy_red_v3_reward": [-1.5259999999999994], "policy_red_v29_reward": [-1.0479999999999976, -0.5753067621838303, 0.5066932378161699], "policy_red_v26_reward": [0.50369323781617], "policy_red_v40_reward": [-1.006, 1.4899346144425925], "policy_red_v17_reward": [-1.588, 0.4936932378161699], "policy_red_v7_reward": [-2.0149999999999997], "policy_red_v32_reward": [1.94565625], "policy_red_v39_reward": [0.6590500000000001, -1.0159999999999993], "policy_red_v46_reward": [-1.005], "policy_red_v18_reward": [3.46656823781617], "policy_red_v31_reward": [-0.5129999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8121328310686805, "mean_inference_ms": 7.721869011038312, "mean_action_processing_ms": 0.292470251953908, "mean_env_wait_ms": 0.388417077053192, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10191905498504639, "StateBufferConnector_ms": 0.004292130470275879, "ViewRequirementAgentConnector_ms": 0.11928427219390869}}, "episode_reward_max": 4.483674032215534, "episode_reward_min": -0.0994218750000001, "episode_reward_mean": 2.239592881395991, "episode_len_mean": 130.06, "episodes_this_iter": 27, "policy_reward_min": {"blue": -2.0159999999999987, "red": -0.11071639499999919, "red_v43": -2.024999999999998, "red_v25": -0.5390653855574077, "red_v11": -0.5089999999999997, "red_v50": -1.006, "red_v12": 0.46769323781520544, "red_v16": -0.8509499999999999, "red_v5": -2.008, "red_v42": -1.033, "red_v30": -1.001, "red_v33": -0.6829999999999986, "red_v19": -0.6450653855574078, "red_v13": -0.019703124999984944, "red_v28": 0.37228360500000035, "red_v27": -2.0119999999999996, "red_v10": -1.542, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997, "red_v8": 1.9349218750000001, "red_v20": -1.0479999999999952, "red_v45": -0.5569999999999999, "red_v14": -2.013999999999999, "red_v3": -1.5259999999999994, "red_v29": -1.0479999999999976, "red_v26": 0.50369323781617, "red_v40": -1.006, "red_v17": -1.588, "red_v7": -2.0149999999999997, "red_v32": 1.94565625, "red_v39": -1.0159999999999993, "red_v46": -1.005, "red_v18": 3.46656823781617, "red_v31": -0.5129999999999999}, "policy_reward_max": {"blue": 1.3053156250000038, "red": 3.995739417772942, "red_v43": -2.024999999999998, "red_v25": -0.5390653855574077, "red_v11": 1.46371875, "red_v50": 0.5036925427729418, "red_v12": 2.0239425427729447, "red_v16": 0.473934614442593, "red_v5": -1.0239999999999982, "red_v42": 0.48693461444259234, "red_v30": 1.9785312499999999, "red_v33": 0.5006932378161699, "red_v19": 1.943765625, "red_v13": -0.019703124999984944, "red_v28": 1.8910624999999999, "red_v27": -2.0119999999999996, "red_v10": 0.43429687500000014, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997, "red_v8": 1.9349218750000001, "red_v20": -1.0479999999999952, "red_v45": 0.4889346144425923, "red_v14": 0.49710303354405505, "red_v3": -1.5259999999999994, "red_v29": 0.5066932378161699, "red_v26": 0.50369323781617, "red_v40": 1.4899346144425925, "red_v17": 0.4936932378161699, "red_v7": -2.0149999999999997, "red_v32": 1.94565625, "red_v39": 0.6590500000000001, "red_v46": -1.005, "red_v18": 3.46656823781617, "red_v31": -0.5129999999999999}, "policy_reward_mean": {"blue": -1.0977257812499996, "red": 2.7601256142073596, "red_v43": -2.024999999999998, "red_v25": -0.5390653855574077, "red_v11": 0.3119062500000001, "red_v50": -0.2511537286135291, "red_v12": 1.245817890294075, "red_v16": -0.18850769277870344, "red_v5": -1.5159999999999991, "red_v42": -0.36868846185246923, "red_v30": 0.4930748292720568, "red_v33": -0.09115338109191434, "red_v19": 0.3724644924195874, "red_v13": -0.019703124999984944, "red_v28": 1.1316730525, "red_v27": -2.0119999999999996, "red_v10": -0.5538515625, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997, "red_v8": 1.9349218750000001, "red_v20": -1.0479999999999952, "red_v45": -0.03403269277870383, "red_v14": -0.35067398881864786, "red_v3": -1.5259999999999994, "red_v29": -0.3722045081225527, "red_v26": 0.50369323781617, "red_v40": 0.24196730722129622, "red_v17": -0.5471533810919151, "red_v7": -2.0149999999999997, "red_v32": 1.94565625, "red_v39": -0.1784749999999996, "red_v46": -1.005, "red_v18": 3.46656823781617, "red_v31": -0.5129999999999999}, "hist_stats": {"episode_reward": [2.46919323781617, 2.461646362816171, 1.2917869878152128, 3.336221602258769, 1.9763026128161703, 1.4447401128161705, 2.4757869878161705, 2.7737771006313823, 2.9878057378161778, 2.471786987816171, 1.489145667772942, 0.7564062500000035, 1.485333862815204, 2.4764901128161703, 1.98422448781617, 1.9609588628162022, 1.7190526128161765, 2.386439855, 1.9504588628161712, 1.489446783544055, 2.4919276128161703, 0.365990112816196, 1.951693237816211, 2.4759311585440544, 1.8937557378161731, 2.916896362816171, 1.4725994878161708, 1.4493252394425924, 2.44994323781617, 1.9648963628161713, 3.9767458506323394, 0.9429901128161706, 1.3322343750000005, 1.43034375, 1.1658000000000004, 3.988104530589112, 3.7908026128161723, 2.48733386281617, 2.472278364442592, 2.47759948781617, 1.817730225632365, 1.9406151128161713, 1.3758494878162058, 2.321635780589143, 1.4654658644425926, 3.981862227258762, 0.9685682378161702, 0.9917557378161788, 1.4874467835440548, 0.2529687500000002, 2.4760092835440557, 2.417911987816172, 3.9832614756323403, 1.4837436585440553, 1.2810057378161703, 1.4194744878161734, 1.353002355000001, 2.92430261281617, 2.472684614442593, 3.9497997272587635, 2.48081823781617, 0.6827244878161709, 1.7315526128161776, 1.9807394177729423, 2.4773026128161706, 3.1437771006323523, 3.996619460545883, 2.9501307378161705, 0.6019269177729426, 1.4715994878161704, 2.4667869878161706, 1.948349487816171, 3.980593146360226, 1.1594744878161702, 2.47549011281617, 2.4662713628161708, 1.9839276128161702, 2.7208682378161715, 2.441693237816171, 2.961161987816171, 0.909875, 1.9519502394425936, 3.97604272563234, 1.7010088628161912, 3.99540210063234, 1.366734375, 3.9791591022587625, 1.9708963628161704, 4.483674032215534, 2.953755737816171, 3.9729646006323405, 2.447431158544055, 3.849554967816172, 1.1253807378161946, 2.4900369878152038, 3.4702614756323404, 2.661143477258804, -0.0994218750000001, 2.950349487816171, 2.431990112816172], "episode_lengths": [32, 47, 162, 130, 29, 81, 34, 227, 172, 34, 15, 62, 19, 33, 22, 907, 109, 14, 43, 18, 21, 385, 1280, 23, 108, 31, 30, 35, 48, 31, 45, 65, 21, 18, 16, 26, 61, 19, 18, 30, 658, 57, 1038, 560, 22, 21, 40, 364, 18, 74, 30, 58, 40, 19, 220, 70, 26, 29, 16, 41, 24, 310, 205, 17, 29, 355, 21, 52, 341, 30, 34, 46, 33, 326, 33, 39, 21, 600, 64, 42, 40, 27, 46, 395, 27, 53, 22, 31, 17, 44, 39, 55, 39, 804, 18, 40, 635, 39, 46, 65], "policy_blue_reward": [-1.0159999999999996, -1.0099999999999991, -1.0079999999999998, -1.0089999999999997, -2.006, -1.0079999999999993, 0.19199999999999978, -2.005, -1.001, 0.4949999999999998, -1.0059999999999998, -1.507, -1.0139999999999991, -2.0159999999999987, -2.0039999999999996, -1.002, -2.005, -1.0059999999999996, -1.003, -2.0079999999999996, 0.6400625000000004, -2.005, -1.0079999999999993, -2.008, -1.557, -1.007, -1.6019999999999999, -1.0089999999999995, -2.0089999999999995, -1.0129999999999992, -1.604, -1.0069999999999995, -1.013999999999999, -2.0069999999999997, -0.014000000000000005, -0.508, -2.0079999999999996, 1.3053156250000038, -2.0069999999999997, -0.016, -1.0149999999999988, 0.6496874999999998, -1.5110000000000001, -1.0189999999999992], "policy_red_v43_reward": [-2.024999999999998], "policy_red_v25_reward": [-0.5390653855574077], "policy_red_v11_reward": [-0.5089999999999997, 1.46371875, -0.019000000000000006], "policy_red_v50_reward": [-1.006, 0.5036925427729418], "policy_red_v12_reward": [0.46769323781520544, 2.0239425427729447], "policy_red_v16_reward": [-0.8509499999999999, 0.473934614442593], "policy_red_v5_reward": [-2.008, -1.0239999999999982], "policy_red_v42_reward": [-1.033, -0.5599999999999999, 0.48693461444259234], "policy_red_v30_reward": [1.9785312499999999, -1.001, 0.5016932378161705], "policy_red_v33_reward": [-0.6829999999999986, 0.5006932378161699], "policy_red_v19_reward": [1.943765625, -0.18130676218383002, -0.6450653855574078], "policy_red_v13_reward": [-0.019703124999984944], "policy_red_v28_reward": [1.8910624999999999, 0.37228360500000035], "policy_red_v27_reward": [-2.0119999999999996], "policy_red_v10_reward": [0.43429687500000014, -1.542], "policy_red_v23_reward": [0.501692542772942], "policy_red_v51_reward": [0.8300000000000001], "policy_red_v15_reward": [-1.0089999999999997], "policy_red_v8_reward": [1.9349218750000001], "policy_red_v20_reward": [-1.0479999999999952], "policy_red_v45_reward": [0.4889346144425923, -0.5569999999999999], "policy_red_v14_reward": [0.46487500000000004, -2.013999999999999, 0.49710303354405505], "policy_red_v3_reward": [-1.5259999999999994], "policy_red_v29_reward": [-1.0479999999999976, -0.5753067621838303, 0.5066932378161699], "policy_red_v26_reward": [0.50369323781617], "policy_red_v40_reward": [-1.006, 1.4899346144425925], "policy_red_v17_reward": [-1.588, 0.4936932378161699], "policy_red_v7_reward": [-2.0149999999999997], "policy_red_v32_reward": [1.94565625], "policy_red_v39_reward": [0.6590500000000001, -1.0159999999999993], "policy_red_v46_reward": [-1.005], "policy_red_v18_reward": [3.46656823781617], "policy_red_v31_reward": [-0.5129999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8121328310686805, "mean_inference_ms": 7.721869011038312, "mean_action_processing_ms": 0.292470251953908, "mean_env_wait_ms": 0.388417077053192, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10191905498504639, "StateBufferConnector_ms": 0.004292130470275879, "ViewRequirementAgentConnector_ms": 0.11928427219390869}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 197.160919314381, "num_env_steps_trained_throughput_per_sec": 197.160919314381, "timesteps_total": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 20025.943, "sample_time_ms": 1152.297, "learn_time_ms": 18789.561, "learn_throughput": 212.884, "synch_weights_time_ms": 81.118}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "episodes_total": 1235, "training_iteration": 88, "trial_id": "a9680_00000", "date": "2023-09-24_03-08-16", "timestamp": 1695539296, "time_this_iter_s": 20.29861617088318, "time_total_s": 1755.5003294944763, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1df3d540>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1df4f640>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1df4edd0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1755.5003294944763, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 5.442424242424242, "ram_util_percent": 23.190909090909088}, "win_rate": 0.69, "league_size": 58}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.531048416222135, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.012971963185555069, "policy_loss": -0.04378557395248208, "vf_loss": 0.10080087739430989, "vf_explained_var": 0.7916249398762981, "kl": 0.017991060939330814, "entropy": 1.7388789039105177, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 84960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 712000, "num_agent_steps_trained": 712000}, "sampler_results": {"episode_reward_max": 4.483674032215534, "episode_reward_min": -0.0994218750000001, "episode_reward_mean": 2.3273302970645475, "episode_len_mean": 134.81, "episode_media": {}, "episodes_this_iter": 23, "policy_reward_min": {"blue": -2.021, "red": -0.11071639499999919, "red_v28": 0.08005000000000817, "red_v42": -0.5599999999999999, "red_v27": -2.0119999999999996, "red_v33": 0.5006932378161699, "red_v10": -1.542, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997, "red_v19": -0.6450653855574078, "red_v8": 1.9349218750000001, "red_v20": -1.0479999999999952, "red_v12": 2.0239425427729447, "red_v45": -0.5569999999999999, "red_v14": -2.013999999999999, "red_v3": -1.5259999999999994, "red_v29": -1.0479999999999976, "red_v26": 0.50369323781617, "red_v11": -0.019000000000000006, "red_v40": -2.029999999999998, "red_v16": -0.1549999999999997, "red_v17": -1.588, "red_v7": -2.0149999999999997, "red_v50": -0.5183074572270582, "red_v32": 1.94565625, "red_v39": -1.0159999999999993, "red_v30": 0.5016932378161705, "red_v5": -1.0239999999999982, "red_v46": -1.005, "red_v18": 3.46656823781617, "red_v31": -0.5129999999999999, "red_v49": 0.38928360500000025, "red_v52": -2.0289999999999977}, "policy_reward_max": {"blue": 1.3053156250000038, "red": 3.995739417772942, "red_v28": 1.8910624999999999, "red_v42": 0.48693461444259234, "red_v27": 0.4946925427729421, "red_v33": 0.5006932378161699, "red_v10": 0.48769323781617013, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997, "red_v19": -0.18130676218383002, "red_v8": 1.9349218750000001, "red_v20": -1.0479999999999952, "red_v12": 2.0239425427729447, "red_v45": 0.4889346144425923, "red_v14": 1.8304119878161718, "red_v3": -1.5259999999999994, "red_v29": 0.5066932378161699, "red_v26": 0.50369323781617, "red_v11": 1.46371875, "red_v40": 1.4899346144425925, "red_v16": 0.473934614442593, "red_v17": 0.4936932378161699, "red_v7": -2.0149999999999997, "red_v50": 0.5036925427729418, "red_v32": 1.94565625, "red_v39": 0.6590500000000001, "red_v30": 0.5016932378161705, "red_v5": 0.3978281250000002, "red_v46": -1.005, "red_v18": 3.46656823781617, "red_v31": -0.5129999999999999, "red_v49": 3.836821783544061, "red_v52": -2.0289999999999977}, "policy_reward_mean": {"blue": -1.1139657155813947, "red": 2.7634330568449474, "red_v28": 0.7811320350000027, "red_v42": -0.0365326927787038, "red_v27": -0.7586537286135288, "red_v33": 0.5006932378161699, "red_v10": -0.20666996239460997, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997, "red_v19": -0.4131860738706189, "red_v8": 1.9349218750000001, "red_v20": -1.0479999999999952, "red_v12": 2.0239425427729447, "red_v45": -0.03403269277870383, "red_v14": 0.2542166518352797, "red_v3": -1.5259999999999994, "red_v29": -0.3722045081225527, "red_v26": 0.50369323781617, "red_v11": 0.722359375, "red_v40": -0.8917663463893509, "red_v16": 0.15946730722129665, "red_v17": -0.5471533810919151, "red_v7": -2.0149999999999997, "red_v50": -0.007307457227058167, "red_v32": 1.94565625, "red_v39": -0.1784749999999996, "red_v30": 0.5016932378161705, "red_v5": -0.313085937499999, "red_v46": -1.005, "red_v18": 3.46656823781617, "red_v31": -0.5129999999999999, "red_v49": 1.909599542120077, "red_v52": -2.0289999999999977}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.4759311585440544, 1.8937557378161731, 2.916896362816171, 1.4725994878161708, 1.4493252394425924, 2.44994323781617, 1.9648963628161713, 3.9767458506323394, 0.9429901128161706, 1.3322343750000005, 1.43034375, 1.1658000000000004, 3.988104530589112, 3.7908026128161723, 2.48733386281617, 2.472278364442592, 2.47759948781617, 1.817730225632365, 1.9406151128161713, 1.3758494878162058, 2.321635780589143, 1.4654658644425926, 3.981862227258762, 0.9685682378161702, 0.9917557378161788, 1.4874467835440548, 0.2529687500000002, 2.4760092835440557, 2.417911987816172, 3.9832614756323403, 1.4837436585440553, 1.2810057378161703, 1.4194744878161734, 1.353002355000001, 2.92430261281617, 2.472684614442593, 3.9497997272587635, 2.48081823781617, 0.6827244878161709, 1.7315526128161776, 1.9807394177729423, 2.4773026128161706, 3.1437771006323523, 3.996619460545883, 2.9501307378161705, 0.6019269177729426, 1.4715994878161704, 2.4667869878161706, 1.948349487816171, 3.980593146360226, 1.1594744878161702, 2.47549011281617, 2.4662713628161708, 1.9839276128161702, 2.7208682378161715, 2.441693237816171, 2.961161987816171, 0.909875, 1.9519502394425936, 3.97604272563234, 1.7010088628161912, 3.99540210063234, 1.366734375, 3.9791591022587625, 1.9708963628161704, 4.483674032215534, 2.953755737816171, 3.9729646006323405, 2.447431158544055, 3.849554967816172, 1.1253807378161946, 2.4900369878152038, 3.4702614756323404, 2.661143477258804, -0.0994218750000001, 2.950349487816171, 2.431990112816172, 2.4349768428162166, 0.9015213628161702, 4.4710114756323405, 3.9480896006323416, 3.835648717816172, 3.839515021360231, 0.23181823781616973, 3.95863647563234, 2.280105225632352, 3.229033605000001, 2.469380737816171, 1.8795994878152096, 1.4350526128161727, 3.9597451555891126, 1.4706846144425925, 1.4184744878161726, 2.4206807378161836, 2.828901405589122, 0.2617244878161772, 2.4553494878161715, 1.3098338628161752, 2.47941198781617, 1.4511619878161712], "episode_lengths": [23, 108, 31, 30, 35, 48, 31, 45, 65, 21, 18, 16, 26, 61, 19, 18, 30, 658, 57, 1038, 560, 22, 21, 40, 364, 18, 74, 30, 58, 40, 19, 220, 70, 26, 29, 16, 41, 24, 310, 205, 17, 29, 355, 21, 52, 341, 30, 34, 46, 33, 326, 33, 39, 21, 600, 64, 42, 40, 27, 46, 395, 27, 53, 22, 31, 17, 44, 39, 55, 39, 804, 18, 40, 635, 39, 46, 65, 1280, 87, 56, 63, 73, 154, 728, 48, 154, 16, 36, 94, 45, 45, 16, 70, 212, 123, 758, 46, 179, 26, 42], "policy_blue_reward": [-1.0059999999999998, -1.507, -1.0139999999999991, -2.0159999999999987, -2.0039999999999996, -1.002, -2.005, -1.0059999999999996, -1.003, -2.0079999999999996, 0.6400625000000004, -2.005, -1.0079999999999993, -2.008, -1.557, -1.007, -1.6019999999999999, -1.0089999999999995, -2.0089999999999995, -1.0129999999999992, -1.604, -1.0069999999999995, -1.013999999999999, -2.0069999999999997, -0.014000000000000005, -0.508, -2.0079999999999996, 1.3053156250000038, -2.0069999999999997, -0.016, -1.0149999999999988, 0.6496874999999998, -1.5110000000000001, -1.0189999999999992, 1.0402836050000104, -0.1968749999999999, -1.0089999999999995, -2.0089999999999995, -1.2000000000000002, -1.0149999999999988, -1.557, -1.0089999999999992, -2.021], "policy_red_v28_reward": [1.8910624999999999, 0.37228360500000035, 0.08005000000000817], "policy_red_v42_reward": [-0.5599999999999999, 0.48693461444259234], "policy_red_v27_reward": [-2.0119999999999996, 0.4946925427729421], "policy_red_v33_reward": [0.5006932378161699], "policy_red_v10_reward": [0.43429687500000014, -1.542, 0.48769323781617013], "policy_red_v23_reward": [0.501692542772942], "policy_red_v51_reward": [0.8300000000000001], "policy_red_v15_reward": [-1.0089999999999997], "policy_red_v19_reward": [-0.18130676218383002, -0.6450653855574078], "policy_red_v8_reward": [1.9349218750000001], "policy_red_v20_reward": [-1.0479999999999952], "policy_red_v12_reward": [2.0239425427729447], "policy_red_v45_reward": [0.4889346144425923, -0.5569999999999999], "policy_red_v14_reward": [0.46487500000000004, -2.013999999999999, 0.49710303354405505, 0.49269323781617036, 1.8304119878161718], "policy_red_v3_reward": [-1.5259999999999994], "policy_red_v29_reward": [-1.0479999999999976, -0.5753067621838303, 0.5066932378161699], "policy_red_v26_reward": [0.50369323781617], "policy_red_v11_reward": [1.46371875, -0.019000000000000006], "policy_red_v40_reward": [-1.006, 1.4899346144425925, -2.020999999999998, -2.029999999999998], "policy_red_v16_reward": [0.473934614442593, -0.1549999999999997], "policy_red_v17_reward": [-1.588, 0.4936932378161699], "policy_red_v7_reward": [-2.0149999999999997], "policy_red_v50_reward": [0.5036925427729418, -0.5183074572270582], "policy_red_v32_reward": [1.94565625], "policy_red_v39_reward": [0.6590500000000001, -1.0159999999999993], "policy_red_v30_reward": [0.5016932378161705], "policy_red_v5_reward": [-1.0239999999999982, 0.3978281250000002], "policy_red_v46_reward": [-1.005], "policy_red_v18_reward": [3.46656823781617], "policy_red_v31_reward": [-0.5129999999999999], "policy_red_v49_reward": [1.5026932378161706, 0.38928360500000025, 3.836821783544061], "policy_red_v52_reward": [-2.0289999999999977]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8114935869231964, "mean_inference_ms": 7.706765051742369, "mean_action_processing_ms": 0.2923378957536125, "mean_env_wait_ms": 0.38806772318153704, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10084199905395508, "StateBufferConnector_ms": 0.004201292991638184, "ViewRequirementAgentConnector_ms": 0.11703717708587646}}, "episode_reward_max": 4.483674032215534, "episode_reward_min": -0.0994218750000001, "episode_reward_mean": 2.3273302970645475, "episode_len_mean": 134.81, "episodes_this_iter": 23, "policy_reward_min": {"blue": -2.021, "red": -0.11071639499999919, "red_v28": 0.08005000000000817, "red_v42": -0.5599999999999999, "red_v27": -2.0119999999999996, "red_v33": 0.5006932378161699, "red_v10": -1.542, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997, "red_v19": -0.6450653855574078, "red_v8": 1.9349218750000001, "red_v20": -1.0479999999999952, "red_v12": 2.0239425427729447, "red_v45": -0.5569999999999999, "red_v14": -2.013999999999999, "red_v3": -1.5259999999999994, "red_v29": -1.0479999999999976, "red_v26": 0.50369323781617, "red_v11": -0.019000000000000006, "red_v40": -2.029999999999998, "red_v16": -0.1549999999999997, "red_v17": -1.588, "red_v7": -2.0149999999999997, "red_v50": -0.5183074572270582, "red_v32": 1.94565625, "red_v39": -1.0159999999999993, "red_v30": 0.5016932378161705, "red_v5": -1.0239999999999982, "red_v46": -1.005, "red_v18": 3.46656823781617, "red_v31": -0.5129999999999999, "red_v49": 0.38928360500000025, "red_v52": -2.0289999999999977}, "policy_reward_max": {"blue": 1.3053156250000038, "red": 3.995739417772942, "red_v28": 1.8910624999999999, "red_v42": 0.48693461444259234, "red_v27": 0.4946925427729421, "red_v33": 0.5006932378161699, "red_v10": 0.48769323781617013, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997, "red_v19": -0.18130676218383002, "red_v8": 1.9349218750000001, "red_v20": -1.0479999999999952, "red_v12": 2.0239425427729447, "red_v45": 0.4889346144425923, "red_v14": 1.8304119878161718, "red_v3": -1.5259999999999994, "red_v29": 0.5066932378161699, "red_v26": 0.50369323781617, "red_v11": 1.46371875, "red_v40": 1.4899346144425925, "red_v16": 0.473934614442593, "red_v17": 0.4936932378161699, "red_v7": -2.0149999999999997, "red_v50": 0.5036925427729418, "red_v32": 1.94565625, "red_v39": 0.6590500000000001, "red_v30": 0.5016932378161705, "red_v5": 0.3978281250000002, "red_v46": -1.005, "red_v18": 3.46656823781617, "red_v31": -0.5129999999999999, "red_v49": 3.836821783544061, "red_v52": -2.0289999999999977}, "policy_reward_mean": {"blue": -1.1139657155813947, "red": 2.7634330568449474, "red_v28": 0.7811320350000027, "red_v42": -0.0365326927787038, "red_v27": -0.7586537286135288, "red_v33": 0.5006932378161699, "red_v10": -0.20666996239460997, "red_v23": 0.501692542772942, "red_v51": 0.8300000000000001, "red_v15": -1.0089999999999997, "red_v19": -0.4131860738706189, "red_v8": 1.9349218750000001, "red_v20": -1.0479999999999952, "red_v12": 2.0239425427729447, "red_v45": -0.03403269277870383, "red_v14": 0.2542166518352797, "red_v3": -1.5259999999999994, "red_v29": -0.3722045081225527, "red_v26": 0.50369323781617, "red_v11": 0.722359375, "red_v40": -0.8917663463893509, "red_v16": 0.15946730722129665, "red_v17": -0.5471533810919151, "red_v7": -2.0149999999999997, "red_v50": -0.007307457227058167, "red_v32": 1.94565625, "red_v39": -0.1784749999999996, "red_v30": 0.5016932378161705, "red_v5": -0.313085937499999, "red_v46": -1.005, "red_v18": 3.46656823781617, "red_v31": -0.5129999999999999, "red_v49": 1.909599542120077, "red_v52": -2.0289999999999977}, "hist_stats": {"episode_reward": [2.4759311585440544, 1.8937557378161731, 2.916896362816171, 1.4725994878161708, 1.4493252394425924, 2.44994323781617, 1.9648963628161713, 3.9767458506323394, 0.9429901128161706, 1.3322343750000005, 1.43034375, 1.1658000000000004, 3.988104530589112, 3.7908026128161723, 2.48733386281617, 2.472278364442592, 2.47759948781617, 1.817730225632365, 1.9406151128161713, 1.3758494878162058, 2.321635780589143, 1.4654658644425926, 3.981862227258762, 0.9685682378161702, 0.9917557378161788, 1.4874467835440548, 0.2529687500000002, 2.4760092835440557, 2.417911987816172, 3.9832614756323403, 1.4837436585440553, 1.2810057378161703, 1.4194744878161734, 1.353002355000001, 2.92430261281617, 2.472684614442593, 3.9497997272587635, 2.48081823781617, 0.6827244878161709, 1.7315526128161776, 1.9807394177729423, 2.4773026128161706, 3.1437771006323523, 3.996619460545883, 2.9501307378161705, 0.6019269177729426, 1.4715994878161704, 2.4667869878161706, 1.948349487816171, 3.980593146360226, 1.1594744878161702, 2.47549011281617, 2.4662713628161708, 1.9839276128161702, 2.7208682378161715, 2.441693237816171, 2.961161987816171, 0.909875, 1.9519502394425936, 3.97604272563234, 1.7010088628161912, 3.99540210063234, 1.366734375, 3.9791591022587625, 1.9708963628161704, 4.483674032215534, 2.953755737816171, 3.9729646006323405, 2.447431158544055, 3.849554967816172, 1.1253807378161946, 2.4900369878152038, 3.4702614756323404, 2.661143477258804, -0.0994218750000001, 2.950349487816171, 2.431990112816172, 2.4349768428162166, 0.9015213628161702, 4.4710114756323405, 3.9480896006323416, 3.835648717816172, 3.839515021360231, 0.23181823781616973, 3.95863647563234, 2.280105225632352, 3.229033605000001, 2.469380737816171, 1.8795994878152096, 1.4350526128161727, 3.9597451555891126, 1.4706846144425925, 1.4184744878161726, 2.4206807378161836, 2.828901405589122, 0.2617244878161772, 2.4553494878161715, 1.3098338628161752, 2.47941198781617, 1.4511619878161712], "episode_lengths": [23, 108, 31, 30, 35, 48, 31, 45, 65, 21, 18, 16, 26, 61, 19, 18, 30, 658, 57, 1038, 560, 22, 21, 40, 364, 18, 74, 30, 58, 40, 19, 220, 70, 26, 29, 16, 41, 24, 310, 205, 17, 29, 355, 21, 52, 341, 30, 34, 46, 33, 326, 33, 39, 21, 600, 64, 42, 40, 27, 46, 395, 27, 53, 22, 31, 17, 44, 39, 55, 39, 804, 18, 40, 635, 39, 46, 65, 1280, 87, 56, 63, 73, 154, 728, 48, 154, 16, 36, 94, 45, 45, 16, 70, 212, 123, 758, 46, 179, 26, 42], "policy_blue_reward": [-1.0059999999999998, -1.507, -1.0139999999999991, -2.0159999999999987, -2.0039999999999996, -1.002, -2.005, -1.0059999999999996, -1.003, -2.0079999999999996, 0.6400625000000004, -2.005, -1.0079999999999993, -2.008, -1.557, -1.007, -1.6019999999999999, -1.0089999999999995, -2.0089999999999995, -1.0129999999999992, -1.604, -1.0069999999999995, -1.013999999999999, -2.0069999999999997, -0.014000000000000005, -0.508, -2.0079999999999996, 1.3053156250000038, -2.0069999999999997, -0.016, -1.0149999999999988, 0.6496874999999998, -1.5110000000000001, -1.0189999999999992, 1.0402836050000104, -0.1968749999999999, -1.0089999999999995, -2.0089999999999995, -1.2000000000000002, -1.0149999999999988, -1.557, -1.0089999999999992, -2.021], "policy_red_v28_reward": [1.8910624999999999, 0.37228360500000035, 0.08005000000000817], "policy_red_v42_reward": [-0.5599999999999999, 0.48693461444259234], "policy_red_v27_reward": [-2.0119999999999996, 0.4946925427729421], "policy_red_v33_reward": [0.5006932378161699], "policy_red_v10_reward": [0.43429687500000014, -1.542, 0.48769323781617013], "policy_red_v23_reward": [0.501692542772942], "policy_red_v51_reward": [0.8300000000000001], "policy_red_v15_reward": [-1.0089999999999997], "policy_red_v19_reward": [-0.18130676218383002, -0.6450653855574078], "policy_red_v8_reward": [1.9349218750000001], "policy_red_v20_reward": [-1.0479999999999952], "policy_red_v12_reward": [2.0239425427729447], "policy_red_v45_reward": [0.4889346144425923, -0.5569999999999999], "policy_red_v14_reward": [0.46487500000000004, -2.013999999999999, 0.49710303354405505, 0.49269323781617036, 1.8304119878161718], "policy_red_v3_reward": [-1.5259999999999994], "policy_red_v29_reward": [-1.0479999999999976, -0.5753067621838303, 0.5066932378161699], "policy_red_v26_reward": [0.50369323781617], "policy_red_v11_reward": [1.46371875, -0.019000000000000006], "policy_red_v40_reward": [-1.006, 1.4899346144425925, -2.020999999999998, -2.029999999999998], "policy_red_v16_reward": [0.473934614442593, -0.1549999999999997], "policy_red_v17_reward": [-1.588, 0.4936932378161699], "policy_red_v7_reward": [-2.0149999999999997], "policy_red_v50_reward": [0.5036925427729418, -0.5183074572270582], "policy_red_v32_reward": [1.94565625], "policy_red_v39_reward": [0.6590500000000001, -1.0159999999999993], "policy_red_v30_reward": [0.5016932378161705], "policy_red_v5_reward": [-1.0239999999999982, 0.3978281250000002], "policy_red_v46_reward": [-1.005], "policy_red_v18_reward": [3.46656823781617], "policy_red_v31_reward": [-0.5129999999999999], "policy_red_v49_reward": [1.5026932378161706, 0.38928360500000025, 3.836821783544061], "policy_red_v52_reward": [-2.0289999999999977]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8114935869231964, "mean_inference_ms": 7.706765051742369, "mean_action_processing_ms": 0.2923378957536125, "mean_env_wait_ms": 0.38806772318153704, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10084199905395508, "StateBufferConnector_ms": 0.004201292991638184, "ViewRequirementAgentConnector_ms": 0.11703717708587646}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 712000, "num_agent_steps_trained": 712000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 198.03401976924664, "num_env_steps_trained_throughput_per_sec": 198.03401976924664, "timesteps_total": 356000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 712000, "timers": {"training_iteration_time_ms": 20034.33, "sample_time_ms": 1151.098, "learn_time_ms": 18797.659, "learn_throughput": 212.792, "synch_weights_time_ms": 82.59}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 712000, "num_agent_steps_trained": 712000}, "done": false, "episodes_total": 1258, "training_iteration": 89, "trial_id": "a9680_00000", "date": "2023-09-24_03-08-40", "timestamp": 1695539320, "time_this_iter_s": 20.208873748779297, "time_total_s": 1775.7092032432556, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dfc30a0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1df985e0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1df98670>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1775.7092032432556, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 5.1499999999999995, "ram_util_percent": 23.370588235294118}, "win_rate": 0.64, "league_size": 58}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.48355696250995, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.04149858734599547, "policy_loss": -0.04714487400148452, "vf_loss": 0.16606631189739954, "vf_explained_var": 0.8130987310782075, "kl": 0.01618400471932849, "entropy": 1.6724968607227007, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 85920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "sampler_results": {"episode_reward_max": 4.483674032215534, "episode_reward_min": -0.0994218750000001, "episode_reward_mean": 2.3222807365774027, "episode_len_mean": 150.73, "episode_media": {}, "episodes_this_iter": 45, "policy_reward_min": {"red_v10": -1.542, "red": -0.0013074572270574958, "blue": -2.021, "red_v32": 1.94565625, "red_v14": -2.017999999999999, "red_v39": -1.0159999999999993, "red_v30": 0.2893125, "red_v29": 0.5066932378161699, "red_v5": -1.0929999999999922, "red_v42": -0.14800000000000002, "red_v40": -2.029999999999998, "red_v17": 0.4936932378161699, "red_v28": 0.08005000000000817, "red_v46": -1.005, "red_v18": 1.718818237816179, "red_v19": -0.6450653855574078, "red_v31": -0.5129999999999999, "red_v49": 0.38928360500000025, "red_v16": -0.1549999999999997, "red_v27": 0.4946925427729421, "red_v52": -2.0289999999999977, "red_v50": -0.5183074572270582, "red_v12": -2.0109999999999992, "red_v34": -1.1709999999999907, "red_v8": -2.0119999999999996, "red_v38": -1.0079999999999998, "red_v11": -1.516, "red_v1": -2.01, "red_v4": -1.0069999999999997, "red_v54": 0.4876932378161708, "red_v26": -1.009, "red_v53": 0.17705000000000004, "red_v47": 3.1438156250000007, "red_v56": -0.5549999999999998, "red_v13": -0.006}, "policy_reward_max": {"red_v10": 0.48769323781617013, "red": 3.9933331677729416, "blue": 1.3053156250000038, "red_v32": 1.94565625, "red_v14": 1.8304119878161718, "red_v39": 0.6590500000000001, "red_v30": 0.5016932378161705, "red_v29": 0.5066932378161699, "red_v5": 0.3978281250000002, "red_v42": 0.48693461444259234, "red_v40": 1.4899346144425925, "red_v17": 0.4936932378161699, "red_v28": 0.37228360500000035, "red_v46": 0.5036925427729417, "red_v18": 3.46656823781617, "red_v19": -0.6450653855574078, "red_v31": -0.5129999999999999, "red_v49": 3.836821783544061, "red_v16": -0.1549999999999997, "red_v27": 0.4946925427729421, "red_v52": -2.0289999999999977, "red_v50": -0.5183074572270582, "red_v12": -2.0109999999999992, "red_v34": -1.1709999999999907, "red_v8": -1.0109999999999997, "red_v38": -1.0079999999999998, "red_v11": -0.17499999999999993, "red_v1": -2.01, "red_v4": -1.0069999999999997, "red_v54": 0.4876932378161708, "red_v26": -1.009, "red_v53": 0.17705000000000004, "red_v47": 3.1438156250000007, "red_v56": -0.5549999999999998, "red_v13": -0.006}, "policy_reward_mean": {"red_v10": -0.40501419054595733, "red": 2.8565304355084367, "blue": -1.0896012671111097, "red_v32": 1.94565625, "red_v14": 0.2005520647940996, "red_v39": -0.1784749999999996, "red_v30": 0.3955028689080852, "red_v29": 0.5066932378161699, "red_v5": -0.6830429687499973, "red_v42": 0.16946730722129616, "red_v40": -0.8536884618524679, "red_v17": 0.4936932378161699, "red_v28": 0.22616680250000426, "red_v46": -0.10641915240901934, "red_v18": 2.5926932378161744, "red_v19": -0.6450653855574078, "red_v31": -0.5129999999999999, "red_v49": 1.909599542120077, "red_v16": -0.1549999999999997, "red_v27": 0.4946925427729421, "red_v52": -2.0289999999999977, "red_v50": -0.5183074572270582, "red_v12": -2.0109999999999992, "red_v34": -1.1709999999999907, "red_v8": -1.5114999999999996, "red_v38": -1.0079999999999998, "red_v11": -0.8454999999999999, "red_v1": -2.01, "red_v4": -1.0069999999999997, "red_v54": 0.4876932378161708, "red_v26": -1.009, "red_v53": 0.17705000000000004, "red_v47": 3.1438156250000007, "red_v56": -0.5549999999999998, "red_v13": -0.006}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.6019269177729426, 1.4715994878161704, 2.4667869878161706, 1.948349487816171, 3.980593146360226, 1.1594744878161702, 2.47549011281617, 2.4662713628161708, 1.9839276128161702, 2.7208682378161715, 2.441693237816171, 2.961161987816171, 0.909875, 1.9519502394425936, 3.97604272563234, 1.7010088628161912, 3.99540210063234, 1.366734375, 3.9791591022587625, 1.9708963628161704, 4.483674032215534, 2.953755737816171, 3.9729646006323405, 2.447431158544055, 3.849554967816172, 1.1253807378161946, 2.4900369878152038, 3.4702614756323404, 2.661143477258804, -0.0994218750000001, 2.950349487816171, 2.431990112816172, 2.4349768428162166, 0.9015213628161702, 4.4710114756323405, 3.9480896006323416, 3.835648717816172, 3.839515021360231, 0.23181823781616973, 3.95863647563234, 2.280105225632352, 3.229033605000001, 2.469380737816171, 1.8795994878152096, 1.4350526128161727, 3.9597451555891126, 1.4706846144425925, 1.4184744878161726, 2.4206807378161836, 2.828901405589122, 0.2617244878161772, 2.4553494878161715, 1.3098338628161752, 2.47941198781617, 1.4511619878161712, 1.6702244878161783, 1.4687088628161709, 2.1367401128161845, 2.4803026128161703, 1.9618721144425926, 2.480817542772942, 2.4054119878161733, 1.446240112816172, 2.15839375, 1.8125838628162012, 1.4728963628161704, 3.2964588628161713, 0.9534276128161698, 1.983333167772942, 2.020511475632378, 3.34122448781617, 2.4501619878161716, 2.4551619878161706, 2.4682783644425923, 1.4828182378161703, 2.4632783644425924, 2.461568237816171, 2.45927136281617, 1.1362713628161698, 3.9361364756323414, 2.4758217835440552, 2.46378698781617, 3.6512189894425924, 1.055021362816201, 3.1425081677729434, 3.6735713628161704, 1.486743658544055, 2.4784119878161706, 0.949943237816171, 2.4665682378161704, 0.7430057378161701, 3.990698280589112, 1.3800526128162174, 2.93230261281617, 1.4702783644425925, 0.3506932378161707, 1.4567557378161715, 2.4581619878161707, 1.975005737816171, 2.9887394177729414], "episode_lengths": [341, 30, 34, 46, 33, 326, 33, 39, 21, 600, 64, 42, 40, 27, 46, 395, 27, 53, 22, 31, 17, 44, 39, 55, 39, 804, 18, 40, 635, 39, 46, 65, 1280, 87, 56, 63, 73, 154, 728, 48, 154, 16, 36, 94, 45, 45, 16, 70, 212, 123, 758, 46, 179, 26, 42, 278, 27, 209, 29, 20, 24, 90, 49, 18, 515, 31, 43, 53, 19, 920, 22, 42, 42, 18, 24, 18, 40, 39, 359, 80, 26, 34, 21, 887, 43, 23, 19, 26, 48, 40, 220, 28, 749, 29, 18, 1280, 44, 42, 28, 17], "policy_red_v10_reward": [-1.542, 0.48769323781617013, -1.0139999999999998, 0.44825000000000026], "policy_blue_reward": [-2.0089999999999995, -1.0129999999999992, -1.604, -1.0069999999999995, -1.013999999999999, -2.0069999999999997, -0.014000000000000005, -0.508, -2.0079999999999996, 1.3053156250000038, -2.0069999999999997, -0.016, -1.0149999999999988, 0.6496874999999998, -1.5110000000000001, -1.0189999999999992, 1.0402836050000104, -0.1968749999999999, -1.0089999999999995, -2.0089999999999995, -1.2000000000000002, -1.0149999999999988, -1.557, -1.0089999999999992, -2.021, 1.1705312500000038, -1.0069999999999997, -1.0059999999999998, -1.0269999999999977, -2.0119999999999996, -1.1279999999999886, -2.0089999999999995, -1.0139999999999991, -1.0149999999999988, -2.0069999999999997, -1.0139999999999996, -1.6139999999999999, -1.0069999999999997, -1.2800000000000002, -2.005, -1.0099999999999991, -1.246999999999977, -2.0049999999999994, -1.0159999999999987, -2.0059999999999993], "policy_red_v32_reward": [1.94565625], "policy_red_v14_reward": [0.49710303354405505, 0.49269323781617036, 1.8304119878161718, -2.017999999999999], "policy_red_v39_reward": [0.6590500000000001, -1.0159999999999993], "policy_red_v30_reward": [0.5016932378161705, 0.2893125], "policy_red_v29_reward": [0.5066932378161699], "policy_red_v5_reward": [-1.0239999999999982, 0.3978281250000002, -1.012999999999999, -1.0929999999999922], "policy_red_v42_reward": [0.48693461444259234, -0.14800000000000002], "policy_red_v40_reward": [1.4899346144425925, -2.020999999999998, -2.029999999999998], "policy_red_v17_reward": [0.4936932378161699], "policy_red_v28_reward": [0.37228360500000035, 0.08005000000000817], "policy_red_v46_reward": [-1.005, 0.18205000000000016, 0.5036925427729417], "policy_red_v18_reward": [3.46656823781617, 1.718818237816179], "policy_red_v19_reward": [-0.6450653855574078], "policy_red_v31_reward": [-0.5129999999999999], "policy_red_v49_reward": [1.5026932378161706, 0.38928360500000025, 3.836821783544061], "policy_red_v16_reward": [-0.1549999999999997], "policy_red_v27_reward": [0.4946925427729421], "policy_red_v52_reward": [-2.0289999999999977], "policy_red_v50_reward": [-0.5183074572270582], "policy_red_v12_reward": [-2.0109999999999992], "policy_red_v34_reward": [-1.1709999999999907], "policy_red_v8_reward": [-2.0119999999999996, -1.0109999999999997], "policy_red_v38_reward": [-1.0079999999999998], "policy_red_v11_reward": [-0.17499999999999993, -1.516], "policy_red_v1_reward": [-2.01], "policy_red_v4_reward": [-1.0069999999999997], "policy_red_v54_reward": [0.4876932378161708], "policy_red_v26_reward": [-1.009], "policy_red_v53_reward": [0.17705000000000004], "policy_red_v47_reward": [3.1438156250000007], "policy_red_v56_reward": [-0.5549999999999998], "policy_red_v13_reward": [-0.006]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8122804325099723, "mean_inference_ms": 7.7071260531380394, "mean_action_processing_ms": 0.2926947710794585, "mean_env_wait_ms": 0.38810176764899057, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10486257076263428, "StateBufferConnector_ms": 0.004338622093200684, "ViewRequirementAgentConnector_ms": 0.120827317237854}}, "episode_reward_max": 4.483674032215534, "episode_reward_min": -0.0994218750000001, "episode_reward_mean": 2.3222807365774027, "episode_len_mean": 150.73, "episodes_this_iter": 45, "policy_reward_min": {"red_v10": -1.542, "red": -0.0013074572270574958, "blue": -2.021, "red_v32": 1.94565625, "red_v14": -2.017999999999999, "red_v39": -1.0159999999999993, "red_v30": 0.2893125, "red_v29": 0.5066932378161699, "red_v5": -1.0929999999999922, "red_v42": -0.14800000000000002, "red_v40": -2.029999999999998, "red_v17": 0.4936932378161699, "red_v28": 0.08005000000000817, "red_v46": -1.005, "red_v18": 1.718818237816179, "red_v19": -0.6450653855574078, "red_v31": -0.5129999999999999, "red_v49": 0.38928360500000025, "red_v16": -0.1549999999999997, "red_v27": 0.4946925427729421, "red_v52": -2.0289999999999977, "red_v50": -0.5183074572270582, "red_v12": -2.0109999999999992, "red_v34": -1.1709999999999907, "red_v8": -2.0119999999999996, "red_v38": -1.0079999999999998, "red_v11": -1.516, "red_v1": -2.01, "red_v4": -1.0069999999999997, "red_v54": 0.4876932378161708, "red_v26": -1.009, "red_v53": 0.17705000000000004, "red_v47": 3.1438156250000007, "red_v56": -0.5549999999999998, "red_v13": -0.006}, "policy_reward_max": {"red_v10": 0.48769323781617013, "red": 3.9933331677729416, "blue": 1.3053156250000038, "red_v32": 1.94565625, "red_v14": 1.8304119878161718, "red_v39": 0.6590500000000001, "red_v30": 0.5016932378161705, "red_v29": 0.5066932378161699, "red_v5": 0.3978281250000002, "red_v42": 0.48693461444259234, "red_v40": 1.4899346144425925, "red_v17": 0.4936932378161699, "red_v28": 0.37228360500000035, "red_v46": 0.5036925427729417, "red_v18": 3.46656823781617, "red_v19": -0.6450653855574078, "red_v31": -0.5129999999999999, "red_v49": 3.836821783544061, "red_v16": -0.1549999999999997, "red_v27": 0.4946925427729421, "red_v52": -2.0289999999999977, "red_v50": -0.5183074572270582, "red_v12": -2.0109999999999992, "red_v34": -1.1709999999999907, "red_v8": -1.0109999999999997, "red_v38": -1.0079999999999998, "red_v11": -0.17499999999999993, "red_v1": -2.01, "red_v4": -1.0069999999999997, "red_v54": 0.4876932378161708, "red_v26": -1.009, "red_v53": 0.17705000000000004, "red_v47": 3.1438156250000007, "red_v56": -0.5549999999999998, "red_v13": -0.006}, "policy_reward_mean": {"red_v10": -0.40501419054595733, "red": 2.8565304355084367, "blue": -1.0896012671111097, "red_v32": 1.94565625, "red_v14": 0.2005520647940996, "red_v39": -0.1784749999999996, "red_v30": 0.3955028689080852, "red_v29": 0.5066932378161699, "red_v5": -0.6830429687499973, "red_v42": 0.16946730722129616, "red_v40": -0.8536884618524679, "red_v17": 0.4936932378161699, "red_v28": 0.22616680250000426, "red_v46": -0.10641915240901934, "red_v18": 2.5926932378161744, "red_v19": -0.6450653855574078, "red_v31": -0.5129999999999999, "red_v49": 1.909599542120077, "red_v16": -0.1549999999999997, "red_v27": 0.4946925427729421, "red_v52": -2.0289999999999977, "red_v50": -0.5183074572270582, "red_v12": -2.0109999999999992, "red_v34": -1.1709999999999907, "red_v8": -1.5114999999999996, "red_v38": -1.0079999999999998, "red_v11": -0.8454999999999999, "red_v1": -2.01, "red_v4": -1.0069999999999997, "red_v54": 0.4876932378161708, "red_v26": -1.009, "red_v53": 0.17705000000000004, "red_v47": 3.1438156250000007, "red_v56": -0.5549999999999998, "red_v13": -0.006}, "hist_stats": {"episode_reward": [0.6019269177729426, 1.4715994878161704, 2.4667869878161706, 1.948349487816171, 3.980593146360226, 1.1594744878161702, 2.47549011281617, 2.4662713628161708, 1.9839276128161702, 2.7208682378161715, 2.441693237816171, 2.961161987816171, 0.909875, 1.9519502394425936, 3.97604272563234, 1.7010088628161912, 3.99540210063234, 1.366734375, 3.9791591022587625, 1.9708963628161704, 4.483674032215534, 2.953755737816171, 3.9729646006323405, 2.447431158544055, 3.849554967816172, 1.1253807378161946, 2.4900369878152038, 3.4702614756323404, 2.661143477258804, -0.0994218750000001, 2.950349487816171, 2.431990112816172, 2.4349768428162166, 0.9015213628161702, 4.4710114756323405, 3.9480896006323416, 3.835648717816172, 3.839515021360231, 0.23181823781616973, 3.95863647563234, 2.280105225632352, 3.229033605000001, 2.469380737816171, 1.8795994878152096, 1.4350526128161727, 3.9597451555891126, 1.4706846144425925, 1.4184744878161726, 2.4206807378161836, 2.828901405589122, 0.2617244878161772, 2.4553494878161715, 1.3098338628161752, 2.47941198781617, 1.4511619878161712, 1.6702244878161783, 1.4687088628161709, 2.1367401128161845, 2.4803026128161703, 1.9618721144425926, 2.480817542772942, 2.4054119878161733, 1.446240112816172, 2.15839375, 1.8125838628162012, 1.4728963628161704, 3.2964588628161713, 0.9534276128161698, 1.983333167772942, 2.020511475632378, 3.34122448781617, 2.4501619878161716, 2.4551619878161706, 2.4682783644425923, 1.4828182378161703, 2.4632783644425924, 2.461568237816171, 2.45927136281617, 1.1362713628161698, 3.9361364756323414, 2.4758217835440552, 2.46378698781617, 3.6512189894425924, 1.055021362816201, 3.1425081677729434, 3.6735713628161704, 1.486743658544055, 2.4784119878161706, 0.949943237816171, 2.4665682378161704, 0.7430057378161701, 3.990698280589112, 1.3800526128162174, 2.93230261281617, 1.4702783644425925, 0.3506932378161707, 1.4567557378161715, 2.4581619878161707, 1.975005737816171, 2.9887394177729414], "episode_lengths": [341, 30, 34, 46, 33, 326, 33, 39, 21, 600, 64, 42, 40, 27, 46, 395, 27, 53, 22, 31, 17, 44, 39, 55, 39, 804, 18, 40, 635, 39, 46, 65, 1280, 87, 56, 63, 73, 154, 728, 48, 154, 16, 36, 94, 45, 45, 16, 70, 212, 123, 758, 46, 179, 26, 42, 278, 27, 209, 29, 20, 24, 90, 49, 18, 515, 31, 43, 53, 19, 920, 22, 42, 42, 18, 24, 18, 40, 39, 359, 80, 26, 34, 21, 887, 43, 23, 19, 26, 48, 40, 220, 28, 749, 29, 18, 1280, 44, 42, 28, 17], "policy_red_v10_reward": [-1.542, 0.48769323781617013, -1.0139999999999998, 0.44825000000000026], "policy_blue_reward": [-2.0089999999999995, -1.0129999999999992, -1.604, -1.0069999999999995, -1.013999999999999, -2.0069999999999997, -0.014000000000000005, -0.508, -2.0079999999999996, 1.3053156250000038, -2.0069999999999997, -0.016, -1.0149999999999988, 0.6496874999999998, -1.5110000000000001, -1.0189999999999992, 1.0402836050000104, -0.1968749999999999, -1.0089999999999995, -2.0089999999999995, -1.2000000000000002, -1.0149999999999988, -1.557, -1.0089999999999992, -2.021, 1.1705312500000038, -1.0069999999999997, -1.0059999999999998, -1.0269999999999977, -2.0119999999999996, -1.1279999999999886, -2.0089999999999995, -1.0139999999999991, -1.0149999999999988, -2.0069999999999997, -1.0139999999999996, -1.6139999999999999, -1.0069999999999997, -1.2800000000000002, -2.005, -1.0099999999999991, -1.246999999999977, -2.0049999999999994, -1.0159999999999987, -2.0059999999999993], "policy_red_v32_reward": [1.94565625], "policy_red_v14_reward": [0.49710303354405505, 0.49269323781617036, 1.8304119878161718, -2.017999999999999], "policy_red_v39_reward": [0.6590500000000001, -1.0159999999999993], "policy_red_v30_reward": [0.5016932378161705, 0.2893125], "policy_red_v29_reward": [0.5066932378161699], "policy_red_v5_reward": [-1.0239999999999982, 0.3978281250000002, -1.012999999999999, -1.0929999999999922], "policy_red_v42_reward": [0.48693461444259234, -0.14800000000000002], "policy_red_v40_reward": [1.4899346144425925, -2.020999999999998, -2.029999999999998], "policy_red_v17_reward": [0.4936932378161699], "policy_red_v28_reward": [0.37228360500000035, 0.08005000000000817], "policy_red_v46_reward": [-1.005, 0.18205000000000016, 0.5036925427729417], "policy_red_v18_reward": [3.46656823781617, 1.718818237816179], "policy_red_v19_reward": [-0.6450653855574078], "policy_red_v31_reward": [-0.5129999999999999], "policy_red_v49_reward": [1.5026932378161706, 0.38928360500000025, 3.836821783544061], "policy_red_v16_reward": [-0.1549999999999997], "policy_red_v27_reward": [0.4946925427729421], "policy_red_v52_reward": [-2.0289999999999977], "policy_red_v50_reward": [-0.5183074572270582], "policy_red_v12_reward": [-2.0109999999999992], "policy_red_v34_reward": [-1.1709999999999907], "policy_red_v8_reward": [-2.0119999999999996, -1.0109999999999997], "policy_red_v38_reward": [-1.0079999999999998], "policy_red_v11_reward": [-0.17499999999999993, -1.516], "policy_red_v1_reward": [-2.01], "policy_red_v4_reward": [-1.0069999999999997], "policy_red_v54_reward": [0.4876932378161708], "policy_red_v26_reward": [-1.009], "policy_red_v53_reward": [0.17705000000000004], "policy_red_v47_reward": [3.1438156250000007], "policy_red_v56_reward": [-0.5549999999999998], "policy_red_v13_reward": [-0.006]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8122804325099723, "mean_inference_ms": 7.7071260531380394, "mean_action_processing_ms": 0.2926947710794585, "mean_env_wait_ms": 0.38810176764899057, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10486257076263428, "StateBufferConnector_ms": 0.004338622093200684, "ViewRequirementAgentConnector_ms": 0.120827317237854}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 196.02846328889953, "num_env_steps_trained_throughput_per_sec": 196.02846328889953, "timesteps_total": 360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 20054.619, "sample_time_ms": 1159.05, "learn_time_ms": 18809.596, "learn_throughput": 212.657, "synch_weights_time_ms": 82.915}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "episodes_total": 1303, "training_iteration": 90, "trial_id": "a9680_00000", "date": "2023-09-24_03-09-00", "timestamp": 1695539340, "time_this_iter_s": 20.415525197982788, "time_total_s": 1796.1247284412384, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1de49d20>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1df99000>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1df99090>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1796.1247284412384, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 5.048275862068966, "ram_util_percent": 23.393103448275852}, "win_rate": 0.69, "league_size": 59}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6001323999216157, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.040882330769575974, "policy_loss": -0.042503840137214866, "vf_loss": 0.15537286816785734, "vf_explained_var": 0.8516132830331723, "kl": 0.01620413181595571, "entropy": 1.5921220352252325, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 86880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 728000, "num_agent_steps_trained": 728000}, "sampler_results": {"episode_reward_max": 3.990698280589112, "episode_reward_min": -0.5296874999999998, "episode_reward_mean": 2.2037784119319674, "episode_len_mean": 124.28, "episode_media": {}, "episodes_this_iter": 45, "policy_reward_min": {"red_v27": 0.4946925427729421, "red": -1.0049999999999997, "blue": -2.021, "red_v52": -2.0289999999999977, "red_v28": 0.08005000000000817, "red_v50": -0.5183074572270582, "red_v12": -2.0109999999999992, "red_v34": -1.1709999999999907, "red_v8": -2.0119999999999996, "red_v38": -1.0079999999999998, "red_v11": -2.012999999999999, "red_v1": -2.01, "red_v18": 1.718818237816179, "red_v42": -0.14800000000000002, "red_v4": -1.0069999999999997, "red_v10": -1.0139999999999998, "red_v54": 0.4876932378161708, "red_v26": -1.009, "red_v53": 0.17705000000000004, "red_v47": -2.0069999999999997, "red_v46": -1.0029999999999997, "red_v5": -1.0929999999999922, "red_v30": 0.2893125, "red_v56": -0.5549999999999998, "red_v14": -2.017999999999999, "red_v13": -0.006, "red_v32": 0.18005000000000004, "red_v2": -0.02900000000000002, "red_v45": -0.556, "red_v23": -2.025999999999998, "red_v51": 0.5016932378161698, "red_v29": -2.0139999999999993, "red_v36": -1.505, "red_v6": 0.41967187500000014, "red_v21": 0.44, "red_v7": -2.001, "red_v3": 0.4956932378161708}, "policy_reward_max": {"red_v27": 0.4946925427729421, "red": 3.9933331677729416, "blue": 1.1705312500000038, "red_v52": -2.0289999999999977, "red_v28": 0.08005000000000817, "red_v50": 1.7967869878161782, "red_v12": 0.4719346144425924, "red_v34": -1.1709999999999907, "red_v8": -1.0109999999999997, "red_v38": -1.0079999999999998, "red_v11": -0.17499999999999993, "red_v1": -2.006, "red_v18": 1.718818237816179, "red_v42": -0.14800000000000002, "red_v4": -1.0069999999999997, "red_v10": 0.44825000000000026, "red_v54": 0.4876932378161708, "red_v26": 0.48569323781617024, "red_v53": 0.17705000000000004, "red_v47": 3.1438156250000007, "red_v46": 0.5036925427729417, "red_v5": -1.012999999999999, "red_v30": 0.2893125, "red_v56": -0.5549999999999998, "red_v14": -2.017999999999999, "red_v13": -0.006, "red_v32": 0.18005000000000004, "red_v2": -0.02900000000000002, "red_v45": 2.349765625, "red_v23": -2.025999999999998, "red_v51": 0.5016932378161698, "red_v29": -2.0139999999999993, "red_v36": -1.505, "red_v6": 0.41967187500000014, "red_v21": 0.44, "red_v7": -2.001, "red_v3": 0.4956932378161708}, "policy_reward_mean": {"red_v27": 0.4946925427729421, "red": 3.03221898160723, "blue": -1.206849260243694, "red_v52": -2.0289999999999977, "red_v28": 0.08005000000000817, "red_v50": 0.6392397652945601, "red_v12": -0.6873551285191355, "red_v34": -1.1709999999999907, "red_v8": -1.5114999999999996, "red_v38": -1.0079999999999998, "red_v11": -1.2346666666666664, "red_v1": -2.008, "red_v18": 1.718818237816179, "red_v42": -0.14800000000000002, "red_v4": -1.0069999999999997, "red_v10": -0.28287499999999977, "red_v54": 0.4876932378161708, "red_v26": -0.22810225406127657, "red_v53": 0.17705000000000004, "red_v47": 0.5684078125000005, "red_v46": -0.10575248574235259, "red_v5": -1.0529999999999955, "red_v30": 0.2893125, "red_v56": -0.5549999999999998, "red_v14": -2.017999999999999, "red_v13": -0.006, "red_v32": 0.18005000000000004, "red_v2": -0.02900000000000002, "red_v45": 0.8968828124999999, "red_v23": -2.025999999999998, "red_v51": 0.5016932378161698, "red_v29": -2.0139999999999993, "red_v36": -1.505, "red_v6": 0.41967187500000014, "red_v21": 0.44, "red_v7": -2.001, "red_v3": 0.4956932378161708}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.9597451555891126, 1.4706846144425925, 1.4184744878161726, 2.4206807378161836, 2.828901405589122, 0.2617244878161772, 2.4553494878161715, 1.3098338628161752, 2.47941198781617, 1.4511619878161712, 1.6702244878161783, 1.4687088628161709, 2.1367401128161845, 2.4803026128161703, 1.9618721144425926, 2.480817542772942, 2.4054119878161733, 1.446240112816172, 2.15839375, 1.8125838628162012, 1.4728963628161704, 3.2964588628161713, 0.9534276128161698, 1.983333167772942, 2.020511475632378, 3.34122448781617, 2.4501619878161716, 2.4551619878161706, 2.4682783644425923, 1.4828182378161703, 2.4632783644425924, 2.461568237816171, 2.45927136281617, 1.1362713628161698, 3.9361364756323414, 2.4758217835440552, 2.46378698781617, 3.6512189894425924, 1.055021362816201, 3.1425081677729434, 3.6735713628161704, 1.486743658544055, 2.4784119878161706, 0.949943237816171, 2.4665682378161704, 0.7430057378161701, 3.990698280589112, 1.3800526128162174, 2.93230261281617, 1.4702783644425925, 0.3506932378161707, 1.4567557378161715, 2.4581619878161707, 1.975005737816171, 2.9887394177729414, 2.261480225632365, 2.159284375, 3.5619742300000006, 2.944130737816172, 2.887661987816176, 2.4736846144425924, 2.3574588628161726, 2.471677612816171, 2.92449011281617, 2.4492471144425925, 1.985036987815204, 2.4649744878161703, 1.441943237816172, 3.98588647563234, 1.4724119878161706, 1.8450492300000019, 3.9505028522587633, 0.87020886281617, 2.4711932378161707, 3.307833862816172, 0.9801932378161702, 2.479490112816171, 1.47941198781617, 2.4285526128161723, 0.8089744878162173, 0.8963651128161731, 3.4203807378161706, 1.459427612816171, 2.4664588628161703, 2.4494588628161718, -0.5296874999999998, 2.451536987816171, 2.485040533544055, 3.952120850632342, 2.4757081677729422, 2.9735994878161707, 1.48781823781617, 2.4658721144425924, 1.471786987816171, 1.4638721144425926, 3.97618335063234, 2.4584588628161717, 2.0909958506314092, 1.9772244878152043, 1.9751144177729423], "episode_lengths": [45, 16, 70, 212, 123, 758, 46, 179, 26, 42, 278, 27, 209, 29, 20, 24, 90, 49, 18, 515, 31, 43, 53, 19, 920, 22, 42, 42, 18, 24, 18, 40, 39, 359, 80, 26, 34, 21, 887, 43, 23, 19, 26, 48, 40, 220, 28, 749, 29, 18, 1280, 44, 42, 28, 17, 738, 21, 19, 52, 74, 16, 107, 37, 33, 28, 18, 38, 48, 32, 26, 43, 40, 123, 32, 51, 32, 33, 26, 77, 1126, 73, 36, 53, 43, 43, 28, 50, 20, 53, 27, 30, 24, 20, 34, 20, 33, 43, 733, 22, 25], "policy_red_v27_reward": [0.4946925427729421], "policy_blue_reward": [-2.0089999999999995, -1.2000000000000002, -1.0149999999999988, -1.557, -1.0089999999999992, -2.021, 1.1705312500000038, -1.0069999999999997, -1.0059999999999998, -1.0269999999999977, -2.0119999999999996, -1.1279999999999886, -2.0089999999999995, -1.0139999999999991, -1.0149999999999988, -2.0069999999999997, -1.0139999999999996, -1.6139999999999999, -1.0069999999999997, -1.2800000000000002, -2.005, -1.0099999999999991, -1.246999999999977, -2.0049999999999994, -1.0159999999999987, -2.0059999999999993, -1.0039999999999998, -1.005, -1.0099999999999991, -1.0099999999999998, -2.0079999999999996, -1.0139999999999991, -2.0119999999999996, -1.5349999999999997, -1.0119999999999993, -1.0179999999999991, -1.3049999999999722, -1.0099999999999996, -1.014999999999999, 0.4753125, -1.017, -1.0079999999999996, -1.0059999999999998, -0.009000000000000001, -1.0059999999999996, -2.007999999999999, -2.0069999999999997, -1.0099999999999996, 0.29069323781521406, -2.01], "policy_red_v52_reward": [-2.0289999999999977], "policy_red_v28_reward": [0.08005000000000817], "policy_red_v50_reward": [-0.5183074572270582, 1.7967869878161782], "policy_red_v12_reward": [-2.0109999999999992, -0.5229999999999995, 0.4719346144425924], "policy_red_v34_reward": [-1.1709999999999907], "policy_red_v8_reward": [-2.0119999999999996, -1.0109999999999997], "policy_red_v38_reward": [-1.0079999999999998], "policy_red_v11_reward": [-0.17499999999999993, -1.516, -2.012999999999999], "policy_red_v1_reward": [-2.01, -2.006], "policy_red_v18_reward": [1.718818237816179], "policy_red_v42_reward": [-0.14800000000000002], "policy_red_v4_reward": [-1.0069999999999997], "policy_red_v10_reward": [-1.0139999999999998, 0.44825000000000026], "policy_red_v54_reward": [0.4876932378161708], "policy_red_v26_reward": [-1.009, -0.16099999999999992, 0.48569323781617024], "policy_red_v53_reward": [0.17705000000000004], "policy_red_v47_reward": [3.1438156250000007, -2.0069999999999997], "policy_red_v46_reward": [0.18205000000000016, 0.5036925427729417, -1.0029999999999997], "policy_red_v5_reward": [-1.012999999999999, -1.0929999999999922], "policy_red_v30_reward": [0.2893125], "policy_red_v56_reward": [-0.5549999999999998], "policy_red_v14_reward": [-2.017999999999999], "policy_red_v13_reward": [-0.006], "policy_red_v32_reward": [0.18005000000000004], "policy_red_v2_reward": [-0.02900000000000002], "policy_red_v45_reward": [2.349765625, -0.556], "policy_red_v23_reward": [-2.025999999999998], "policy_red_v51_reward": [0.5016932378161698], "policy_red_v29_reward": [-2.0139999999999993], "policy_red_v36_reward": [-1.505], "policy_red_v6_reward": [0.41967187500000014], "policy_red_v21_reward": [0.44], "policy_red_v7_reward": [-2.001], "policy_red_v3_reward": [0.4956932378161708]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8120676154157361, "mean_inference_ms": 7.696509807256016, "mean_action_processing_ms": 0.2924331179443131, "mean_env_wait_ms": 0.38790635745019936, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10580503940582275, "StateBufferConnector_ms": 0.0043833255767822266, "ViewRequirementAgentConnector_ms": 0.12137854099273682}}, "episode_reward_max": 3.990698280589112, "episode_reward_min": -0.5296874999999998, "episode_reward_mean": 2.2037784119319674, "episode_len_mean": 124.28, "episodes_this_iter": 45, "policy_reward_min": {"red_v27": 0.4946925427729421, "red": -1.0049999999999997, "blue": -2.021, "red_v52": -2.0289999999999977, "red_v28": 0.08005000000000817, "red_v50": -0.5183074572270582, "red_v12": -2.0109999999999992, "red_v34": -1.1709999999999907, "red_v8": -2.0119999999999996, "red_v38": -1.0079999999999998, "red_v11": -2.012999999999999, "red_v1": -2.01, "red_v18": 1.718818237816179, "red_v42": -0.14800000000000002, "red_v4": -1.0069999999999997, "red_v10": -1.0139999999999998, "red_v54": 0.4876932378161708, "red_v26": -1.009, "red_v53": 0.17705000000000004, "red_v47": -2.0069999999999997, "red_v46": -1.0029999999999997, "red_v5": -1.0929999999999922, "red_v30": 0.2893125, "red_v56": -0.5549999999999998, "red_v14": -2.017999999999999, "red_v13": -0.006, "red_v32": 0.18005000000000004, "red_v2": -0.02900000000000002, "red_v45": -0.556, "red_v23": -2.025999999999998, "red_v51": 0.5016932378161698, "red_v29": -2.0139999999999993, "red_v36": -1.505, "red_v6": 0.41967187500000014, "red_v21": 0.44, "red_v7": -2.001, "red_v3": 0.4956932378161708}, "policy_reward_max": {"red_v27": 0.4946925427729421, "red": 3.9933331677729416, "blue": 1.1705312500000038, "red_v52": -2.0289999999999977, "red_v28": 0.08005000000000817, "red_v50": 1.7967869878161782, "red_v12": 0.4719346144425924, "red_v34": -1.1709999999999907, "red_v8": -1.0109999999999997, "red_v38": -1.0079999999999998, "red_v11": -0.17499999999999993, "red_v1": -2.006, "red_v18": 1.718818237816179, "red_v42": -0.14800000000000002, "red_v4": -1.0069999999999997, "red_v10": 0.44825000000000026, "red_v54": 0.4876932378161708, "red_v26": 0.48569323781617024, "red_v53": 0.17705000000000004, "red_v47": 3.1438156250000007, "red_v46": 0.5036925427729417, "red_v5": -1.012999999999999, "red_v30": 0.2893125, "red_v56": -0.5549999999999998, "red_v14": -2.017999999999999, "red_v13": -0.006, "red_v32": 0.18005000000000004, "red_v2": -0.02900000000000002, "red_v45": 2.349765625, "red_v23": -2.025999999999998, "red_v51": 0.5016932378161698, "red_v29": -2.0139999999999993, "red_v36": -1.505, "red_v6": 0.41967187500000014, "red_v21": 0.44, "red_v7": -2.001, "red_v3": 0.4956932378161708}, "policy_reward_mean": {"red_v27": 0.4946925427729421, "red": 3.03221898160723, "blue": -1.206849260243694, "red_v52": -2.0289999999999977, "red_v28": 0.08005000000000817, "red_v50": 0.6392397652945601, "red_v12": -0.6873551285191355, "red_v34": -1.1709999999999907, "red_v8": -1.5114999999999996, "red_v38": -1.0079999999999998, "red_v11": -1.2346666666666664, "red_v1": -2.008, "red_v18": 1.718818237816179, "red_v42": -0.14800000000000002, "red_v4": -1.0069999999999997, "red_v10": -0.28287499999999977, "red_v54": 0.4876932378161708, "red_v26": -0.22810225406127657, "red_v53": 0.17705000000000004, "red_v47": 0.5684078125000005, "red_v46": -0.10575248574235259, "red_v5": -1.0529999999999955, "red_v30": 0.2893125, "red_v56": -0.5549999999999998, "red_v14": -2.017999999999999, "red_v13": -0.006, "red_v32": 0.18005000000000004, "red_v2": -0.02900000000000002, "red_v45": 0.8968828124999999, "red_v23": -2.025999999999998, "red_v51": 0.5016932378161698, "red_v29": -2.0139999999999993, "red_v36": -1.505, "red_v6": 0.41967187500000014, "red_v21": 0.44, "red_v7": -2.001, "red_v3": 0.4956932378161708}, "hist_stats": {"episode_reward": [3.9597451555891126, 1.4706846144425925, 1.4184744878161726, 2.4206807378161836, 2.828901405589122, 0.2617244878161772, 2.4553494878161715, 1.3098338628161752, 2.47941198781617, 1.4511619878161712, 1.6702244878161783, 1.4687088628161709, 2.1367401128161845, 2.4803026128161703, 1.9618721144425926, 2.480817542772942, 2.4054119878161733, 1.446240112816172, 2.15839375, 1.8125838628162012, 1.4728963628161704, 3.2964588628161713, 0.9534276128161698, 1.983333167772942, 2.020511475632378, 3.34122448781617, 2.4501619878161716, 2.4551619878161706, 2.4682783644425923, 1.4828182378161703, 2.4632783644425924, 2.461568237816171, 2.45927136281617, 1.1362713628161698, 3.9361364756323414, 2.4758217835440552, 2.46378698781617, 3.6512189894425924, 1.055021362816201, 3.1425081677729434, 3.6735713628161704, 1.486743658544055, 2.4784119878161706, 0.949943237816171, 2.4665682378161704, 0.7430057378161701, 3.990698280589112, 1.3800526128162174, 2.93230261281617, 1.4702783644425925, 0.3506932378161707, 1.4567557378161715, 2.4581619878161707, 1.975005737816171, 2.9887394177729414, 2.261480225632365, 2.159284375, 3.5619742300000006, 2.944130737816172, 2.887661987816176, 2.4736846144425924, 2.3574588628161726, 2.471677612816171, 2.92449011281617, 2.4492471144425925, 1.985036987815204, 2.4649744878161703, 1.441943237816172, 3.98588647563234, 1.4724119878161706, 1.8450492300000019, 3.9505028522587633, 0.87020886281617, 2.4711932378161707, 3.307833862816172, 0.9801932378161702, 2.479490112816171, 1.47941198781617, 2.4285526128161723, 0.8089744878162173, 0.8963651128161731, 3.4203807378161706, 1.459427612816171, 2.4664588628161703, 2.4494588628161718, -0.5296874999999998, 2.451536987816171, 2.485040533544055, 3.952120850632342, 2.4757081677729422, 2.9735994878161707, 1.48781823781617, 2.4658721144425924, 1.471786987816171, 1.4638721144425926, 3.97618335063234, 2.4584588628161717, 2.0909958506314092, 1.9772244878152043, 1.9751144177729423], "episode_lengths": [45, 16, 70, 212, 123, 758, 46, 179, 26, 42, 278, 27, 209, 29, 20, 24, 90, 49, 18, 515, 31, 43, 53, 19, 920, 22, 42, 42, 18, 24, 18, 40, 39, 359, 80, 26, 34, 21, 887, 43, 23, 19, 26, 48, 40, 220, 28, 749, 29, 18, 1280, 44, 42, 28, 17, 738, 21, 19, 52, 74, 16, 107, 37, 33, 28, 18, 38, 48, 32, 26, 43, 40, 123, 32, 51, 32, 33, 26, 77, 1126, 73, 36, 53, 43, 43, 28, 50, 20, 53, 27, 30, 24, 20, 34, 20, 33, 43, 733, 22, 25], "policy_red_v27_reward": [0.4946925427729421], "policy_blue_reward": [-2.0089999999999995, -1.2000000000000002, -1.0149999999999988, -1.557, -1.0089999999999992, -2.021, 1.1705312500000038, -1.0069999999999997, -1.0059999999999998, -1.0269999999999977, -2.0119999999999996, -1.1279999999999886, -2.0089999999999995, -1.0139999999999991, -1.0149999999999988, -2.0069999999999997, -1.0139999999999996, -1.6139999999999999, -1.0069999999999997, -1.2800000000000002, -2.005, -1.0099999999999991, -1.246999999999977, -2.0049999999999994, -1.0159999999999987, -2.0059999999999993, -1.0039999999999998, -1.005, -1.0099999999999991, -1.0099999999999998, -2.0079999999999996, -1.0139999999999991, -2.0119999999999996, -1.5349999999999997, -1.0119999999999993, -1.0179999999999991, -1.3049999999999722, -1.0099999999999996, -1.014999999999999, 0.4753125, -1.017, -1.0079999999999996, -1.0059999999999998, -0.009000000000000001, -1.0059999999999996, -2.007999999999999, -2.0069999999999997, -1.0099999999999996, 0.29069323781521406, -2.01], "policy_red_v52_reward": [-2.0289999999999977], "policy_red_v28_reward": [0.08005000000000817], "policy_red_v50_reward": [-0.5183074572270582, 1.7967869878161782], "policy_red_v12_reward": [-2.0109999999999992, -0.5229999999999995, 0.4719346144425924], "policy_red_v34_reward": [-1.1709999999999907], "policy_red_v8_reward": [-2.0119999999999996, -1.0109999999999997], "policy_red_v38_reward": [-1.0079999999999998], "policy_red_v11_reward": [-0.17499999999999993, -1.516, -2.012999999999999], "policy_red_v1_reward": [-2.01, -2.006], "policy_red_v18_reward": [1.718818237816179], "policy_red_v42_reward": [-0.14800000000000002], "policy_red_v4_reward": [-1.0069999999999997], "policy_red_v10_reward": [-1.0139999999999998, 0.44825000000000026], "policy_red_v54_reward": [0.4876932378161708], "policy_red_v26_reward": [-1.009, -0.16099999999999992, 0.48569323781617024], "policy_red_v53_reward": [0.17705000000000004], "policy_red_v47_reward": [3.1438156250000007, -2.0069999999999997], "policy_red_v46_reward": [0.18205000000000016, 0.5036925427729417, -1.0029999999999997], "policy_red_v5_reward": [-1.012999999999999, -1.0929999999999922], "policy_red_v30_reward": [0.2893125], "policy_red_v56_reward": [-0.5549999999999998], "policy_red_v14_reward": [-2.017999999999999], "policy_red_v13_reward": [-0.006], "policy_red_v32_reward": [0.18005000000000004], "policy_red_v2_reward": [-0.02900000000000002], "policy_red_v45_reward": [2.349765625, -0.556], "policy_red_v23_reward": [-2.025999999999998], "policy_red_v51_reward": [0.5016932378161698], "policy_red_v29_reward": [-2.0139999999999993], "policy_red_v36_reward": [-1.505], "policy_red_v6_reward": [0.41967187500000014], "policy_red_v21_reward": [0.44], "policy_red_v7_reward": [-2.001], "policy_red_v3_reward": [0.4956932378161708]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8120676154157361, "mean_inference_ms": 7.696509807256016, "mean_action_processing_ms": 0.2924331179443131, "mean_env_wait_ms": 0.38790635745019936, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10580503940582275, "StateBufferConnector_ms": 0.0043833255767822266, "ViewRequirementAgentConnector_ms": 0.12137854099273682}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 728000, "num_agent_steps_trained": 728000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.3204397467664, "num_env_steps_trained_throughput_per_sec": 199.3204397467664, "timesteps_total": 364000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 728000, "timers": {"training_iteration_time_ms": 20108.522, "sample_time_ms": 1157.125, "learn_time_ms": 18865.895, "learn_throughput": 212.023, "synch_weights_time_ms": 82.351}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 728000, "num_agent_steps_trained": 728000}, "done": false, "episodes_total": 1348, "training_iteration": 91, "trial_id": "a9680_00000", "date": "2023-09-24_03-09-28", "timestamp": 1695539368, "time_this_iter_s": 20.08235454559326, "time_total_s": 1816.2070829868317, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1de4b8b0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1df99900>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1df9a050>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1816.2070829868317, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 4.715789473684212, "ram_util_percent": 23.486842105263158}, "win_rate": 0.78, "league_size": 60}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.649006014689803, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.03163469171340694, "policy_loss": -0.049537324040041616, "vf_loss": 0.150612327712588, "vf_explained_var": 0.8652205977588892, "kl": 0.01666657190520103, "entropy": 1.6341049318512282, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 87840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "sampler_results": {"episode_reward_max": 4.487370850632339, "episode_reward_min": -0.5296874999999998, "episode_reward_mean": 2.253628546739745, "episode_len_mean": 105.49, "episode_media": {}, "episodes_this_iter": 48, "policy_reward_min": {"red_v56": -2.005, "red": -1.0049999999999997, "blue": -2.1819999999999835, "red_v5": -1.0929999999999922, "red_v14": -2.017999999999999, "red_v13": -0.02300000000000001, "red_v50": 1.7967869878161782, "red_v32": -2.0119999999999987, "red_v12": -2.0149999999999997, "red_v2": -0.02900000000000002, "red_v45": -0.556, "red_v23": -2.025999999999998, "red_v51": 0.5016932378161698, "red_v29": -2.0139999999999993, "red_v26": -0.16099999999999992, "red_v36": -1.505, "red_v46": -1.0029999999999997, "red_v47": -2.0069999999999997, "red_v6": 0.41967187500000014, "red_v21": 0.44, "red_v1": -2.006, "red_v7": -2.001, "red_v3": 0.4956932378161708, "red_v11": -2.012999999999999, "red_v48": -0.5599999999999998, "red_v31": 0.47301562499999994, "red_v57": 3.363864417772946, "red_v30": -0.15430676218383022, "red_v4": -2.0059999999999993, "red_v10": -1.5899999999999999, "red_v55": 1.5016932378152037, "red_v41": 1.5076932378161698, "red_v37": -2.002, "red_v25": -1.0099999999999993, "red_v40": -0.5579999999999999}, "policy_reward_max": {"red_v56": -0.5549999999999998, "red": 3.9930369878152034, "blue": 0.4753125, "red_v5": -0.004, "red_v14": -2.017999999999999, "red_v13": -0.006, "red_v50": 1.7967869878161782, "red_v32": 1.4886925427729423, "red_v12": 0.4719346144425924, "red_v2": -0.02900000000000002, "red_v45": 2.349765625, "red_v23": -2.025999999999998, "red_v51": 0.5016932378161698, "red_v29": -2.0139999999999993, "red_v26": 0.4901030335440556, "red_v36": -1.505, "red_v46": -1.0029999999999997, "red_v47": 1.4926932378161704, "red_v6": 0.41967187500000014, "red_v21": 1.19015625, "red_v1": -0.5630000000000001, "red_v7": -2.001, "red_v3": 0.4956932378161708, "red_v11": -2.012999999999999, "red_v48": -0.5599999999999998, "red_v31": 0.47301562499999994, "red_v57": 3.363864417772946, "red_v30": -0.15430676218383022, "red_v4": -2.0059999999999993, "red_v10": -1.5899999999999999, "red_v55": 1.5016932378152037, "red_v41": 1.5076932378161698, "red_v37": -2.002, "red_v25": -1.0099999999999993, "red_v40": -0.5579999999999999}, "policy_reward_mean": {"red_v56": -1.521, "red": 3.06085699562283, "blue": -1.3158198852436942, "red_v5": -0.5484999999999961, "red_v14": -2.017999999999999, "red_v13": -0.014500000000000006, "red_v50": 1.7967869878161782, "red_v32": -0.11441915240901879, "red_v12": -0.688688461852469, "red_v2": -0.02900000000000002, "red_v45": 0.8699218749999998, "red_v23": -2.025999999999998, "red_v51": 0.5016932378161698, "red_v29": -2.0139999999999993, "red_v26": 0.2715987571200753, "red_v36": -1.505, "red_v46": -1.0029999999999997, "red_v47": 0.2774872439078441, "red_v6": 0.41967187500000014, "red_v21": 0.815078125, "red_v1": -1.2845, "red_v7": -2.001, "red_v3": 0.4956932378161708, "red_v11": -2.012999999999999, "red_v48": -0.5599999999999998, "red_v31": 0.47301562499999994, "red_v57": 3.363864417772946, "red_v30": -0.15430676218383022, "red_v4": -2.0059999999999993, "red_v10": -1.5899999999999999, "red_v55": 1.5016932378152037, "red_v41": 1.5076932378161698, "red_v37": -2.002, "red_v25": -1.0099999999999993, "red_v40": -0.5579999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.93230261281617, 1.4702783644425925, 0.3506932378161707, 1.4567557378161715, 2.4581619878161707, 1.975005737816171, 2.9887394177729414, 2.261480225632365, 2.159284375, 3.5619742300000006, 2.944130737816172, 2.887661987816176, 2.4736846144425924, 2.3574588628161726, 2.471677612816171, 2.92449011281617, 2.4492471144425925, 1.985036987815204, 2.4649744878161703, 1.441943237816172, 3.98588647563234, 1.4724119878161706, 1.8450492300000019, 3.9505028522587633, 0.87020886281617, 2.4711932378161707, 3.307833862816172, 0.9801932378161702, 2.479490112816171, 1.47941198781617, 2.4285526128161723, 0.8089744878162173, 0.8963651128161731, 3.4203807378161706, 1.459427612816171, 2.4664588628161703, 2.4494588628161718, -0.5296874999999998, 2.451536987816171, 2.485040533544055, 3.952120850632342, 2.4757081677729422, 2.9735994878161707, 1.48781823781617, 2.4658721144425924, 1.471786987816171, 1.4638721144425926, 3.97618335063234, 2.4584588628161717, 2.0909958506314092, 1.9772244878152043, 1.9751144177729423, 2.4805994878161703, 1.4845213628161704, 2.4693807378161705, 2.883630737816171, 0.9787088628161698, 4.466448975632341, 2.4401307378161716, 2.9872244878152037, 2.9150838628161706, 1.9616846144425926, 2.4684901128161707, 1.1566906250000004, 3.3665576555891192, 3.534027100632367, 1.6738494878161796, 1.267943237816179, 1.8777367300000005, 2.48111511281617, 1.48281823781617, 1.8797367300000003, 1.4555369878161708, 0.7824276128161699, 1.2075213628162, 4.482480225631374, 4.487370850632339, 2.8286989756313874, 1.9726846144425922, 1.4650838628161702, 1.4670838628161706, 3.9670775213602254, 1.4730057378152046, 4.4638545305891135, 1.0742557378161912, 2.9318374085440553, 2.4332869878161727, 1.470193237815204, 1.664096875, 1.4773026128161706, 2.4402158644425938, 1.266614417772943, 2.465981489442593, 2.1438468750000004, 2.9261932378161704, 3.7078651128161786, 2.4324276128161713, 1.8748148550000006, 1.2939531250000007, 1.488337408544055], "episode_lengths": [29, 18, 1280, 44, 42, 28, 17, 738, 21, 19, 52, 74, 16, 107, 37, 33, 28, 18, 38, 48, 32, 26, 43, 40, 123, 32, 51, 32, 33, 26, 77, 1126, 73, 36, 53, 43, 43, 28, 50, 20, 53, 27, 30, 24, 20, 34, 20, 33, 43, 733, 22, 25, 30, 23, 36, 84, 27, 44, 52, 22, 35, 16, 33, 19, 105, 339, 142, 176, 15, 25, 24, 15, 50, 181, 599, 34, 37, 796, 16, 35, 35, 38, 28, 42, 908, 53, 66, 32, 17, 29, 38, 185, 17, 33, 32, 105, 53, 22, 47, 21], "policy_red_v56_reward": [-0.5549999999999998, -2.005, -2.003], "policy_blue_reward": [-2.0049999999999994, -1.0159999999999987, -2.0059999999999993, -1.0039999999999998, -1.005, -1.0099999999999991, -1.0099999999999998, -2.0079999999999996, -1.0139999999999991, -2.0119999999999996, -1.5349999999999997, -1.0119999999999993, -1.0179999999999991, -1.3049999999999722, -1.0099999999999996, -1.014999999999999, 0.4753125, -1.017, -1.0079999999999996, -1.0059999999999998, -0.009000000000000001, -1.0059999999999996, -2.007999999999999, -2.0069999999999997, -1.0099999999999996, 0.29069323781521406, -2.01, -1.0069999999999997, -2.0069999999999997, -1.0099999999999993, -1.0189999999999992, -1.0109999999999995, -1.044999999999999, -2.0079999999999996, -1.009, -2.006, -2.1819999999999835, -2.0109999999999997, -2.0099999999999993, -2.0119999999999996, -1.0199999999999996, -2.0069999999999997, -2.003, -2.0059999999999993, -1.0119999999999993, -1.552, -1.0089999999999997, -1.0239999999999987, -2.0069999999999997, -0.514], "policy_red_v5_reward": [-1.0929999999999922, -0.004], "policy_red_v14_reward": [-2.017999999999999], "policy_red_v13_reward": [-0.006, -0.02300000000000001], "policy_red_v50_reward": [1.7967869878161782], "policy_red_v32_reward": [0.18005000000000004, -2.0119999999999987, 1.4886925427729423], "policy_red_v12_reward": [-0.5229999999999995, 0.4719346144425924, -2.0149999999999997], "policy_red_v2_reward": [-0.02900000000000002], "policy_red_v45_reward": [2.349765625, -0.556, 0.816], "policy_red_v23_reward": [-2.025999999999998], "policy_red_v51_reward": [0.5016932378161698], "policy_red_v29_reward": [-2.0139999999999993], "policy_red_v26_reward": [-0.16099999999999992, 0.48569323781617024, 0.4901030335440556], "policy_red_v36_reward": [-1.505], "policy_red_v46_reward": [-1.0029999999999997], "policy_red_v47_reward": [-2.0069999999999997, 1.4926932378161704, 0.9696932378152052, 0.6545625000000006], "policy_red_v6_reward": [0.41967187500000014], "policy_red_v21_reward": [0.44, 1.19015625], "policy_red_v1_reward": [-2.006, -0.5630000000000001], "policy_red_v7_reward": [-2.001], "policy_red_v3_reward": [0.4956932378161708], "policy_red_v11_reward": [-2.012999999999999], "policy_red_v48_reward": [-0.5599999999999998], "policy_red_v31_reward": [0.47301562499999994], "policy_red_v57_reward": [3.363864417772946], "policy_red_v30_reward": [-0.15430676218383022], "policy_red_v4_reward": [-2.0059999999999993], "policy_red_v10_reward": [-1.5899999999999999], "policy_red_v55_reward": [1.5016932378152037], "policy_red_v41_reward": [1.5076932378161698], "policy_red_v37_reward": [-2.002], "policy_red_v25_reward": [-1.0099999999999993], "policy_red_v40_reward": [-0.5579999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8130177719104097, "mean_inference_ms": 7.702929404799513, "mean_action_processing_ms": 0.2926480046302894, "mean_env_wait_ms": 0.38845226513442377, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10331499576568604, "StateBufferConnector_ms": 0.004313945770263672, "ViewRequirementAgentConnector_ms": 0.11899173259735107}}, "episode_reward_max": 4.487370850632339, "episode_reward_min": -0.5296874999999998, "episode_reward_mean": 2.253628546739745, "episode_len_mean": 105.49, "episodes_this_iter": 48, "policy_reward_min": {"red_v56": -2.005, "red": -1.0049999999999997, "blue": -2.1819999999999835, "red_v5": -1.0929999999999922, "red_v14": -2.017999999999999, "red_v13": -0.02300000000000001, "red_v50": 1.7967869878161782, "red_v32": -2.0119999999999987, "red_v12": -2.0149999999999997, "red_v2": -0.02900000000000002, "red_v45": -0.556, "red_v23": -2.025999999999998, "red_v51": 0.5016932378161698, "red_v29": -2.0139999999999993, "red_v26": -0.16099999999999992, "red_v36": -1.505, "red_v46": -1.0029999999999997, "red_v47": -2.0069999999999997, "red_v6": 0.41967187500000014, "red_v21": 0.44, "red_v1": -2.006, "red_v7": -2.001, "red_v3": 0.4956932378161708, "red_v11": -2.012999999999999, "red_v48": -0.5599999999999998, "red_v31": 0.47301562499999994, "red_v57": 3.363864417772946, "red_v30": -0.15430676218383022, "red_v4": -2.0059999999999993, "red_v10": -1.5899999999999999, "red_v55": 1.5016932378152037, "red_v41": 1.5076932378161698, "red_v37": -2.002, "red_v25": -1.0099999999999993, "red_v40": -0.5579999999999999}, "policy_reward_max": {"red_v56": -0.5549999999999998, "red": 3.9930369878152034, "blue": 0.4753125, "red_v5": -0.004, "red_v14": -2.017999999999999, "red_v13": -0.006, "red_v50": 1.7967869878161782, "red_v32": 1.4886925427729423, "red_v12": 0.4719346144425924, "red_v2": -0.02900000000000002, "red_v45": 2.349765625, "red_v23": -2.025999999999998, "red_v51": 0.5016932378161698, "red_v29": -2.0139999999999993, "red_v26": 0.4901030335440556, "red_v36": -1.505, "red_v46": -1.0029999999999997, "red_v47": 1.4926932378161704, "red_v6": 0.41967187500000014, "red_v21": 1.19015625, "red_v1": -0.5630000000000001, "red_v7": -2.001, "red_v3": 0.4956932378161708, "red_v11": -2.012999999999999, "red_v48": -0.5599999999999998, "red_v31": 0.47301562499999994, "red_v57": 3.363864417772946, "red_v30": -0.15430676218383022, "red_v4": -2.0059999999999993, "red_v10": -1.5899999999999999, "red_v55": 1.5016932378152037, "red_v41": 1.5076932378161698, "red_v37": -2.002, "red_v25": -1.0099999999999993, "red_v40": -0.5579999999999999}, "policy_reward_mean": {"red_v56": -1.521, "red": 3.06085699562283, "blue": -1.3158198852436942, "red_v5": -0.5484999999999961, "red_v14": -2.017999999999999, "red_v13": -0.014500000000000006, "red_v50": 1.7967869878161782, "red_v32": -0.11441915240901879, "red_v12": -0.688688461852469, "red_v2": -0.02900000000000002, "red_v45": 0.8699218749999998, "red_v23": -2.025999999999998, "red_v51": 0.5016932378161698, "red_v29": -2.0139999999999993, "red_v26": 0.2715987571200753, "red_v36": -1.505, "red_v46": -1.0029999999999997, "red_v47": 0.2774872439078441, "red_v6": 0.41967187500000014, "red_v21": 0.815078125, "red_v1": -1.2845, "red_v7": -2.001, "red_v3": 0.4956932378161708, "red_v11": -2.012999999999999, "red_v48": -0.5599999999999998, "red_v31": 0.47301562499999994, "red_v57": 3.363864417772946, "red_v30": -0.15430676218383022, "red_v4": -2.0059999999999993, "red_v10": -1.5899999999999999, "red_v55": 1.5016932378152037, "red_v41": 1.5076932378161698, "red_v37": -2.002, "red_v25": -1.0099999999999993, "red_v40": -0.5579999999999999}, "hist_stats": {"episode_reward": [2.93230261281617, 1.4702783644425925, 0.3506932378161707, 1.4567557378161715, 2.4581619878161707, 1.975005737816171, 2.9887394177729414, 2.261480225632365, 2.159284375, 3.5619742300000006, 2.944130737816172, 2.887661987816176, 2.4736846144425924, 2.3574588628161726, 2.471677612816171, 2.92449011281617, 2.4492471144425925, 1.985036987815204, 2.4649744878161703, 1.441943237816172, 3.98588647563234, 1.4724119878161706, 1.8450492300000019, 3.9505028522587633, 0.87020886281617, 2.4711932378161707, 3.307833862816172, 0.9801932378161702, 2.479490112816171, 1.47941198781617, 2.4285526128161723, 0.8089744878162173, 0.8963651128161731, 3.4203807378161706, 1.459427612816171, 2.4664588628161703, 2.4494588628161718, -0.5296874999999998, 2.451536987816171, 2.485040533544055, 3.952120850632342, 2.4757081677729422, 2.9735994878161707, 1.48781823781617, 2.4658721144425924, 1.471786987816171, 1.4638721144425926, 3.97618335063234, 2.4584588628161717, 2.0909958506314092, 1.9772244878152043, 1.9751144177729423, 2.4805994878161703, 1.4845213628161704, 2.4693807378161705, 2.883630737816171, 0.9787088628161698, 4.466448975632341, 2.4401307378161716, 2.9872244878152037, 2.9150838628161706, 1.9616846144425926, 2.4684901128161707, 1.1566906250000004, 3.3665576555891192, 3.534027100632367, 1.6738494878161796, 1.267943237816179, 1.8777367300000005, 2.48111511281617, 1.48281823781617, 1.8797367300000003, 1.4555369878161708, 0.7824276128161699, 1.2075213628162, 4.482480225631374, 4.487370850632339, 2.8286989756313874, 1.9726846144425922, 1.4650838628161702, 1.4670838628161706, 3.9670775213602254, 1.4730057378152046, 4.4638545305891135, 1.0742557378161912, 2.9318374085440553, 2.4332869878161727, 1.470193237815204, 1.664096875, 1.4773026128161706, 2.4402158644425938, 1.266614417772943, 2.465981489442593, 2.1438468750000004, 2.9261932378161704, 3.7078651128161786, 2.4324276128161713, 1.8748148550000006, 1.2939531250000007, 1.488337408544055], "episode_lengths": [29, 18, 1280, 44, 42, 28, 17, 738, 21, 19, 52, 74, 16, 107, 37, 33, 28, 18, 38, 48, 32, 26, 43, 40, 123, 32, 51, 32, 33, 26, 77, 1126, 73, 36, 53, 43, 43, 28, 50, 20, 53, 27, 30, 24, 20, 34, 20, 33, 43, 733, 22, 25, 30, 23, 36, 84, 27, 44, 52, 22, 35, 16, 33, 19, 105, 339, 142, 176, 15, 25, 24, 15, 50, 181, 599, 34, 37, 796, 16, 35, 35, 38, 28, 42, 908, 53, 66, 32, 17, 29, 38, 185, 17, 33, 32, 105, 53, 22, 47, 21], "policy_red_v56_reward": [-0.5549999999999998, -2.005, -2.003], "policy_blue_reward": [-2.0049999999999994, -1.0159999999999987, -2.0059999999999993, -1.0039999999999998, -1.005, -1.0099999999999991, -1.0099999999999998, -2.0079999999999996, -1.0139999999999991, -2.0119999999999996, -1.5349999999999997, -1.0119999999999993, -1.0179999999999991, -1.3049999999999722, -1.0099999999999996, -1.014999999999999, 0.4753125, -1.017, -1.0079999999999996, -1.0059999999999998, -0.009000000000000001, -1.0059999999999996, -2.007999999999999, -2.0069999999999997, -1.0099999999999996, 0.29069323781521406, -2.01, -1.0069999999999997, -2.0069999999999997, -1.0099999999999993, -1.0189999999999992, -1.0109999999999995, -1.044999999999999, -2.0079999999999996, -1.009, -2.006, -2.1819999999999835, -2.0109999999999997, -2.0099999999999993, -2.0119999999999996, -1.0199999999999996, -2.0069999999999997, -2.003, -2.0059999999999993, -1.0119999999999993, -1.552, -1.0089999999999997, -1.0239999999999987, -2.0069999999999997, -0.514], "policy_red_v5_reward": [-1.0929999999999922, -0.004], "policy_red_v14_reward": [-2.017999999999999], "policy_red_v13_reward": [-0.006, -0.02300000000000001], "policy_red_v50_reward": [1.7967869878161782], "policy_red_v32_reward": [0.18005000000000004, -2.0119999999999987, 1.4886925427729423], "policy_red_v12_reward": [-0.5229999999999995, 0.4719346144425924, -2.0149999999999997], "policy_red_v2_reward": [-0.02900000000000002], "policy_red_v45_reward": [2.349765625, -0.556, 0.816], "policy_red_v23_reward": [-2.025999999999998], "policy_red_v51_reward": [0.5016932378161698], "policy_red_v29_reward": [-2.0139999999999993], "policy_red_v26_reward": [-0.16099999999999992, 0.48569323781617024, 0.4901030335440556], "policy_red_v36_reward": [-1.505], "policy_red_v46_reward": [-1.0029999999999997], "policy_red_v47_reward": [-2.0069999999999997, 1.4926932378161704, 0.9696932378152052, 0.6545625000000006], "policy_red_v6_reward": [0.41967187500000014], "policy_red_v21_reward": [0.44, 1.19015625], "policy_red_v1_reward": [-2.006, -0.5630000000000001], "policy_red_v7_reward": [-2.001], "policy_red_v3_reward": [0.4956932378161708], "policy_red_v11_reward": [-2.012999999999999], "policy_red_v48_reward": [-0.5599999999999998], "policy_red_v31_reward": [0.47301562499999994], "policy_red_v57_reward": [3.363864417772946], "policy_red_v30_reward": [-0.15430676218383022], "policy_red_v4_reward": [-2.0059999999999993], "policy_red_v10_reward": [-1.5899999999999999], "policy_red_v55_reward": [1.5016932378152037], "policy_red_v41_reward": [1.5076932378161698], "policy_red_v37_reward": [-2.002], "policy_red_v25_reward": [-1.0099999999999993], "policy_red_v40_reward": [-0.5579999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8130177719104097, "mean_inference_ms": 7.702929404799513, "mean_action_processing_ms": 0.2926480046302894, "mean_env_wait_ms": 0.38845226513442377, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10331499576568604, "StateBufferConnector_ms": 0.004313945770263672, "ViewRequirementAgentConnector_ms": 0.11899173259735107}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.60344110304658, "num_env_steps_trained_throughput_per_sec": 201.60344110304658, "timesteps_total": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 20104.55, "sample_time_ms": 1158.237, "learn_time_ms": 18859.842, "learn_throughput": 212.091, "synch_weights_time_ms": 83.178}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "episodes_total": 1396, "training_iteration": 92, "trial_id": "a9680_00000", "date": "2023-09-24_03-09-51", "timestamp": 1695539391, "time_this_iter_s": 19.8545343875885, "time_total_s": 1836.0616173744202, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1de4a560>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1df983a0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1df98790>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1836.0616173744202, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 5.390909090909091, "ram_util_percent": 23.58787878787879}, "win_rate": 0.78, "league_size": 61}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.917979593326648, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.026623534235113766, "policy_loss": -0.05064922128318964, "vf_loss": 0.14178903747039537, "vf_explained_var": 0.8618778094649315, "kl": 0.017726578040249782, "entropy": 1.5987235187242428, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 88800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 744000, "num_agent_steps_trained": 744000}, "sampler_results": {"episode_reward_max": 4.487370850632339, "episode_reward_min": 0.1851932378161738, "episode_reward_mean": 2.402323609247466, "episode_len_mean": 94.89, "episode_media": {}, "episodes_this_iter": 47, "policy_reward_min": {"red_v3": -2.003, "red": -0.0053067621838289725, "blue": -2.1819999999999835, "red_v11": -2.012999999999999, "red_v48": -0.5599999999999998, "red_v31": 0.47301562499999994, "red_v47": 0.6545625000000006, "red_v5": -0.004, "red_v1": -0.5630000000000001, "red_v12": -2.0149999999999997, "red_v56": -2.005, "red_v57": -1.0169999999999988, "red_v30": -0.15430676218383022, "red_v21": 0.49769323781617014, "red_v4": -2.0059999999999993, "red_v32": -2.0119999999999987, "red_v10": -1.5899999999999999, "red_v55": 1.5016932378152037, "red_v41": 1.5076932378161698, "red_v37": -2.002, "red_v26": 0.4901030335440556, "red_v13": -0.02300000000000001, "red_v25": -1.0099999999999993, "red_v40": -0.5579999999999999, "red_v45": 0.816, "red_v46": -0.29849999999999655, "red_v22": -1.0109999999999997, "red_v39": -0.16300000000000003, "red_v34": 0.4861030335440564, "red_v9": -1.0139999999999996, "red_v7": -1.0099999999999998, "red_v43": 0.18105000000000004, "red_v50": 0.5061030335440548, "red_v6": -0.011000000000000003, "red_v52": 0.4986932378161706, "red_v29": -1.0159999999999991, "red_v15": -0.027499999999999414}, "policy_reward_max": {"red_v3": 0.4956932378161708, "red": 3.9902244878152033, "blue": 1.529721875000007, "red_v11": 0.447, "red_v48": 0.5066932378161698, "red_v31": 0.47301562499999994, "red_v47": 1.4926932378161704, "red_v5": -0.004, "red_v1": 0.4067656250000009, "red_v12": 0.5016932378152038, "red_v56": -2.003, "red_v57": 3.363864417772946, "red_v30": 0.49969323781520414, "red_v21": 1.19015625, "red_v4": -2.0059999999999993, "red_v32": 1.4886925427729423, "red_v10": -1.5899999999999999, "red_v55": 1.5016932378152037, "red_v41": 1.5076932378161698, "red_v37": -2.002, "red_v26": 0.4901030335440556, "red_v13": -0.02300000000000001, "red_v25": -0.04230676218382623, "red_v40": -0.5579999999999999, "red_v45": 0.816, "red_v46": -0.29849999999999655, "red_v22": 1.4946925427729418, "red_v39": 3.4096612927729444, "red_v34": 0.4861030335440564, "red_v9": -1.0139999999999996, "red_v7": -1.0099999999999998, "red_v43": 0.18105000000000004, "red_v50": 0.5061030335440548, "red_v6": 1.9125625, "red_v52": 0.4986932378161706, "red_v29": -1.0159999999999991, "red_v15": -0.027499999999999414}, "policy_reward_mean": {"red_v3": -0.7536533810919146, "red": 3.0186955132360094, "blue": -1.3253605410257556, "red_v11": -0.7829999999999995, "red_v48": -0.026653381091915007, "red_v31": 0.47301562499999994, "red_v47": 1.0389829918771254, "red_v5": -0.004, "red_v1": -0.07811718749999957, "red_v12": -0.7566533810923979, "red_v56": -2.004, "red_v57": 0.45988941389727916, "red_v30": 0.17381215854379142, "red_v21": 0.843924743908085, "red_v4": -2.0059999999999993, "red_v32": -0.2616537286135282, "red_v10": -1.5899999999999999, "red_v55": 1.5016932378152037, "red_v41": 1.5076932378161698, "red_v37": -2.002, "red_v26": 0.4901030335440556, "red_v13": -0.02300000000000001, "red_v25": -0.5261533810919128, "red_v40": -0.5579999999999999, "red_v45": 0.816, "red_v46": -0.29849999999999655, "red_v22": 0.24184627138647108, "red_v39": 1.623330646386472, "red_v34": 0.4861030335440564, "red_v9": -1.0139999999999996, "red_v7": -1.0099999999999998, "red_v43": 0.18105000000000004, "red_v50": 0.5061030335440548, "red_v6": 0.95078125, "red_v52": 0.4986932378161706, "red_v29": -1.0159999999999991, "red_v15": -0.027499999999999414}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.97618335063234, 2.4584588628161717, 2.0909958506314092, 1.9772244878152043, 1.9751144177729423, 2.4805994878161703, 1.4845213628161704, 2.4693807378161705, 2.883630737816171, 0.9787088628161698, 4.466448975632341, 2.4401307378161716, 2.9872244878152037, 2.9150838628161706, 1.9616846144425926, 2.4684901128161707, 1.1566906250000004, 3.3665576555891192, 3.534027100632367, 1.6738494878161796, 1.267943237816179, 1.8777367300000005, 2.48111511281617, 1.48281823781617, 1.8797367300000003, 1.4555369878161708, 0.7824276128161699, 1.2075213628162, 4.482480225631374, 4.487370850632339, 2.8286989756313874, 1.9726846144425922, 1.4650838628161702, 1.4670838628161706, 3.9670775213602254, 1.4730057378152046, 4.4638545305891135, 1.0742557378161912, 2.9318374085440553, 2.4332869878161727, 1.470193237815204, 1.664096875, 1.4773026128161706, 2.4402158644425938, 1.266614417772943, 2.465981489442593, 2.1438468750000004, 2.9261932378161704, 3.7078651128161786, 2.4324276128161713, 1.8748148550000006, 1.2939531250000007, 1.488337408544055, 0.1851932378161738, 2.4517557378161716, 2.4840369878152044, 3.9946989756323408, 2.0034151128161852, 3.3019432378161717, 1.1635031250000003, 3.941573975632342, 3.9464993963602266, 2.4660838628161708, 1.3827367300000002, 2.47089636281617, 3.960495850631375, 1.4873374085440547, 3.6651686585440557, 2.465380737815205, 3.997218146360225, 2.491446783544055, 1.9072557378161732, 2.4666776128161705, 4.471073280589113, 3.9898083506313746, 1.4784119878161703, 2.4686776128161707, 3.416354530589116, 2.480708862815204, 3.9697458506323406, 0.9603807378161707, 2.435396362816171, 2.29726147563235, 3.43119323781617, 2.3800336050000004, 2.9721932378161706, 0.9044588628161714, 2.7575369878161764, 2.941943237815206, 1.4777088628161708, 0.4181932378161719, 3.431683350631377, 1.1689093750000001, 3.66627448781617, 1.9640838628161708, 2.9809276128161706, 2.989743658544055, 1.48422448781617, 1.4715994878161704, 1.7121117300000024], "episode_lengths": [33, 43, 733, 22, 25, 30, 23, 36, 84, 27, 44, 52, 22, 35, 16, 33, 19, 105, 339, 142, 176, 15, 25, 24, 15, 50, 181, 599, 34, 37, 796, 16, 35, 35, 38, 28, 42, 908, 53, 66, 32, 17, 29, 38, 185, 17, 33, 32, 105, 53, 22, 47, 21, 480, 44, 18, 28, 649, 48, 15, 68, 63, 35, 15, 31, 61, 21, 27, 36, 25, 18, 76, 37, 36, 25, 26, 37, 74, 27, 45, 36, 63, 168, 32, 16, 32, 107, 178, 48, 27, 672, 65, 13, 22, 35, 21, 19, 22, 30, 151], "policy_red_v3_reward": [0.4956932378161708, -2.003], "policy_blue_reward": [-1.0099999999999996, 0.29069323781521406, -2.01, -1.0069999999999997, -2.0069999999999997, -1.0099999999999993, -1.0189999999999992, -1.0109999999999995, -1.044999999999999, -2.0079999999999996, -1.009, -2.006, -2.1819999999999835, -2.0109999999999997, -2.0099999999999993, -2.0119999999999996, -1.0199999999999996, -2.0069999999999997, -2.003, -2.0059999999999993, -1.0119999999999993, -1.552, -1.0089999999999997, -1.0239999999999987, -2.0069999999999997, -0.514, -1.0119999999999998, 1.529721875000007, -2.006, -2.003, -1.003, -1.0129999999999997, -2.01, -1.0059999999999996, -1.0029999999999997, -1.517, -1.0039999999999998, -0.009000000000000001, -1.097999999999998, -0.015000000000000005, -2.0089999999999995, -2.003, -2.016, -2.005, -2.008, -0.536], "policy_red_v11_reward": [-2.012999999999999, 0.447], "policy_red_v48_reward": [-0.5599999999999998, 0.5066932378161698], "policy_red_v31_reward": [0.47301562499999994], "policy_red_v47_reward": [1.4926932378161704, 0.9696932378152052, 0.6545625000000006], "policy_red_v5_reward": [-0.004], "policy_red_v1_reward": [-0.5630000000000001, 0.4067656250000009], "policy_red_v12_reward": [-2.0149999999999997, 0.5016932378152038], "policy_red_v56_reward": [-2.005, -2.003], "policy_red_v57_reward": [3.363864417772946, -1.0169999999999988, -0.5043067621838304, -0.003], "policy_red_v30_reward": [-0.15430676218383022, 0.49969323781520414, 0.17605000000000037], "policy_red_v21_reward": [1.19015625, 0.49769323781617014], "policy_red_v4_reward": [-2.0059999999999993], "policy_red_v32_reward": [-2.0119999999999987, 1.4886925427729423], "policy_red_v10_reward": [-1.5899999999999999], "policy_red_v55_reward": [1.5016932378152037], "policy_red_v41_reward": [1.5076932378161698], "policy_red_v37_reward": [-2.002], "policy_red_v26_reward": [0.4901030335440556], "policy_red_v13_reward": [-0.02300000000000001], "policy_red_v25_reward": [-1.0099999999999993, -0.04230676218382623], "policy_red_v40_reward": [-0.5579999999999999], "policy_red_v45_reward": [0.816], "policy_red_v46_reward": [-0.29849999999999655], "policy_red_v22_reward": [-1.0109999999999997, 1.4946925427729418], "policy_red_v39_reward": [-0.16300000000000003, 3.4096612927729444], "policy_red_v34_reward": [0.4861030335440564], "policy_red_v9_reward": [-1.0139999999999996], "policy_red_v7_reward": [-1.0099999999999998], "policy_red_v43_reward": [0.18105000000000004], "policy_red_v50_reward": [0.5061030335440548], "policy_red_v6_reward": [1.9125625, -0.011000000000000003], "policy_red_v52_reward": [0.4986932378161706], "policy_red_v29_reward": [-1.0159999999999991], "policy_red_v15_reward": [-0.027499999999999414]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8159192810530069, "mean_inference_ms": 7.721299492076827, "mean_action_processing_ms": 0.2933578540241658, "mean_env_wait_ms": 0.3891358770311011, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10242223739624023, "StateBufferConnector_ms": 0.004243254661560059, "ViewRequirementAgentConnector_ms": 0.11733627319335938}}, "episode_reward_max": 4.487370850632339, "episode_reward_min": 0.1851932378161738, "episode_reward_mean": 2.402323609247466, "episode_len_mean": 94.89, "episodes_this_iter": 47, "policy_reward_min": {"red_v3": -2.003, "red": -0.0053067621838289725, "blue": -2.1819999999999835, "red_v11": -2.012999999999999, "red_v48": -0.5599999999999998, "red_v31": 0.47301562499999994, "red_v47": 0.6545625000000006, "red_v5": -0.004, "red_v1": -0.5630000000000001, "red_v12": -2.0149999999999997, "red_v56": -2.005, "red_v57": -1.0169999999999988, "red_v30": -0.15430676218383022, "red_v21": 0.49769323781617014, "red_v4": -2.0059999999999993, "red_v32": -2.0119999999999987, "red_v10": -1.5899999999999999, "red_v55": 1.5016932378152037, "red_v41": 1.5076932378161698, "red_v37": -2.002, "red_v26": 0.4901030335440556, "red_v13": -0.02300000000000001, "red_v25": -1.0099999999999993, "red_v40": -0.5579999999999999, "red_v45": 0.816, "red_v46": -0.29849999999999655, "red_v22": -1.0109999999999997, "red_v39": -0.16300000000000003, "red_v34": 0.4861030335440564, "red_v9": -1.0139999999999996, "red_v7": -1.0099999999999998, "red_v43": 0.18105000000000004, "red_v50": 0.5061030335440548, "red_v6": -0.011000000000000003, "red_v52": 0.4986932378161706, "red_v29": -1.0159999999999991, "red_v15": -0.027499999999999414}, "policy_reward_max": {"red_v3": 0.4956932378161708, "red": 3.9902244878152033, "blue": 1.529721875000007, "red_v11": 0.447, "red_v48": 0.5066932378161698, "red_v31": 0.47301562499999994, "red_v47": 1.4926932378161704, "red_v5": -0.004, "red_v1": 0.4067656250000009, "red_v12": 0.5016932378152038, "red_v56": -2.003, "red_v57": 3.363864417772946, "red_v30": 0.49969323781520414, "red_v21": 1.19015625, "red_v4": -2.0059999999999993, "red_v32": 1.4886925427729423, "red_v10": -1.5899999999999999, "red_v55": 1.5016932378152037, "red_v41": 1.5076932378161698, "red_v37": -2.002, "red_v26": 0.4901030335440556, "red_v13": -0.02300000000000001, "red_v25": -0.04230676218382623, "red_v40": -0.5579999999999999, "red_v45": 0.816, "red_v46": -0.29849999999999655, "red_v22": 1.4946925427729418, "red_v39": 3.4096612927729444, "red_v34": 0.4861030335440564, "red_v9": -1.0139999999999996, "red_v7": -1.0099999999999998, "red_v43": 0.18105000000000004, "red_v50": 0.5061030335440548, "red_v6": 1.9125625, "red_v52": 0.4986932378161706, "red_v29": -1.0159999999999991, "red_v15": -0.027499999999999414}, "policy_reward_mean": {"red_v3": -0.7536533810919146, "red": 3.0186955132360094, "blue": -1.3253605410257556, "red_v11": -0.7829999999999995, "red_v48": -0.026653381091915007, "red_v31": 0.47301562499999994, "red_v47": 1.0389829918771254, "red_v5": -0.004, "red_v1": -0.07811718749999957, "red_v12": -0.7566533810923979, "red_v56": -2.004, "red_v57": 0.45988941389727916, "red_v30": 0.17381215854379142, "red_v21": 0.843924743908085, "red_v4": -2.0059999999999993, "red_v32": -0.2616537286135282, "red_v10": -1.5899999999999999, "red_v55": 1.5016932378152037, "red_v41": 1.5076932378161698, "red_v37": -2.002, "red_v26": 0.4901030335440556, "red_v13": -0.02300000000000001, "red_v25": -0.5261533810919128, "red_v40": -0.5579999999999999, "red_v45": 0.816, "red_v46": -0.29849999999999655, "red_v22": 0.24184627138647108, "red_v39": 1.623330646386472, "red_v34": 0.4861030335440564, "red_v9": -1.0139999999999996, "red_v7": -1.0099999999999998, "red_v43": 0.18105000000000004, "red_v50": 0.5061030335440548, "red_v6": 0.95078125, "red_v52": 0.4986932378161706, "red_v29": -1.0159999999999991, "red_v15": -0.027499999999999414}, "hist_stats": {"episode_reward": [3.97618335063234, 2.4584588628161717, 2.0909958506314092, 1.9772244878152043, 1.9751144177729423, 2.4805994878161703, 1.4845213628161704, 2.4693807378161705, 2.883630737816171, 0.9787088628161698, 4.466448975632341, 2.4401307378161716, 2.9872244878152037, 2.9150838628161706, 1.9616846144425926, 2.4684901128161707, 1.1566906250000004, 3.3665576555891192, 3.534027100632367, 1.6738494878161796, 1.267943237816179, 1.8777367300000005, 2.48111511281617, 1.48281823781617, 1.8797367300000003, 1.4555369878161708, 0.7824276128161699, 1.2075213628162, 4.482480225631374, 4.487370850632339, 2.8286989756313874, 1.9726846144425922, 1.4650838628161702, 1.4670838628161706, 3.9670775213602254, 1.4730057378152046, 4.4638545305891135, 1.0742557378161912, 2.9318374085440553, 2.4332869878161727, 1.470193237815204, 1.664096875, 1.4773026128161706, 2.4402158644425938, 1.266614417772943, 2.465981489442593, 2.1438468750000004, 2.9261932378161704, 3.7078651128161786, 2.4324276128161713, 1.8748148550000006, 1.2939531250000007, 1.488337408544055, 0.1851932378161738, 2.4517557378161716, 2.4840369878152044, 3.9946989756323408, 2.0034151128161852, 3.3019432378161717, 1.1635031250000003, 3.941573975632342, 3.9464993963602266, 2.4660838628161708, 1.3827367300000002, 2.47089636281617, 3.960495850631375, 1.4873374085440547, 3.6651686585440557, 2.465380737815205, 3.997218146360225, 2.491446783544055, 1.9072557378161732, 2.4666776128161705, 4.471073280589113, 3.9898083506313746, 1.4784119878161703, 2.4686776128161707, 3.416354530589116, 2.480708862815204, 3.9697458506323406, 0.9603807378161707, 2.435396362816171, 2.29726147563235, 3.43119323781617, 2.3800336050000004, 2.9721932378161706, 0.9044588628161714, 2.7575369878161764, 2.941943237815206, 1.4777088628161708, 0.4181932378161719, 3.431683350631377, 1.1689093750000001, 3.66627448781617, 1.9640838628161708, 2.9809276128161706, 2.989743658544055, 1.48422448781617, 1.4715994878161704, 1.7121117300000024], "episode_lengths": [33, 43, 733, 22, 25, 30, 23, 36, 84, 27, 44, 52, 22, 35, 16, 33, 19, 105, 339, 142, 176, 15, 25, 24, 15, 50, 181, 599, 34, 37, 796, 16, 35, 35, 38, 28, 42, 908, 53, 66, 32, 17, 29, 38, 185, 17, 33, 32, 105, 53, 22, 47, 21, 480, 44, 18, 28, 649, 48, 15, 68, 63, 35, 15, 31, 61, 21, 27, 36, 25, 18, 76, 37, 36, 25, 26, 37, 74, 27, 45, 36, 63, 168, 32, 16, 32, 107, 178, 48, 27, 672, 65, 13, 22, 35, 21, 19, 22, 30, 151], "policy_red_v3_reward": [0.4956932378161708, -2.003], "policy_blue_reward": [-1.0099999999999996, 0.29069323781521406, -2.01, -1.0069999999999997, -2.0069999999999997, -1.0099999999999993, -1.0189999999999992, -1.0109999999999995, -1.044999999999999, -2.0079999999999996, -1.009, -2.006, -2.1819999999999835, -2.0109999999999997, -2.0099999999999993, -2.0119999999999996, -1.0199999999999996, -2.0069999999999997, -2.003, -2.0059999999999993, -1.0119999999999993, -1.552, -1.0089999999999997, -1.0239999999999987, -2.0069999999999997, -0.514, -1.0119999999999998, 1.529721875000007, -2.006, -2.003, -1.003, -1.0129999999999997, -2.01, -1.0059999999999996, -1.0029999999999997, -1.517, -1.0039999999999998, -0.009000000000000001, -1.097999999999998, -0.015000000000000005, -2.0089999999999995, -2.003, -2.016, -2.005, -2.008, -0.536], "policy_red_v11_reward": [-2.012999999999999, 0.447], "policy_red_v48_reward": [-0.5599999999999998, 0.5066932378161698], "policy_red_v31_reward": [0.47301562499999994], "policy_red_v47_reward": [1.4926932378161704, 0.9696932378152052, 0.6545625000000006], "policy_red_v5_reward": [-0.004], "policy_red_v1_reward": [-0.5630000000000001, 0.4067656250000009], "policy_red_v12_reward": [-2.0149999999999997, 0.5016932378152038], "policy_red_v56_reward": [-2.005, -2.003], "policy_red_v57_reward": [3.363864417772946, -1.0169999999999988, -0.5043067621838304, -0.003], "policy_red_v30_reward": [-0.15430676218383022, 0.49969323781520414, 0.17605000000000037], "policy_red_v21_reward": [1.19015625, 0.49769323781617014], "policy_red_v4_reward": [-2.0059999999999993], "policy_red_v32_reward": [-2.0119999999999987, 1.4886925427729423], "policy_red_v10_reward": [-1.5899999999999999], "policy_red_v55_reward": [1.5016932378152037], "policy_red_v41_reward": [1.5076932378161698], "policy_red_v37_reward": [-2.002], "policy_red_v26_reward": [0.4901030335440556], "policy_red_v13_reward": [-0.02300000000000001], "policy_red_v25_reward": [-1.0099999999999993, -0.04230676218382623], "policy_red_v40_reward": [-0.5579999999999999], "policy_red_v45_reward": [0.816], "policy_red_v46_reward": [-0.29849999999999655], "policy_red_v22_reward": [-1.0109999999999997, 1.4946925427729418], "policy_red_v39_reward": [-0.16300000000000003, 3.4096612927729444], "policy_red_v34_reward": [0.4861030335440564], "policy_red_v9_reward": [-1.0139999999999996], "policy_red_v7_reward": [-1.0099999999999998], "policy_red_v43_reward": [0.18105000000000004], "policy_red_v50_reward": [0.5061030335440548], "policy_red_v6_reward": [1.9125625, -0.011000000000000003], "policy_red_v52_reward": [0.4986932378161706], "policy_red_v29_reward": [-1.0159999999999991], "policy_red_v15_reward": [-0.027499999999999414]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8159192810530069, "mean_inference_ms": 7.721299492076827, "mean_action_processing_ms": 0.2933578540241658, "mean_env_wait_ms": 0.3891358770311011, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10242223739624023, "StateBufferConnector_ms": 0.004243254661560059, "ViewRequirementAgentConnector_ms": 0.11733627319335938}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 744000, "num_agent_steps_trained": 744000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.04449642012958, "num_env_steps_trained_throughput_per_sec": 200.04449642012958, "timesteps_total": 372000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 744000, "timers": {"training_iteration_time_ms": 20058.289, "sample_time_ms": 1165.609, "learn_time_ms": 18806.705, "learn_throughput": 212.69, "synch_weights_time_ms": 82.682}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 744000, "num_agent_steps_trained": 744000}, "done": false, "episodes_total": 1443, "training_iteration": 93, "trial_id": "a9680_00000", "date": "2023-09-24_03-10-15", "timestamp": 1695539415, "time_this_iter_s": 20.005682945251465, "time_total_s": 1856.0673003196716, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1de49810>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1df9bd90>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1df9bbe0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1856.0673003196716, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 5.514705882352941, "ram_util_percent": 23.855882352941176}, "win_rate": 0.72, "league_size": 62}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6482743846873444, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.03895774582779268, "policy_loss": -0.042325414403361114, "vf_loss": 0.15309441683348268, "vf_explained_var": 0.8363235297923287, "kl": 0.013936955326431319, "entropy": 1.5356778085231781, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 89760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "sampler_results": {"episode_reward_max": 4.471073280589113, "episode_reward_min": -6.749999999999995, "episode_reward_mean": 2.443323178682204, "episode_len_mean": 75.29, "episode_media": {}, "episodes_this_iter": 45, "policy_reward_min": {"red_v25": -1.0099999999999993, "red": -11.340999999999962, "blue": -2.016, "red_v40": -0.5579999999999999, "red_v45": 0.816, "red_v56": -2.003, "red_v46": -0.29849999999999655, "red_v22": -1.0109999999999997, "red_v48": 0.5066932378161698, "red_v39": -0.16300000000000003, "red_v21": 0.17905000000000004, "red_v34": 0.4861030335440564, "red_v9": -1.0139999999999996, "red_v3": -2.003, "red_v7": -1.0129999999999992, "red_v30": 0.17605000000000037, "red_v43": 0.18105000000000004, "red_v57": -1.0169999999999988, "red_v50": 0.5061030335440548, "red_v6": -0.011000000000000003, "red_v12": -2.035999999999998, "red_v52": 0.4986932378161706, "red_v29": -1.0159999999999991, "red_v11": 0.447, "red_v1": 0.4067656250000009, "red_v15": -0.027499999999999414, "red_v32": 2.9436932378161704, "red_v13": -2.0169999999999995, "red_v19": 0.49469323781616986, "red_v59": 1.4716932378161731, "red_v38": -2.0069999999999997, "red_v60": -2.0089999999999995, "red_v16": -1.008, "red_v18": 0.8500000000000001, "red_v54": 0.4946932378152038, "red_v55": -2.005, "red_v20": 0.4996932378161695}, "policy_reward_max": {"red_v25": 0.3922836050000006, "red": 3.992926917772942, "blue": 4.590999999999986, "red_v40": -0.5579999999999999, "red_v45": 0.816, "red_v56": -2.003, "red_v46": -0.29849999999999655, "red_v22": 1.909458167772942, "red_v48": 0.5066932378161698, "red_v39": 3.4096612927729444, "red_v21": 0.49769323781617014, "red_v34": 0.4861030335440564, "red_v9": -1.0139999999999996, "red_v3": -2.003, "red_v7": -1.0099999999999998, "red_v30": 0.49969323781520414, "red_v43": 1.166050000000001, "red_v57": -0.003, "red_v50": 0.5061030335440548, "red_v6": 1.9125625, "red_v12": 0.5016932378152038, "red_v52": 0.4986932378161706, "red_v29": -1.0159999999999991, "red_v11": 0.447, "red_v1": 0.4067656250000009, "red_v15": 0.4936932378161706, "red_v32": 2.9436932378161704, "red_v13": -0.016000000000000007, "red_v19": 0.49469323781616986, "red_v59": 1.4716932378161731, "red_v38": -2.0069999999999997, "red_v60": -2.0089999999999995, "red_v16": -1.008, "red_v18": 0.8500000000000001, "red_v54": 0.4946932378152038, "red_v55": -2.005, "red_v20": 0.4996932378161695}, "policy_reward_mean": {"red_v25": -0.220007719061275, "red": 2.8824589532984586, "blue": -1.009850625, "red_v40": -0.5579999999999999, "red_v45": 0.816, "red_v56": -2.003, "red_v46": -0.29849999999999655, "red_v22": 1.064506427636471, "red_v48": 0.5066932378161698, "red_v39": 1.3083643910332925, "red_v21": 0.3383716189080851, "red_v34": 0.4861030335440564, "red_v9": -1.0139999999999996, "red_v3": -2.003, "red_v7": -1.0114999999999994, "red_v30": 0.33787161890760226, "red_v43": 0.6735500000000005, "red_v57": -0.5081022540612764, "red_v50": 0.5061030335440548, "red_v6": 0.95078125, "red_v12": -0.4243730873949311, "red_v52": 0.4986932378161706, "red_v29": -1.0159999999999991, "red_v11": 0.447, "red_v1": 0.4067656250000009, "red_v15": 0.23309661890808558, "red_v32": 2.9436932378161704, "red_v13": -1.3496666666666661, "red_v19": 0.49469323781616986, "red_v59": 1.4716932378161731, "red_v38": -2.0069999999999997, "red_v60": -2.0089999999999995, "red_v16": -1.008, "red_v18": 0.8500000000000001, "red_v54": 0.4946932378152038, "red_v55": -2.005, "red_v20": 0.4996932378161695}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.465981489442593, 2.1438468750000004, 2.9261932378161704, 3.7078651128161786, 2.4324276128161713, 1.8748148550000006, 1.2939531250000007, 1.488337408544055, 0.1851932378161738, 2.4517557378161716, 2.4840369878152044, 3.9946989756323408, 2.0034151128161852, 3.3019432378161717, 1.1635031250000003, 3.941573975632342, 3.9464993963602266, 2.4660838628161708, 1.3827367300000002, 2.47089636281617, 3.960495850631375, 1.4873374085440547, 3.6651686585440557, 2.465380737815205, 3.997218146360225, 2.491446783544055, 1.9072557378161732, 2.4666776128161705, 4.471073280589113, 3.9898083506313746, 1.4784119878161703, 2.4686776128161707, 3.416354530589116, 2.480708862815204, 3.9697458506323406, 0.9603807378161707, 2.435396362816171, 2.29726147563235, 3.43119323781617, 2.3800336050000004, 2.9721932378161706, 0.9044588628161714, 2.7575369878161764, 2.941943237815206, 1.4777088628161708, 0.4181932378161719, 3.431683350631377, 1.1689093750000001, 3.66627448781617, 1.9640838628161708, 2.9809276128161706, 2.989743658544055, 1.48422448781617, 1.4715994878161704, 1.7121117300000024, 2.475708862815204, 2.9203864756323448, 4.470968146360226, 2.9466932378161714, 2.455646362816172, 1.9769269177729425, 1.9791151128161701, 2.9530526128161707, 3.976073975632341, 4.392339600632344, -6.749999999999995, 1.4482713628161705, 2.9672783644425924, 1.8691117300000002, 2.434099487816172, 2.983931158544055, 2.4751932378161703, 1.8565682378161754, 3.669571362816171, 1.98211511281617, 1.4850362927729424, 2.469677612816171, 2.4642713628161705, 2.4131514055891143, 1.4518338628161713, 2.454240112816171, 3.967152100632341, 1.4712783644425922, 1.8308026128161767, 2.4847436585440548, 0.7618807378161705, 2.974411987816171, 3.8413331677729423, 4.145727612816171, 3.9599333506323413, 3.982105225631374, 0.83134375, 2.48452136281617, 2.425036987816172, 3.8789924678161705, 0.9260468750000002, 0.6389250000000003, 2.8765057378161734, 1.9694901128161708, 3.97344897563234], "episode_lengths": [17, 33, 32, 105, 53, 22, 47, 21, 480, 44, 18, 28, 649, 48, 15, 68, 63, 35, 15, 31, 61, 21, 27, 36, 25, 18, 76, 37, 36, 25, 26, 37, 74, 27, 45, 36, 63, 168, 32, 16, 32, 107, 178, 48, 27, 672, 65, 13, 22, 35, 21, 19, 22, 30, 151, 27, 64, 41, 64, 47, 21, 25, 45, 36, 111, 1280, 39, 18, 23, 62, 23, 32, 104, 23, 25, 18, 37, 39, 107, 51, 49, 43, 18, 125, 19, 196, 26, 19, 37, 49, 26, 18, 23, 82, 27, 17, 40, 124, 33, 44], "policy_red_v25_reward": [-1.0099999999999993, -0.04230676218382623, 0.3922836050000006], "policy_blue_reward": [-1.0089999999999997, -1.0239999999999987, -2.0069999999999997, -0.514, -1.0119999999999998, 1.529721875000007, -2.006, -2.003, -1.003, -1.0129999999999997, -2.01, -1.0059999999999996, -1.0029999999999997, -1.517, -1.0039999999999998, -0.009000000000000001, -1.097999999999998, -0.015000000000000005, -2.0089999999999995, -2.003, -2.016, -2.005, -2.008, -0.536, -0.015000000000000006, -1.0099999999999991, -2.0089999999999995, 4.590999999999986, -0.006, -1.017, -0.004, -1.0089999999999992, -2.006, -1.0109999999999995, -1.0109999999999997, -2.009999999999999, -1.0149999999999992, -2.005, -0.012000000000000004, -1.0059999999999998, -1.0189999999999981, -2.0079999999999996, -1.512, -0.04000000000000003, -2.0089999999999995], "policy_red_v40_reward": [-0.5579999999999999], "policy_red_v45_reward": [0.816], "policy_red_v56_reward": [-2.003], "policy_red_v46_reward": [-0.29849999999999655], "policy_red_v22_reward": [-1.0109999999999997, 1.4946925427729418, 1.8648749999999998, 1.909458167772942], "policy_red_v48_reward": [0.5066932378161698], "policy_red_v39_reward": [-0.16300000000000003, 3.4096612927729444, 1.495103033544055, 0.4916932378161707], "policy_red_v21_reward": [0.49769323781617014, 0.17905000000000004], "policy_red_v34_reward": [0.4861030335440564], "policy_red_v9_reward": [-1.0139999999999996], "policy_red_v3_reward": [-2.003], "policy_red_v7_reward": [-1.0099999999999998, -1.0129999999999992], "policy_red_v30_reward": [0.49969323781520414, 0.17605000000000037], "policy_red_v43_reward": [0.18105000000000004, 1.166050000000001], "policy_red_v57_reward": [-1.0169999999999988, -0.5043067621838304, -0.003], "policy_red_v50_reward": [0.5061030335440548], "policy_red_v6_reward": [1.9125625, -0.011000000000000003], "policy_red_v12_reward": [0.5016932378152038, -2.035999999999998, 0.26118750000000046], "policy_red_v52_reward": [0.4986932378161706], "policy_red_v29_reward": [-1.0159999999999991], "policy_red_v11_reward": [0.447], "policy_red_v1_reward": [0.4067656250000009], "policy_red_v15_reward": [-0.027499999999999414, 0.4936932378161706], "policy_red_v32_reward": [2.9436932378161704], "policy_red_v13_reward": [-2.015999999999999, -0.016000000000000007, -2.0169999999999995], "policy_red_v19_reward": [0.49469323781616986], "policy_red_v59_reward": [1.4716932378161731], "policy_red_v38_reward": [-2.0069999999999997], "policy_red_v60_reward": [-2.0089999999999995], "policy_red_v16_reward": [-1.008], "policy_red_v18_reward": [0.8500000000000001], "policy_red_v54_reward": [0.4946932378152038], "policy_red_v55_reward": [-2.005], "policy_red_v20_reward": [0.4996932378161695]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8163766473688081, "mean_inference_ms": 7.716922980398843, "mean_action_processing_ms": 0.29330562475638644, "mean_env_wait_ms": 0.38854126325870636, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10029113292694092, "StateBufferConnector_ms": 0.004142284393310547, "ViewRequirementAgentConnector_ms": 0.11489176750183105}}, "episode_reward_max": 4.471073280589113, "episode_reward_min": -6.749999999999995, "episode_reward_mean": 2.443323178682204, "episode_len_mean": 75.29, "episodes_this_iter": 45, "policy_reward_min": {"red_v25": -1.0099999999999993, "red": -11.340999999999962, "blue": -2.016, "red_v40": -0.5579999999999999, "red_v45": 0.816, "red_v56": -2.003, "red_v46": -0.29849999999999655, "red_v22": -1.0109999999999997, "red_v48": 0.5066932378161698, "red_v39": -0.16300000000000003, "red_v21": 0.17905000000000004, "red_v34": 0.4861030335440564, "red_v9": -1.0139999999999996, "red_v3": -2.003, "red_v7": -1.0129999999999992, "red_v30": 0.17605000000000037, "red_v43": 0.18105000000000004, "red_v57": -1.0169999999999988, "red_v50": 0.5061030335440548, "red_v6": -0.011000000000000003, "red_v12": -2.035999999999998, "red_v52": 0.4986932378161706, "red_v29": -1.0159999999999991, "red_v11": 0.447, "red_v1": 0.4067656250000009, "red_v15": -0.027499999999999414, "red_v32": 2.9436932378161704, "red_v13": -2.0169999999999995, "red_v19": 0.49469323781616986, "red_v59": 1.4716932378161731, "red_v38": -2.0069999999999997, "red_v60": -2.0089999999999995, "red_v16": -1.008, "red_v18": 0.8500000000000001, "red_v54": 0.4946932378152038, "red_v55": -2.005, "red_v20": 0.4996932378161695}, "policy_reward_max": {"red_v25": 0.3922836050000006, "red": 3.992926917772942, "blue": 4.590999999999986, "red_v40": -0.5579999999999999, "red_v45": 0.816, "red_v56": -2.003, "red_v46": -0.29849999999999655, "red_v22": 1.909458167772942, "red_v48": 0.5066932378161698, "red_v39": 3.4096612927729444, "red_v21": 0.49769323781617014, "red_v34": 0.4861030335440564, "red_v9": -1.0139999999999996, "red_v3": -2.003, "red_v7": -1.0099999999999998, "red_v30": 0.49969323781520414, "red_v43": 1.166050000000001, "red_v57": -0.003, "red_v50": 0.5061030335440548, "red_v6": 1.9125625, "red_v12": 0.5016932378152038, "red_v52": 0.4986932378161706, "red_v29": -1.0159999999999991, "red_v11": 0.447, "red_v1": 0.4067656250000009, "red_v15": 0.4936932378161706, "red_v32": 2.9436932378161704, "red_v13": -0.016000000000000007, "red_v19": 0.49469323781616986, "red_v59": 1.4716932378161731, "red_v38": -2.0069999999999997, "red_v60": -2.0089999999999995, "red_v16": -1.008, "red_v18": 0.8500000000000001, "red_v54": 0.4946932378152038, "red_v55": -2.005, "red_v20": 0.4996932378161695}, "policy_reward_mean": {"red_v25": -0.220007719061275, "red": 2.8824589532984586, "blue": -1.009850625, "red_v40": -0.5579999999999999, "red_v45": 0.816, "red_v56": -2.003, "red_v46": -0.29849999999999655, "red_v22": 1.064506427636471, "red_v48": 0.5066932378161698, "red_v39": 1.3083643910332925, "red_v21": 0.3383716189080851, "red_v34": 0.4861030335440564, "red_v9": -1.0139999999999996, "red_v3": -2.003, "red_v7": -1.0114999999999994, "red_v30": 0.33787161890760226, "red_v43": 0.6735500000000005, "red_v57": -0.5081022540612764, "red_v50": 0.5061030335440548, "red_v6": 0.95078125, "red_v12": -0.4243730873949311, "red_v52": 0.4986932378161706, "red_v29": -1.0159999999999991, "red_v11": 0.447, "red_v1": 0.4067656250000009, "red_v15": 0.23309661890808558, "red_v32": 2.9436932378161704, "red_v13": -1.3496666666666661, "red_v19": 0.49469323781616986, "red_v59": 1.4716932378161731, "red_v38": -2.0069999999999997, "red_v60": -2.0089999999999995, "red_v16": -1.008, "red_v18": 0.8500000000000001, "red_v54": 0.4946932378152038, "red_v55": -2.005, "red_v20": 0.4996932378161695}, "hist_stats": {"episode_reward": [2.465981489442593, 2.1438468750000004, 2.9261932378161704, 3.7078651128161786, 2.4324276128161713, 1.8748148550000006, 1.2939531250000007, 1.488337408544055, 0.1851932378161738, 2.4517557378161716, 2.4840369878152044, 3.9946989756323408, 2.0034151128161852, 3.3019432378161717, 1.1635031250000003, 3.941573975632342, 3.9464993963602266, 2.4660838628161708, 1.3827367300000002, 2.47089636281617, 3.960495850631375, 1.4873374085440547, 3.6651686585440557, 2.465380737815205, 3.997218146360225, 2.491446783544055, 1.9072557378161732, 2.4666776128161705, 4.471073280589113, 3.9898083506313746, 1.4784119878161703, 2.4686776128161707, 3.416354530589116, 2.480708862815204, 3.9697458506323406, 0.9603807378161707, 2.435396362816171, 2.29726147563235, 3.43119323781617, 2.3800336050000004, 2.9721932378161706, 0.9044588628161714, 2.7575369878161764, 2.941943237815206, 1.4777088628161708, 0.4181932378161719, 3.431683350631377, 1.1689093750000001, 3.66627448781617, 1.9640838628161708, 2.9809276128161706, 2.989743658544055, 1.48422448781617, 1.4715994878161704, 1.7121117300000024, 2.475708862815204, 2.9203864756323448, 4.470968146360226, 2.9466932378161714, 2.455646362816172, 1.9769269177729425, 1.9791151128161701, 2.9530526128161707, 3.976073975632341, 4.392339600632344, -6.749999999999995, 1.4482713628161705, 2.9672783644425924, 1.8691117300000002, 2.434099487816172, 2.983931158544055, 2.4751932378161703, 1.8565682378161754, 3.669571362816171, 1.98211511281617, 1.4850362927729424, 2.469677612816171, 2.4642713628161705, 2.4131514055891143, 1.4518338628161713, 2.454240112816171, 3.967152100632341, 1.4712783644425922, 1.8308026128161767, 2.4847436585440548, 0.7618807378161705, 2.974411987816171, 3.8413331677729423, 4.145727612816171, 3.9599333506323413, 3.982105225631374, 0.83134375, 2.48452136281617, 2.425036987816172, 3.8789924678161705, 0.9260468750000002, 0.6389250000000003, 2.8765057378161734, 1.9694901128161708, 3.97344897563234], "episode_lengths": [17, 33, 32, 105, 53, 22, 47, 21, 480, 44, 18, 28, 649, 48, 15, 68, 63, 35, 15, 31, 61, 21, 27, 36, 25, 18, 76, 37, 36, 25, 26, 37, 74, 27, 45, 36, 63, 168, 32, 16, 32, 107, 178, 48, 27, 672, 65, 13, 22, 35, 21, 19, 22, 30, 151, 27, 64, 41, 64, 47, 21, 25, 45, 36, 111, 1280, 39, 18, 23, 62, 23, 32, 104, 23, 25, 18, 37, 39, 107, 51, 49, 43, 18, 125, 19, 196, 26, 19, 37, 49, 26, 18, 23, 82, 27, 17, 40, 124, 33, 44], "policy_red_v25_reward": [-1.0099999999999993, -0.04230676218382623, 0.3922836050000006], "policy_blue_reward": [-1.0089999999999997, -1.0239999999999987, -2.0069999999999997, -0.514, -1.0119999999999998, 1.529721875000007, -2.006, -2.003, -1.003, -1.0129999999999997, -2.01, -1.0059999999999996, -1.0029999999999997, -1.517, -1.0039999999999998, -0.009000000000000001, -1.097999999999998, -0.015000000000000005, -2.0089999999999995, -2.003, -2.016, -2.005, -2.008, -0.536, -0.015000000000000006, -1.0099999999999991, -2.0089999999999995, 4.590999999999986, -0.006, -1.017, -0.004, -1.0089999999999992, -2.006, -1.0109999999999995, -1.0109999999999997, -2.009999999999999, -1.0149999999999992, -2.005, -0.012000000000000004, -1.0059999999999998, -1.0189999999999981, -2.0079999999999996, -1.512, -0.04000000000000003, -2.0089999999999995], "policy_red_v40_reward": [-0.5579999999999999], "policy_red_v45_reward": [0.816], "policy_red_v56_reward": [-2.003], "policy_red_v46_reward": [-0.29849999999999655], "policy_red_v22_reward": [-1.0109999999999997, 1.4946925427729418, 1.8648749999999998, 1.909458167772942], "policy_red_v48_reward": [0.5066932378161698], "policy_red_v39_reward": [-0.16300000000000003, 3.4096612927729444, 1.495103033544055, 0.4916932378161707], "policy_red_v21_reward": [0.49769323781617014, 0.17905000000000004], "policy_red_v34_reward": [0.4861030335440564], "policy_red_v9_reward": [-1.0139999999999996], "policy_red_v3_reward": [-2.003], "policy_red_v7_reward": [-1.0099999999999998, -1.0129999999999992], "policy_red_v30_reward": [0.49969323781520414, 0.17605000000000037], "policy_red_v43_reward": [0.18105000000000004, 1.166050000000001], "policy_red_v57_reward": [-1.0169999999999988, -0.5043067621838304, -0.003], "policy_red_v50_reward": [0.5061030335440548], "policy_red_v6_reward": [1.9125625, -0.011000000000000003], "policy_red_v12_reward": [0.5016932378152038, -2.035999999999998, 0.26118750000000046], "policy_red_v52_reward": [0.4986932378161706], "policy_red_v29_reward": [-1.0159999999999991], "policy_red_v11_reward": [0.447], "policy_red_v1_reward": [0.4067656250000009], "policy_red_v15_reward": [-0.027499999999999414, 0.4936932378161706], "policy_red_v32_reward": [2.9436932378161704], "policy_red_v13_reward": [-2.015999999999999, -0.016000000000000007, -2.0169999999999995], "policy_red_v19_reward": [0.49469323781616986], "policy_red_v59_reward": [1.4716932378161731], "policy_red_v38_reward": [-2.0069999999999997], "policy_red_v60_reward": [-2.0089999999999995], "policy_red_v16_reward": [-1.008], "policy_red_v18_reward": [0.8500000000000001], "policy_red_v54_reward": [0.4946932378152038], "policy_red_v55_reward": [-2.005], "policy_red_v20_reward": [0.4996932378161695]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8163766473688081, "mean_inference_ms": 7.716922980398843, "mean_action_processing_ms": 0.29330562475638644, "mean_env_wait_ms": 0.38854126325870636, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10029113292694092, "StateBufferConnector_ms": 0.004142284393310547, "ViewRequirementAgentConnector_ms": 0.11489176750183105}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 204.51166900376478, "num_env_steps_trained_throughput_per_sec": 204.51166900376478, "timesteps_total": 376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 20078.637, "sample_time_ms": 1167.859, "learn_time_ms": 18824.124, "learn_throughput": 212.493, "synch_weights_time_ms": 83.279}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "episodes_total": 1488, "training_iteration": 94, "trial_id": "a9680_00000", "date": "2023-09-24_03-10-38", "timestamp": 1695539438, "time_this_iter_s": 19.568006992340088, "time_total_s": 1875.6353073120117, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1de9d240>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1de40040>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1de40670>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1875.6353073120117, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 5.375, "ram_util_percent": 23.975}, "win_rate": 0.68, "league_size": 63}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8194593018541734, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.03815792121555812, "policy_loss": -0.049915892067413856, "vf_loss": 0.16440676139512408, "vf_explained_var": 0.8264329751332601, "kl": 0.016430081085976173, "entropy": 1.523103375484546, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 90720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 760000, "num_agent_steps_trained": 760000}, "sampler_results": {"episode_reward_max": 4.4729646006323405, "episode_reward_min": -6.749999999999995, "episode_reward_mean": 2.3665184256849816, "episode_len_mean": 91.02, "episode_media": {}, "episodes_this_iter": 48, "policy_reward_min": {"red_v30": 0.17605000000000037, "red": -11.340999999999962, "blue": -2.016, "red_v6": -0.011000000000000003, "red_v57": -1.0059999999999996, "red_v7": -1.0129999999999992, "red_v32": 2.9436932378161704, "red_v39": 0.4916932378161707, "red_v13": -2.0169999999999995, "red_v19": 0.49469323781616986, "red_v59": -2.024, "red_v38": -2.0069999999999997, "red_v22": 1.8648749999999998, "red_v21": -2.0069999999999997, "red_v60": -2.0089999999999995, "red_v15": 0.4936932378161706, "red_v12": -2.035999999999998, "red_v16": -1.008, "red_v18": 0.8500000000000001, "red_v43": 0.14805000000000068, "red_v54": 0.4946932378152038, "red_v55": -2.005, "red_v25": 0.3922836050000006, "red_v20": 0.4996932378161695, "red_v26": 1.8270624999999998, "red_v23": -1.005, "red_v27": -0.5330653855574066, "red_v46": -0.055999999999999994, "red_v31": 1.3902836050000011, "red_v24": 1.497693237816171, "red_v45": 0.39528360500000026, "red_v4": -0.008, "red_v2": -2.017999999999999, "red_v36": 0.48393461444259245, "red_v47": 0.4676932378161702, "red_v28": -2.015999999999999}, "policy_reward_max": {"red_v30": 0.17605000000000037, "red": 3.992926917772942, "blue": 4.590999999999986, "red_v6": -0.011000000000000003, "red_v57": 0.17505000000000015, "red_v7": -1.0129999999999992, "red_v32": 2.9436932378161704, "red_v39": 1.495103033544055, "red_v13": -0.003, "red_v19": 0.49469323781616986, "red_v59": 1.4716932378161731, "red_v38": -1.015999999999999, "red_v22": 1.909458167772942, "red_v21": 1.4365213628161724, "red_v60": -1.004, "red_v15": 0.4936932378161706, "red_v12": 0.26118750000000046, "red_v16": -1.008, "red_v18": 0.8500000000000001, "red_v43": 1.166050000000001, "red_v54": 0.4946932378152038, "red_v55": -2.005, "red_v25": 0.3922836050000006, "red_v20": 0.4996932378161695, "red_v26": 1.8270624999999998, "red_v23": -1.005, "red_v27": 0.4839346144425925, "red_v46": 0.060296874999999805, "red_v31": 1.3902836050000011, "red_v24": 1.497693237816171, "red_v45": 0.39528360500000026, "red_v4": -0.008, "red_v2": -2.017999999999999, "red_v36": 0.48393461444259245, "red_v47": 0.4676932378161702, "red_v28": -2.015999999999999}, "policy_reward_mean": {"red_v30": 0.17605000000000037, "red": 2.9365119433069267, "blue": -1.0646938775510204, "red_v6": -0.011000000000000003, "red_v57": -0.27798333333333314, "red_v7": -1.0129999999999992, "red_v32": 2.9436932378161704, "red_v39": 0.9933981356801128, "red_v13": -1.0129999999999997, "red_v19": 0.49469323781616986, "red_v59": -0.27615338109191345, "red_v38": -1.5114999999999994, "red_v22": 1.8871665838864708, "red_v21": -0.48335715929595674, "red_v60": -1.5064999999999997, "red_v15": 0.4936932378161706, "red_v12": -0.8874062499999986, "red_v16": -1.008, "red_v18": 0.8500000000000001, "red_v43": 0.6570500000000008, "red_v54": 0.4946932378152038, "red_v55": -2.005, "red_v25": 0.3922836050000006, "red_v20": 0.4996932378161695, "red_v26": 1.8270624999999998, "red_v23": -1.005, "red_v27": -0.024565385557407032, "red_v46": 0.0021484374999999056, "red_v31": 1.3902836050000011, "red_v24": 1.497693237816171, "red_v45": 0.39528360500000026, "red_v4": -0.008, "red_v2": -2.017999999999999, "red_v36": 0.48393461444259245, "red_v47": 0.4676932378161702, "red_v28": -2.015999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.66627448781617, 1.9640838628161708, 2.9809276128161706, 2.989743658544055, 1.48422448781617, 1.4715994878161704, 1.7121117300000024, 2.475708862815204, 2.9203864756323448, 4.470968146360226, 2.9466932378161714, 2.455646362816172, 1.9769269177729425, 1.9791151128161701, 2.9530526128161707, 3.976073975632341, 4.392339600632344, -6.749999999999995, 1.4482713628161705, 2.9672783644425924, 1.8691117300000002, 2.434099487816172, 2.983931158544055, 2.4751932378161703, 1.8565682378161754, 3.669571362816171, 1.98211511281617, 1.4850362927729424, 2.469677612816171, 2.4642713628161705, 2.4131514055891143, 1.4518338628161713, 2.454240112816171, 3.967152100632341, 1.4712783644425922, 1.8308026128161767, 2.4847436585440548, 0.7618807378161705, 2.974411987816171, 3.8413331677729423, 4.145727612816171, 3.9599333506323413, 3.982105225631374, 0.83134375, 2.48452136281617, 2.425036987816172, 3.8789924678161705, 0.9260468750000002, 0.6389250000000003, 2.8765057378161734, 1.9694901128161708, 3.97344897563234, 1.8227557378161756, 1.98070886281617, 2.474490112816171, 2.474005737816171, 2.4822237927729427, 1.6665031250000002, 1.98422448781617, 0.9405057378161708, 2.471981489442592, 3.6620557378161704, 2.447396362816171, 1.4910369878152037, 2.469380042772942, 2.484333167772942, 2.4537244878161713, 2.461865112816171, 3.596336987816173, 0.6745369878161718, 2.427075239442594, 3.3898309772587654, 3.9717528522587626, 2.4646776128161707, 0.8984432378161734, 0.07899011281620671, 2.371990112816173, 2.451833862816171, 2.9677557378161707, 4.356711217816171, 2.3984155335440582, 4.4729646006323405, 1.7482146006323775, 1.968446783544055, 3.56578673, 1.8583773550000002, 2.4470213628161703, 2.969684614442593, 1.454161987816172, 2.3599901128161713, 3.9713466022587625, 1.848386475632411, 2.33875, 1.124161987816178, 2.45005261281617, 2.47600573781617, 2.465083862815204, 2.48622448781617, 1.4460213628161713, 1.4717124085440554], "episode_lengths": [22, 35, 21, 19, 22, 30, 151, 27, 64, 41, 64, 47, 21, 25, 45, 36, 111, 1280, 39, 18, 23, 62, 23, 32, 104, 23, 25, 18, 37, 39, 107, 51, 49, 43, 18, 125, 19, 196, 26, 19, 37, 49, 26, 18, 23, 82, 27, 17, 40, 124, 33, 44, 172, 27, 33, 28, 22, 15, 22, 60, 17, 28, 63, 18, 36, 19, 54, 41, 66, 242, 51, 95, 24, 37, 80, 961, 129, 51, 44, 53, 92, 39, 599, 18, 15, 34, 55, 16, 42, 129, 26, 1280, 16, 362, 45, 28, 35, 22, 55, 29], "policy_red_v30_reward": [0.17605000000000037], "policy_blue_reward": [-2.016, -2.005, -2.008, -0.536, -0.015000000000000006, -1.0099999999999991, -2.0089999999999995, 4.590999999999986, -0.006, -1.017, -0.004, -1.0089999999999992, -2.006, -1.0109999999999995, -1.0109999999999997, -2.009999999999999, -1.0149999999999992, -2.005, -0.012000000000000004, -1.0059999999999998, -1.0189999999999981, -2.0079999999999996, -1.512, -0.04000000000000003, -2.0089999999999995, -2.006, -1.0089999999999997, -1.0119999999999996, -1.0079999999999996, -2.0029999999999997, -1.518999999999999, -1.0149999999999988, -2.003, -1.0079999999999993, -1.0049999999999997, -1.572, -1.0139999999999991, -1.0119999999999993, -1.0379999999999971, -1.0189999999999988, -0.5049999999999996, 0.474, -2.006, -1.0159999999999991, -1.1150000000000002, -1.0179999999999993, -1.0109999999999995, -1.0119999999999996, -2.01], "policy_red_v6_reward": [-0.011000000000000003], "policy_red_v57_reward": [-0.003, 0.17505000000000015, -1.0059999999999996], "policy_red_v7_reward": [-1.0129999999999992], "policy_red_v32_reward": [2.9436932378161704], "policy_red_v39_reward": [1.495103033544055, 0.4916932378161707], "policy_red_v13_reward": [-2.015999999999999, -0.016000000000000007, -2.0169999999999995, -0.003], "policy_red_v19_reward": [0.49469323781616986], "policy_red_v59_reward": [1.4716932378161731, -2.024], "policy_red_v38_reward": [-2.0069999999999997, -1.015999999999999], "policy_red_v22_reward": [1.8648749999999998, 1.909458167772942], "policy_red_v21_reward": [0.17905000000000004, -2.0069999999999997, -1.542, 1.4365213628161724], "policy_red_v60_reward": [-2.0089999999999995, -1.004], "policy_red_v15_reward": [0.4936932378161706], "policy_red_v12_reward": [-2.035999999999998, 0.26118750000000046], "policy_red_v16_reward": [-1.008], "policy_red_v18_reward": [0.8500000000000001], "policy_red_v43_reward": [1.166050000000001, 0.14805000000000068], "policy_red_v54_reward": [0.4946932378152038], "policy_red_v55_reward": [-2.005], "policy_red_v25_reward": [0.3922836050000006], "policy_red_v20_reward": [0.4996932378161695], "policy_red_v26_reward": [1.8270624999999998], "policy_red_v23_reward": [-1.005], "policy_red_v27_reward": [-0.5330653855574066, 0.4839346144425925], "policy_red_v46_reward": [0.060296874999999805, -0.055999999999999994], "policy_red_v31_reward": [1.3902836050000011], "policy_red_v24_reward": [1.497693237816171], "policy_red_v45_reward": [0.39528360500000026], "policy_red_v4_reward": [-0.008], "policy_red_v2_reward": [-2.017999999999999], "policy_red_v36_reward": [0.48393461444259245], "policy_red_v47_reward": [0.4676932378161702], "policy_red_v28_reward": [-2.015999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8150488023665016, "mean_inference_ms": 7.696119075095026, "mean_action_processing_ms": 0.29329315510058523, "mean_env_wait_ms": 0.38873373910453873, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10105502605438232, "StateBufferConnector_ms": 0.004131317138671875, "ViewRequirementAgentConnector_ms": 0.11466836929321289}}, "episode_reward_max": 4.4729646006323405, "episode_reward_min": -6.749999999999995, "episode_reward_mean": 2.3665184256849816, "episode_len_mean": 91.02, "episodes_this_iter": 48, "policy_reward_min": {"red_v30": 0.17605000000000037, "red": -11.340999999999962, "blue": -2.016, "red_v6": -0.011000000000000003, "red_v57": -1.0059999999999996, "red_v7": -1.0129999999999992, "red_v32": 2.9436932378161704, "red_v39": 0.4916932378161707, "red_v13": -2.0169999999999995, "red_v19": 0.49469323781616986, "red_v59": -2.024, "red_v38": -2.0069999999999997, "red_v22": 1.8648749999999998, "red_v21": -2.0069999999999997, "red_v60": -2.0089999999999995, "red_v15": 0.4936932378161706, "red_v12": -2.035999999999998, "red_v16": -1.008, "red_v18": 0.8500000000000001, "red_v43": 0.14805000000000068, "red_v54": 0.4946932378152038, "red_v55": -2.005, "red_v25": 0.3922836050000006, "red_v20": 0.4996932378161695, "red_v26": 1.8270624999999998, "red_v23": -1.005, "red_v27": -0.5330653855574066, "red_v46": -0.055999999999999994, "red_v31": 1.3902836050000011, "red_v24": 1.497693237816171, "red_v45": 0.39528360500000026, "red_v4": -0.008, "red_v2": -2.017999999999999, "red_v36": 0.48393461444259245, "red_v47": 0.4676932378161702, "red_v28": -2.015999999999999}, "policy_reward_max": {"red_v30": 0.17605000000000037, "red": 3.992926917772942, "blue": 4.590999999999986, "red_v6": -0.011000000000000003, "red_v57": 0.17505000000000015, "red_v7": -1.0129999999999992, "red_v32": 2.9436932378161704, "red_v39": 1.495103033544055, "red_v13": -0.003, "red_v19": 0.49469323781616986, "red_v59": 1.4716932378161731, "red_v38": -1.015999999999999, "red_v22": 1.909458167772942, "red_v21": 1.4365213628161724, "red_v60": -1.004, "red_v15": 0.4936932378161706, "red_v12": 0.26118750000000046, "red_v16": -1.008, "red_v18": 0.8500000000000001, "red_v43": 1.166050000000001, "red_v54": 0.4946932378152038, "red_v55": -2.005, "red_v25": 0.3922836050000006, "red_v20": 0.4996932378161695, "red_v26": 1.8270624999999998, "red_v23": -1.005, "red_v27": 0.4839346144425925, "red_v46": 0.060296874999999805, "red_v31": 1.3902836050000011, "red_v24": 1.497693237816171, "red_v45": 0.39528360500000026, "red_v4": -0.008, "red_v2": -2.017999999999999, "red_v36": 0.48393461444259245, "red_v47": 0.4676932378161702, "red_v28": -2.015999999999999}, "policy_reward_mean": {"red_v30": 0.17605000000000037, "red": 2.9365119433069267, "blue": -1.0646938775510204, "red_v6": -0.011000000000000003, "red_v57": -0.27798333333333314, "red_v7": -1.0129999999999992, "red_v32": 2.9436932378161704, "red_v39": 0.9933981356801128, "red_v13": -1.0129999999999997, "red_v19": 0.49469323781616986, "red_v59": -0.27615338109191345, "red_v38": -1.5114999999999994, "red_v22": 1.8871665838864708, "red_v21": -0.48335715929595674, "red_v60": -1.5064999999999997, "red_v15": 0.4936932378161706, "red_v12": -0.8874062499999986, "red_v16": -1.008, "red_v18": 0.8500000000000001, "red_v43": 0.6570500000000008, "red_v54": 0.4946932378152038, "red_v55": -2.005, "red_v25": 0.3922836050000006, "red_v20": 0.4996932378161695, "red_v26": 1.8270624999999998, "red_v23": -1.005, "red_v27": -0.024565385557407032, "red_v46": 0.0021484374999999056, "red_v31": 1.3902836050000011, "red_v24": 1.497693237816171, "red_v45": 0.39528360500000026, "red_v4": -0.008, "red_v2": -2.017999999999999, "red_v36": 0.48393461444259245, "red_v47": 0.4676932378161702, "red_v28": -2.015999999999999}, "hist_stats": {"episode_reward": [3.66627448781617, 1.9640838628161708, 2.9809276128161706, 2.989743658544055, 1.48422448781617, 1.4715994878161704, 1.7121117300000024, 2.475708862815204, 2.9203864756323448, 4.470968146360226, 2.9466932378161714, 2.455646362816172, 1.9769269177729425, 1.9791151128161701, 2.9530526128161707, 3.976073975632341, 4.392339600632344, -6.749999999999995, 1.4482713628161705, 2.9672783644425924, 1.8691117300000002, 2.434099487816172, 2.983931158544055, 2.4751932378161703, 1.8565682378161754, 3.669571362816171, 1.98211511281617, 1.4850362927729424, 2.469677612816171, 2.4642713628161705, 2.4131514055891143, 1.4518338628161713, 2.454240112816171, 3.967152100632341, 1.4712783644425922, 1.8308026128161767, 2.4847436585440548, 0.7618807378161705, 2.974411987816171, 3.8413331677729423, 4.145727612816171, 3.9599333506323413, 3.982105225631374, 0.83134375, 2.48452136281617, 2.425036987816172, 3.8789924678161705, 0.9260468750000002, 0.6389250000000003, 2.8765057378161734, 1.9694901128161708, 3.97344897563234, 1.8227557378161756, 1.98070886281617, 2.474490112816171, 2.474005737816171, 2.4822237927729427, 1.6665031250000002, 1.98422448781617, 0.9405057378161708, 2.471981489442592, 3.6620557378161704, 2.447396362816171, 1.4910369878152037, 2.469380042772942, 2.484333167772942, 2.4537244878161713, 2.461865112816171, 3.596336987816173, 0.6745369878161718, 2.427075239442594, 3.3898309772587654, 3.9717528522587626, 2.4646776128161707, 0.8984432378161734, 0.07899011281620671, 2.371990112816173, 2.451833862816171, 2.9677557378161707, 4.356711217816171, 2.3984155335440582, 4.4729646006323405, 1.7482146006323775, 1.968446783544055, 3.56578673, 1.8583773550000002, 2.4470213628161703, 2.969684614442593, 1.454161987816172, 2.3599901128161713, 3.9713466022587625, 1.848386475632411, 2.33875, 1.124161987816178, 2.45005261281617, 2.47600573781617, 2.465083862815204, 2.48622448781617, 1.4460213628161713, 1.4717124085440554], "episode_lengths": [22, 35, 21, 19, 22, 30, 151, 27, 64, 41, 64, 47, 21, 25, 45, 36, 111, 1280, 39, 18, 23, 62, 23, 32, 104, 23, 25, 18, 37, 39, 107, 51, 49, 43, 18, 125, 19, 196, 26, 19, 37, 49, 26, 18, 23, 82, 27, 17, 40, 124, 33, 44, 172, 27, 33, 28, 22, 15, 22, 60, 17, 28, 63, 18, 36, 19, 54, 41, 66, 242, 51, 95, 24, 37, 80, 961, 129, 51, 44, 53, 92, 39, 599, 18, 15, 34, 55, 16, 42, 129, 26, 1280, 16, 362, 45, 28, 35, 22, 55, 29], "policy_red_v30_reward": [0.17605000000000037], "policy_blue_reward": [-2.016, -2.005, -2.008, -0.536, -0.015000000000000006, -1.0099999999999991, -2.0089999999999995, 4.590999999999986, -0.006, -1.017, -0.004, -1.0089999999999992, -2.006, -1.0109999999999995, -1.0109999999999997, -2.009999999999999, -1.0149999999999992, -2.005, -0.012000000000000004, -1.0059999999999998, -1.0189999999999981, -2.0079999999999996, -1.512, -0.04000000000000003, -2.0089999999999995, -2.006, -1.0089999999999997, -1.0119999999999996, -1.0079999999999996, -2.0029999999999997, -1.518999999999999, -1.0149999999999988, -2.003, -1.0079999999999993, -1.0049999999999997, -1.572, -1.0139999999999991, -1.0119999999999993, -1.0379999999999971, -1.0189999999999988, -0.5049999999999996, 0.474, -2.006, -1.0159999999999991, -1.1150000000000002, -1.0179999999999993, -1.0109999999999995, -1.0119999999999996, -2.01], "policy_red_v6_reward": [-0.011000000000000003], "policy_red_v57_reward": [-0.003, 0.17505000000000015, -1.0059999999999996], "policy_red_v7_reward": [-1.0129999999999992], "policy_red_v32_reward": [2.9436932378161704], "policy_red_v39_reward": [1.495103033544055, 0.4916932378161707], "policy_red_v13_reward": [-2.015999999999999, -0.016000000000000007, -2.0169999999999995, -0.003], "policy_red_v19_reward": [0.49469323781616986], "policy_red_v59_reward": [1.4716932378161731, -2.024], "policy_red_v38_reward": [-2.0069999999999997, -1.015999999999999], "policy_red_v22_reward": [1.8648749999999998, 1.909458167772942], "policy_red_v21_reward": [0.17905000000000004, -2.0069999999999997, -1.542, 1.4365213628161724], "policy_red_v60_reward": [-2.0089999999999995, -1.004], "policy_red_v15_reward": [0.4936932378161706], "policy_red_v12_reward": [-2.035999999999998, 0.26118750000000046], "policy_red_v16_reward": [-1.008], "policy_red_v18_reward": [0.8500000000000001], "policy_red_v43_reward": [1.166050000000001, 0.14805000000000068], "policy_red_v54_reward": [0.4946932378152038], "policy_red_v55_reward": [-2.005], "policy_red_v25_reward": [0.3922836050000006], "policy_red_v20_reward": [0.4996932378161695], "policy_red_v26_reward": [1.8270624999999998], "policy_red_v23_reward": [-1.005], "policy_red_v27_reward": [-0.5330653855574066, 0.4839346144425925], "policy_red_v46_reward": [0.060296874999999805, -0.055999999999999994], "policy_red_v31_reward": [1.3902836050000011], "policy_red_v24_reward": [1.497693237816171], "policy_red_v45_reward": [0.39528360500000026], "policy_red_v4_reward": [-0.008], "policy_red_v2_reward": [-2.017999999999999], "policy_red_v36_reward": [0.48393461444259245], "policy_red_v47_reward": [0.4676932378161702], "policy_red_v28_reward": [-2.015999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8150488023665016, "mean_inference_ms": 7.696119075095026, "mean_action_processing_ms": 0.29329315510058523, "mean_env_wait_ms": 0.38873373910453873, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10105502605438232, "StateBufferConnector_ms": 0.004131317138671875, "ViewRequirementAgentConnector_ms": 0.11466836929321289}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 760000, "num_agent_steps_trained": 760000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 205.65138216187162, "num_env_steps_trained_throughput_per_sec": 205.65138216187162, "timesteps_total": 380000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 760000, "timers": {"training_iteration_time_ms": 20028.766, "sample_time_ms": 1158.143, "learn_time_ms": 18783.87, "learn_throughput": 212.949, "synch_weights_time_ms": 83.416}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 760000, "num_agent_steps_trained": 760000}, "done": false, "episodes_total": 1536, "training_iteration": 95, "trial_id": "a9680_00000", "date": "2023-09-24_03-11-01", "timestamp": 1695539461, "time_this_iter_s": 19.4644992351532, "time_total_s": 1895.099806547165, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1de9d1e0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1de412d0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1de41360>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1895.099806547165, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 5.345454545454546, "ram_util_percent": 24.084848484848486}, "win_rate": 0.71, "league_size": 64}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5892581950873135, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.04788611236144789, "policy_loss": -0.04500148301061321, "vf_loss": 0.17554089876357465, "vf_explained_var": 0.8262023879836004, "kl": 0.014769475881917061, "entropy": 1.5291175965219737, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 91680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "sampler_results": {"episode_reward_max": 4.4729646006323405, "episode_reward_min": 0.07899011281620671, "episode_reward_mean": 2.37599991033761, "episode_len_mean": 90.45, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"blue": -2.0149999999999992, "red": -0.00430676218382986, "red_v20": 0.4996932378161695, "red_v26": 0.48093461444259256, "red_v21": -2.0069999999999997, "red_v23": -1.005, "red_v57": -1.0059999999999996, "red_v38": -1.015999999999999, "red_v43": 0.14805000000000068, "red_v27": -0.5603074572270585, "red_v46": -0.055999999999999994, "red_v31": 0.5006932378161698, "red_v24": 1.497693237816171, "red_v59": -2.024, "red_v45": 0.39528360500000026, "red_v4": -0.008, "red_v2": -2.017999999999999, "red_v36": 0.48393461444259245, "red_v47": 0.4676932378161702, "red_v13": -1.0149999999999992, "red_v60": -1.004, "red_v28": -2.015999999999999, "red_v51": -2.002, "red_v3": 0.44, "red_v9": 1.2712343750000001, "red_v10": -2.008, "red_v14": -0.5919999999999999, "red_v19": -1.0059999999999996, "red_v42": -1.501, "red_v17": -2.0020000000000002, "red_v5": -2.013, "red_v22": 0.4956932378152037, "red_v56": 0.3862836050000005, "red_v25": -0.5569999999999997, "red_v30": 0.4799375, "red_v7": -2.017999999999999, "red_v1": 0.17350000000000754, "red_v12": -0.026000000000000016, "red_v33": -1.001, "red_v50": 0.5026932378161697}, "policy_reward_max": {"blue": 0.8380000000000001, "red": 3.9974425427729416, "red_v20": 0.4996932378161695, "red_v26": 1.8270624999999998, "red_v21": 1.4365213628161724, "red_v23": -1.005, "red_v57": 0.17505000000000015, "red_v38": -1.015999999999999, "red_v43": 0.14805000000000068, "red_v27": 0.4839346144425925, "red_v46": 0.060296874999999805, "red_v31": 1.3902836050000011, "red_v24": 1.497693237816171, "red_v59": 0.47831250000000025, "red_v45": 0.39528360500000026, "red_v4": -0.008, "red_v2": -1.0269999999999986, "red_v36": 0.48393461444259245, "red_v47": 0.4676932378161702, "red_v13": -0.003, "red_v60": -1.004, "red_v28": 1.7651586050000008, "red_v51": -2.002, "red_v3": 0.44, "red_v9": 1.2712343750000001, "red_v10": -1.0099999999999996, "red_v14": -0.5919999999999999, "red_v19": -1.0059999999999996, "red_v42": -1.501, "red_v17": -2.0020000000000002, "red_v5": -2.013, "red_v22": 0.4956932378152037, "red_v56": 0.3862836050000005, "red_v25": -0.5569999999999997, "red_v30": 0.4799375, "red_v7": -2.017999999999999, "red_v1": 0.17350000000000754, "red_v12": -0.026000000000000016, "red_v33": -1.001, "red_v50": 0.5026932378161697}, "policy_reward_mean": {"blue": -1.1523246527777773, "red": 3.0626788241496126, "red_v20": 0.4996932378161695, "red_v26": 1.1539985572212963, "red_v21": -0.29126512072795424, "red_v23": -1.005, "red_v57": -0.46364999999999973, "red_v38": -1.015999999999999, "red_v43": 0.14805000000000068, "red_v27": -0.1956095570854681, "red_v46": 0.0021484374999999056, "red_v31": 0.9454884214080854, "red_v24": 1.497693237816171, "red_v59": -0.7728437499999998, "red_v45": 0.39528360500000026, "red_v4": -0.008, "red_v2": -1.5224999999999986, "red_v36": 0.48393461444259245, "red_v47": 0.4676932378161702, "red_v13": -0.5089999999999996, "red_v60": -1.004, "red_v28": -0.12542069749999918, "red_v51": -2.002, "red_v3": 0.44, "red_v9": 1.2712343750000001, "red_v10": -1.509, "red_v14": -0.5919999999999999, "red_v19": -1.0059999999999996, "red_v42": -1.501, "red_v17": -2.0020000000000002, "red_v5": -2.013, "red_v22": 0.4956932378152037, "red_v56": 0.3862836050000005, "red_v25": -0.5569999999999997, "red_v30": 0.4799375, "red_v7": -2.017999999999999, "red_v1": 0.17350000000000754, "red_v12": -0.026000000000000016, "red_v33": -1.001, "red_v50": 0.5026932378161697}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.9694901128161708, 3.97344897563234, 1.8227557378161756, 1.98070886281617, 2.474490112816171, 2.474005737816171, 2.4822237927729427, 1.6665031250000002, 1.98422448781617, 0.9405057378161708, 2.471981489442592, 3.6620557378161704, 2.447396362816171, 1.4910369878152037, 2.469380042772942, 2.484333167772942, 2.4537244878161713, 2.461865112816171, 3.596336987816173, 0.6745369878161718, 2.427075239442594, 3.3898309772587654, 3.9717528522587626, 2.4646776128161707, 0.8984432378161734, 0.07899011281620671, 2.371990112816173, 2.451833862816171, 2.9677557378161707, 4.356711217816171, 2.3984155335440582, 4.4729646006323405, 1.7482146006323775, 1.968446783544055, 3.56578673, 1.8583773550000002, 2.4470213628161703, 2.969684614442593, 1.454161987816172, 2.3599901128161713, 3.9713466022587625, 1.848386475632411, 2.33875, 1.124161987816178, 2.45005261281617, 2.47600573781617, 2.465083862815204, 2.48622448781617, 1.4460213628161713, 1.4717124085440554, 1.1658000000000004, 3.615149487816172, 3.2769014055891237, 3.9928112013169965, 2.898505737816171, 3.4185682378152045, 1.4692783644425924, 2.2688518428161757, 2.4117088628161714, 2.493333862815204, 1.7659276128161734, 2.4645752394425924, 2.8321307378161737, 2.466568237816171, 2.4891499085440545, 3.9689403522587634, 2.166503125, 1.9924425427729422, 0.9779780335440551, 0.2353338628161693, 2.334755042772942, 0.9724936585440553, 1.4828182378161703, 1.97652136281617, 2.9788175427729424, 3.976589600631375, 3.864554967816171, 3.796911987816171, 2.4724119878161703, 2.97870886281617, 2.935333167772942, 0.9830057378161698, 0.986630042772942, 1.463896362816171, 0.6261932378161836, 2.1517687500000005, 1.4635682378161712, 2.37933048, 2.47941198781617, 1.4620526128161706, 2.9227713628161727, 2.47881823781617, 2.468271362816171, 3.298240112816173, 1.9628956677729434, 1.3551932378161697, 3.9782614756323404, 1.9659814894425924, 2.3836273550000007, 3.9688239756323402], "episode_lengths": [33, 44, 172, 27, 33, 28, 22, 15, 22, 60, 17, 28, 63, 18, 36, 19, 54, 41, 66, 242, 51, 95, 24, 37, 80, 961, 129, 51, 44, 53, 92, 39, 599, 18, 15, 34, 55, 16, 42, 129, 26, 1280, 16, 362, 45, 28, 35, 22, 55, 29, 16, 62, 187, 27, 60, 40, 18, 104, 91, 19, 85, 19, 116, 40, 17, 28, 15, 16, 40, 1043, 108, 35, 24, 23, 24, 31, 39, 58, 26, 27, 19, 28, 20, 31, 352, 26, 40, 17, 26, 45, 71, 24, 39, 49, 31, 160, 40, 17, 18, 52], "policy_blue_reward": [-2.0089999999999995, -2.006, -1.0089999999999997, -1.0119999999999996, -1.0079999999999996, -2.0029999999999997, -1.518999999999999, -1.0149999999999988, -2.003, -1.0079999999999993, -1.0049999999999997, -1.572, -1.0139999999999991, -1.0119999999999993, -1.0379999999999971, -1.0189999999999988, -0.5049999999999996, 0.474, -2.006, -1.0159999999999991, -1.1150000000000002, -1.0179999999999993, -1.0109999999999995, -1.0119999999999996, -2.01, -2.0060000000000002, -1.001, -1.011, -1.0039999999999998, -2.0049999999999994, -1.0309999999999975, 0.46939062499999995, -2.006, -0.005, 0.8380000000000001, -0.006, -1.0089999999999997, -2.0149999999999992, -1.0039999999999998, -1.0069999999999995, -2.0109999999999992, -1.0109999999999995, -1.0099999999999993, -2.011999999999999, -1.537], "policy_red_v20_reward": [0.4996932378161695], "policy_red_v26_reward": [1.8270624999999998, 0.48093461444259256], "policy_red_v21_reward": [-2.0069999999999997, -1.542, 1.4365213628161724, 0.1530500000000009, 0.503103033544055], "policy_red_v23_reward": [-1.005], "policy_red_v57_reward": [0.17505000000000015, -1.0059999999999996, -0.5599999999999999], "policy_red_v38_reward": [-1.015999999999999], "policy_red_v43_reward": [0.14805000000000068], "policy_red_v27_reward": [-0.5330653855574066, 0.4839346144425925, -0.5603074572270585, -0.1729999999999997], "policy_red_v46_reward": [0.060296874999999805, -0.055999999999999994], "policy_red_v31_reward": [1.3902836050000011, 0.5006932378161698], "policy_red_v24_reward": [1.497693237816171], "policy_red_v59_reward": [-2.024, 0.47831250000000025], "policy_red_v45_reward": [0.39528360500000026], "policy_red_v4_reward": [-0.008], "policy_red_v2_reward": [-2.017999999999999, -1.0269999999999986], "policy_red_v36_reward": [0.48393461444259245], "policy_red_v47_reward": [0.4676932378161702], "policy_red_v13_reward": [-0.003, -1.0149999999999992], "policy_red_v60_reward": [-1.004], "policy_red_v28_reward": [-2.015999999999999, 1.7651586050000008], "policy_red_v51_reward": [-2.002], "policy_red_v3_reward": [0.44], "policy_red_v9_reward": [1.2712343750000001], "policy_red_v10_reward": [-1.0099999999999996, -2.008], "policy_red_v14_reward": [-0.5919999999999999], "policy_red_v19_reward": [-1.0059999999999996], "policy_red_v42_reward": [-1.501], "policy_red_v17_reward": [-2.0020000000000002], "policy_red_v5_reward": [-2.013], "policy_red_v22_reward": [0.4956932378152037], "policy_red_v56_reward": [0.3862836050000005], "policy_red_v25_reward": [-0.5569999999999997], "policy_red_v30_reward": [0.4799375], "policy_red_v7_reward": [-2.017999999999999], "policy_red_v1_reward": [0.17350000000000754], "policy_red_v12_reward": [-0.026000000000000016], "policy_red_v33_reward": [-1.001], "policy_red_v50_reward": [0.5026932378161697]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8160111257510665, "mean_inference_ms": 7.717216331688171, "mean_action_processing_ms": 0.29438451440267366, "mean_env_wait_ms": 0.3901009647426564, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10348546504974365, "StateBufferConnector_ms": 0.004216790199279785, "ViewRequirementAgentConnector_ms": 0.11662650108337402}}, "episode_reward_max": 4.4729646006323405, "episode_reward_min": 0.07899011281620671, "episode_reward_mean": 2.37599991033761, "episode_len_mean": 90.45, "episodes_this_iter": 50, "policy_reward_min": {"blue": -2.0149999999999992, "red": -0.00430676218382986, "red_v20": 0.4996932378161695, "red_v26": 0.48093461444259256, "red_v21": -2.0069999999999997, "red_v23": -1.005, "red_v57": -1.0059999999999996, "red_v38": -1.015999999999999, "red_v43": 0.14805000000000068, "red_v27": -0.5603074572270585, "red_v46": -0.055999999999999994, "red_v31": 0.5006932378161698, "red_v24": 1.497693237816171, "red_v59": -2.024, "red_v45": 0.39528360500000026, "red_v4": -0.008, "red_v2": -2.017999999999999, "red_v36": 0.48393461444259245, "red_v47": 0.4676932378161702, "red_v13": -1.0149999999999992, "red_v60": -1.004, "red_v28": -2.015999999999999, "red_v51": -2.002, "red_v3": 0.44, "red_v9": 1.2712343750000001, "red_v10": -2.008, "red_v14": -0.5919999999999999, "red_v19": -1.0059999999999996, "red_v42": -1.501, "red_v17": -2.0020000000000002, "red_v5": -2.013, "red_v22": 0.4956932378152037, "red_v56": 0.3862836050000005, "red_v25": -0.5569999999999997, "red_v30": 0.4799375, "red_v7": -2.017999999999999, "red_v1": 0.17350000000000754, "red_v12": -0.026000000000000016, "red_v33": -1.001, "red_v50": 0.5026932378161697}, "policy_reward_max": {"blue": 0.8380000000000001, "red": 3.9974425427729416, "red_v20": 0.4996932378161695, "red_v26": 1.8270624999999998, "red_v21": 1.4365213628161724, "red_v23": -1.005, "red_v57": 0.17505000000000015, "red_v38": -1.015999999999999, "red_v43": 0.14805000000000068, "red_v27": 0.4839346144425925, "red_v46": 0.060296874999999805, "red_v31": 1.3902836050000011, "red_v24": 1.497693237816171, "red_v59": 0.47831250000000025, "red_v45": 0.39528360500000026, "red_v4": -0.008, "red_v2": -1.0269999999999986, "red_v36": 0.48393461444259245, "red_v47": 0.4676932378161702, "red_v13": -0.003, "red_v60": -1.004, "red_v28": 1.7651586050000008, "red_v51": -2.002, "red_v3": 0.44, "red_v9": 1.2712343750000001, "red_v10": -1.0099999999999996, "red_v14": -0.5919999999999999, "red_v19": -1.0059999999999996, "red_v42": -1.501, "red_v17": -2.0020000000000002, "red_v5": -2.013, "red_v22": 0.4956932378152037, "red_v56": 0.3862836050000005, "red_v25": -0.5569999999999997, "red_v30": 0.4799375, "red_v7": -2.017999999999999, "red_v1": 0.17350000000000754, "red_v12": -0.026000000000000016, "red_v33": -1.001, "red_v50": 0.5026932378161697}, "policy_reward_mean": {"blue": -1.1523246527777773, "red": 3.0626788241496126, "red_v20": 0.4996932378161695, "red_v26": 1.1539985572212963, "red_v21": -0.29126512072795424, "red_v23": -1.005, "red_v57": -0.46364999999999973, "red_v38": -1.015999999999999, "red_v43": 0.14805000000000068, "red_v27": -0.1956095570854681, "red_v46": 0.0021484374999999056, "red_v31": 0.9454884214080854, "red_v24": 1.497693237816171, "red_v59": -0.7728437499999998, "red_v45": 0.39528360500000026, "red_v4": -0.008, "red_v2": -1.5224999999999986, "red_v36": 0.48393461444259245, "red_v47": 0.4676932378161702, "red_v13": -0.5089999999999996, "red_v60": -1.004, "red_v28": -0.12542069749999918, "red_v51": -2.002, "red_v3": 0.44, "red_v9": 1.2712343750000001, "red_v10": -1.509, "red_v14": -0.5919999999999999, "red_v19": -1.0059999999999996, "red_v42": -1.501, "red_v17": -2.0020000000000002, "red_v5": -2.013, "red_v22": 0.4956932378152037, "red_v56": 0.3862836050000005, "red_v25": -0.5569999999999997, "red_v30": 0.4799375, "red_v7": -2.017999999999999, "red_v1": 0.17350000000000754, "red_v12": -0.026000000000000016, "red_v33": -1.001, "red_v50": 0.5026932378161697}, "hist_stats": {"episode_reward": [1.9694901128161708, 3.97344897563234, 1.8227557378161756, 1.98070886281617, 2.474490112816171, 2.474005737816171, 2.4822237927729427, 1.6665031250000002, 1.98422448781617, 0.9405057378161708, 2.471981489442592, 3.6620557378161704, 2.447396362816171, 1.4910369878152037, 2.469380042772942, 2.484333167772942, 2.4537244878161713, 2.461865112816171, 3.596336987816173, 0.6745369878161718, 2.427075239442594, 3.3898309772587654, 3.9717528522587626, 2.4646776128161707, 0.8984432378161734, 0.07899011281620671, 2.371990112816173, 2.451833862816171, 2.9677557378161707, 4.356711217816171, 2.3984155335440582, 4.4729646006323405, 1.7482146006323775, 1.968446783544055, 3.56578673, 1.8583773550000002, 2.4470213628161703, 2.969684614442593, 1.454161987816172, 2.3599901128161713, 3.9713466022587625, 1.848386475632411, 2.33875, 1.124161987816178, 2.45005261281617, 2.47600573781617, 2.465083862815204, 2.48622448781617, 1.4460213628161713, 1.4717124085440554, 1.1658000000000004, 3.615149487816172, 3.2769014055891237, 3.9928112013169965, 2.898505737816171, 3.4185682378152045, 1.4692783644425924, 2.2688518428161757, 2.4117088628161714, 2.493333862815204, 1.7659276128161734, 2.4645752394425924, 2.8321307378161737, 2.466568237816171, 2.4891499085440545, 3.9689403522587634, 2.166503125, 1.9924425427729422, 0.9779780335440551, 0.2353338628161693, 2.334755042772942, 0.9724936585440553, 1.4828182378161703, 1.97652136281617, 2.9788175427729424, 3.976589600631375, 3.864554967816171, 3.796911987816171, 2.4724119878161703, 2.97870886281617, 2.935333167772942, 0.9830057378161698, 0.986630042772942, 1.463896362816171, 0.6261932378161836, 2.1517687500000005, 1.4635682378161712, 2.37933048, 2.47941198781617, 1.4620526128161706, 2.9227713628161727, 2.47881823781617, 2.468271362816171, 3.298240112816173, 1.9628956677729434, 1.3551932378161697, 3.9782614756323404, 1.9659814894425924, 2.3836273550000007, 3.9688239756323402], "episode_lengths": [33, 44, 172, 27, 33, 28, 22, 15, 22, 60, 17, 28, 63, 18, 36, 19, 54, 41, 66, 242, 51, 95, 24, 37, 80, 961, 129, 51, 44, 53, 92, 39, 599, 18, 15, 34, 55, 16, 42, 129, 26, 1280, 16, 362, 45, 28, 35, 22, 55, 29, 16, 62, 187, 27, 60, 40, 18, 104, 91, 19, 85, 19, 116, 40, 17, 28, 15, 16, 40, 1043, 108, 35, 24, 23, 24, 31, 39, 58, 26, 27, 19, 28, 20, 31, 352, 26, 40, 17, 26, 45, 71, 24, 39, 49, 31, 160, 40, 17, 18, 52], "policy_blue_reward": [-2.0089999999999995, -2.006, -1.0089999999999997, -1.0119999999999996, -1.0079999999999996, -2.0029999999999997, -1.518999999999999, -1.0149999999999988, -2.003, -1.0079999999999993, -1.0049999999999997, -1.572, -1.0139999999999991, -1.0119999999999993, -1.0379999999999971, -1.0189999999999988, -0.5049999999999996, 0.474, -2.006, -1.0159999999999991, -1.1150000000000002, -1.0179999999999993, -1.0109999999999995, -1.0119999999999996, -2.01, -2.0060000000000002, -1.001, -1.011, -1.0039999999999998, -2.0049999999999994, -1.0309999999999975, 0.46939062499999995, -2.006, -0.005, 0.8380000000000001, -0.006, -1.0089999999999997, -2.0149999999999992, -1.0039999999999998, -1.0069999999999995, -2.0109999999999992, -1.0109999999999995, -1.0099999999999993, -2.011999999999999, -1.537], "policy_red_v20_reward": [0.4996932378161695], "policy_red_v26_reward": [1.8270624999999998, 0.48093461444259256], "policy_red_v21_reward": [-2.0069999999999997, -1.542, 1.4365213628161724, 0.1530500000000009, 0.503103033544055], "policy_red_v23_reward": [-1.005], "policy_red_v57_reward": [0.17505000000000015, -1.0059999999999996, -0.5599999999999999], "policy_red_v38_reward": [-1.015999999999999], "policy_red_v43_reward": [0.14805000000000068], "policy_red_v27_reward": [-0.5330653855574066, 0.4839346144425925, -0.5603074572270585, -0.1729999999999997], "policy_red_v46_reward": [0.060296874999999805, -0.055999999999999994], "policy_red_v31_reward": [1.3902836050000011, 0.5006932378161698], "policy_red_v24_reward": [1.497693237816171], "policy_red_v59_reward": [-2.024, 0.47831250000000025], "policy_red_v45_reward": [0.39528360500000026], "policy_red_v4_reward": [-0.008], "policy_red_v2_reward": [-2.017999999999999, -1.0269999999999986], "policy_red_v36_reward": [0.48393461444259245], "policy_red_v47_reward": [0.4676932378161702], "policy_red_v13_reward": [-0.003, -1.0149999999999992], "policy_red_v60_reward": [-1.004], "policy_red_v28_reward": [-2.015999999999999, 1.7651586050000008], "policy_red_v51_reward": [-2.002], "policy_red_v3_reward": [0.44], "policy_red_v9_reward": [1.2712343750000001], "policy_red_v10_reward": [-1.0099999999999996, -2.008], "policy_red_v14_reward": [-0.5919999999999999], "policy_red_v19_reward": [-1.0059999999999996], "policy_red_v42_reward": [-1.501], "policy_red_v17_reward": [-2.0020000000000002], "policy_red_v5_reward": [-2.013], "policy_red_v22_reward": [0.4956932378152037], "policy_red_v56_reward": [0.3862836050000005], "policy_red_v25_reward": [-0.5569999999999997], "policy_red_v30_reward": [0.4799375], "policy_red_v7_reward": [-2.017999999999999], "policy_red_v1_reward": [0.17350000000000754], "policy_red_v12_reward": [-0.026000000000000016], "policy_red_v33_reward": [-1.001], "policy_red_v50_reward": [0.5026932378161697]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8160111257510665, "mean_inference_ms": 7.717216331688171, "mean_action_processing_ms": 0.29438451440267366, "mean_env_wait_ms": 0.3901009647426564, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10348546504974365, "StateBufferConnector_ms": 0.004216790199279785, "ViewRequirementAgentConnector_ms": 0.11662650108337402}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.18469000023276, "num_env_steps_trained_throughput_per_sec": 201.18469000023276, "timesteps_total": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 19969.604, "sample_time_ms": 1160.083, "learn_time_ms": 18723.81, "learn_throughput": 213.632, "synch_weights_time_ms": 82.274}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "episodes_total": 1586, "training_iteration": 96, "trial_id": "a9680_00000", "date": "2023-09-24_03-11-25", "timestamp": 1695539485, "time_this_iter_s": 19.891892671585083, "time_total_s": 1914.99169921875, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1de9e020>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b34284310>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1df4c0d0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1914.99169921875, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 5.424242424242424, "ram_util_percent": 24.187878787878788}, "win_rate": 0.72, "league_size": 65}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8225561073670784, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.053386610696422095, "policy_loss": -0.04073985096280618, "vf_loss": 0.1777582636840331, "vf_explained_var": 0.8385998704160254, "kl": 0.014957061966108198, "entropy": 1.483347879598538, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 92640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 776000, "num_agent_steps_trained": 776000}, "sampler_results": {"episode_reward_max": 4.159540112816171, "episode_reward_min": 0.2353338628161693, "episode_reward_mean": 2.477072749447979, "episode_len_mean": 76.24, "episode_media": {}, "episodes_this_iter": 51, "policy_reward_min": {"red_v21": 0.1530500000000009, "red": 0.0036932378161698143, "red_v27": -0.5603074572270585, "red_v57": -2.007999999999999, "red_v3": 0.44, "blue": -2.0219999999999985, "red_v28": 1.7651586050000008, "red_v2": -1.0269999999999986, "red_v9": 1.2712343750000001, "red_v10": -2.008, "red_v14": -0.5919999999999999, "red_v19": -1.0059999999999996, "red_v26": 0.18105000000000004, "red_v42": -1.501, "red_v17": -2.0020000000000002, "red_v5": -2.013, "red_v22": 0.4956932378152037, "red_v56": 0.3862836050000005, "red_v13": -1.0149999999999992, "red_v25": -1.0, "red_v59": 0.47831250000000025, "red_v30": 0.4799375, "red_v7": -2.017999999999999, "red_v1": -1.0109999999999995, "red_v12": -0.026000000000000016, "red_v31": 0.5006932378161698, "red_v33": -1.001, "red_v50": 0.5026932378161697, "red_v38": -1.0129999999999997, "red_v61": -2.006, "red_v11": 0.5066932378152039, "red_v32": -2.0069999999999997, "red_v43": 1.1750500000000008, "red_v41": -1.0109999999999997, "red_v36": 0.39328360500000026, "red_v63": -2.002, "red_v37": 0.4859346144425923, "red_v6": -0.009000000000000001, "red_v46": 0.9199346144425923, "red_v4": -2.0059999999999993, "red_v55": -1.0189999999999997, "red_v18": 0.16805000000000092, "red_v34": -0.15699999999999992, "red_v54": 0.4976925427729424}, "policy_reward_max": {"red_v21": 0.503103033544055, "red": 3.9974425427729416, "red_v27": -0.1729999999999997, "red_v57": -0.5599999999999999, "red_v3": 0.44, "blue": 0.8380000000000001, "red_v28": 1.7651586050000008, "red_v2": -1.0269999999999986, "red_v9": 1.2712343750000001, "red_v10": 1.9686093749999998, "red_v14": -0.5919999999999999, "red_v19": -1.0059999999999996, "red_v26": 0.48093461444259256, "red_v42": -0.5529999999999999, "red_v17": -2.0020000000000002, "red_v5": -2.013, "red_v22": 0.4956932378152037, "red_v56": 0.3862836050000005, "red_v13": -1.0149999999999992, "red_v25": -0.5569999999999997, "red_v59": 0.47831250000000025, "red_v30": 0.4799375, "red_v7": 0.67265625, "red_v1": 0.17350000000000754, "red_v12": -0.026000000000000016, "red_v31": 0.5006932378161698, "red_v33": -1.001, "red_v50": 0.5026932378161697, "red_v38": 1.1590500000000012, "red_v61": -2.006, "red_v11": 0.5066932378152039, "red_v32": -2.0069999999999997, "red_v43": 1.1750500000000008, "red_v41": -1.0069999999999997, "red_v36": 0.444, "red_v63": -2.002, "red_v37": 0.4859346144425923, "red_v6": -0.009000000000000001, "red_v46": 0.9199346144425923, "red_v4": -2.0059999999999993, "red_v55": -1.0189999999999997, "red_v18": 0.17505000000000015, "red_v34": -0.15699999999999992, "red_v54": 0.4976925427729424}, "policy_reward_mean": {"red_v21": 0.37869588266221604, "red": 3.1170135897667466, "red_v27": -0.36665372861352913, "red_v57": -1.2839999999999996, "red_v3": 0.44, "blue": -1.0924037063953485, "red_v28": 1.7651586050000008, "red_v2": -1.0269999999999986, "red_v9": 1.2712343750000001, "red_v10": -0.349796875, "red_v14": -0.5919999999999999, "red_v19": -1.0059999999999996, "red_v26": 0.3309923072212963, "red_v42": -1.027, "red_v17": -2.0020000000000002, "red_v5": -2.013, "red_v22": 0.4956932378152037, "red_v56": 0.3862836050000005, "red_v13": -1.0149999999999992, "red_v25": -0.7784999999999999, "red_v59": 0.47831250000000025, "red_v30": 0.4799375, "red_v7": -0.6726718749999995, "red_v1": -0.41874999999999596, "red_v12": -0.026000000000000016, "red_v31": 0.5006932378161698, "red_v33": -1.001, "red_v50": 0.5026932378161697, "red_v38": 0.07302500000000078, "red_v61": -2.006, "red_v11": 0.5066932378152039, "red_v32": -2.0069999999999997, "red_v43": 1.1750500000000008, "red_v41": -1.0089999999999997, "red_v36": 0.41864180250000016, "red_v63": -2.002, "red_v37": 0.4859346144425923, "red_v6": -0.009000000000000001, "red_v46": 0.9199346144425923, "red_v4": -2.0059999999999993, "red_v55": -1.0189999999999997, "red_v18": 0.17155000000000054, "red_v34": -0.15699999999999992, "red_v54": 0.4976925427729424}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.615149487816172, 3.2769014055891237, 3.9928112013169965, 2.898505737816171, 3.4185682378152045, 1.4692783644425924, 2.2688518428161757, 2.4117088628161714, 2.493333862815204, 1.7659276128161734, 2.4645752394425924, 2.8321307378161737, 2.466568237816171, 2.4891499085440545, 3.9689403522587634, 2.166503125, 1.9924425427729422, 0.9779780335440551, 0.2353338628161693, 2.334755042772942, 0.9724936585440553, 1.4828182378161703, 1.97652136281617, 2.9788175427729424, 3.976589600631375, 3.864554967816171, 3.796911987816171, 2.4724119878161703, 2.97870886281617, 2.935333167772942, 0.9830057378161698, 0.986630042772942, 1.463896362816171, 0.6261932378161836, 2.1517687500000005, 1.4635682378161712, 2.37933048, 2.47941198781617, 1.4620526128161706, 2.9227713628161727, 2.47881823781617, 2.468271362816171, 3.298240112816173, 1.9628956677729434, 1.3551932378161697, 3.9782614756323404, 1.9659814894425924, 2.3836273550000007, 3.9688239756323402, 4.119258862816173, 2.47478698781617, 2.4343963628161727, 1.3354531250000001, 1.9808182378161705, 1.071943237816189, 3.998620850631373, 2.4828182378152044, 1.3336406250000001, 2.490739417772942, 1.9754901128161706, 1.47297448781617, 2.4669744878161706, 2.483115112815204, 2.475005737815204, 4.159540112816171, 2.47330261281617, 2.4891499085440545, 3.427599487816171, 1.8837367300000003, 3.9806740322155334, 2.48863073781617, 2.46394323781617, 1.4046307378161738, 2.415865112816171, 2.48270886281617, 1.4493494878161721, 2.8272211050000005, 2.98333386281617, 2.9207713628161733, 2.273627852258786, 1.9794119878161702, 2.47589636281617, 2.987337408544055, 2.4547557378161717, 1.3388593750000002, 1.4577557378161714, 3.8870272635440553, 1.1743494878161775, 3.641180737816171, 2.4842244878161703, 2.496036987815204, 1.8275312499999998, 2.4810057378161705, 3.3226776128161712, 3.591243237816174, 3.959612227258763, 3.350146875, 3.9760732805891124, 1.9723026128161703, 2.3764086050000004], "episode_lengths": [62, 187, 27, 60, 40, 18, 104, 91, 19, 85, 19, 116, 40, 17, 28, 15, 16, 40, 1043, 108, 35, 24, 23, 24, 31, 39, 58, 26, 27, 19, 28, 20, 31, 352, 26, 40, 17, 26, 45, 71, 24, 39, 49, 31, 160, 40, 17, 18, 52, 59, 34, 63, 15, 24, 880, 21, 24, 19, 17, 33, 38, 38, 25, 28, 33, 29, 17, 30, 15, 17, 20, 48, 84, 105, 27, 46, 20, 19, 71, 1280, 26, 31, 21, 44, 13, 44, 19, 302, 52, 22, 18, 22, 28, 37, 96, 37, 17, 36, 29, 24], "policy_red_v21_reward": [0.1530500000000009, 0.503103033544055, 0.4799346144425924], "policy_red_v27_reward": [-0.5603074572270585, -0.1729999999999997], "policy_red_v57_reward": [-0.5599999999999999, -2.007999999999999], "policy_red_v3_reward": [0.44], "policy_blue_reward": [-2.0060000000000002, -1.001, -1.011, -1.0039999999999998, -2.0049999999999994, -1.0309999999999975, 0.46939062499999995, -2.006, -0.005, 0.8380000000000001, -0.006, -1.0089999999999997, -2.0149999999999992, -1.0039999999999998, -1.0069999999999995, -2.0109999999999992, -1.0109999999999995, -1.0099999999999993, -2.011999999999999, -1.537, -1.0079999999999996, -1.0179999999999985, -2.0079999999999996, 0.5802499999999997, -1.0039999999999998, -2.0079999999999996, -1.0039999999999998, -2.005, -1.0059999999999998, -1.006, -1.0049999999999997, -1.0039999999999998, -2.0219999999999985, -1.0029999999999997, -0.01800000000000001, -1.0079999999999996, -0.005, -2.0039999999999996, -2.0109999999999992, -1.0059999999999996, -1.0049999999999994, -1.0079999999999996, -1.0039999999999998], "policy_red_v28_reward": [1.7651586050000008], "policy_red_v2_reward": [-1.0269999999999986], "policy_red_v9_reward": [1.2712343750000001], "policy_red_v10_reward": [-1.0099999999999996, -2.008, 1.9686093749999998], "policy_red_v14_reward": [-0.5919999999999999], "policy_red_v19_reward": [-1.0059999999999996], "policy_red_v26_reward": [0.48093461444259256, 0.18105000000000004], "policy_red_v42_reward": [-1.501, -0.5529999999999999], "policy_red_v17_reward": [-2.0020000000000002], "policy_red_v5_reward": [-2.013], "policy_red_v22_reward": [0.4956932378152037], "policy_red_v56_reward": [0.3862836050000005], "policy_red_v13_reward": [-1.0149999999999992], "policy_red_v25_reward": [-0.5569999999999997, -1.0], "policy_red_v59_reward": [0.47831250000000025], "policy_red_v30_reward": [0.4799375], "policy_red_v7_reward": [-2.017999999999999, 0.67265625], "policy_red_v1_reward": [0.17350000000000754, -1.0109999999999995], "policy_red_v12_reward": [-0.026000000000000016], "policy_red_v31_reward": [0.5006932378161698], "policy_red_v33_reward": [-1.001], "policy_red_v50_reward": [0.5026932378161697], "policy_red_v38_reward": [1.1590500000000012, -1.0129999999999997], "policy_red_v61_reward": [-2.006], "policy_red_v11_reward": [0.5066932378152039], "policy_red_v32_reward": [-2.0069999999999997], "policy_red_v43_reward": [1.1750500000000008], "policy_red_v41_reward": [-1.0109999999999997, -1.0069999999999997], "policy_red_v36_reward": [0.444, 0.39328360500000026], "policy_red_v63_reward": [-2.002], "policy_red_v37_reward": [0.4859346144425923], "policy_red_v6_reward": [-0.009000000000000001], "policy_red_v46_reward": [0.9199346144425923], "policy_red_v4_reward": [-2.0059999999999993], "policy_red_v55_reward": [-1.0189999999999997], "policy_red_v18_reward": [0.17505000000000015, 0.16805000000000092], "policy_red_v34_reward": [-0.15699999999999992], "policy_red_v54_reward": [0.4976925427729424]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8187026904118239, "mean_inference_ms": 7.74681931926265, "mean_action_processing_ms": 0.29531932183258613, "mean_env_wait_ms": 0.3918198611826046, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10595107078552246, "StateBufferConnector_ms": 0.004331469535827637, "ViewRequirementAgentConnector_ms": 0.11910760402679443}}, "episode_reward_max": 4.159540112816171, "episode_reward_min": 0.2353338628161693, "episode_reward_mean": 2.477072749447979, "episode_len_mean": 76.24, "episodes_this_iter": 51, "policy_reward_min": {"red_v21": 0.1530500000000009, "red": 0.0036932378161698143, "red_v27": -0.5603074572270585, "red_v57": -2.007999999999999, "red_v3": 0.44, "blue": -2.0219999999999985, "red_v28": 1.7651586050000008, "red_v2": -1.0269999999999986, "red_v9": 1.2712343750000001, "red_v10": -2.008, "red_v14": -0.5919999999999999, "red_v19": -1.0059999999999996, "red_v26": 0.18105000000000004, "red_v42": -1.501, "red_v17": -2.0020000000000002, "red_v5": -2.013, "red_v22": 0.4956932378152037, "red_v56": 0.3862836050000005, "red_v13": -1.0149999999999992, "red_v25": -1.0, "red_v59": 0.47831250000000025, "red_v30": 0.4799375, "red_v7": -2.017999999999999, "red_v1": -1.0109999999999995, "red_v12": -0.026000000000000016, "red_v31": 0.5006932378161698, "red_v33": -1.001, "red_v50": 0.5026932378161697, "red_v38": -1.0129999999999997, "red_v61": -2.006, "red_v11": 0.5066932378152039, "red_v32": -2.0069999999999997, "red_v43": 1.1750500000000008, "red_v41": -1.0109999999999997, "red_v36": 0.39328360500000026, "red_v63": -2.002, "red_v37": 0.4859346144425923, "red_v6": -0.009000000000000001, "red_v46": 0.9199346144425923, "red_v4": -2.0059999999999993, "red_v55": -1.0189999999999997, "red_v18": 0.16805000000000092, "red_v34": -0.15699999999999992, "red_v54": 0.4976925427729424}, "policy_reward_max": {"red_v21": 0.503103033544055, "red": 3.9974425427729416, "red_v27": -0.1729999999999997, "red_v57": -0.5599999999999999, "red_v3": 0.44, "blue": 0.8380000000000001, "red_v28": 1.7651586050000008, "red_v2": -1.0269999999999986, "red_v9": 1.2712343750000001, "red_v10": 1.9686093749999998, "red_v14": -0.5919999999999999, "red_v19": -1.0059999999999996, "red_v26": 0.48093461444259256, "red_v42": -0.5529999999999999, "red_v17": -2.0020000000000002, "red_v5": -2.013, "red_v22": 0.4956932378152037, "red_v56": 0.3862836050000005, "red_v13": -1.0149999999999992, "red_v25": -0.5569999999999997, "red_v59": 0.47831250000000025, "red_v30": 0.4799375, "red_v7": 0.67265625, "red_v1": 0.17350000000000754, "red_v12": -0.026000000000000016, "red_v31": 0.5006932378161698, "red_v33": -1.001, "red_v50": 0.5026932378161697, "red_v38": 1.1590500000000012, "red_v61": -2.006, "red_v11": 0.5066932378152039, "red_v32": -2.0069999999999997, "red_v43": 1.1750500000000008, "red_v41": -1.0069999999999997, "red_v36": 0.444, "red_v63": -2.002, "red_v37": 0.4859346144425923, "red_v6": -0.009000000000000001, "red_v46": 0.9199346144425923, "red_v4": -2.0059999999999993, "red_v55": -1.0189999999999997, "red_v18": 0.17505000000000015, "red_v34": -0.15699999999999992, "red_v54": 0.4976925427729424}, "policy_reward_mean": {"red_v21": 0.37869588266221604, "red": 3.1170135897667466, "red_v27": -0.36665372861352913, "red_v57": -1.2839999999999996, "red_v3": 0.44, "blue": -1.0924037063953485, "red_v28": 1.7651586050000008, "red_v2": -1.0269999999999986, "red_v9": 1.2712343750000001, "red_v10": -0.349796875, "red_v14": -0.5919999999999999, "red_v19": -1.0059999999999996, "red_v26": 0.3309923072212963, "red_v42": -1.027, "red_v17": -2.0020000000000002, "red_v5": -2.013, "red_v22": 0.4956932378152037, "red_v56": 0.3862836050000005, "red_v13": -1.0149999999999992, "red_v25": -0.7784999999999999, "red_v59": 0.47831250000000025, "red_v30": 0.4799375, "red_v7": -0.6726718749999995, "red_v1": -0.41874999999999596, "red_v12": -0.026000000000000016, "red_v31": 0.5006932378161698, "red_v33": -1.001, "red_v50": 0.5026932378161697, "red_v38": 0.07302500000000078, "red_v61": -2.006, "red_v11": 0.5066932378152039, "red_v32": -2.0069999999999997, "red_v43": 1.1750500000000008, "red_v41": -1.0089999999999997, "red_v36": 0.41864180250000016, "red_v63": -2.002, "red_v37": 0.4859346144425923, "red_v6": -0.009000000000000001, "red_v46": 0.9199346144425923, "red_v4": -2.0059999999999993, "red_v55": -1.0189999999999997, "red_v18": 0.17155000000000054, "red_v34": -0.15699999999999992, "red_v54": 0.4976925427729424}, "hist_stats": {"episode_reward": [3.615149487816172, 3.2769014055891237, 3.9928112013169965, 2.898505737816171, 3.4185682378152045, 1.4692783644425924, 2.2688518428161757, 2.4117088628161714, 2.493333862815204, 1.7659276128161734, 2.4645752394425924, 2.8321307378161737, 2.466568237816171, 2.4891499085440545, 3.9689403522587634, 2.166503125, 1.9924425427729422, 0.9779780335440551, 0.2353338628161693, 2.334755042772942, 0.9724936585440553, 1.4828182378161703, 1.97652136281617, 2.9788175427729424, 3.976589600631375, 3.864554967816171, 3.796911987816171, 2.4724119878161703, 2.97870886281617, 2.935333167772942, 0.9830057378161698, 0.986630042772942, 1.463896362816171, 0.6261932378161836, 2.1517687500000005, 1.4635682378161712, 2.37933048, 2.47941198781617, 1.4620526128161706, 2.9227713628161727, 2.47881823781617, 2.468271362816171, 3.298240112816173, 1.9628956677729434, 1.3551932378161697, 3.9782614756323404, 1.9659814894425924, 2.3836273550000007, 3.9688239756323402, 4.119258862816173, 2.47478698781617, 2.4343963628161727, 1.3354531250000001, 1.9808182378161705, 1.071943237816189, 3.998620850631373, 2.4828182378152044, 1.3336406250000001, 2.490739417772942, 1.9754901128161706, 1.47297448781617, 2.4669744878161706, 2.483115112815204, 2.475005737815204, 4.159540112816171, 2.47330261281617, 2.4891499085440545, 3.427599487816171, 1.8837367300000003, 3.9806740322155334, 2.48863073781617, 2.46394323781617, 1.4046307378161738, 2.415865112816171, 2.48270886281617, 1.4493494878161721, 2.8272211050000005, 2.98333386281617, 2.9207713628161733, 2.273627852258786, 1.9794119878161702, 2.47589636281617, 2.987337408544055, 2.4547557378161717, 1.3388593750000002, 1.4577557378161714, 3.8870272635440553, 1.1743494878161775, 3.641180737816171, 2.4842244878161703, 2.496036987815204, 1.8275312499999998, 2.4810057378161705, 3.3226776128161712, 3.591243237816174, 3.959612227258763, 3.350146875, 3.9760732805891124, 1.9723026128161703, 2.3764086050000004], "episode_lengths": [62, 187, 27, 60, 40, 18, 104, 91, 19, 85, 19, 116, 40, 17, 28, 15, 16, 40, 1043, 108, 35, 24, 23, 24, 31, 39, 58, 26, 27, 19, 28, 20, 31, 352, 26, 40, 17, 26, 45, 71, 24, 39, 49, 31, 160, 40, 17, 18, 52, 59, 34, 63, 15, 24, 880, 21, 24, 19, 17, 33, 38, 38, 25, 28, 33, 29, 17, 30, 15, 17, 20, 48, 84, 105, 27, 46, 20, 19, 71, 1280, 26, 31, 21, 44, 13, 44, 19, 302, 52, 22, 18, 22, 28, 37, 96, 37, 17, 36, 29, 24], "policy_red_v21_reward": [0.1530500000000009, 0.503103033544055, 0.4799346144425924], "policy_red_v27_reward": [-0.5603074572270585, -0.1729999999999997], "policy_red_v57_reward": [-0.5599999999999999, -2.007999999999999], "policy_red_v3_reward": [0.44], "policy_blue_reward": [-2.0060000000000002, -1.001, -1.011, -1.0039999999999998, -2.0049999999999994, -1.0309999999999975, 0.46939062499999995, -2.006, -0.005, 0.8380000000000001, -0.006, -1.0089999999999997, -2.0149999999999992, -1.0039999999999998, -1.0069999999999995, -2.0109999999999992, -1.0109999999999995, -1.0099999999999993, -2.011999999999999, -1.537, -1.0079999999999996, -1.0179999999999985, -2.0079999999999996, 0.5802499999999997, -1.0039999999999998, -2.0079999999999996, -1.0039999999999998, -2.005, -1.0059999999999998, -1.006, -1.0049999999999997, -1.0039999999999998, -2.0219999999999985, -1.0029999999999997, -0.01800000000000001, -1.0079999999999996, -0.005, -2.0039999999999996, -2.0109999999999992, -1.0059999999999996, -1.0049999999999994, -1.0079999999999996, -1.0039999999999998], "policy_red_v28_reward": [1.7651586050000008], "policy_red_v2_reward": [-1.0269999999999986], "policy_red_v9_reward": [1.2712343750000001], "policy_red_v10_reward": [-1.0099999999999996, -2.008, 1.9686093749999998], "policy_red_v14_reward": [-0.5919999999999999], "policy_red_v19_reward": [-1.0059999999999996], "policy_red_v26_reward": [0.48093461444259256, 0.18105000000000004], "policy_red_v42_reward": [-1.501, -0.5529999999999999], "policy_red_v17_reward": [-2.0020000000000002], "policy_red_v5_reward": [-2.013], "policy_red_v22_reward": [0.4956932378152037], "policy_red_v56_reward": [0.3862836050000005], "policy_red_v13_reward": [-1.0149999999999992], "policy_red_v25_reward": [-0.5569999999999997, -1.0], "policy_red_v59_reward": [0.47831250000000025], "policy_red_v30_reward": [0.4799375], "policy_red_v7_reward": [-2.017999999999999, 0.67265625], "policy_red_v1_reward": [0.17350000000000754, -1.0109999999999995], "policy_red_v12_reward": [-0.026000000000000016], "policy_red_v31_reward": [0.5006932378161698], "policy_red_v33_reward": [-1.001], "policy_red_v50_reward": [0.5026932378161697], "policy_red_v38_reward": [1.1590500000000012, -1.0129999999999997], "policy_red_v61_reward": [-2.006], "policy_red_v11_reward": [0.5066932378152039], "policy_red_v32_reward": [-2.0069999999999997], "policy_red_v43_reward": [1.1750500000000008], "policy_red_v41_reward": [-1.0109999999999997, -1.0069999999999997], "policy_red_v36_reward": [0.444, 0.39328360500000026], "policy_red_v63_reward": [-2.002], "policy_red_v37_reward": [0.4859346144425923], "policy_red_v6_reward": [-0.009000000000000001], "policy_red_v46_reward": [0.9199346144425923], "policy_red_v4_reward": [-2.0059999999999993], "policy_red_v55_reward": [-1.0189999999999997], "policy_red_v18_reward": [0.17505000000000015, 0.16805000000000092], "policy_red_v34_reward": [-0.15699999999999992], "policy_red_v54_reward": [0.4976925427729424]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8187026904118239, "mean_inference_ms": 7.74681931926265, "mean_action_processing_ms": 0.29531932183258613, "mean_env_wait_ms": 0.3918198611826046, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10595107078552246, "StateBufferConnector_ms": 0.004331469535827637, "ViewRequirementAgentConnector_ms": 0.11910760402679443}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 776000, "num_agent_steps_trained": 776000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 205.3058111650904, "num_env_steps_trained_throughput_per_sec": 205.3058111650904, "timesteps_total": 388000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 776000, "timers": {"training_iteration_time_ms": 19917.055, "sample_time_ms": 1162.946, "learn_time_ms": 18669.246, "learn_throughput": 214.256, "synch_weights_time_ms": 81.363}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 776000, "num_agent_steps_trained": 776000}, "done": false, "episodes_total": 1637, "training_iteration": 97, "trial_id": "a9680_00000", "date": "2023-09-24_03-11-48", "timestamp": 1695539508, "time_this_iter_s": 19.49233102798462, "time_total_s": 1934.4840302467346, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dee52d0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1de43010>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1de430a0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1934.4840302467346, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 5.245454545454545, "ram_util_percent": 24.28787878787879}, "win_rate": 0.7, "league_size": 66}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6710720378905535, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.03984979381251227, "policy_loss": -0.047753598421695645, "vf_loss": 0.1621801401061627, "vf_explained_var": 0.8345974961295723, "kl": 0.0177140869347141, "entropy": 1.458016901711623, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 93600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "sampler_results": {"episode_reward_max": 4.159540112816171, "episode_reward_min": -1.284525512183825, "episode_reward_mean": 2.3395491060027154, "episode_len_mean": 83.43, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"blue": -2.0219999999999985, "red": -2.206525512183829, "red_v61": -2.006, "red_v11": 0.5066932378152039, "red_v32": -2.0069999999999997, "red_v1": -1.0109999999999995, "red_v43": 1.1750500000000008, "red_v41": -1.0109999999999997, "red_v36": 0.1640500000000017, "red_v63": -2.0369999999999973, "red_v37": 0.4859346144425923, "red_v38": -1.0129999999999997, "red_v57": -2.007999999999999, "red_v42": -0.5529999999999999, "red_v6": -1.0079999999999998, "red_v46": 0.9199346144425923, "red_v4": -2.0059999999999993, "red_v55": -1.0189999999999997, "red_v7": 0.67265625, "red_v18": 0.16805000000000092, "red_v25": -1.0, "red_v34": -1.0339999999999974, "red_v21": 0.4799346144425924, "red_v26": 0.18105000000000004, "red_v54": 0.4976925427729424, "red_v10": 1.9686093749999998, "red_v19": -1.0169999999999988, "red_v53": -1.005, "red_v22": -1.0249999999999988, "red_v56": 0.39028360500000026, "red_v3": 0.5006932378161698, "red_v40": 1.9596093749999999, "red_v29": -1.0059999999999998, "red_v39": 1.9035000000000002, "red_v2": -2.013, "red_v23": -1.0079999999999993, "red_v24": 3.6184901128161817, "red_v33": -1.0049999999999997, "red_v9": -2.0189999999999992}, "policy_reward_max": {"blue": 0.9220000000000015, "red": 3.9888182378161696, "red_v61": -2.006, "red_v11": 0.5066932378152039, "red_v32": -2.0069999999999997, "red_v1": -0.007, "red_v43": 1.1750500000000008, "red_v41": -1.0069999999999997, "red_v36": 0.444, "red_v63": -2.002, "red_v37": 0.4859346144425923, "red_v38": -1.0129999999999997, "red_v57": -2.007999999999999, "red_v42": -0.5529999999999999, "red_v6": -0.009000000000000001, "red_v46": 0.9199346144425923, "red_v4": -2.0059999999999993, "red_v55": -1.0189999999999997, "red_v7": 0.67265625, "red_v18": 0.442, "red_v25": -1.0, "red_v34": -0.15699999999999992, "red_v21": 0.4799346144425924, "red_v26": 0.18105000000000004, "red_v54": 0.4976925427729424, "red_v10": 1.9686093749999998, "red_v19": -1.0169999999999988, "red_v53": 0.4946932378161707, "red_v22": -1.0249999999999988, "red_v56": 0.39028360500000026, "red_v3": 0.5006932378161698, "red_v40": 1.9596093749999999, "red_v29": -1.0059999999999998, "red_v39": 1.9035000000000002, "red_v2": -2.013, "red_v23": -1.0079999999999993, "red_v24": 3.6184901128161817, "red_v33": -1.0049999999999997, "red_v9": -2.0189999999999992}, "policy_reward_mean": {"blue": -1.2220321514423071, "red": 3.11568324052907, "red_v61": -2.006, "red_v11": 0.5066932378152039, "red_v32": -2.0069999999999997, "red_v1": -0.5089999999999997, "red_v43": 1.1750500000000008, "red_v41": -1.0089999999999997, "red_v36": 0.33377786833333395, "red_v63": -2.0194999999999985, "red_v37": 0.4859346144425923, "red_v38": -1.0129999999999997, "red_v57": -2.007999999999999, "red_v42": -0.5529999999999999, "red_v6": -0.5084999999999998, "red_v46": 0.9199346144425923, "red_v4": -2.0059999999999993, "red_v55": -1.0189999999999997, "red_v7": 0.67265625, "red_v18": 0.2617000000000003, "red_v25": -1.0, "red_v34": -0.5954999999999986, "red_v21": 0.4799346144425924, "red_v26": 0.18105000000000004, "red_v54": 0.4976925427729424, "red_v10": 1.9686093749999998, "red_v19": -1.0169999999999988, "red_v53": -0.3754355873946098, "red_v22": -1.0249999999999988, "red_v56": 0.39028360500000026, "red_v3": 0.5006932378161698, "red_v40": 1.9596093749999999, "red_v29": -1.0059999999999998, "red_v39": 1.9035000000000002, "red_v2": -2.013, "red_v23": -1.0079999999999993, "red_v24": 3.6184901128161817, "red_v33": -1.0049999999999997, "red_v9": -2.0189999999999992}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.47478698781617, 2.4343963628161727, 1.3354531250000001, 1.9808182378161705, 1.071943237816189, 3.998620850631373, 2.4828182378152044, 1.3336406250000001, 2.490739417772942, 1.9754901128161706, 1.47297448781617, 2.4669744878161706, 2.483115112815204, 2.475005737815204, 4.159540112816171, 2.47330261281617, 2.4891499085440545, 3.427599487816171, 1.8837367300000003, 3.9806740322155334, 2.48863073781617, 2.46394323781617, 1.4046307378161738, 2.415865112816171, 2.48270886281617, 1.4493494878161721, 2.8272211050000005, 2.98333386281617, 2.9207713628161733, 2.273627852258786, 1.9794119878161702, 2.47589636281617, 2.987337408544055, 2.4547557378161717, 1.3388593750000002, 1.4577557378161714, 3.8870272635440553, 1.1743494878161775, 3.641180737816171, 2.4842244878161703, 2.496036987815204, 1.8275312499999998, 2.4810057378161705, 3.3226776128161712, 3.591243237816174, 3.959612227258763, 3.350146875, 3.9760732805891124, 1.9723026128161703, 2.3764086050000004, 2.427255737815206, 2.47408386281617, 0.957240112816171, 1.9784112927729418, 1.4314531250000002, 2.379033605, 1.4519189894425932, 2.4548963628161706, 3.87688309281617, 3.9682302256323405, 2.48252136281617, 1.9754119878161702, 2.420255737816171, 2.470575239442592, 1.9795994878161705, 2.486739417772942, 3.6313994878161724, 2.436052612816172, 1.0786932378162308, 1.9461307378161723, 1.9675994878161713, 2.3403956677729485, -0.06622863718382876, 1.962302612816171, 2.4852244878161702, 2.4836300427729423, 1.163503125, 3.4322244878161703, 1.8861932378161752, 1.4863331677729423, 1.9244276128161717, 2.4543494878161716, 2.4771932378161705, 1.9602713628161714, 2.4815213628152044, 3.4671833506323733, 2.441505737816172, 2.977193237815204, -1.284525512183825, 2.48052136281617, 1.6675031250000003, 1.487926917772942, 2.4398807378161713, 0.8835057378161713, 1.4761932378161702, 2.4647869878161712, 2.4747869878161706, 2.4841151128161703, 1.9641932378161706, 3.9497146006323423], "episode_lengths": [34, 63, 15, 24, 880, 21, 24, 19, 17, 33, 38, 38, 25, 28, 33, 29, 17, 30, 15, 17, 20, 48, 84, 105, 27, 46, 20, 19, 71, 1280, 26, 31, 21, 44, 13, 44, 19, 302, 52, 22, 18, 22, 28, 37, 96, 37, 17, 36, 29, 24, 76, 35, 49, 26, 15, 16, 37, 31, 30, 50, 23, 26, 76, 19, 30, 17, 46, 45, 1280, 52, 30, 127, 583, 29, 22, 20, 15, 22, 96, 19, 53, 46, 32, 39, 23, 353, 60, 32, 262, 23, 15, 21, 68, 124, 32, 34, 34, 25, 32, 55], "policy_blue_reward": [-1.0079999999999996, -1.0179999999999985, -2.0079999999999996, 0.5802499999999997, -1.0039999999999998, -2.0079999999999996, -1.0039999999999998, -2.005, -1.0059999999999998, -1.006, -1.0049999999999997, -1.0039999999999998, -2.0219999999999985, -1.0029999999999997, -0.01800000000000001, -1.0079999999999996, -0.005, -2.0039999999999996, -2.0109999999999992, -1.0059999999999996, -1.0049999999999994, -1.0079999999999996, -1.0039999999999998, -1.0079999999999996, -1.513999999999999, -2.0089999999999995, -1.0039999999999998, -2.007999999999999, -2.012999999999999, -1.0299999999999976, -1.003, -2.0069999999999997, -1.0069999999999997, -2.0139999999999985, -2.0139999999999985, -1.041999999999997, 0.4380781249999999, -1.0079999999999996, -2.005, -2.006, -1.0079999999999998, -1.0069999999999992, -1.0159999999999985, 0.9220000000000015, -1.0099999999999996, -2.003, -2.0039999999999996, -1.0199999999999982, -1.529, -2.0089999999999995, -1.0099999999999991, -1.0079999999999996], "policy_red_v61_reward": [-2.006], "policy_red_v11_reward": [0.5066932378152039], "policy_red_v32_reward": [-2.0069999999999997], "policy_red_v1_reward": [-1.0109999999999995, -0.007], "policy_red_v43_reward": [1.1750500000000008], "policy_red_v41_reward": [-1.0109999999999997, -1.0069999999999997], "policy_red_v36_reward": [0.444, 0.39328360500000026, 0.1640500000000017], "policy_red_v63_reward": [-2.002, -2.0369999999999973], "policy_red_v37_reward": [0.4859346144425923], "policy_red_v38_reward": [-1.0129999999999997], "policy_red_v57_reward": [-2.007999999999999], "policy_red_v42_reward": [-0.5529999999999999], "policy_red_v6_reward": [-0.009000000000000001, -1.0079999999999998], "policy_red_v46_reward": [0.9199346144425923], "policy_red_v4_reward": [-2.0059999999999993], "policy_red_v55_reward": [-1.0189999999999997], "policy_red_v7_reward": [0.67265625], "policy_red_v18_reward": [0.17505000000000015, 0.16805000000000092, 0.442], "policy_red_v25_reward": [-1.0], "policy_red_v34_reward": [-0.15699999999999992, -1.0339999999999974], "policy_red_v21_reward": [0.4799346144425924], "policy_red_v26_reward": [0.18105000000000004], "policy_red_v54_reward": [0.4976925427729424], "policy_red_v10_reward": [1.9686093749999998], "policy_red_v19_reward": [-1.0169999999999988], "policy_red_v53_reward": [-1.005, -0.616, 0.4946932378161707], "policy_red_v22_reward": [-1.0249999999999988], "policy_red_v56_reward": [0.39028360500000026], "policy_red_v3_reward": [0.5006932378161698], "policy_red_v40_reward": [1.9596093749999999], "policy_red_v29_reward": [-1.0059999999999998], "policy_red_v39_reward": [1.9035000000000002], "policy_red_v2_reward": [-2.013], "policy_red_v23_reward": [-1.0079999999999993], "policy_red_v24_reward": [3.6184901128161817], "policy_red_v33_reward": [-1.0049999999999997], "policy_red_v9_reward": [-2.0189999999999992]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8187133059602314, "mean_inference_ms": 7.745495195994745, "mean_action_processing_ms": 0.2952169454173674, "mean_env_wait_ms": 0.3923758408271162, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10330033302307129, "StateBufferConnector_ms": 0.004296422004699707, "ViewRequirementAgentConnector_ms": 0.11787557601928711}}, "episode_reward_max": 4.159540112816171, "episode_reward_min": -1.284525512183825, "episode_reward_mean": 2.3395491060027154, "episode_len_mean": 83.43, "episodes_this_iter": 50, "policy_reward_min": {"blue": -2.0219999999999985, "red": -2.206525512183829, "red_v61": -2.006, "red_v11": 0.5066932378152039, "red_v32": -2.0069999999999997, "red_v1": -1.0109999999999995, "red_v43": 1.1750500000000008, "red_v41": -1.0109999999999997, "red_v36": 0.1640500000000017, "red_v63": -2.0369999999999973, "red_v37": 0.4859346144425923, "red_v38": -1.0129999999999997, "red_v57": -2.007999999999999, "red_v42": -0.5529999999999999, "red_v6": -1.0079999999999998, "red_v46": 0.9199346144425923, "red_v4": -2.0059999999999993, "red_v55": -1.0189999999999997, "red_v7": 0.67265625, "red_v18": 0.16805000000000092, "red_v25": -1.0, "red_v34": -1.0339999999999974, "red_v21": 0.4799346144425924, "red_v26": 0.18105000000000004, "red_v54": 0.4976925427729424, "red_v10": 1.9686093749999998, "red_v19": -1.0169999999999988, "red_v53": -1.005, "red_v22": -1.0249999999999988, "red_v56": 0.39028360500000026, "red_v3": 0.5006932378161698, "red_v40": 1.9596093749999999, "red_v29": -1.0059999999999998, "red_v39": 1.9035000000000002, "red_v2": -2.013, "red_v23": -1.0079999999999993, "red_v24": 3.6184901128161817, "red_v33": -1.0049999999999997, "red_v9": -2.0189999999999992}, "policy_reward_max": {"blue": 0.9220000000000015, "red": 3.9888182378161696, "red_v61": -2.006, "red_v11": 0.5066932378152039, "red_v32": -2.0069999999999997, "red_v1": -0.007, "red_v43": 1.1750500000000008, "red_v41": -1.0069999999999997, "red_v36": 0.444, "red_v63": -2.002, "red_v37": 0.4859346144425923, "red_v38": -1.0129999999999997, "red_v57": -2.007999999999999, "red_v42": -0.5529999999999999, "red_v6": -0.009000000000000001, "red_v46": 0.9199346144425923, "red_v4": -2.0059999999999993, "red_v55": -1.0189999999999997, "red_v7": 0.67265625, "red_v18": 0.442, "red_v25": -1.0, "red_v34": -0.15699999999999992, "red_v21": 0.4799346144425924, "red_v26": 0.18105000000000004, "red_v54": 0.4976925427729424, "red_v10": 1.9686093749999998, "red_v19": -1.0169999999999988, "red_v53": 0.4946932378161707, "red_v22": -1.0249999999999988, "red_v56": 0.39028360500000026, "red_v3": 0.5006932378161698, "red_v40": 1.9596093749999999, "red_v29": -1.0059999999999998, "red_v39": 1.9035000000000002, "red_v2": -2.013, "red_v23": -1.0079999999999993, "red_v24": 3.6184901128161817, "red_v33": -1.0049999999999997, "red_v9": -2.0189999999999992}, "policy_reward_mean": {"blue": -1.2220321514423071, "red": 3.11568324052907, "red_v61": -2.006, "red_v11": 0.5066932378152039, "red_v32": -2.0069999999999997, "red_v1": -0.5089999999999997, "red_v43": 1.1750500000000008, "red_v41": -1.0089999999999997, "red_v36": 0.33377786833333395, "red_v63": -2.0194999999999985, "red_v37": 0.4859346144425923, "red_v38": -1.0129999999999997, "red_v57": -2.007999999999999, "red_v42": -0.5529999999999999, "red_v6": -0.5084999999999998, "red_v46": 0.9199346144425923, "red_v4": -2.0059999999999993, "red_v55": -1.0189999999999997, "red_v7": 0.67265625, "red_v18": 0.2617000000000003, "red_v25": -1.0, "red_v34": -0.5954999999999986, "red_v21": 0.4799346144425924, "red_v26": 0.18105000000000004, "red_v54": 0.4976925427729424, "red_v10": 1.9686093749999998, "red_v19": -1.0169999999999988, "red_v53": -0.3754355873946098, "red_v22": -1.0249999999999988, "red_v56": 0.39028360500000026, "red_v3": 0.5006932378161698, "red_v40": 1.9596093749999999, "red_v29": -1.0059999999999998, "red_v39": 1.9035000000000002, "red_v2": -2.013, "red_v23": -1.0079999999999993, "red_v24": 3.6184901128161817, "red_v33": -1.0049999999999997, "red_v9": -2.0189999999999992}, "hist_stats": {"episode_reward": [2.47478698781617, 2.4343963628161727, 1.3354531250000001, 1.9808182378161705, 1.071943237816189, 3.998620850631373, 2.4828182378152044, 1.3336406250000001, 2.490739417772942, 1.9754901128161706, 1.47297448781617, 2.4669744878161706, 2.483115112815204, 2.475005737815204, 4.159540112816171, 2.47330261281617, 2.4891499085440545, 3.427599487816171, 1.8837367300000003, 3.9806740322155334, 2.48863073781617, 2.46394323781617, 1.4046307378161738, 2.415865112816171, 2.48270886281617, 1.4493494878161721, 2.8272211050000005, 2.98333386281617, 2.9207713628161733, 2.273627852258786, 1.9794119878161702, 2.47589636281617, 2.987337408544055, 2.4547557378161717, 1.3388593750000002, 1.4577557378161714, 3.8870272635440553, 1.1743494878161775, 3.641180737816171, 2.4842244878161703, 2.496036987815204, 1.8275312499999998, 2.4810057378161705, 3.3226776128161712, 3.591243237816174, 3.959612227258763, 3.350146875, 3.9760732805891124, 1.9723026128161703, 2.3764086050000004, 2.427255737815206, 2.47408386281617, 0.957240112816171, 1.9784112927729418, 1.4314531250000002, 2.379033605, 1.4519189894425932, 2.4548963628161706, 3.87688309281617, 3.9682302256323405, 2.48252136281617, 1.9754119878161702, 2.420255737816171, 2.470575239442592, 1.9795994878161705, 2.486739417772942, 3.6313994878161724, 2.436052612816172, 1.0786932378162308, 1.9461307378161723, 1.9675994878161713, 2.3403956677729485, -0.06622863718382876, 1.962302612816171, 2.4852244878161702, 2.4836300427729423, 1.163503125, 3.4322244878161703, 1.8861932378161752, 1.4863331677729423, 1.9244276128161717, 2.4543494878161716, 2.4771932378161705, 1.9602713628161714, 2.4815213628152044, 3.4671833506323733, 2.441505737816172, 2.977193237815204, -1.284525512183825, 2.48052136281617, 1.6675031250000003, 1.487926917772942, 2.4398807378161713, 0.8835057378161713, 1.4761932378161702, 2.4647869878161712, 2.4747869878161706, 2.4841151128161703, 1.9641932378161706, 3.9497146006323423], "episode_lengths": [34, 63, 15, 24, 880, 21, 24, 19, 17, 33, 38, 38, 25, 28, 33, 29, 17, 30, 15, 17, 20, 48, 84, 105, 27, 46, 20, 19, 71, 1280, 26, 31, 21, 44, 13, 44, 19, 302, 52, 22, 18, 22, 28, 37, 96, 37, 17, 36, 29, 24, 76, 35, 49, 26, 15, 16, 37, 31, 30, 50, 23, 26, 76, 19, 30, 17, 46, 45, 1280, 52, 30, 127, 583, 29, 22, 20, 15, 22, 96, 19, 53, 46, 32, 39, 23, 353, 60, 32, 262, 23, 15, 21, 68, 124, 32, 34, 34, 25, 32, 55], "policy_blue_reward": [-1.0079999999999996, -1.0179999999999985, -2.0079999999999996, 0.5802499999999997, -1.0039999999999998, -2.0079999999999996, -1.0039999999999998, -2.005, -1.0059999999999998, -1.006, -1.0049999999999997, -1.0039999999999998, -2.0219999999999985, -1.0029999999999997, -0.01800000000000001, -1.0079999999999996, -0.005, -2.0039999999999996, -2.0109999999999992, -1.0059999999999996, -1.0049999999999994, -1.0079999999999996, -1.0039999999999998, -1.0079999999999996, -1.513999999999999, -2.0089999999999995, -1.0039999999999998, -2.007999999999999, -2.012999999999999, -1.0299999999999976, -1.003, -2.0069999999999997, -1.0069999999999997, -2.0139999999999985, -2.0139999999999985, -1.041999999999997, 0.4380781249999999, -1.0079999999999996, -2.005, -2.006, -1.0079999999999998, -1.0069999999999992, -1.0159999999999985, 0.9220000000000015, -1.0099999999999996, -2.003, -2.0039999999999996, -1.0199999999999982, -1.529, -2.0089999999999995, -1.0099999999999991, -1.0079999999999996], "policy_red_v61_reward": [-2.006], "policy_red_v11_reward": [0.5066932378152039], "policy_red_v32_reward": [-2.0069999999999997], "policy_red_v1_reward": [-1.0109999999999995, -0.007], "policy_red_v43_reward": [1.1750500000000008], "policy_red_v41_reward": [-1.0109999999999997, -1.0069999999999997], "policy_red_v36_reward": [0.444, 0.39328360500000026, 0.1640500000000017], "policy_red_v63_reward": [-2.002, -2.0369999999999973], "policy_red_v37_reward": [0.4859346144425923], "policy_red_v38_reward": [-1.0129999999999997], "policy_red_v57_reward": [-2.007999999999999], "policy_red_v42_reward": [-0.5529999999999999], "policy_red_v6_reward": [-0.009000000000000001, -1.0079999999999998], "policy_red_v46_reward": [0.9199346144425923], "policy_red_v4_reward": [-2.0059999999999993], "policy_red_v55_reward": [-1.0189999999999997], "policy_red_v7_reward": [0.67265625], "policy_red_v18_reward": [0.17505000000000015, 0.16805000000000092, 0.442], "policy_red_v25_reward": [-1.0], "policy_red_v34_reward": [-0.15699999999999992, -1.0339999999999974], "policy_red_v21_reward": [0.4799346144425924], "policy_red_v26_reward": [0.18105000000000004], "policy_red_v54_reward": [0.4976925427729424], "policy_red_v10_reward": [1.9686093749999998], "policy_red_v19_reward": [-1.0169999999999988], "policy_red_v53_reward": [-1.005, -0.616, 0.4946932378161707], "policy_red_v22_reward": [-1.0249999999999988], "policy_red_v56_reward": [0.39028360500000026], "policy_red_v3_reward": [0.5006932378161698], "policy_red_v40_reward": [1.9596093749999999], "policy_red_v29_reward": [-1.0059999999999998], "policy_red_v39_reward": [1.9035000000000002], "policy_red_v2_reward": [-2.013], "policy_red_v23_reward": [-1.0079999999999993], "policy_red_v24_reward": [3.6184901128161817], "policy_red_v33_reward": [-1.0049999999999997], "policy_red_v9_reward": [-2.0189999999999992]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8187133059602314, "mean_inference_ms": 7.745495195994745, "mean_action_processing_ms": 0.2952169454173674, "mean_env_wait_ms": 0.3923758408271162, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10330033302307129, "StateBufferConnector_ms": 0.004296422004699707, "ViewRequirementAgentConnector_ms": 0.11787557601928711}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 198.5683826464901, "num_env_steps_trained_throughput_per_sec": 198.5683826464901, "timesteps_total": 392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 19902.675, "sample_time_ms": 1162.316, "learn_time_ms": 18655.007, "learn_throughput": 214.42, "synch_weights_time_ms": 81.837}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "episodes_total": 1687, "training_iteration": 98, "trial_id": "a9680_00000", "date": "2023-09-24_03-12-12", "timestamp": 1695539532, "time_this_iter_s": 20.15833878517151, "time_total_s": 1954.6423690319061, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1df3c790>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1df4c3a0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b3433a7a0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1954.6423690319061, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 5.608823529411764, "ram_util_percent": 24.470588235294116}, "win_rate": 0.76, "league_size": 67}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.585227577139934, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.051624260149643914, "policy_loss": -0.04316314441287735, "vf_loss": 0.17772083497839047, "vf_explained_var": 0.8398682072137793, "kl": 0.016364020629346974, "entropy": 1.4368221241980792, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 94560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 792000, "num_agent_steps_trained": 792000}, "sampler_results": {"episode_reward_max": 4.47766772563234, "episode_reward_min": -1.284525512183825, "episode_reward_mean": 2.2635825853631384, "episode_len_mean": 96.35, "episode_media": {}, "episodes_this_iter": 51, "policy_reward_min": {"blue": -2.0279999999999982, "red": -2.206525512183829, "red_v53": -1.005, "red_v22": -1.0249999999999988, "red_v56": 0.39028360500000026, "red_v3": -0.012000000000000002, "red_v6": -1.0079999999999998, "red_v36": 0.1640500000000017, "red_v34": -1.0339999999999974, "red_v40": 0.38128360500000047, "red_v29": -1.0059999999999998, "red_v18": 0.442, "red_v39": -0.552, "red_v63": -2.0369999999999973, "red_v2": -2.013, "red_v23": -1.0079999999999993, "red_v24": 3.6184901128161817, "red_v1": -0.007, "red_v33": -2.002, "red_v9": -2.0189999999999992, "red_v21": -1.0309999999999988, "red_v12": -1.0309999999999981, "red_v27": 0.17505000000000015, "red_v20": -0.0903067621838286, "red_v61": -2.014, "red_v47": 0.26028125, "red_v16": -2.0359999999999987, "red_v57": -1.1019999999999952, "red_v37": -1.0079999999999998, "red_v31": 0.5046932378152036, "red_v64": 1.5016932378161698, "red_v50": 1.4936932378161716, "red_v60": -0.5233067621838299, "red_v13": -2.01, "red_v32": -1.5070000000000001, "red_v14": -1.5139999999999998, "red_v19": 0.17605000000000015, "red_v35": 1.65399011281617, "red_v17": -0.5170653855574079, "red_v65": -2.005, "red_v25": 0.5056932378152037}, "policy_reward_max": {"blue": 1.1001874999999999, "red": 3.9884119878161695, "red_v53": 0.4946932378161707, "red_v22": -1.0249999999999988, "red_v56": 0.39028360500000026, "red_v3": 0.5006932378161698, "red_v6": -1.0079999999999998, "red_v36": 0.1640500000000017, "red_v34": -1.0339999999999974, "red_v40": 1.9596093749999999, "red_v29": -1.0059999999999998, "red_v18": 0.442, "red_v39": 1.9035000000000002, "red_v63": -2.0369999999999973, "red_v2": -2.013, "red_v23": 0.48969323781617, "red_v24": 3.6184901128161817, "red_v1": -0.007, "red_v33": -1.0049999999999997, "red_v9": -2.0189999999999992, "red_v21": -1.0309999999999988, "red_v12": -1.0309999999999981, "red_v27": 1.561768750000001, "red_v20": 0.498103033544055, "red_v61": -2.014, "red_v47": 0.26028125, "red_v16": -2.0359999999999987, "red_v57": -1.1019999999999952, "red_v37": -1.002, "red_v31": 0.5046932378152036, "red_v64": 1.5016932378161698, "red_v50": 1.4936932378161716, "red_v60": -0.5233067621838299, "red_v13": -2.01, "red_v32": 1.4936932378161707, "red_v14": -1.5139999999999998, "red_v19": 0.17605000000000015, "red_v35": 1.65399011281617, "red_v17": -0.5170653855574079, "red_v65": -2.005, "red_v25": 0.5056932378152037}, "policy_reward_mean": {"blue": -1.3193007015306115, "red": 3.0288053533671877, "red_v53": -0.3754355873946098, "red_v22": -1.0249999999999988, "red_v56": 0.39028360500000026, "red_v3": 0.2443466189080849, "red_v6": -1.0079999999999998, "red_v36": 0.1640500000000017, "red_v34": -1.0339999999999974, "red_v40": 1.3450079059387239, "red_v29": -1.0059999999999998, "red_v18": 0.442, "red_v39": 0.6757500000000001, "red_v63": -2.0369999999999973, "red_v2": -2.013, "red_v23": -0.25915338109191466, "red_v24": 3.6184901128161817, "red_v1": -0.007, "red_v33": -1.5034999999999998, "red_v9": -2.0189999999999992, "red_v21": -1.0309999999999988, "red_v12": -1.0309999999999981, "red_v27": 0.8684093750000006, "red_v20": 0.2038981356801132, "red_v61": -2.014, "red_v47": 0.26028125, "red_v16": -2.0359999999999987, "red_v57": -1.1019999999999952, "red_v37": -1.005, "red_v31": 0.5046932378152036, "red_v64": 1.5016932378161698, "red_v50": 1.4936932378161716, "red_v60": -0.5233067621838299, "red_v13": -2.01, "red_v32": -0.006653381091914712, "red_v14": -1.5139999999999998, "red_v19": 0.17605000000000015, "red_v35": 1.65399011281617, "red_v17": -0.5170653855574079, "red_v65": -2.005, "red_v25": 0.5056932378152037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.47408386281617, 0.957240112816171, 1.9784112927729418, 1.4314531250000002, 2.379033605, 1.4519189894425932, 2.4548963628161706, 3.87688309281617, 3.9682302256323405, 2.48252136281617, 1.9754119878161702, 2.420255737816171, 2.470575239442592, 1.9795994878161705, 2.486739417772942, 3.6313994878161724, 2.436052612816172, 1.0786932378162308, 1.9461307378161723, 1.9675994878161713, 2.3403956677729485, -0.06622863718382876, 1.962302612816171, 2.4852244878161702, 2.4836300427729423, 1.163503125, 3.4322244878161703, 1.8861932378161752, 1.4863331677729423, 1.9244276128161717, 2.4543494878161716, 2.4771932378161705, 1.9602713628161714, 2.4815213628152044, 3.4671833506323733, 2.441505737816172, 2.977193237815204, -1.284525512183825, 2.48052136281617, 1.6675031250000003, 1.487926917772942, 2.4398807378161713, 0.8835057378161713, 1.4761932378161702, 2.4647869878161712, 2.4747869878161706, 2.4841151128161703, 1.9641932378161706, 3.9497146006323423, 2.4288338628161728, 2.432802612816172, 1.3175023550000038, 1.5740968750000004, 2.92959948781617, 2.48141198781617, 1.4616533644425926, 3.5600836050000004, 1.8086364756323683, 1.4744119878161703, 1.4726776128161707, 0.748974487816183, 1.9346463628161712, 1.4700838628161705, 2.214661987816183, 1.4839276128161702, 2.4619744878161707, 2.48752136281617, 3.993105225631374, 4.47766772563234, 2.97430261281617, 1.4874119878161698, 2.464568237816171, 3.8524455928161716, 2.4132557378161725, 2.4626463628161708, 2.477598792772942, 4.3742997272587685, 2.1898239756323563, 2.4460994878161717, 3.06490210063236, 1.4072244878161726, 1.8764398550000005, 4.459120850632342, 0.696677612816173, 2.4429588628161714, 0.9478408644425934, 1.4589502394425928, 2.472278364442592, 3.65694636281617, 2.155683350632349, 2.6469221144425927, 1.973599487816171, 1.4623807378161713, 2.5338807378161743, 1.3800336050000004, 3.9545271006323413, 0.6642062500000001, 2.0674619878161766, 3.992436896359259, 3.9941052256313734], "episode_lengths": [35, 49, 26, 15, 16, 37, 31, 30, 50, 23, 26, 76, 19, 30, 17, 46, 45, 1280, 52, 30, 127, 583, 29, 22, 20, 15, 22, 96, 19, 53, 46, 32, 39, 23, 353, 60, 32, 262, 23, 15, 21, 68, 124, 32, 34, 34, 25, 32, 55, 51, 61, 58, 81, 30, 26, 26, 16, 624, 26, 37, 806, 47, 35, 202, 21, 38, 23, 26, 38, 29, 26, 40, 42, 76, 47, 30, 73, 244, 62, 379, 86, 14, 53, 293, 75, 30, 27, 18, 31, 385, 20, 30, 36, 772, 16, 51, 14, 90, 19, 26], "policy_blue_reward": [-1.0079999999999996, -1.513999999999999, -2.0089999999999995, -1.0039999999999998, -2.007999999999999, -2.012999999999999, -1.0299999999999976, -1.003, -2.0069999999999997, -1.0069999999999997, -2.0139999999999985, -2.0139999999999985, -1.041999999999997, 0.4380781249999999, -1.0079999999999996, -2.005, -2.006, -1.0079999999999998, -1.0069999999999992, -1.0159999999999985, 0.9220000000000015, -1.0099999999999996, -2.003, -2.0039999999999996, -1.0199999999999982, -1.529, -2.0089999999999995, -1.0099999999999991, -1.0079999999999996, -2.014999999999999, -0.518, -1.0059999999999996, -2.0079999999999996, -2.0049999999999994, -2.0069999999999997, -2.009, -1.0129999999999992, -1.013999999999999, -1.019999999999999, -1.010999999999999, -1.0079999999999996, -1.015999999999999, -2.0279999999999982, -1.084, -2.005, -1.003, -2.0079999999999996, -2.011999999999999, 1.1001874999999999], "policy_red_v53_reward": [-1.005, -0.616, 0.4946932378161707], "policy_red_v22_reward": [-1.0249999999999988], "policy_red_v56_reward": [0.39028360500000026], "policy_red_v3_reward": [0.5006932378161698, -0.012000000000000002], "policy_red_v6_reward": [-1.0079999999999998], "policy_red_v36_reward": [0.1640500000000017], "policy_red_v34_reward": [-1.0339999999999974], "policy_red_v40_reward": [1.9596093749999999, 0.38128360500000047, 1.6941307378161712], "policy_red_v29_reward": [-1.0059999999999998], "policy_red_v18_reward": [0.442], "policy_red_v39_reward": [1.9035000000000002, -0.552], "policy_red_v63_reward": [-2.0369999999999973], "policy_red_v2_reward": [-2.013], "policy_red_v23_reward": [-1.0079999999999993, 0.48969323781617], "policy_red_v24_reward": [3.6184901128161817], "policy_red_v1_reward": [-0.007], "policy_red_v33_reward": [-1.0049999999999997, -2.002], "policy_red_v9_reward": [-2.0189999999999992], "policy_red_v21_reward": [-1.0309999999999988], "policy_red_v12_reward": [-1.0309999999999981], "policy_red_v27_reward": [0.17505000000000015, 1.561768750000001], "policy_red_v20_reward": [-0.0903067621838286, 0.498103033544055], "policy_red_v61_reward": [-2.014], "policy_red_v47_reward": [0.26028125], "policy_red_v16_reward": [-2.0359999999999987], "policy_red_v57_reward": [-1.1019999999999952], "policy_red_v37_reward": [-1.002, -1.0079999999999998], "policy_red_v31_reward": [0.5046932378152036], "policy_red_v64_reward": [1.5016932378161698], "policy_red_v50_reward": [1.4936932378161716], "policy_red_v60_reward": [-0.5233067621838299], "policy_red_v13_reward": [-2.01], "policy_red_v32_reward": [1.4936932378161707, -1.5070000000000001], "policy_red_v14_reward": [-1.5139999999999998], "policy_red_v19_reward": [0.17605000000000015], "policy_red_v35_reward": [1.65399011281617], "policy_red_v17_reward": [-0.5170653855574079], "policy_red_v65_reward": [-2.005], "policy_red_v25_reward": [0.5056932378152037]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.818230133034627, "mean_inference_ms": 7.726474529293887, "mean_action_processing_ms": 0.2947541271438699, "mean_env_wait_ms": 0.3917454657538722, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10025739669799805, "StateBufferConnector_ms": 0.004239916801452637, "ViewRequirementAgentConnector_ms": 0.11668479442596436}}, "episode_reward_max": 4.47766772563234, "episode_reward_min": -1.284525512183825, "episode_reward_mean": 2.2635825853631384, "episode_len_mean": 96.35, "episodes_this_iter": 51, "policy_reward_min": {"blue": -2.0279999999999982, "red": -2.206525512183829, "red_v53": -1.005, "red_v22": -1.0249999999999988, "red_v56": 0.39028360500000026, "red_v3": -0.012000000000000002, "red_v6": -1.0079999999999998, "red_v36": 0.1640500000000017, "red_v34": -1.0339999999999974, "red_v40": 0.38128360500000047, "red_v29": -1.0059999999999998, "red_v18": 0.442, "red_v39": -0.552, "red_v63": -2.0369999999999973, "red_v2": -2.013, "red_v23": -1.0079999999999993, "red_v24": 3.6184901128161817, "red_v1": -0.007, "red_v33": -2.002, "red_v9": -2.0189999999999992, "red_v21": -1.0309999999999988, "red_v12": -1.0309999999999981, "red_v27": 0.17505000000000015, "red_v20": -0.0903067621838286, "red_v61": -2.014, "red_v47": 0.26028125, "red_v16": -2.0359999999999987, "red_v57": -1.1019999999999952, "red_v37": -1.0079999999999998, "red_v31": 0.5046932378152036, "red_v64": 1.5016932378161698, "red_v50": 1.4936932378161716, "red_v60": -0.5233067621838299, "red_v13": -2.01, "red_v32": -1.5070000000000001, "red_v14": -1.5139999999999998, "red_v19": 0.17605000000000015, "red_v35": 1.65399011281617, "red_v17": -0.5170653855574079, "red_v65": -2.005, "red_v25": 0.5056932378152037}, "policy_reward_max": {"blue": 1.1001874999999999, "red": 3.9884119878161695, "red_v53": 0.4946932378161707, "red_v22": -1.0249999999999988, "red_v56": 0.39028360500000026, "red_v3": 0.5006932378161698, "red_v6": -1.0079999999999998, "red_v36": 0.1640500000000017, "red_v34": -1.0339999999999974, "red_v40": 1.9596093749999999, "red_v29": -1.0059999999999998, "red_v18": 0.442, "red_v39": 1.9035000000000002, "red_v63": -2.0369999999999973, "red_v2": -2.013, "red_v23": 0.48969323781617, "red_v24": 3.6184901128161817, "red_v1": -0.007, "red_v33": -1.0049999999999997, "red_v9": -2.0189999999999992, "red_v21": -1.0309999999999988, "red_v12": -1.0309999999999981, "red_v27": 1.561768750000001, "red_v20": 0.498103033544055, "red_v61": -2.014, "red_v47": 0.26028125, "red_v16": -2.0359999999999987, "red_v57": -1.1019999999999952, "red_v37": -1.002, "red_v31": 0.5046932378152036, "red_v64": 1.5016932378161698, "red_v50": 1.4936932378161716, "red_v60": -0.5233067621838299, "red_v13": -2.01, "red_v32": 1.4936932378161707, "red_v14": -1.5139999999999998, "red_v19": 0.17605000000000015, "red_v35": 1.65399011281617, "red_v17": -0.5170653855574079, "red_v65": -2.005, "red_v25": 0.5056932378152037}, "policy_reward_mean": {"blue": -1.3193007015306115, "red": 3.0288053533671877, "red_v53": -0.3754355873946098, "red_v22": -1.0249999999999988, "red_v56": 0.39028360500000026, "red_v3": 0.2443466189080849, "red_v6": -1.0079999999999998, "red_v36": 0.1640500000000017, "red_v34": -1.0339999999999974, "red_v40": 1.3450079059387239, "red_v29": -1.0059999999999998, "red_v18": 0.442, "red_v39": 0.6757500000000001, "red_v63": -2.0369999999999973, "red_v2": -2.013, "red_v23": -0.25915338109191466, "red_v24": 3.6184901128161817, "red_v1": -0.007, "red_v33": -1.5034999999999998, "red_v9": -2.0189999999999992, "red_v21": -1.0309999999999988, "red_v12": -1.0309999999999981, "red_v27": 0.8684093750000006, "red_v20": 0.2038981356801132, "red_v61": -2.014, "red_v47": 0.26028125, "red_v16": -2.0359999999999987, "red_v57": -1.1019999999999952, "red_v37": -1.005, "red_v31": 0.5046932378152036, "red_v64": 1.5016932378161698, "red_v50": 1.4936932378161716, "red_v60": -0.5233067621838299, "red_v13": -2.01, "red_v32": -0.006653381091914712, "red_v14": -1.5139999999999998, "red_v19": 0.17605000000000015, "red_v35": 1.65399011281617, "red_v17": -0.5170653855574079, "red_v65": -2.005, "red_v25": 0.5056932378152037}, "hist_stats": {"episode_reward": [2.47408386281617, 0.957240112816171, 1.9784112927729418, 1.4314531250000002, 2.379033605, 1.4519189894425932, 2.4548963628161706, 3.87688309281617, 3.9682302256323405, 2.48252136281617, 1.9754119878161702, 2.420255737816171, 2.470575239442592, 1.9795994878161705, 2.486739417772942, 3.6313994878161724, 2.436052612816172, 1.0786932378162308, 1.9461307378161723, 1.9675994878161713, 2.3403956677729485, -0.06622863718382876, 1.962302612816171, 2.4852244878161702, 2.4836300427729423, 1.163503125, 3.4322244878161703, 1.8861932378161752, 1.4863331677729423, 1.9244276128161717, 2.4543494878161716, 2.4771932378161705, 1.9602713628161714, 2.4815213628152044, 3.4671833506323733, 2.441505737816172, 2.977193237815204, -1.284525512183825, 2.48052136281617, 1.6675031250000003, 1.487926917772942, 2.4398807378161713, 0.8835057378161713, 1.4761932378161702, 2.4647869878161712, 2.4747869878161706, 2.4841151128161703, 1.9641932378161706, 3.9497146006323423, 2.4288338628161728, 2.432802612816172, 1.3175023550000038, 1.5740968750000004, 2.92959948781617, 2.48141198781617, 1.4616533644425926, 3.5600836050000004, 1.8086364756323683, 1.4744119878161703, 1.4726776128161707, 0.748974487816183, 1.9346463628161712, 1.4700838628161705, 2.214661987816183, 1.4839276128161702, 2.4619744878161707, 2.48752136281617, 3.993105225631374, 4.47766772563234, 2.97430261281617, 1.4874119878161698, 2.464568237816171, 3.8524455928161716, 2.4132557378161725, 2.4626463628161708, 2.477598792772942, 4.3742997272587685, 2.1898239756323563, 2.4460994878161717, 3.06490210063236, 1.4072244878161726, 1.8764398550000005, 4.459120850632342, 0.696677612816173, 2.4429588628161714, 0.9478408644425934, 1.4589502394425928, 2.472278364442592, 3.65694636281617, 2.155683350632349, 2.6469221144425927, 1.973599487816171, 1.4623807378161713, 2.5338807378161743, 1.3800336050000004, 3.9545271006323413, 0.6642062500000001, 2.0674619878161766, 3.992436896359259, 3.9941052256313734], "episode_lengths": [35, 49, 26, 15, 16, 37, 31, 30, 50, 23, 26, 76, 19, 30, 17, 46, 45, 1280, 52, 30, 127, 583, 29, 22, 20, 15, 22, 96, 19, 53, 46, 32, 39, 23, 353, 60, 32, 262, 23, 15, 21, 68, 124, 32, 34, 34, 25, 32, 55, 51, 61, 58, 81, 30, 26, 26, 16, 624, 26, 37, 806, 47, 35, 202, 21, 38, 23, 26, 38, 29, 26, 40, 42, 76, 47, 30, 73, 244, 62, 379, 86, 14, 53, 293, 75, 30, 27, 18, 31, 385, 20, 30, 36, 772, 16, 51, 14, 90, 19, 26], "policy_blue_reward": [-1.0079999999999996, -1.513999999999999, -2.0089999999999995, -1.0039999999999998, -2.007999999999999, -2.012999999999999, -1.0299999999999976, -1.003, -2.0069999999999997, -1.0069999999999997, -2.0139999999999985, -2.0139999999999985, -1.041999999999997, 0.4380781249999999, -1.0079999999999996, -2.005, -2.006, -1.0079999999999998, -1.0069999999999992, -1.0159999999999985, 0.9220000000000015, -1.0099999999999996, -2.003, -2.0039999999999996, -1.0199999999999982, -1.529, -2.0089999999999995, -1.0099999999999991, -1.0079999999999996, -2.014999999999999, -0.518, -1.0059999999999996, -2.0079999999999996, -2.0049999999999994, -2.0069999999999997, -2.009, -1.0129999999999992, -1.013999999999999, -1.019999999999999, -1.010999999999999, -1.0079999999999996, -1.015999999999999, -2.0279999999999982, -1.084, -2.005, -1.003, -2.0079999999999996, -2.011999999999999, 1.1001874999999999], "policy_red_v53_reward": [-1.005, -0.616, 0.4946932378161707], "policy_red_v22_reward": [-1.0249999999999988], "policy_red_v56_reward": [0.39028360500000026], "policy_red_v3_reward": [0.5006932378161698, -0.012000000000000002], "policy_red_v6_reward": [-1.0079999999999998], "policy_red_v36_reward": [0.1640500000000017], "policy_red_v34_reward": [-1.0339999999999974], "policy_red_v40_reward": [1.9596093749999999, 0.38128360500000047, 1.6941307378161712], "policy_red_v29_reward": [-1.0059999999999998], "policy_red_v18_reward": [0.442], "policy_red_v39_reward": [1.9035000000000002, -0.552], "policy_red_v63_reward": [-2.0369999999999973], "policy_red_v2_reward": [-2.013], "policy_red_v23_reward": [-1.0079999999999993, 0.48969323781617], "policy_red_v24_reward": [3.6184901128161817], "policy_red_v1_reward": [-0.007], "policy_red_v33_reward": [-1.0049999999999997, -2.002], "policy_red_v9_reward": [-2.0189999999999992], "policy_red_v21_reward": [-1.0309999999999988], "policy_red_v12_reward": [-1.0309999999999981], "policy_red_v27_reward": [0.17505000000000015, 1.561768750000001], "policy_red_v20_reward": [-0.0903067621838286, 0.498103033544055], "policy_red_v61_reward": [-2.014], "policy_red_v47_reward": [0.26028125], "policy_red_v16_reward": [-2.0359999999999987], "policy_red_v57_reward": [-1.1019999999999952], "policy_red_v37_reward": [-1.002, -1.0079999999999998], "policy_red_v31_reward": [0.5046932378152036], "policy_red_v64_reward": [1.5016932378161698], "policy_red_v50_reward": [1.4936932378161716], "policy_red_v60_reward": [-0.5233067621838299], "policy_red_v13_reward": [-2.01], "policy_red_v32_reward": [1.4936932378161707, -1.5070000000000001], "policy_red_v14_reward": [-1.5139999999999998], "policy_red_v19_reward": [0.17605000000000015], "policy_red_v35_reward": [1.65399011281617], "policy_red_v17_reward": [-0.5170653855574079], "policy_red_v65_reward": [-2.005], "policy_red_v25_reward": [0.5056932378152037]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.818230133034627, "mean_inference_ms": 7.726474529293887, "mean_action_processing_ms": 0.2947541271438699, "mean_env_wait_ms": 0.3917454657538722, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10025739669799805, "StateBufferConnector_ms": 0.004239916801452637, "ViewRequirementAgentConnector_ms": 0.11668479442596436}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 792000, "num_agent_steps_trained": 792000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 205.5522832169904, "num_env_steps_trained_throughput_per_sec": 205.5522832169904, "timesteps_total": 396000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 792000, "timers": {"training_iteration_time_ms": 19828.797, "sample_time_ms": 1164.696, "learn_time_ms": 18579.439, "learn_throughput": 215.292, "synch_weights_time_ms": 81.121}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 792000, "num_agent_steps_trained": 792000}, "done": false, "episodes_total": 1738, "training_iteration": 99, "trial_id": "a9680_00000", "date": "2023-09-24_03-12-36", "timestamp": 1695539556, "time_this_iter_s": 19.469804763793945, "time_total_s": 1974.1121737957, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dee52a0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1df4f640>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1df4f6d0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1974.1121737957, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 5.4, "ram_util_percent": 24.572727272727274}, "win_rate": 0.75, "league_size": 68}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.537815733005603, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.04360221432143589, "policy_loss": -0.0437573844731863, "vf_loss": 0.16365374810993671, "vf_explained_var": 0.8542751634493471, "kl": 0.015503981004439994, "entropy": 1.4440659439812105, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 95520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "sampler_results": {"episode_reward_max": 4.497214600631374, "episode_reward_min": -1.3416973871838234, "episode_reward_mean": 2.393775856328111, "episode_len_mean": 78.67, "episode_media": {}, "episodes_this_iter": 56, "policy_reward_min": {"red_v27": 0.17505000000000015, "red": -1.7426973871838298, "red_v20": -2.0069999999999997, "red_v61": -2.014, "blue": -2.0279999999999982, "red_v47": 0.26028125, "red_v16": -2.0359999999999987, "red_v57": -2.003, "red_v37": -1.0079999999999998, "red_v31": 0.5046932378152036, "red_v64": -1.0019999999999998, "red_v3": -0.012000000000000002, "red_v33": -2.002, "red_v40": 0.38128360500000047, "red_v50": 1.4936932378161716, "red_v60": -0.5233067621838299, "red_v13": -2.01, "red_v32": -2.015999999999999, "red_v14": -1.5139999999999998, "red_v19": 0.17605000000000015, "red_v35": -0.5559999999999998, "red_v17": -2.0199999999999987, "red_v65": -2.005, "red_v23": -1.0119999999999996, "red_v25": 0.4926932378161699, "red_v29": 0.504103033544055, "red_v30": 1.5066932378152036, "red_v21": -0.006, "red_v12": -2.0239999999999982, "red_v38": 0.4899346144425923, "red_v46": -1.0019999999999998, "red_v18": 0.5006932378161698, "red_v51": -0.017000000000000005, "red_v34": -1.0139999999999998, "red_v36": -0.05999999999999983, "red_v2": -2.001}, "policy_reward_max": {"red_v27": 1.561768750000001, "red": 3.98922448781617, "red_v20": 0.498103033544055, "red_v61": -2.014, "blue": 1.1001874999999999, "red_v47": 0.26028125, "red_v16": -2.0359999999999987, "red_v57": -1.1019999999999952, "red_v37": 0.49669323781617036, "red_v31": 0.5046932378152036, "red_v64": 1.5016932378161698, "red_v3": -0.008, "red_v33": -2.002, "red_v40": 1.6941307378161712, "red_v50": 1.4936932378161716, "red_v60": 0.19046875000000107, "red_v13": -2.01, "red_v32": 1.50369323781617, "red_v14": -1.5139999999999998, "red_v19": 0.17605000000000015, "red_v35": 1.65399011281617, "red_v17": -0.5170653855574079, "red_v65": -2.005, "red_v23": 0.48969323781617, "red_v25": 0.5056932378152037, "red_v29": 0.504103033544055, "red_v30": 1.5066932378152036, "red_v21": -0.006, "red_v12": -2.0239999999999982, "red_v38": 0.4899346144425923, "red_v46": -0.15599999999999986, "red_v18": 0.5006932378161698, "red_v51": -0.017000000000000005, "red_v34": -1.0139999999999998, "red_v36": -0.05999999999999983, "red_v2": -1.0279999999999974}, "policy_reward_mean": {"red_v27": 0.8684093750000006, "red": 3.1313928753959805, "red_v20": -0.5330679095465911, "red_v61": -2.014, "blue": -1.1858437499999994, "red_v47": 0.26028125, "red_v16": -2.0359999999999987, "red_v57": -1.5524999999999975, "red_v37": -0.5044355873946098, "red_v31": 0.5046932378152036, "red_v64": 0.24984661890808502, "red_v3": -0.010000000000000002, "red_v33": -2.002, "red_v40": 1.0377071714080859, "red_v50": 1.4936932378161716, "red_v60": -0.1664190060919144, "red_v13": -2.01, "red_v32": -0.13140338109191463, "red_v14": -1.5139999999999998, "red_v19": 0.17605000000000015, "red_v35": 0.5489950564080851, "red_v17": -1.5166884618524688, "red_v65": -2.005, "red_v23": -0.26115338109191477, "red_v25": 0.4991932378156868, "red_v29": 0.504103033544055, "red_v30": 1.5066932378152036, "red_v21": -0.006, "red_v12": -2.0239999999999982, "red_v38": 0.4899346144425923, "red_v46": -0.5789999999999998, "red_v18": 0.5006932378161698, "red_v51": -0.017000000000000005, "red_v34": -1.0139999999999998, "red_v36": -0.05999999999999983, "red_v2": -1.5144999999999986}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.5600836050000004, 1.8086364756323683, 1.4744119878161703, 1.4726776128161707, 0.748974487816183, 1.9346463628161712, 1.4700838628161705, 2.214661987816183, 1.4839276128161702, 2.4619744878161707, 2.48752136281617, 3.993105225631374, 4.47766772563234, 2.97430261281617, 1.4874119878161698, 2.464568237816171, 3.8524455928161716, 2.4132557378161725, 2.4626463628161708, 2.477598792772942, 4.3742997272587685, 2.1898239756323563, 2.4460994878161717, 3.06490210063236, 1.4072244878161726, 1.8764398550000005, 4.459120850632342, 0.696677612816173, 2.4429588628161714, 0.9478408644425934, 1.4589502394425928, 2.472278364442592, 3.65694636281617, 2.155683350632349, 2.6469221144425927, 1.973599487816171, 1.4623807378161713, 2.5338807378161743, 1.3800336050000004, 3.9545271006323413, 0.6642062500000001, 2.0674619878161766, 3.992436896359259, 3.9941052256313734, 2.8827367300000004, 3.983483771360225, 0.43115625000000013, 4.497214600631374, 1.3796776128161756, 2.472490112815205, 2.948833862816172, 2.3319119878161705, 1.4660838628161705, 1.982446783544055, 3.4586463628161708, 2.48249011281617, 2.4717124085440556, 1.9647869878161714, 2.9904425427729415, 1.4384276128161724, 2.4777088628161703, 3.874265094442592, 2.4555369878161715, 1.9551619878161708, 1.3763304800000005, 2.4923338628152036, 3.9727458506323408, 2.606565625, 1.4753877394425925, 2.4738963628161703, -1.3416973871838234, 2.485818237815204, 2.4641619878161705, 0.46116198781522577, 1.9717869878161702, 1.15820625, 2.454349487816171, 2.9362244878161703, 3.3252713628161708, 2.4592401128152046, 2.4346932378161723, 2.3765179800000005, 1.4246307378161713, 2.967896362816171, 2.3684086050000004, 2.4636776128161704, 1.48270886281617, 3.952792725632342, 4.49310522563234, 1.9770057378161705, 2.0939562500000015, 1.9599744878161702, 2.3915249085440573, 2.4926307378161696, 1.88573673, 2.4747088628161706, 3.9704489756323413, 2.9741932378161704, 2.4543494878161716, 1.9822244878161699], "episode_lengths": [16, 624, 26, 37, 806, 47, 35, 202, 21, 38, 23, 26, 38, 29, 26, 40, 42, 76, 47, 30, 73, 244, 62, 379, 86, 14, 53, 293, 75, 30, 27, 18, 31, 385, 20, 30, 36, 772, 16, 51, 14, 90, 19, 26, 15, 36, 14, 23, 101, 33, 51, 122, 35, 18, 47, 33, 29, 34, 16, 53, 27, 17, 50, 42, 17, 19, 45, 59, 15, 31, 349, 24, 42, 426, 34, 14, 46, 22, 39, 49, 64, 21, 84, 31, 24, 37, 27, 62, 26, 28, 30, 38, 89, 20, 15, 27, 44, 32, 46, 22], "policy_red_v27_reward": [0.17505000000000015, 1.561768750000001], "policy_red_v20_reward": [-0.0903067621838286, 0.498103033544055, -2.0069999999999997], "policy_red_v61_reward": [-2.014], "policy_blue_reward": [-2.0049999999999994, -2.0069999999999997, -2.009, -1.0129999999999992, -1.013999999999999, -1.019999999999999, -1.010999999999999, -1.0079999999999996, -1.015999999999999, -2.0279999999999982, -1.084, -2.005, -1.003, -2.0079999999999996, -2.011999999999999, 1.1001874999999999, -0.003, -2.006, -2.0279999999999974, -1.0099999999999993, -0.010000000000000002, -1.0329999999999973, -2.0079999999999996, -2.006, 0.487, -1.0129999999999997, -1.007, -1.0069999999999995, -0.017000000000000005, -1.0079999999999998, 0.40100000000000424, -1.005, -1.0079999999999996, -2.0089999999999995, -1.0109999999999997, -1.0089999999999997, -1.023999999999998, -1.005, -1.0190000000000001, -1.0069999999999995, -2.0049999999999994, -2.007999999999999, -2.0139999999999993, -1.001, -1.0059999999999998, -2.0069999999999997], "policy_red_v47_reward": [0.26028125], "policy_red_v16_reward": [-2.0359999999999987], "policy_red_v57_reward": [-1.1019999999999952, -2.003], "policy_red_v37_reward": [-1.002, -1.0079999999999998, 0.49669323781617036], "policy_red_v31_reward": [0.5046932378152036], "policy_red_v64_reward": [1.5016932378161698, -1.0019999999999998], "policy_red_v3_reward": [-0.012000000000000002, -0.008], "policy_red_v33_reward": [-2.002], "policy_red_v40_reward": [0.38128360500000047, 1.6941307378161712], "policy_red_v50_reward": [1.4936932378161716], "policy_red_v60_reward": [-0.5233067621838299, 0.19046875000000107], "policy_red_v13_reward": [-2.01], "policy_red_v32_reward": [1.4936932378161707, -1.5070000000000001, -2.015999999999999, 1.50369323781617], "policy_red_v14_reward": [-1.5139999999999998], "policy_red_v19_reward": [0.17605000000000015], "policy_red_v35_reward": [1.65399011281617, -0.5559999999999998], "policy_red_v17_reward": [-0.5170653855574079, -2.0199999999999987, -2.013], "policy_red_v65_reward": [-2.005], "policy_red_v23_reward": [0.48969323781617, -1.0119999999999996], "policy_red_v25_reward": [0.5056932378152037, 0.4926932378161699], "policy_red_v29_reward": [0.504103033544055], "policy_red_v30_reward": [1.5066932378152036], "policy_red_v21_reward": [-0.006], "policy_red_v12_reward": [-2.0239999999999982], "policy_red_v38_reward": [0.4899346144425923], "policy_red_v46_reward": [-1.0019999999999998, -0.15599999999999986], "policy_red_v18_reward": [0.5006932378161698], "policy_red_v51_reward": [-0.017000000000000005], "policy_red_v34_reward": [-1.0139999999999998], "policy_red_v36_reward": [-0.05999999999999983], "policy_red_v2_reward": [-1.0279999999999974, -2.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8181108159325031, "mean_inference_ms": 7.709452073119527, "mean_action_processing_ms": 0.2945266950307074, "mean_env_wait_ms": 0.3919241644189564, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10454726219177246, "StateBufferConnector_ms": 0.0043964385986328125, "ViewRequirementAgentConnector_ms": 0.12175476551055908}}, "episode_reward_max": 4.497214600631374, "episode_reward_min": -1.3416973871838234, "episode_reward_mean": 2.393775856328111, "episode_len_mean": 78.67, "episodes_this_iter": 56, "policy_reward_min": {"red_v27": 0.17505000000000015, "red": -1.7426973871838298, "red_v20": -2.0069999999999997, "red_v61": -2.014, "blue": -2.0279999999999982, "red_v47": 0.26028125, "red_v16": -2.0359999999999987, "red_v57": -2.003, "red_v37": -1.0079999999999998, "red_v31": 0.5046932378152036, "red_v64": -1.0019999999999998, "red_v3": -0.012000000000000002, "red_v33": -2.002, "red_v40": 0.38128360500000047, "red_v50": 1.4936932378161716, "red_v60": -0.5233067621838299, "red_v13": -2.01, "red_v32": -2.015999999999999, "red_v14": -1.5139999999999998, "red_v19": 0.17605000000000015, "red_v35": -0.5559999999999998, "red_v17": -2.0199999999999987, "red_v65": -2.005, "red_v23": -1.0119999999999996, "red_v25": 0.4926932378161699, "red_v29": 0.504103033544055, "red_v30": 1.5066932378152036, "red_v21": -0.006, "red_v12": -2.0239999999999982, "red_v38": 0.4899346144425923, "red_v46": -1.0019999999999998, "red_v18": 0.5006932378161698, "red_v51": -0.017000000000000005, "red_v34": -1.0139999999999998, "red_v36": -0.05999999999999983, "red_v2": -2.001}, "policy_reward_max": {"red_v27": 1.561768750000001, "red": 3.98922448781617, "red_v20": 0.498103033544055, "red_v61": -2.014, "blue": 1.1001874999999999, "red_v47": 0.26028125, "red_v16": -2.0359999999999987, "red_v57": -1.1019999999999952, "red_v37": 0.49669323781617036, "red_v31": 0.5046932378152036, "red_v64": 1.5016932378161698, "red_v3": -0.008, "red_v33": -2.002, "red_v40": 1.6941307378161712, "red_v50": 1.4936932378161716, "red_v60": 0.19046875000000107, "red_v13": -2.01, "red_v32": 1.50369323781617, "red_v14": -1.5139999999999998, "red_v19": 0.17605000000000015, "red_v35": 1.65399011281617, "red_v17": -0.5170653855574079, "red_v65": -2.005, "red_v23": 0.48969323781617, "red_v25": 0.5056932378152037, "red_v29": 0.504103033544055, "red_v30": 1.5066932378152036, "red_v21": -0.006, "red_v12": -2.0239999999999982, "red_v38": 0.4899346144425923, "red_v46": -0.15599999999999986, "red_v18": 0.5006932378161698, "red_v51": -0.017000000000000005, "red_v34": -1.0139999999999998, "red_v36": -0.05999999999999983, "red_v2": -1.0279999999999974}, "policy_reward_mean": {"red_v27": 0.8684093750000006, "red": 3.1313928753959805, "red_v20": -0.5330679095465911, "red_v61": -2.014, "blue": -1.1858437499999994, "red_v47": 0.26028125, "red_v16": -2.0359999999999987, "red_v57": -1.5524999999999975, "red_v37": -0.5044355873946098, "red_v31": 0.5046932378152036, "red_v64": 0.24984661890808502, "red_v3": -0.010000000000000002, "red_v33": -2.002, "red_v40": 1.0377071714080859, "red_v50": 1.4936932378161716, "red_v60": -0.1664190060919144, "red_v13": -2.01, "red_v32": -0.13140338109191463, "red_v14": -1.5139999999999998, "red_v19": 0.17605000000000015, "red_v35": 0.5489950564080851, "red_v17": -1.5166884618524688, "red_v65": -2.005, "red_v23": -0.26115338109191477, "red_v25": 0.4991932378156868, "red_v29": 0.504103033544055, "red_v30": 1.5066932378152036, "red_v21": -0.006, "red_v12": -2.0239999999999982, "red_v38": 0.4899346144425923, "red_v46": -0.5789999999999998, "red_v18": 0.5006932378161698, "red_v51": -0.017000000000000005, "red_v34": -1.0139999999999998, "red_v36": -0.05999999999999983, "red_v2": -1.5144999999999986}, "hist_stats": {"episode_reward": [3.5600836050000004, 1.8086364756323683, 1.4744119878161703, 1.4726776128161707, 0.748974487816183, 1.9346463628161712, 1.4700838628161705, 2.214661987816183, 1.4839276128161702, 2.4619744878161707, 2.48752136281617, 3.993105225631374, 4.47766772563234, 2.97430261281617, 1.4874119878161698, 2.464568237816171, 3.8524455928161716, 2.4132557378161725, 2.4626463628161708, 2.477598792772942, 4.3742997272587685, 2.1898239756323563, 2.4460994878161717, 3.06490210063236, 1.4072244878161726, 1.8764398550000005, 4.459120850632342, 0.696677612816173, 2.4429588628161714, 0.9478408644425934, 1.4589502394425928, 2.472278364442592, 3.65694636281617, 2.155683350632349, 2.6469221144425927, 1.973599487816171, 1.4623807378161713, 2.5338807378161743, 1.3800336050000004, 3.9545271006323413, 0.6642062500000001, 2.0674619878161766, 3.992436896359259, 3.9941052256313734, 2.8827367300000004, 3.983483771360225, 0.43115625000000013, 4.497214600631374, 1.3796776128161756, 2.472490112815205, 2.948833862816172, 2.3319119878161705, 1.4660838628161705, 1.982446783544055, 3.4586463628161708, 2.48249011281617, 2.4717124085440556, 1.9647869878161714, 2.9904425427729415, 1.4384276128161724, 2.4777088628161703, 3.874265094442592, 2.4555369878161715, 1.9551619878161708, 1.3763304800000005, 2.4923338628152036, 3.9727458506323408, 2.606565625, 1.4753877394425925, 2.4738963628161703, -1.3416973871838234, 2.485818237815204, 2.4641619878161705, 0.46116198781522577, 1.9717869878161702, 1.15820625, 2.454349487816171, 2.9362244878161703, 3.3252713628161708, 2.4592401128152046, 2.4346932378161723, 2.3765179800000005, 1.4246307378161713, 2.967896362816171, 2.3684086050000004, 2.4636776128161704, 1.48270886281617, 3.952792725632342, 4.49310522563234, 1.9770057378161705, 2.0939562500000015, 1.9599744878161702, 2.3915249085440573, 2.4926307378161696, 1.88573673, 2.4747088628161706, 3.9704489756323413, 2.9741932378161704, 2.4543494878161716, 1.9822244878161699], "episode_lengths": [16, 624, 26, 37, 806, 47, 35, 202, 21, 38, 23, 26, 38, 29, 26, 40, 42, 76, 47, 30, 73, 244, 62, 379, 86, 14, 53, 293, 75, 30, 27, 18, 31, 385, 20, 30, 36, 772, 16, 51, 14, 90, 19, 26, 15, 36, 14, 23, 101, 33, 51, 122, 35, 18, 47, 33, 29, 34, 16, 53, 27, 17, 50, 42, 17, 19, 45, 59, 15, 31, 349, 24, 42, 426, 34, 14, 46, 22, 39, 49, 64, 21, 84, 31, 24, 37, 27, 62, 26, 28, 30, 38, 89, 20, 15, 27, 44, 32, 46, 22], "policy_red_v27_reward": [0.17505000000000015, 1.561768750000001], "policy_red_v20_reward": [-0.0903067621838286, 0.498103033544055, -2.0069999999999997], "policy_red_v61_reward": [-2.014], "policy_blue_reward": [-2.0049999999999994, -2.0069999999999997, -2.009, -1.0129999999999992, -1.013999999999999, -1.019999999999999, -1.010999999999999, -1.0079999999999996, -1.015999999999999, -2.0279999999999982, -1.084, -2.005, -1.003, -2.0079999999999996, -2.011999999999999, 1.1001874999999999, -0.003, -2.006, -2.0279999999999974, -1.0099999999999993, -0.010000000000000002, -1.0329999999999973, -2.0079999999999996, -2.006, 0.487, -1.0129999999999997, -1.007, -1.0069999999999995, -0.017000000000000005, -1.0079999999999998, 0.40100000000000424, -1.005, -1.0079999999999996, -2.0089999999999995, -1.0109999999999997, -1.0089999999999997, -1.023999999999998, -1.005, -1.0190000000000001, -1.0069999999999995, -2.0049999999999994, -2.007999999999999, -2.0139999999999993, -1.001, -1.0059999999999998, -2.0069999999999997], "policy_red_v47_reward": [0.26028125], "policy_red_v16_reward": [-2.0359999999999987], "policy_red_v57_reward": [-1.1019999999999952, -2.003], "policy_red_v37_reward": [-1.002, -1.0079999999999998, 0.49669323781617036], "policy_red_v31_reward": [0.5046932378152036], "policy_red_v64_reward": [1.5016932378161698, -1.0019999999999998], "policy_red_v3_reward": [-0.012000000000000002, -0.008], "policy_red_v33_reward": [-2.002], "policy_red_v40_reward": [0.38128360500000047, 1.6941307378161712], "policy_red_v50_reward": [1.4936932378161716], "policy_red_v60_reward": [-0.5233067621838299, 0.19046875000000107], "policy_red_v13_reward": [-2.01], "policy_red_v32_reward": [1.4936932378161707, -1.5070000000000001, -2.015999999999999, 1.50369323781617], "policy_red_v14_reward": [-1.5139999999999998], "policy_red_v19_reward": [0.17605000000000015], "policy_red_v35_reward": [1.65399011281617, -0.5559999999999998], "policy_red_v17_reward": [-0.5170653855574079, -2.0199999999999987, -2.013], "policy_red_v65_reward": [-2.005], "policy_red_v23_reward": [0.48969323781617, -1.0119999999999996], "policy_red_v25_reward": [0.5056932378152037, 0.4926932378161699], "policy_red_v29_reward": [0.504103033544055], "policy_red_v30_reward": [1.5066932378152036], "policy_red_v21_reward": [-0.006], "policy_red_v12_reward": [-2.0239999999999982], "policy_red_v38_reward": [0.4899346144425923], "policy_red_v46_reward": [-1.0019999999999998, -0.15599999999999986], "policy_red_v18_reward": [0.5006932378161698], "policy_red_v51_reward": [-0.017000000000000005], "policy_red_v34_reward": [-1.0139999999999998], "policy_red_v36_reward": [-0.05999999999999983], "policy_red_v2_reward": [-1.0279999999999974, -2.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8181108159325031, "mean_inference_ms": 7.709452073119527, "mean_action_processing_ms": 0.2945266950307074, "mean_env_wait_ms": 0.3919241644189564, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10454726219177246, "StateBufferConnector_ms": 0.0043964385986328125, "ViewRequirementAgentConnector_ms": 0.12175476551055908}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.5550654874925, "num_env_steps_trained_throughput_per_sec": 200.5550654874925, "timesteps_total": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 19782.742, "sample_time_ms": 1157.673, "learn_time_ms": 18540.97, "learn_throughput": 215.738, "synch_weights_time_ms": 80.53}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "episodes_total": 1794, "training_iteration": 100, "trial_id": "a9680_00000", "date": "2023-09-24_03-13-00", "timestamp": 1695539580, "time_this_iter_s": 19.956924438476562, "time_total_s": 1994.0690982341766, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dee4400>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1de40040>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1de400d0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 1994.0690982341766, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 5.326470588235294, "ram_util_percent": 24.676470588235297}, "win_rate": 0.75, "league_size": 69}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4259997104605038, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.052155674551856164, "policy_loss": -0.03982617251458578, "vf_loss": 0.1750553295093899, "vf_explained_var": 0.8280829586088657, "kl": 0.013186570595947463, "entropy": 1.4797748232881227, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 96480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_agent_steps_sampled": 808000, "num_agent_steps_trained": 808000}, "sampler_results": {"episode_reward_max": 4.497214600631374, "episode_reward_min": -1.3416973871838234, "episode_reward_mean": 2.3317000518296247, "episode_len_mean": 66.34, "episode_media": {}, "episodes_this_iter": 47, "policy_reward_min": {"red_v30": 1.5066932378152036, "red": -1.7426973871838298, "blue": -2.0279999999999974, "red_v64": -1.0019999999999998, "red_v32": -2.015999999999999, "red_v21": -1.030999999999997, "red_v12": -2.0239999999999982, "red_v38": 0.4899346144425923, "red_v17": -2.0199999999999987, "red_v20": -2.0069999999999997, "red_v46": -1.0019999999999998, "red_v18": 0.5006932378161698, "red_v57": -2.003, "red_v60": 0.19046875000000107, "red_v35": -0.5559999999999998, "red_v51": -0.017000000000000005, "red_v34": -1.0139999999999998, "red_v25": -0.009000000000000001, "red_v36": -0.05999999999999983, "red_v2": -2.001, "red_v23": -1.0119999999999996, "red_v37": -0.1489999999999999, "red_v3": -0.008, "red_v15": -2.0059999999999993, "red_v14": 0.490692542772942, "red_v16": -1.0139999999999998, "red_v45": -1.002, "red_v22": -0.15499999999999992, "red_v1": -2.025999999999998, "red_v40": 0.7856932378161704, "red_v11": -2.012999999999999, "red_v4": -1.0119999999999996, "red_v56": -1.004, "red_v13": -1.5649999999999995, "red_v66": 0.48969323781617136, "red_v28": -1.0069999999999997, "red_v63": -0.5549999999999999, "red_v58": -1.002, "red_v52": -1.002, "red_v31": 1.6016562500000022}, "policy_reward_max": {"red_v30": 1.5066932378152036, "red": 3.994446783544055, "blue": 1.465390625, "red_v64": -1.0019999999999998, "red_v32": 1.50369323781617, "red_v21": -0.006, "red_v12": -2.0239999999999982, "red_v38": 1.887421875, "red_v17": -2.013, "red_v20": -1.525, "red_v46": -0.15599999999999986, "red_v18": 0.5006932378161698, "red_v57": -2.003, "red_v60": 0.19046875000000107, "red_v35": -0.5559999999999998, "red_v51": 0.4996925427729423, "red_v34": -1.0079999999999993, "red_v25": 0.4926932378161699, "red_v36": -0.05999999999999983, "red_v2": -1.0079999999999998, "red_v23": -1.0119999999999996, "red_v37": 0.49669323781617036, "red_v3": -0.008, "red_v15": 0.4916932378161699, "red_v14": 0.490692542772942, "red_v16": -1.0139999999999998, "red_v45": -1.002, "red_v22": -0.15499999999999992, "red_v1": -2.025999999999998, "red_v40": 0.7856932378161704, "red_v11": -2.012999999999999, "red_v4": -1.0119999999999996, "red_v56": -1.004, "red_v13": -1.5649999999999995, "red_v66": 0.48969323781617136, "red_v28": -1.0069999999999997, "red_v63": -0.5549999999999999, "red_v58": -1.002, "red_v52": -1.002, "red_v31": 1.6016562500000022}, "policy_reward_mean": {"red_v30": 1.5066932378152036, "red": 3.135472645804454, "blue": -1.0575139973958327, "red_v64": -1.0019999999999998, "red_v32": -0.5061022540612763, "red_v21": -0.5184999999999985, "red_v12": -2.0239999999999982, "red_v38": 1.1886782447212962, "red_v17": -2.0164999999999993, "red_v20": -1.7659999999999998, "red_v46": -0.5789999999999998, "red_v18": 0.5006932378161698, "red_v57": -2.003, "red_v60": 0.19046875000000107, "red_v35": -0.5559999999999998, "red_v51": 0.24134627138647113, "red_v34": -1.0109999999999997, "red_v25": 0.24184661890808495, "red_v36": -0.05999999999999983, "red_v2": -1.3456666666666657, "red_v23": -1.0119999999999996, "red_v37": 0.17384661890808523, "red_v3": -0.008, "red_v15": -0.7571533810919147, "red_v14": 0.490692542772942, "red_v16": -1.0139999999999998, "red_v45": -1.002, "red_v22": -0.15499999999999992, "red_v1": -2.025999999999998, "red_v40": 0.7856932378161704, "red_v11": -2.012999999999999, "red_v4": -1.0119999999999996, "red_v56": -1.004, "red_v13": -1.5649999999999995, "red_v66": 0.48969323781617136, "red_v28": -1.0069999999999997, "red_v63": -0.5549999999999999, "red_v58": -1.002, "red_v52": -1.002, "red_v31": 1.6016562500000022}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.497214600631374, 1.3796776128161756, 2.472490112815205, 2.948833862816172, 2.3319119878161705, 1.4660838628161705, 1.982446783544055, 3.4586463628161708, 2.48249011281617, 2.4717124085440556, 1.9647869878161714, 2.9904425427729415, 1.4384276128161724, 2.4777088628161703, 3.874265094442592, 2.4555369878161715, 1.9551619878161708, 1.3763304800000005, 2.4923338628152036, 3.9727458506323408, 2.606565625, 1.4753877394425925, 2.4738963628161703, -1.3416973871838234, 2.485818237815204, 2.4641619878161705, 0.46116198781522577, 1.9717869878161702, 1.15820625, 2.454349487816171, 2.9362244878161703, 3.3252713628161708, 2.4592401128152046, 2.4346932378161723, 2.3765179800000005, 1.4246307378161713, 2.967896362816171, 2.3684086050000004, 2.4636776128161704, 1.48270886281617, 3.952792725632342, 4.49310522563234, 1.9770057378161705, 2.0939562500000015, 1.9599744878161702, 2.3915249085440573, 2.4926307378161696, 1.88573673, 2.4747088628161706, 3.9704489756323413, 2.9741932378161704, 2.4543494878161716, 1.9822244878161699, 1.9710838628161704, 3.9828857805891125, 3.953010780589112, 1.8931151128161745, 2.3772557378161725, 1.4135369878161703, 2.4659744878161707, 2.38473673, 1.4757088628161705, 2.3705179800000002, 1.9307713628161716, 0.9396151128161699, 0.8512244878161703, 3.336743658544055, 1.931474487816172, 2.372814855, 2.3303437500000004, 2.484927612815204, 2.2843864756323655, 2.453911987816171, 2.47641198781617, 1.4761151128161707, 2.476411987816171, 1.7346718750000056, 2.4875213628152038, 2.441240112816171, 0.8446932378161708, 1.985446783544055, 2.4709744878161706, 2.48622448781617, 2.4681619878161705, 0.9077401128161724, 1.2791619878161755, 2.4715682378161703, 3.3419269177729425, 3.920542725632342, 2.468575239442593, 2.98111511281617, 2.826221105, 2.4803807378161697, 2.4539432378161705, 3.934839600632342, 0.988040533544055, 2.47938073781617, 1.4660838628161703, 2.475415533544055, 2.102349487816175], "episode_lengths": [23, 101, 33, 51, 122, 35, 18, 47, 33, 29, 34, 16, 53, 27, 17, 50, 42, 17, 19, 45, 59, 15, 31, 349, 24, 42, 426, 34, 14, 46, 22, 39, 49, 64, 21, 84, 31, 24, 37, 27, 62, 26, 28, 30, 38, 89, 20, 15, 27, 44, 32, 46, 22, 35, 32, 56, 89, 140, 114, 38, 15, 27, 21, 71, 57, 150, 19, 70, 22, 18, 21, 1280, 58, 26, 25, 26, 73, 23, 49, 128, 18, 38, 22, 42, 81, 234, 40, 21, 78, 19, 25, 20, 36, 48, 79, 20, 36, 35, 28, 302], "policy_red_v30_reward": [1.5066932378152036], "policy_blue_reward": [-2.0279999999999974, -1.0099999999999993, -0.010000000000000002, -1.0329999999999973, -2.0079999999999996, -2.006, 0.487, -1.0129999999999997, -1.007, -1.0069999999999995, -0.017000000000000005, -1.0079999999999998, 0.40100000000000424, -1.005, -1.0079999999999996, -2.0089999999999995, -1.0109999999999997, -1.0089999999999997, -1.023999999999998, -1.005, -1.0190000000000001, -1.0069999999999995, -2.0049999999999994, -2.007999999999999, -2.0139999999999993, -1.001, -1.0059999999999998, -2.0069999999999997, -1.0139999999999991, -2.008, -1.0059999999999996, -2.0189999999999984, -1.548, -1.007, -0.008, -1.0129999999999997, -1.0089999999999997, -1.0239999999999998, -1.0199999999999994, -2.0089999999999995, -1.0049999999999994, -1.535, -1.053, -1.0089999999999995, -1.0159999999999993, 0.4809375, 1.465390625, -1.0069999999999992], "policy_red_v64_reward": [-1.0019999999999998], "policy_red_v32_reward": [-2.015999999999999, 1.50369323781617, -1.0059999999999998], "policy_red_v21_reward": [-0.006, -1.030999999999997], "policy_red_v12_reward": [-2.0239999999999982], "policy_red_v38_reward": [0.4899346144425923, 1.887421875], "policy_red_v17_reward": [-2.0199999999999987, -2.013], "policy_red_v20_reward": [-2.0069999999999997, -1.525], "policy_red_v46_reward": [-1.0019999999999998, -0.15599999999999986], "policy_red_v18_reward": [0.5006932378161698], "policy_red_v57_reward": [-2.003], "policy_red_v60_reward": [0.19046875000000107], "policy_red_v35_reward": [-0.5559999999999998], "policy_red_v51_reward": [-0.017000000000000005, 0.4996925427729423], "policy_red_v34_reward": [-1.0139999999999998, -1.0079999999999993], "policy_red_v25_reward": [0.4926932378161699, -0.009000000000000001], "policy_red_v36_reward": [-0.05999999999999983], "policy_red_v2_reward": [-1.0279999999999974, -2.001, -1.0079999999999998], "policy_red_v23_reward": [-1.0119999999999996], "policy_red_v37_reward": [0.49669323781617036, -0.1489999999999999], "policy_red_v3_reward": [-0.008], "policy_red_v15_reward": [-2.0059999999999993, 0.4916932378161699], "policy_red_v14_reward": [0.490692542772942], "policy_red_v16_reward": [-1.0139999999999998], "policy_red_v45_reward": [-1.002], "policy_red_v22_reward": [-0.15499999999999992], "policy_red_v1_reward": [-2.025999999999998], "policy_red_v40_reward": [0.7856932378161704], "policy_red_v11_reward": [-2.012999999999999], "policy_red_v4_reward": [-1.0119999999999996], "policy_red_v56_reward": [-1.004], "policy_red_v13_reward": [-1.5649999999999995], "policy_red_v66_reward": [0.48969323781617136], "policy_red_v28_reward": [-1.0069999999999997], "policy_red_v63_reward": [-0.5549999999999999], "policy_red_v58_reward": [-1.002], "policy_red_v52_reward": [-1.002], "policy_red_v31_reward": [1.6016562500000022]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8191597519723632, "mean_inference_ms": 7.718294216520023, "mean_action_processing_ms": 0.294859083363142, "mean_env_wait_ms": 0.39248867226648215, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10448598861694336, "StateBufferConnector_ms": 0.004374861717224121, "ViewRequirementAgentConnector_ms": 0.12138092517852783}}, "episode_reward_max": 4.497214600631374, "episode_reward_min": -1.3416973871838234, "episode_reward_mean": 2.3317000518296247, "episode_len_mean": 66.34, "episodes_this_iter": 47, "policy_reward_min": {"red_v30": 1.5066932378152036, "red": -1.7426973871838298, "blue": -2.0279999999999974, "red_v64": -1.0019999999999998, "red_v32": -2.015999999999999, "red_v21": -1.030999999999997, "red_v12": -2.0239999999999982, "red_v38": 0.4899346144425923, "red_v17": -2.0199999999999987, "red_v20": -2.0069999999999997, "red_v46": -1.0019999999999998, "red_v18": 0.5006932378161698, "red_v57": -2.003, "red_v60": 0.19046875000000107, "red_v35": -0.5559999999999998, "red_v51": -0.017000000000000005, "red_v34": -1.0139999999999998, "red_v25": -0.009000000000000001, "red_v36": -0.05999999999999983, "red_v2": -2.001, "red_v23": -1.0119999999999996, "red_v37": -0.1489999999999999, "red_v3": -0.008, "red_v15": -2.0059999999999993, "red_v14": 0.490692542772942, "red_v16": -1.0139999999999998, "red_v45": -1.002, "red_v22": -0.15499999999999992, "red_v1": -2.025999999999998, "red_v40": 0.7856932378161704, "red_v11": -2.012999999999999, "red_v4": -1.0119999999999996, "red_v56": -1.004, "red_v13": -1.5649999999999995, "red_v66": 0.48969323781617136, "red_v28": -1.0069999999999997, "red_v63": -0.5549999999999999, "red_v58": -1.002, "red_v52": -1.002, "red_v31": 1.6016562500000022}, "policy_reward_max": {"red_v30": 1.5066932378152036, "red": 3.994446783544055, "blue": 1.465390625, "red_v64": -1.0019999999999998, "red_v32": 1.50369323781617, "red_v21": -0.006, "red_v12": -2.0239999999999982, "red_v38": 1.887421875, "red_v17": -2.013, "red_v20": -1.525, "red_v46": -0.15599999999999986, "red_v18": 0.5006932378161698, "red_v57": -2.003, "red_v60": 0.19046875000000107, "red_v35": -0.5559999999999998, "red_v51": 0.4996925427729423, "red_v34": -1.0079999999999993, "red_v25": 0.4926932378161699, "red_v36": -0.05999999999999983, "red_v2": -1.0079999999999998, "red_v23": -1.0119999999999996, "red_v37": 0.49669323781617036, "red_v3": -0.008, "red_v15": 0.4916932378161699, "red_v14": 0.490692542772942, "red_v16": -1.0139999999999998, "red_v45": -1.002, "red_v22": -0.15499999999999992, "red_v1": -2.025999999999998, "red_v40": 0.7856932378161704, "red_v11": -2.012999999999999, "red_v4": -1.0119999999999996, "red_v56": -1.004, "red_v13": -1.5649999999999995, "red_v66": 0.48969323781617136, "red_v28": -1.0069999999999997, "red_v63": -0.5549999999999999, "red_v58": -1.002, "red_v52": -1.002, "red_v31": 1.6016562500000022}, "policy_reward_mean": {"red_v30": 1.5066932378152036, "red": 3.135472645804454, "blue": -1.0575139973958327, "red_v64": -1.0019999999999998, "red_v32": -0.5061022540612763, "red_v21": -0.5184999999999985, "red_v12": -2.0239999999999982, "red_v38": 1.1886782447212962, "red_v17": -2.0164999999999993, "red_v20": -1.7659999999999998, "red_v46": -0.5789999999999998, "red_v18": 0.5006932378161698, "red_v57": -2.003, "red_v60": 0.19046875000000107, "red_v35": -0.5559999999999998, "red_v51": 0.24134627138647113, "red_v34": -1.0109999999999997, "red_v25": 0.24184661890808495, "red_v36": -0.05999999999999983, "red_v2": -1.3456666666666657, "red_v23": -1.0119999999999996, "red_v37": 0.17384661890808523, "red_v3": -0.008, "red_v15": -0.7571533810919147, "red_v14": 0.490692542772942, "red_v16": -1.0139999999999998, "red_v45": -1.002, "red_v22": -0.15499999999999992, "red_v1": -2.025999999999998, "red_v40": 0.7856932378161704, "red_v11": -2.012999999999999, "red_v4": -1.0119999999999996, "red_v56": -1.004, "red_v13": -1.5649999999999995, "red_v66": 0.48969323781617136, "red_v28": -1.0069999999999997, "red_v63": -0.5549999999999999, "red_v58": -1.002, "red_v52": -1.002, "red_v31": 1.6016562500000022}, "hist_stats": {"episode_reward": [4.497214600631374, 1.3796776128161756, 2.472490112815205, 2.948833862816172, 2.3319119878161705, 1.4660838628161705, 1.982446783544055, 3.4586463628161708, 2.48249011281617, 2.4717124085440556, 1.9647869878161714, 2.9904425427729415, 1.4384276128161724, 2.4777088628161703, 3.874265094442592, 2.4555369878161715, 1.9551619878161708, 1.3763304800000005, 2.4923338628152036, 3.9727458506323408, 2.606565625, 1.4753877394425925, 2.4738963628161703, -1.3416973871838234, 2.485818237815204, 2.4641619878161705, 0.46116198781522577, 1.9717869878161702, 1.15820625, 2.454349487816171, 2.9362244878161703, 3.3252713628161708, 2.4592401128152046, 2.4346932378161723, 2.3765179800000005, 1.4246307378161713, 2.967896362816171, 2.3684086050000004, 2.4636776128161704, 1.48270886281617, 3.952792725632342, 4.49310522563234, 1.9770057378161705, 2.0939562500000015, 1.9599744878161702, 2.3915249085440573, 2.4926307378161696, 1.88573673, 2.4747088628161706, 3.9704489756323413, 2.9741932378161704, 2.4543494878161716, 1.9822244878161699, 1.9710838628161704, 3.9828857805891125, 3.953010780589112, 1.8931151128161745, 2.3772557378161725, 1.4135369878161703, 2.4659744878161707, 2.38473673, 1.4757088628161705, 2.3705179800000002, 1.9307713628161716, 0.9396151128161699, 0.8512244878161703, 3.336743658544055, 1.931474487816172, 2.372814855, 2.3303437500000004, 2.484927612815204, 2.2843864756323655, 2.453911987816171, 2.47641198781617, 1.4761151128161707, 2.476411987816171, 1.7346718750000056, 2.4875213628152038, 2.441240112816171, 0.8446932378161708, 1.985446783544055, 2.4709744878161706, 2.48622448781617, 2.4681619878161705, 0.9077401128161724, 1.2791619878161755, 2.4715682378161703, 3.3419269177729425, 3.920542725632342, 2.468575239442593, 2.98111511281617, 2.826221105, 2.4803807378161697, 2.4539432378161705, 3.934839600632342, 0.988040533544055, 2.47938073781617, 1.4660838628161703, 2.475415533544055, 2.102349487816175], "episode_lengths": [23, 101, 33, 51, 122, 35, 18, 47, 33, 29, 34, 16, 53, 27, 17, 50, 42, 17, 19, 45, 59, 15, 31, 349, 24, 42, 426, 34, 14, 46, 22, 39, 49, 64, 21, 84, 31, 24, 37, 27, 62, 26, 28, 30, 38, 89, 20, 15, 27, 44, 32, 46, 22, 35, 32, 56, 89, 140, 114, 38, 15, 27, 21, 71, 57, 150, 19, 70, 22, 18, 21, 1280, 58, 26, 25, 26, 73, 23, 49, 128, 18, 38, 22, 42, 81, 234, 40, 21, 78, 19, 25, 20, 36, 48, 79, 20, 36, 35, 28, 302], "policy_red_v30_reward": [1.5066932378152036], "policy_blue_reward": [-2.0279999999999974, -1.0099999999999993, -0.010000000000000002, -1.0329999999999973, -2.0079999999999996, -2.006, 0.487, -1.0129999999999997, -1.007, -1.0069999999999995, -0.017000000000000005, -1.0079999999999998, 0.40100000000000424, -1.005, -1.0079999999999996, -2.0089999999999995, -1.0109999999999997, -1.0089999999999997, -1.023999999999998, -1.005, -1.0190000000000001, -1.0069999999999995, -2.0049999999999994, -2.007999999999999, -2.0139999999999993, -1.001, -1.0059999999999998, -2.0069999999999997, -1.0139999999999991, -2.008, -1.0059999999999996, -2.0189999999999984, -1.548, -1.007, -0.008, -1.0129999999999997, -1.0089999999999997, -1.0239999999999998, -1.0199999999999994, -2.0089999999999995, -1.0049999999999994, -1.535, -1.053, -1.0089999999999995, -1.0159999999999993, 0.4809375, 1.465390625, -1.0069999999999992], "policy_red_v64_reward": [-1.0019999999999998], "policy_red_v32_reward": [-2.015999999999999, 1.50369323781617, -1.0059999999999998], "policy_red_v21_reward": [-0.006, -1.030999999999997], "policy_red_v12_reward": [-2.0239999999999982], "policy_red_v38_reward": [0.4899346144425923, 1.887421875], "policy_red_v17_reward": [-2.0199999999999987, -2.013], "policy_red_v20_reward": [-2.0069999999999997, -1.525], "policy_red_v46_reward": [-1.0019999999999998, -0.15599999999999986], "policy_red_v18_reward": [0.5006932378161698], "policy_red_v57_reward": [-2.003], "policy_red_v60_reward": [0.19046875000000107], "policy_red_v35_reward": [-0.5559999999999998], "policy_red_v51_reward": [-0.017000000000000005, 0.4996925427729423], "policy_red_v34_reward": [-1.0139999999999998, -1.0079999999999993], "policy_red_v25_reward": [0.4926932378161699, -0.009000000000000001], "policy_red_v36_reward": [-0.05999999999999983], "policy_red_v2_reward": [-1.0279999999999974, -2.001, -1.0079999999999998], "policy_red_v23_reward": [-1.0119999999999996], "policy_red_v37_reward": [0.49669323781617036, -0.1489999999999999], "policy_red_v3_reward": [-0.008], "policy_red_v15_reward": [-2.0059999999999993, 0.4916932378161699], "policy_red_v14_reward": [0.490692542772942], "policy_red_v16_reward": [-1.0139999999999998], "policy_red_v45_reward": [-1.002], "policy_red_v22_reward": [-0.15499999999999992], "policy_red_v1_reward": [-2.025999999999998], "policy_red_v40_reward": [0.7856932378161704], "policy_red_v11_reward": [-2.012999999999999], "policy_red_v4_reward": [-1.0119999999999996], "policy_red_v56_reward": [-1.004], "policy_red_v13_reward": [-1.5649999999999995], "policy_red_v66_reward": [0.48969323781617136], "policy_red_v28_reward": [-1.0069999999999997], "policy_red_v63_reward": [-0.5549999999999999], "policy_red_v58_reward": [-1.002], "policy_red_v52_reward": [-1.002], "policy_red_v31_reward": [1.6016562500000022]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8191597519723632, "mean_inference_ms": 7.718294216520023, "mean_action_processing_ms": 0.294859083363142, "mean_env_wait_ms": 0.39248867226648215, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10448598861694336, "StateBufferConnector_ms": 0.004374861717224121, "ViewRequirementAgentConnector_ms": 0.12138092517852783}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 808000, "num_agent_steps_trained": 808000, "num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 203.9651223523323, "num_env_steps_trained_throughput_per_sec": 203.9651223523323, "timesteps_total": 404000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 808000, "timers": {"training_iteration_time_ms": 19737.042, "sample_time_ms": 1165.546, "learn_time_ms": 18487.333, "learn_throughput": 216.364, "synch_weights_time_ms": 80.586}, "counters": {"num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_agent_steps_sampled": 808000, "num_agent_steps_trained": 808000}, "done": false, "episodes_total": 1841, "training_iteration": 101, "trial_id": "a9680_00000", "date": "2023-09-24_03-13-27", "timestamp": 1695539607, "time_this_iter_s": 19.621370792388916, "time_total_s": 2013.6904690265656, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dee7550>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1de43b50>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1de43be0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2013.6904690265656, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 5.015789473684212, "ram_util_percent": 24.78684210526315}, "win_rate": 0.82, "league_size": 70}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.461294424037139, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.060262190087208484, "policy_loss": -0.04195264853381862, "vf_loss": 0.19281465550496554, "vf_explained_var": 0.8400636326521635, "kl": 0.016188043595351094, "entropy": 1.4771084484954675, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 97440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "sampler_results": {"episode_reward_max": 3.9945150213602254, "episode_reward_min": -2.0144005121838227, "episode_reward_mean": 2.3255834691810624, "episode_len_mean": 77.35, "episode_media": {}, "episodes_this_iter": 44, "policy_reward_min": {"blue": -2.0189999999999984, "red": -3.3844005121838316, "red_v2": -2.001, "red_v23": -1.0119999999999996, "red_v37": -0.1489999999999999, "red_v3": -0.008, "red_v15": -2.0059999999999993, "red_v51": 0.4996925427729423, "red_v14": 0.490692542772942, "red_v38": 1.887421875, "red_v21": -1.030999999999997, "red_v16": -1.0139999999999998, "red_v45": -1.002, "red_v20": -1.525, "red_v22": -0.15499999999999992, "red_v1": -2.025999999999998, "red_v32": -1.0059999999999998, "red_v40": 0.7856932378161704, "red_v11": -2.012999999999999, "red_v4": -1.0119999999999996, "red_v56": -1.004, "red_v13": -1.5649999999999995, "red_v34": -1.0079999999999993, "red_v66": 0.48969323781617136, "red_v28": -1.0069999999999997, "red_v25": -0.009000000000000001, "red_v63": -0.5549999999999999, "red_v58": -1.002, "red_v52": -1.002, "red_v31": 0.49869323781520425, "red_v10": -2.038999999999997, "red_v47": -0.01900000000000001, "red_v46": -1.001, "red_v57": -1.005, "red_v33": -1.7849999999999542, "red_v64": 0.5051030335440551, "red_v7": -1.0129999999999995, "red_v26": -2.0089999999999995, "red_v30": 0.5016925427729421, "red_v17": -0.1499999999999999, "red_v8": -2.0149999999999997, "red_v50": 1.9449119878161707, "red_v61": -2.0069999999999997, "red_v29": 0.4769346144425925, "red_v68": -2.008}, "policy_reward_max": {"blue": 1.465390625, "red": 3.9950362927729417, "red_v2": -1.0079999999999998, "red_v23": 0.44, "red_v37": 0.49669323781617036, "red_v3": 0.38728360500000036, "red_v15": 0.4916932378161699, "red_v51": 0.4996925427729423, "red_v14": 0.490692542772942, "red_v38": 1.887421875, "red_v21": -1.030999999999997, "red_v16": -1.0139999999999998, "red_v45": -1.002, "red_v20": -1.525, "red_v22": -0.15499999999999992, "red_v1": -2.025999999999998, "red_v32": -1.0059999999999998, "red_v40": 0.7856932378161704, "red_v11": -2.012999999999999, "red_v4": -1.0119999999999996, "red_v56": -1.004, "red_v13": -1.5649999999999995, "red_v34": -1.0079999999999993, "red_v66": 0.48969323781617136, "red_v28": -1.0069999999999997, "red_v25": -0.009000000000000001, "red_v63": 0.49869323781617036, "red_v58": -1.002, "red_v52": -1.002, "red_v31": 1.6016562500000022, "red_v10": 0.4946932378152038, "red_v47": -0.01900000000000001, "red_v46": -0.568, "red_v57": -1.005, "red_v33": -1.7849999999999542, "red_v64": 0.5051030335440551, "red_v7": -1.0129999999999995, "red_v26": -2.0089999999999995, "red_v30": 0.5016925427729421, "red_v17": -0.1499999999999999, "red_v8": -2.0149999999999997, "red_v50": 1.9449119878161707, "red_v61": -2.0069999999999997, "red_v29": 0.4769346144425925, "red_v68": -2.008}, "policy_reward_mean": {"blue": -1.168666779891304, "red": 3.166037771342732, "red_v2": -1.3456666666666657, "red_v23": -0.2859999999999998, "red_v37": 0.17384661890808523, "red_v3": 0.18964180250000018, "red_v15": -0.7571533810919147, "red_v51": 0.4996925427729423, "red_v14": 0.490692542772942, "red_v38": 1.887421875, "red_v21": -1.030999999999997, "red_v16": -1.0139999999999998, "red_v45": -1.002, "red_v20": -1.525, "red_v22": -0.15499999999999992, "red_v1": -2.025999999999998, "red_v32": -1.0059999999999998, "red_v40": 0.7856932378161704, "red_v11": -2.012999999999999, "red_v4": -1.0119999999999996, "red_v56": -1.004, "red_v13": -1.5649999999999995, "red_v34": -1.0079999999999993, "red_v66": 0.48969323781617136, "red_v28": -1.0069999999999997, "red_v25": -0.009000000000000001, "red_v63": -0.028153381091914786, "red_v58": -1.002, "red_v52": -1.002, "red_v31": 1.0501747439076032, "red_v10": -1.1851022540615976, "red_v47": -0.01900000000000001, "red_v46": -0.7845, "red_v57": -1.005, "red_v33": -1.7849999999999542, "red_v64": 0.5051030335440551, "red_v7": -1.0129999999999995, "red_v26": -2.0089999999999995, "red_v30": 0.5016925427729421, "red_v17": -0.1499999999999999, "red_v8": -2.0149999999999997, "red_v50": 1.9449119878161707, "red_v61": -2.0069999999999997, "red_v29": 0.4769346144425925, "red_v68": -2.008}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.9599744878161702, 2.3915249085440573, 2.4926307378161696, 1.88573673, 2.4747088628161706, 3.9704489756323413, 2.9741932378161704, 2.4543494878161716, 1.9822244878161699, 1.9710838628161704, 3.9828857805891125, 3.953010780589112, 1.8931151128161745, 2.3772557378161725, 1.4135369878161703, 2.4659744878161707, 2.38473673, 1.4757088628161705, 2.3705179800000002, 1.9307713628161716, 0.9396151128161699, 0.8512244878161703, 3.336743658544055, 1.931474487816172, 2.372814855, 2.3303437500000004, 2.484927612815204, 2.2843864756323655, 2.453911987816171, 2.47641198781617, 1.4761151128161707, 2.476411987816171, 1.7346718750000056, 2.4875213628152038, 2.441240112816171, 0.8446932378161708, 1.985446783544055, 2.4709744878161706, 2.48622448781617, 2.4681619878161705, 0.9077401128161724, 1.2791619878161755, 2.4715682378161703, 3.3419269177729425, 3.920542725632342, 2.468575239442593, 2.98111511281617, 2.826221105, 2.4803807378161697, 2.4539432378161705, 3.934839600632342, 0.988040533544055, 2.47938073781617, 1.4660838628161703, 2.475415533544055, 2.102349487816175, 2.4646776128161707, 3.971370850631375, 2.444021362816172, 1.991036292772942, 2.4641925427729423, -2.0144005121838227, 2.9523494878161722, 1.9804119878161701, 1.987333862815204, 2.4708651128161705, 2.4645682378161706, 2.48481823781617, 1.3925994878161738, 2.3721117300000003, -0.4433067621838311, 2.453536987816171, 1.9503963628161702, 2.4719744878161705, 1.9514276128161716, 0.9674901128161703, 2.486630042772942, 3.9945150213602254, 2.4708963628161706, 1.947802612816171, 3.992213905589112, 3.4023182378161714, 3.958011475632341, 1.962161987816171, 3.343446783544055, 1.9721151128161702, 2.4486052256323427, 2.437724487816172, 1.4563182378161708, 1.9539432378161714, 1.4743026128161705, 2.463271362816171, 3.8594455928161704, 1.340859375, 2.945943237816172, 3.962198975631374, 2.883208862816173, 3.956127852258762, 1.8794398550000002, 1.4743807378161704], "episode_lengths": [38, 89, 20, 15, 27, 44, 32, 46, 22, 35, 32, 56, 89, 140, 114, 38, 15, 27, 21, 71, 57, 150, 19, 70, 22, 18, 21, 1280, 58, 26, 25, 26, 73, 23, 49, 128, 18, 38, 22, 42, 81, 234, 40, 21, 78, 19, 25, 20, 36, 48, 79, 20, 36, 35, 28, 302, 37, 37, 55, 18, 32, 542, 46, 26, 19, 41, 40, 24, 94, 23, 1280, 50, 63, 38, 53, 33, 20, 26, 31, 61, 23, 56, 56, 42, 18, 25, 58, 54, 56, 48, 29, 39, 42, 13, 48, 60, 59, 32, 14, 36], "policy_blue_reward": [-2.0139999999999993, -1.001, -1.0059999999999998, -2.0069999999999997, -1.0139999999999991, -2.008, -1.0059999999999996, -2.0189999999999984, -1.548, -1.007, -0.008, -1.0129999999999997, -1.0089999999999997, -1.0239999999999998, -1.0199999999999994, -2.0089999999999995, -1.0049999999999994, -1.535, -1.053, -1.0089999999999995, -1.0159999999999993, 0.4809375, 1.465390625, -1.0069999999999992, -1.016999999999999, -1.0179999999999987, -2.0039999999999996, -1.0129999999999997, 1.3700000000000063, -2.009, -2.0039999999999996, -1.0139999999999996, -1.0059999999999996, -1.0169999999999997, -1.0089999999999995, -2.012999999999999, -1.513, -1.0059999999999998, -2.0119999999999996, -1.0229999999999988, -2.0089999999999995, -2.008, -1.011999999999999, -2.003, -0.020000000000000004, -2.0069999999999997], "policy_red_v2_reward": [-1.0279999999999974, -2.001, -1.0079999999999998], "policy_red_v23_reward": [-1.0119999999999996, 0.44], "policy_red_v37_reward": [0.49669323781617036, -0.1489999999999999], "policy_red_v3_reward": [-0.008, 0.38728360500000036], "policy_red_v15_reward": [-2.0059999999999993, 0.4916932378161699], "policy_red_v51_reward": [0.4996925427729423], "policy_red_v14_reward": [0.490692542772942], "policy_red_v38_reward": [1.887421875], "policy_red_v21_reward": [-1.030999999999997], "policy_red_v16_reward": [-1.0139999999999998], "policy_red_v45_reward": [-1.002], "policy_red_v20_reward": [-1.525], "policy_red_v22_reward": [-0.15499999999999992], "policy_red_v1_reward": [-2.025999999999998], "policy_red_v32_reward": [-1.0059999999999998], "policy_red_v40_reward": [0.7856932378161704], "policy_red_v11_reward": [-2.012999999999999], "policy_red_v4_reward": [-1.0119999999999996], "policy_red_v56_reward": [-1.004], "policy_red_v13_reward": [-1.5649999999999995], "policy_red_v34_reward": [-1.0079999999999993], "policy_red_v66_reward": [0.48969323781617136], "policy_red_v28_reward": [-1.0069999999999997], "policy_red_v25_reward": [-0.009000000000000001], "policy_red_v63_reward": [-0.5549999999999999, 0.49869323781617036], "policy_red_v58_reward": [-1.002], "policy_red_v52_reward": [-1.002], "policy_red_v31_reward": [1.6016562500000022, 0.49869323781520425], "policy_red_v10_reward": [0.4946932378152038, -2.038999999999997, -2.0109999999999997], "policy_red_v47_reward": [-0.01900000000000001], "policy_red_v46_reward": [-1.001, -0.568], "policy_red_v57_reward": [-1.005], "policy_red_v33_reward": [-1.7849999999999542], "policy_red_v64_reward": [0.5051030335440551], "policy_red_v7_reward": [-1.0129999999999995], "policy_red_v26_reward": [-2.0089999999999995], "policy_red_v30_reward": [0.5016925427729421], "policy_red_v17_reward": [-0.1499999999999999], "policy_red_v8_reward": [-2.0149999999999997], "policy_red_v50_reward": [1.9449119878161707], "policy_red_v61_reward": [-2.0069999999999997], "policy_red_v29_reward": [0.4769346144425925], "policy_red_v68_reward": [-2.008]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8200125755217982, "mean_inference_ms": 7.7306076417900975, "mean_action_processing_ms": 0.295034224891589, "mean_env_wait_ms": 0.3918626713769283, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10287749767303467, "StateBufferConnector_ms": 0.004269957542419434, "ViewRequirementAgentConnector_ms": 0.1186060905456543}}, "episode_reward_max": 3.9945150213602254, "episode_reward_min": -2.0144005121838227, "episode_reward_mean": 2.3255834691810624, "episode_len_mean": 77.35, "episodes_this_iter": 44, "policy_reward_min": {"blue": -2.0189999999999984, "red": -3.3844005121838316, "red_v2": -2.001, "red_v23": -1.0119999999999996, "red_v37": -0.1489999999999999, "red_v3": -0.008, "red_v15": -2.0059999999999993, "red_v51": 0.4996925427729423, "red_v14": 0.490692542772942, "red_v38": 1.887421875, "red_v21": -1.030999999999997, "red_v16": -1.0139999999999998, "red_v45": -1.002, "red_v20": -1.525, "red_v22": -0.15499999999999992, "red_v1": -2.025999999999998, "red_v32": -1.0059999999999998, "red_v40": 0.7856932378161704, "red_v11": -2.012999999999999, "red_v4": -1.0119999999999996, "red_v56": -1.004, "red_v13": -1.5649999999999995, "red_v34": -1.0079999999999993, "red_v66": 0.48969323781617136, "red_v28": -1.0069999999999997, "red_v25": -0.009000000000000001, "red_v63": -0.5549999999999999, "red_v58": -1.002, "red_v52": -1.002, "red_v31": 0.49869323781520425, "red_v10": -2.038999999999997, "red_v47": -0.01900000000000001, "red_v46": -1.001, "red_v57": -1.005, "red_v33": -1.7849999999999542, "red_v64": 0.5051030335440551, "red_v7": -1.0129999999999995, "red_v26": -2.0089999999999995, "red_v30": 0.5016925427729421, "red_v17": -0.1499999999999999, "red_v8": -2.0149999999999997, "red_v50": 1.9449119878161707, "red_v61": -2.0069999999999997, "red_v29": 0.4769346144425925, "red_v68": -2.008}, "policy_reward_max": {"blue": 1.465390625, "red": 3.9950362927729417, "red_v2": -1.0079999999999998, "red_v23": 0.44, "red_v37": 0.49669323781617036, "red_v3": 0.38728360500000036, "red_v15": 0.4916932378161699, "red_v51": 0.4996925427729423, "red_v14": 0.490692542772942, "red_v38": 1.887421875, "red_v21": -1.030999999999997, "red_v16": -1.0139999999999998, "red_v45": -1.002, "red_v20": -1.525, "red_v22": -0.15499999999999992, "red_v1": -2.025999999999998, "red_v32": -1.0059999999999998, "red_v40": 0.7856932378161704, "red_v11": -2.012999999999999, "red_v4": -1.0119999999999996, "red_v56": -1.004, "red_v13": -1.5649999999999995, "red_v34": -1.0079999999999993, "red_v66": 0.48969323781617136, "red_v28": -1.0069999999999997, "red_v25": -0.009000000000000001, "red_v63": 0.49869323781617036, "red_v58": -1.002, "red_v52": -1.002, "red_v31": 1.6016562500000022, "red_v10": 0.4946932378152038, "red_v47": -0.01900000000000001, "red_v46": -0.568, "red_v57": -1.005, "red_v33": -1.7849999999999542, "red_v64": 0.5051030335440551, "red_v7": -1.0129999999999995, "red_v26": -2.0089999999999995, "red_v30": 0.5016925427729421, "red_v17": -0.1499999999999999, "red_v8": -2.0149999999999997, "red_v50": 1.9449119878161707, "red_v61": -2.0069999999999997, "red_v29": 0.4769346144425925, "red_v68": -2.008}, "policy_reward_mean": {"blue": -1.168666779891304, "red": 3.166037771342732, "red_v2": -1.3456666666666657, "red_v23": -0.2859999999999998, "red_v37": 0.17384661890808523, "red_v3": 0.18964180250000018, "red_v15": -0.7571533810919147, "red_v51": 0.4996925427729423, "red_v14": 0.490692542772942, "red_v38": 1.887421875, "red_v21": -1.030999999999997, "red_v16": -1.0139999999999998, "red_v45": -1.002, "red_v20": -1.525, "red_v22": -0.15499999999999992, "red_v1": -2.025999999999998, "red_v32": -1.0059999999999998, "red_v40": 0.7856932378161704, "red_v11": -2.012999999999999, "red_v4": -1.0119999999999996, "red_v56": -1.004, "red_v13": -1.5649999999999995, "red_v34": -1.0079999999999993, "red_v66": 0.48969323781617136, "red_v28": -1.0069999999999997, "red_v25": -0.009000000000000001, "red_v63": -0.028153381091914786, "red_v58": -1.002, "red_v52": -1.002, "red_v31": 1.0501747439076032, "red_v10": -1.1851022540615976, "red_v47": -0.01900000000000001, "red_v46": -0.7845, "red_v57": -1.005, "red_v33": -1.7849999999999542, "red_v64": 0.5051030335440551, "red_v7": -1.0129999999999995, "red_v26": -2.0089999999999995, "red_v30": 0.5016925427729421, "red_v17": -0.1499999999999999, "red_v8": -2.0149999999999997, "red_v50": 1.9449119878161707, "red_v61": -2.0069999999999997, "red_v29": 0.4769346144425925, "red_v68": -2.008}, "hist_stats": {"episode_reward": [1.9599744878161702, 2.3915249085440573, 2.4926307378161696, 1.88573673, 2.4747088628161706, 3.9704489756323413, 2.9741932378161704, 2.4543494878161716, 1.9822244878161699, 1.9710838628161704, 3.9828857805891125, 3.953010780589112, 1.8931151128161745, 2.3772557378161725, 1.4135369878161703, 2.4659744878161707, 2.38473673, 1.4757088628161705, 2.3705179800000002, 1.9307713628161716, 0.9396151128161699, 0.8512244878161703, 3.336743658544055, 1.931474487816172, 2.372814855, 2.3303437500000004, 2.484927612815204, 2.2843864756323655, 2.453911987816171, 2.47641198781617, 1.4761151128161707, 2.476411987816171, 1.7346718750000056, 2.4875213628152038, 2.441240112816171, 0.8446932378161708, 1.985446783544055, 2.4709744878161706, 2.48622448781617, 2.4681619878161705, 0.9077401128161724, 1.2791619878161755, 2.4715682378161703, 3.3419269177729425, 3.920542725632342, 2.468575239442593, 2.98111511281617, 2.826221105, 2.4803807378161697, 2.4539432378161705, 3.934839600632342, 0.988040533544055, 2.47938073781617, 1.4660838628161703, 2.475415533544055, 2.102349487816175, 2.4646776128161707, 3.971370850631375, 2.444021362816172, 1.991036292772942, 2.4641925427729423, -2.0144005121838227, 2.9523494878161722, 1.9804119878161701, 1.987333862815204, 2.4708651128161705, 2.4645682378161706, 2.48481823781617, 1.3925994878161738, 2.3721117300000003, -0.4433067621838311, 2.453536987816171, 1.9503963628161702, 2.4719744878161705, 1.9514276128161716, 0.9674901128161703, 2.486630042772942, 3.9945150213602254, 2.4708963628161706, 1.947802612816171, 3.992213905589112, 3.4023182378161714, 3.958011475632341, 1.962161987816171, 3.343446783544055, 1.9721151128161702, 2.4486052256323427, 2.437724487816172, 1.4563182378161708, 1.9539432378161714, 1.4743026128161705, 2.463271362816171, 3.8594455928161704, 1.340859375, 2.945943237816172, 3.962198975631374, 2.883208862816173, 3.956127852258762, 1.8794398550000002, 1.4743807378161704], "episode_lengths": [38, 89, 20, 15, 27, 44, 32, 46, 22, 35, 32, 56, 89, 140, 114, 38, 15, 27, 21, 71, 57, 150, 19, 70, 22, 18, 21, 1280, 58, 26, 25, 26, 73, 23, 49, 128, 18, 38, 22, 42, 81, 234, 40, 21, 78, 19, 25, 20, 36, 48, 79, 20, 36, 35, 28, 302, 37, 37, 55, 18, 32, 542, 46, 26, 19, 41, 40, 24, 94, 23, 1280, 50, 63, 38, 53, 33, 20, 26, 31, 61, 23, 56, 56, 42, 18, 25, 58, 54, 56, 48, 29, 39, 42, 13, 48, 60, 59, 32, 14, 36], "policy_blue_reward": [-2.0139999999999993, -1.001, -1.0059999999999998, -2.0069999999999997, -1.0139999999999991, -2.008, -1.0059999999999996, -2.0189999999999984, -1.548, -1.007, -0.008, -1.0129999999999997, -1.0089999999999997, -1.0239999999999998, -1.0199999999999994, -2.0089999999999995, -1.0049999999999994, -1.535, -1.053, -1.0089999999999995, -1.0159999999999993, 0.4809375, 1.465390625, -1.0069999999999992, -1.016999999999999, -1.0179999999999987, -2.0039999999999996, -1.0129999999999997, 1.3700000000000063, -2.009, -2.0039999999999996, -1.0139999999999996, -1.0059999999999996, -1.0169999999999997, -1.0089999999999995, -2.012999999999999, -1.513, -1.0059999999999998, -2.0119999999999996, -1.0229999999999988, -2.0089999999999995, -2.008, -1.011999999999999, -2.003, -0.020000000000000004, -2.0069999999999997], "policy_red_v2_reward": [-1.0279999999999974, -2.001, -1.0079999999999998], "policy_red_v23_reward": [-1.0119999999999996, 0.44], "policy_red_v37_reward": [0.49669323781617036, -0.1489999999999999], "policy_red_v3_reward": [-0.008, 0.38728360500000036], "policy_red_v15_reward": [-2.0059999999999993, 0.4916932378161699], "policy_red_v51_reward": [0.4996925427729423], "policy_red_v14_reward": [0.490692542772942], "policy_red_v38_reward": [1.887421875], "policy_red_v21_reward": [-1.030999999999997], "policy_red_v16_reward": [-1.0139999999999998], "policy_red_v45_reward": [-1.002], "policy_red_v20_reward": [-1.525], "policy_red_v22_reward": [-0.15499999999999992], "policy_red_v1_reward": [-2.025999999999998], "policy_red_v32_reward": [-1.0059999999999998], "policy_red_v40_reward": [0.7856932378161704], "policy_red_v11_reward": [-2.012999999999999], "policy_red_v4_reward": [-1.0119999999999996], "policy_red_v56_reward": [-1.004], "policy_red_v13_reward": [-1.5649999999999995], "policy_red_v34_reward": [-1.0079999999999993], "policy_red_v66_reward": [0.48969323781617136], "policy_red_v28_reward": [-1.0069999999999997], "policy_red_v25_reward": [-0.009000000000000001], "policy_red_v63_reward": [-0.5549999999999999, 0.49869323781617036], "policy_red_v58_reward": [-1.002], "policy_red_v52_reward": [-1.002], "policy_red_v31_reward": [1.6016562500000022, 0.49869323781520425], "policy_red_v10_reward": [0.4946932378152038, -2.038999999999997, -2.0109999999999997], "policy_red_v47_reward": [-0.01900000000000001], "policy_red_v46_reward": [-1.001, -0.568], "policy_red_v57_reward": [-1.005], "policy_red_v33_reward": [-1.7849999999999542], "policy_red_v64_reward": [0.5051030335440551], "policy_red_v7_reward": [-1.0129999999999995], "policy_red_v26_reward": [-2.0089999999999995], "policy_red_v30_reward": [0.5016925427729421], "policy_red_v17_reward": [-0.1499999999999999], "policy_red_v8_reward": [-2.0149999999999997], "policy_red_v50_reward": [1.9449119878161707], "policy_red_v61_reward": [-2.0069999999999997], "policy_red_v29_reward": [0.4769346144425925], "policy_red_v68_reward": [-2.008]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8200125755217982, "mean_inference_ms": 7.7306076417900975, "mean_action_processing_ms": 0.295034224891589, "mean_env_wait_ms": 0.3918626713769283, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10287749767303467, "StateBufferConnector_ms": 0.004269957542419434, "ViewRequirementAgentConnector_ms": 0.1186060905456543}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.52876045117586, "num_env_steps_trained_throughput_per_sec": 199.52876045117586, "timesteps_total": 408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 19757.673, "sample_time_ms": 1163.03, "learn_time_ms": 18510.501, "learn_throughput": 216.094, "synch_weights_time_ms": 80.638}, "counters": {"num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "episodes_total": 1885, "training_iteration": 102, "trial_id": "a9680_00000", "date": "2023-09-24_03-13-51", "timestamp": 1695539631, "time_this_iter_s": 20.05983805656433, "time_total_s": 2033.7503070831299, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1de4b250>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1dd50040>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1dd500d0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2033.7503070831299, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 5.6571428571428575, "ram_util_percent": 24.888571428571424}, "win_rate": 0.8, "league_size": 71}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4676047939807177, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.02545176782781103, "policy_loss": -0.05520925964131796, "vf_loss": 0.14825250919675453, "vf_explained_var": 0.8458534764125943, "kl": 0.01791281461797401, "entropy": 1.5259933392206828, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 98400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_agent_steps_sampled": 824000, "num_agent_steps_trained": 824000}, "sampler_results": {"episode_reward_max": 4.467721602258763, "episode_reward_min": -2.0144005121838227, "episode_reward_mean": 2.3104148965673783, "episode_len_mean": 81.87, "episode_media": {}, "episodes_this_iter": 47, "policy_reward_min": {"red_v63": -0.5549999999999999, "red": -3.3844005121838316, "red_v58": -2.003, "blue": -2.012999999999999, "red_v15": 0.4916932378161699, "red_v52": -1.002, "red_v31": 0.49869323781520425, "red_v10": -2.038999999999997, "red_v47": -0.01900000000000001, "red_v46": -1.001, "red_v57": -1.005, "red_v33": -1.7849999999999542, "red_v64": 0.5051030335440551, "red_v7": -1.0129999999999995, "red_v26": -2.0089999999999995, "red_v30": 0.5016925427729421, "red_v23": 0.44, "red_v17": -0.1499999999999999, "red_v8": -2.0149999999999997, "red_v50": 1.9449119878161707, "red_v61": -2.0069999999999997, "red_v3": 0.38728360500000036, "red_v29": 0.4769346144425925, "red_v68": -2.0089999999999995, "red_v40": -2.100999999999993, "red_v45": 0.4996932378161705, "red_v19": -0.728, "red_v20": -2.0539999999999967, "red_v12": -0.002, "red_v60": -2.057999999999994, "red_v38": -1.0169999999999995, "red_v39": -1.5099999999999998, "red_v53": -2.005, "red_v54": 0.45869323781616966, "red_v36": -0.14900000000000002, "red_v56": -2.0069999999999997, "red_v27": -1.0129999999999995, "red_v67": -2.002, "red_v16": -1.0359999999999987, "red_v43": 1.5056932378161703, "red_v22": 0.447, "red_v14": 0.39428360500000026, "red_v59": 0.44181250000000005, "red_v24": 1.3588182378161728}, "policy_reward_max": {"red_v63": 0.49869323781617036, "red": 3.9975561585440547, "red_v58": -1.002, "blue": 1.465390625, "red_v15": 0.4916932378161699, "red_v52": -1.002, "red_v31": 1.6016562500000022, "red_v10": 0.4946932378152038, "red_v47": -0.01900000000000001, "red_v46": 0.423, "red_v57": -1.005, "red_v33": -1.5070000000000001, "red_v64": 0.5051030335440551, "red_v7": -1.0079999999999998, "red_v26": -2.0089999999999995, "red_v30": 0.5016925427729421, "red_v23": 0.44, "red_v17": -0.1499999999999999, "red_v8": -2.0149999999999997, "red_v50": 1.9449119878161707, "red_v61": -2.0069999999999997, "red_v3": 0.38728360500000036, "red_v29": 0.4769346144425925, "red_v68": -2.008, "red_v40": 1.4976932378161705, "red_v45": 0.4996932378161705, "red_v19": -0.728, "red_v20": 0.4836925427729417, "red_v12": -0.002, "red_v60": -2.057999999999994, "red_v38": -1.0169999999999995, "red_v39": -1.5099999999999998, "red_v53": -2.005, "red_v54": 0.45869323781616966, "red_v36": -0.14900000000000002, "red_v56": -2.0069999999999997, "red_v27": -1.0129999999999995, "red_v67": -2.002, "red_v16": -0.516, "red_v43": 1.5056932378161703, "red_v22": 0.447, "red_v14": 0.39428360500000026, "red_v59": 0.44181250000000005, "red_v24": 1.3588182378161728}, "policy_reward_mean": {"red_v63": -0.028153381091914786, "red": 3.1149232367650126, "red_v58": -1.5025, "blue": -1.1679243607954541, "red_v15": 0.4916932378161699, "red_v52": -1.002, "red_v31": 0.8668175071197538, "red_v10": -1.1851022540615976, "red_v47": -0.01900000000000001, "red_v46": -0.38199999999999995, "red_v57": -1.005, "red_v33": -1.6459999999999773, "red_v64": 0.5051030335440551, "red_v7": -1.0104999999999995, "red_v26": -2.0089999999999995, "red_v30": 0.5016925427729421, "red_v23": 0.44, "red_v17": -0.1499999999999999, "red_v8": -2.0149999999999997, "red_v50": 1.9449119878161707, "red_v61": -2.0069999999999997, "red_v3": 0.38728360500000036, "red_v29": 0.4769346144425925, "red_v68": -2.0084999999999997, "red_v40": -0.3016533810919112, "red_v45": 0.4996932378161705, "red_v19": -0.728, "red_v20": -0.7851537286135275, "red_v12": -0.002, "red_v60": -2.057999999999994, "red_v38": -1.0169999999999995, "red_v39": -1.5099999999999998, "red_v53": -2.005, "red_v54": 0.45869323781616966, "red_v36": -0.14900000000000002, "red_v56": -2.0069999999999997, "red_v27": -1.0129999999999995, "red_v67": -2.002, "red_v16": -0.7759999999999994, "red_v43": 1.5056932378161703, "red_v22": 0.447, "red_v14": 0.39428360500000026, "red_v59": 0.44181250000000005, "red_v24": 1.3588182378161728}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.826221105, 2.4803807378161697, 2.4539432378161705, 3.934839600632342, 0.988040533544055, 2.47938073781617, 1.4660838628161703, 2.475415533544055, 2.102349487816175, 2.4646776128161707, 3.971370850631375, 2.444021362816172, 1.991036292772942, 2.4641925427729423, -2.0144005121838227, 2.9523494878161722, 1.9804119878161701, 1.987333862815204, 2.4708651128161705, 2.4645682378161706, 2.48481823781617, 1.3925994878161738, 2.3721117300000003, -0.4433067621838311, 2.453536987816171, 1.9503963628161702, 2.4719744878161705, 1.9514276128161716, 0.9674901128161703, 2.486630042772942, 3.9945150213602254, 2.4708963628161706, 1.947802612816171, 3.992213905589112, 3.4023182378161714, 3.958011475632341, 1.962161987816171, 3.343446783544055, 1.9721151128161702, 2.4486052256323427, 2.437724487816172, 1.4563182378161708, 1.9539432378161714, 1.4743026128161705, 2.463271362816171, 3.8594455928161704, 1.340859375, 2.945943237816172, 3.962198975631374, 2.883208862816173, 3.956127852258762, 1.8794398550000002, 1.4743807378161704, 1.2913182378161805, 3.9727458506323408, 4.458933350632342, 3.9812962713602262, 2.4328026128161726, 2.4834119878161705, 0.9145994878161703, 3.3826932378161723, 2.810193237816197, 3.929245155589112, 0.4248281250000001, 2.9938530335440547, 2.962271362816171, 1.3454744878161762, 2.455458862816171, 1.3957401128161733, 1.3682557378161784, 0.9207869878161704, 1.4588338628161708, 1.9879276128161703, 2.6251521006323593, 3.3412244878152038, 1.98681823781617, 1.9905561585440552, 1.8838461050000006, 2.4701932378161713, 2.48141198781617, 2.4613494878161704, 2.447427612816171, 1.3789242300000004, 2.3789242300000004, 2.4225057378161727, 4.467721602258763, 1.8199554800000008, 0.9695682378161706, 2.2329119878161787, 0.9144276128161698, 1.3686273550000005, 3.33133048, 2.485446783544055, 1.4754901128161706, 3.8851018428161703, 1.47038073781617, 0.9425057378161705, 2.48122448781617, 1.839511475632365, 2.4682713628161705], "episode_lengths": [20, 36, 48, 79, 20, 36, 35, 28, 302, 37, 37, 55, 18, 32, 542, 46, 26, 19, 41, 40, 24, 94, 23, 1280, 50, 63, 38, 53, 33, 20, 26, 31, 61, 23, 56, 56, 42, 18, 25, 58, 54, 56, 48, 29, 39, 42, 13, 48, 60, 59, 32, 14, 36, 120, 45, 49, 32, 61, 26, 94, 64, 416, 77, 23, 16, 39, 134, 43, 81, 588, 98, 51, 21, 299, 22, 24, 15, 12, 32, 26, 46, 53, 19, 19, 60, 34, 73, 40, 250, 117, 18, 17, 18, 33, 24, 36, 60, 22, 600, 39], "policy_red_v63_reward": [-0.5549999999999999, 0.49869323781617036], "policy_red_v58_reward": [-1.002, -2.003], "policy_blue_reward": [-1.0159999999999993, 0.4809375, 1.465390625, -1.0069999999999992, -1.016999999999999, -1.0179999999999987, -2.0039999999999996, -1.0129999999999997, 1.3700000000000063, -2.009, -2.0039999999999996, -1.0139999999999996, -1.0059999999999996, -1.0169999999999997, -1.0089999999999995, -2.012999999999999, -1.513, -1.0059999999999998, -2.0119999999999996, -1.0229999999999988, -2.0089999999999995, -2.008, -1.011999999999999, -2.003, -0.020000000000000004, -2.0069999999999997, -1.0189999999999988, -1.0039999999999998, -1.527, -2.008, -0.015000000000000006, -0.712, -2.0049999999999994, -1.0119999999999987, -1.0189999999999988, -1.003, -1.508, -1.0639999999999945, -2.0109999999999997, -1.0059999999999996, -2.008, -2.008, -1.0059999999999998, -1.0099999999999996], "policy_red_v15_reward": [0.4916932378161699], "policy_red_v52_reward": [-1.002], "policy_red_v31_reward": [1.6016562500000022, 0.49869323781520425, 0.5001030335440549], "policy_red_v10_reward": [0.4946932378152038, -2.038999999999997, -2.0109999999999997], "policy_red_v47_reward": [-0.01900000000000001], "policy_red_v46_reward": [-1.001, -0.568, 0.423], "policy_red_v57_reward": [-1.005], "policy_red_v33_reward": [-1.7849999999999542, -1.5070000000000001], "policy_red_v64_reward": [0.5051030335440551], "policy_red_v7_reward": [-1.0129999999999995, -1.0079999999999998], "policy_red_v26_reward": [-2.0089999999999995], "policy_red_v30_reward": [0.5016925427729421], "policy_red_v23_reward": [0.44], "policy_red_v17_reward": [-0.1499999999999999], "policy_red_v8_reward": [-2.0149999999999997], "policy_red_v50_reward": [1.9449119878161707], "policy_red_v61_reward": [-2.0069999999999997], "policy_red_v3_reward": [0.38728360500000036], "policy_red_v29_reward": [0.4769346144425925], "policy_red_v68_reward": [-2.008, -2.0089999999999995], "policy_red_v40_reward": [-2.100999999999993, 1.4976932378161705], "policy_red_v45_reward": [0.4996932378161705], "policy_red_v19_reward": [-0.728], "policy_red_v20_reward": [0.4836925427729417, -2.0539999999999967], "policy_red_v12_reward": [-0.002], "policy_red_v60_reward": [-2.057999999999994], "policy_red_v38_reward": [-1.0169999999999995], "policy_red_v39_reward": [-1.5099999999999998], "policy_red_v53_reward": [-2.005], "policy_red_v54_reward": [0.45869323781616966], "policy_red_v36_reward": [-0.14900000000000002], "policy_red_v56_reward": [-2.0069999999999997], "policy_red_v27_reward": [-1.0129999999999995], "policy_red_v67_reward": [-2.002], "policy_red_v16_reward": [-1.0359999999999987, -0.516], "policy_red_v43_reward": [1.5056932378161703], "policy_red_v22_reward": [0.447], "policy_red_v14_reward": [0.39428360500000026], "policy_red_v59_reward": [0.44181250000000005], "policy_red_v24_reward": [1.3588182378161728]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8186534990252065, "mean_inference_ms": 7.713465512085636, "mean_action_processing_ms": 0.29382548032161687, "mean_env_wait_ms": 0.39062779153268756, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10344183444976807, "StateBufferConnector_ms": 0.004283785820007324, "ViewRequirementAgentConnector_ms": 0.1186593770980835}}, "episode_reward_max": 4.467721602258763, "episode_reward_min": -2.0144005121838227, "episode_reward_mean": 2.3104148965673783, "episode_len_mean": 81.87, "episodes_this_iter": 47, "policy_reward_min": {"red_v63": -0.5549999999999999, "red": -3.3844005121838316, "red_v58": -2.003, "blue": -2.012999999999999, "red_v15": 0.4916932378161699, "red_v52": -1.002, "red_v31": 0.49869323781520425, "red_v10": -2.038999999999997, "red_v47": -0.01900000000000001, "red_v46": -1.001, "red_v57": -1.005, "red_v33": -1.7849999999999542, "red_v64": 0.5051030335440551, "red_v7": -1.0129999999999995, "red_v26": -2.0089999999999995, "red_v30": 0.5016925427729421, "red_v23": 0.44, "red_v17": -0.1499999999999999, "red_v8": -2.0149999999999997, "red_v50": 1.9449119878161707, "red_v61": -2.0069999999999997, "red_v3": 0.38728360500000036, "red_v29": 0.4769346144425925, "red_v68": -2.0089999999999995, "red_v40": -2.100999999999993, "red_v45": 0.4996932378161705, "red_v19": -0.728, "red_v20": -2.0539999999999967, "red_v12": -0.002, "red_v60": -2.057999999999994, "red_v38": -1.0169999999999995, "red_v39": -1.5099999999999998, "red_v53": -2.005, "red_v54": 0.45869323781616966, "red_v36": -0.14900000000000002, "red_v56": -2.0069999999999997, "red_v27": -1.0129999999999995, "red_v67": -2.002, "red_v16": -1.0359999999999987, "red_v43": 1.5056932378161703, "red_v22": 0.447, "red_v14": 0.39428360500000026, "red_v59": 0.44181250000000005, "red_v24": 1.3588182378161728}, "policy_reward_max": {"red_v63": 0.49869323781617036, "red": 3.9975561585440547, "red_v58": -1.002, "blue": 1.465390625, "red_v15": 0.4916932378161699, "red_v52": -1.002, "red_v31": 1.6016562500000022, "red_v10": 0.4946932378152038, "red_v47": -0.01900000000000001, "red_v46": 0.423, "red_v57": -1.005, "red_v33": -1.5070000000000001, "red_v64": 0.5051030335440551, "red_v7": -1.0079999999999998, "red_v26": -2.0089999999999995, "red_v30": 0.5016925427729421, "red_v23": 0.44, "red_v17": -0.1499999999999999, "red_v8": -2.0149999999999997, "red_v50": 1.9449119878161707, "red_v61": -2.0069999999999997, "red_v3": 0.38728360500000036, "red_v29": 0.4769346144425925, "red_v68": -2.008, "red_v40": 1.4976932378161705, "red_v45": 0.4996932378161705, "red_v19": -0.728, "red_v20": 0.4836925427729417, "red_v12": -0.002, "red_v60": -2.057999999999994, "red_v38": -1.0169999999999995, "red_v39": -1.5099999999999998, "red_v53": -2.005, "red_v54": 0.45869323781616966, "red_v36": -0.14900000000000002, "red_v56": -2.0069999999999997, "red_v27": -1.0129999999999995, "red_v67": -2.002, "red_v16": -0.516, "red_v43": 1.5056932378161703, "red_v22": 0.447, "red_v14": 0.39428360500000026, "red_v59": 0.44181250000000005, "red_v24": 1.3588182378161728}, "policy_reward_mean": {"red_v63": -0.028153381091914786, "red": 3.1149232367650126, "red_v58": -1.5025, "blue": -1.1679243607954541, "red_v15": 0.4916932378161699, "red_v52": -1.002, "red_v31": 0.8668175071197538, "red_v10": -1.1851022540615976, "red_v47": -0.01900000000000001, "red_v46": -0.38199999999999995, "red_v57": -1.005, "red_v33": -1.6459999999999773, "red_v64": 0.5051030335440551, "red_v7": -1.0104999999999995, "red_v26": -2.0089999999999995, "red_v30": 0.5016925427729421, "red_v23": 0.44, "red_v17": -0.1499999999999999, "red_v8": -2.0149999999999997, "red_v50": 1.9449119878161707, "red_v61": -2.0069999999999997, "red_v3": 0.38728360500000036, "red_v29": 0.4769346144425925, "red_v68": -2.0084999999999997, "red_v40": -0.3016533810919112, "red_v45": 0.4996932378161705, "red_v19": -0.728, "red_v20": -0.7851537286135275, "red_v12": -0.002, "red_v60": -2.057999999999994, "red_v38": -1.0169999999999995, "red_v39": -1.5099999999999998, "red_v53": -2.005, "red_v54": 0.45869323781616966, "red_v36": -0.14900000000000002, "red_v56": -2.0069999999999997, "red_v27": -1.0129999999999995, "red_v67": -2.002, "red_v16": -0.7759999999999994, "red_v43": 1.5056932378161703, "red_v22": 0.447, "red_v14": 0.39428360500000026, "red_v59": 0.44181250000000005, "red_v24": 1.3588182378161728}, "hist_stats": {"episode_reward": [2.826221105, 2.4803807378161697, 2.4539432378161705, 3.934839600632342, 0.988040533544055, 2.47938073781617, 1.4660838628161703, 2.475415533544055, 2.102349487816175, 2.4646776128161707, 3.971370850631375, 2.444021362816172, 1.991036292772942, 2.4641925427729423, -2.0144005121838227, 2.9523494878161722, 1.9804119878161701, 1.987333862815204, 2.4708651128161705, 2.4645682378161706, 2.48481823781617, 1.3925994878161738, 2.3721117300000003, -0.4433067621838311, 2.453536987816171, 1.9503963628161702, 2.4719744878161705, 1.9514276128161716, 0.9674901128161703, 2.486630042772942, 3.9945150213602254, 2.4708963628161706, 1.947802612816171, 3.992213905589112, 3.4023182378161714, 3.958011475632341, 1.962161987816171, 3.343446783544055, 1.9721151128161702, 2.4486052256323427, 2.437724487816172, 1.4563182378161708, 1.9539432378161714, 1.4743026128161705, 2.463271362816171, 3.8594455928161704, 1.340859375, 2.945943237816172, 3.962198975631374, 2.883208862816173, 3.956127852258762, 1.8794398550000002, 1.4743807378161704, 1.2913182378161805, 3.9727458506323408, 4.458933350632342, 3.9812962713602262, 2.4328026128161726, 2.4834119878161705, 0.9145994878161703, 3.3826932378161723, 2.810193237816197, 3.929245155589112, 0.4248281250000001, 2.9938530335440547, 2.962271362816171, 1.3454744878161762, 2.455458862816171, 1.3957401128161733, 1.3682557378161784, 0.9207869878161704, 1.4588338628161708, 1.9879276128161703, 2.6251521006323593, 3.3412244878152038, 1.98681823781617, 1.9905561585440552, 1.8838461050000006, 2.4701932378161713, 2.48141198781617, 2.4613494878161704, 2.447427612816171, 1.3789242300000004, 2.3789242300000004, 2.4225057378161727, 4.467721602258763, 1.8199554800000008, 0.9695682378161706, 2.2329119878161787, 0.9144276128161698, 1.3686273550000005, 3.33133048, 2.485446783544055, 1.4754901128161706, 3.8851018428161703, 1.47038073781617, 0.9425057378161705, 2.48122448781617, 1.839511475632365, 2.4682713628161705], "episode_lengths": [20, 36, 48, 79, 20, 36, 35, 28, 302, 37, 37, 55, 18, 32, 542, 46, 26, 19, 41, 40, 24, 94, 23, 1280, 50, 63, 38, 53, 33, 20, 26, 31, 61, 23, 56, 56, 42, 18, 25, 58, 54, 56, 48, 29, 39, 42, 13, 48, 60, 59, 32, 14, 36, 120, 45, 49, 32, 61, 26, 94, 64, 416, 77, 23, 16, 39, 134, 43, 81, 588, 98, 51, 21, 299, 22, 24, 15, 12, 32, 26, 46, 53, 19, 19, 60, 34, 73, 40, 250, 117, 18, 17, 18, 33, 24, 36, 60, 22, 600, 39], "policy_red_v63_reward": [-0.5549999999999999, 0.49869323781617036], "policy_red_v58_reward": [-1.002, -2.003], "policy_blue_reward": [-1.0159999999999993, 0.4809375, 1.465390625, -1.0069999999999992, -1.016999999999999, -1.0179999999999987, -2.0039999999999996, -1.0129999999999997, 1.3700000000000063, -2.009, -2.0039999999999996, -1.0139999999999996, -1.0059999999999996, -1.0169999999999997, -1.0089999999999995, -2.012999999999999, -1.513, -1.0059999999999998, -2.0119999999999996, -1.0229999999999988, -2.0089999999999995, -2.008, -1.011999999999999, -2.003, -0.020000000000000004, -2.0069999999999997, -1.0189999999999988, -1.0039999999999998, -1.527, -2.008, -0.015000000000000006, -0.712, -2.0049999999999994, -1.0119999999999987, -1.0189999999999988, -1.003, -1.508, -1.0639999999999945, -2.0109999999999997, -1.0059999999999996, -2.008, -2.008, -1.0059999999999998, -1.0099999999999996], "policy_red_v15_reward": [0.4916932378161699], "policy_red_v52_reward": [-1.002], "policy_red_v31_reward": [1.6016562500000022, 0.49869323781520425, 0.5001030335440549], "policy_red_v10_reward": [0.4946932378152038, -2.038999999999997, -2.0109999999999997], "policy_red_v47_reward": [-0.01900000000000001], "policy_red_v46_reward": [-1.001, -0.568, 0.423], "policy_red_v57_reward": [-1.005], "policy_red_v33_reward": [-1.7849999999999542, -1.5070000000000001], "policy_red_v64_reward": [0.5051030335440551], "policy_red_v7_reward": [-1.0129999999999995, -1.0079999999999998], "policy_red_v26_reward": [-2.0089999999999995], "policy_red_v30_reward": [0.5016925427729421], "policy_red_v23_reward": [0.44], "policy_red_v17_reward": [-0.1499999999999999], "policy_red_v8_reward": [-2.0149999999999997], "policy_red_v50_reward": [1.9449119878161707], "policy_red_v61_reward": [-2.0069999999999997], "policy_red_v3_reward": [0.38728360500000036], "policy_red_v29_reward": [0.4769346144425925], "policy_red_v68_reward": [-2.008, -2.0089999999999995], "policy_red_v40_reward": [-2.100999999999993, 1.4976932378161705], "policy_red_v45_reward": [0.4996932378161705], "policy_red_v19_reward": [-0.728], "policy_red_v20_reward": [0.4836925427729417, -2.0539999999999967], "policy_red_v12_reward": [-0.002], "policy_red_v60_reward": [-2.057999999999994], "policy_red_v38_reward": [-1.0169999999999995], "policy_red_v39_reward": [-1.5099999999999998], "policy_red_v53_reward": [-2.005], "policy_red_v54_reward": [0.45869323781616966], "policy_red_v36_reward": [-0.14900000000000002], "policy_red_v56_reward": [-2.0069999999999997], "policy_red_v27_reward": [-1.0129999999999995], "policy_red_v67_reward": [-2.002], "policy_red_v16_reward": [-1.0359999999999987, -0.516], "policy_red_v43_reward": [1.5056932378161703], "policy_red_v22_reward": [0.447], "policy_red_v14_reward": [0.39428360500000026], "policy_red_v59_reward": [0.44181250000000005], "policy_red_v24_reward": [1.3588182378161728]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8186534990252065, "mean_inference_ms": 7.713465512085636, "mean_action_processing_ms": 0.29382548032161687, "mean_env_wait_ms": 0.39062779153268756, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10344183444976807, "StateBufferConnector_ms": 0.004283785820007324, "ViewRequirementAgentConnector_ms": 0.1186593770980835}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 824000, "num_agent_steps_trained": 824000, "num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.74480979768984, "num_env_steps_trained_throughput_per_sec": 201.74480979768984, "timesteps_total": 412000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 824000, "timers": {"training_iteration_time_ms": 19740.82, "sample_time_ms": 1157.16, "learn_time_ms": 18500.377, "learn_throughput": 216.212, "synch_weights_time_ms": 79.825}, "counters": {"num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_agent_steps_sampled": 824000, "num_agent_steps_trained": 824000}, "done": false, "episodes_total": 1932, "training_iteration": 103, "trial_id": "a9680_00000", "date": "2023-09-24_03-14-15", "timestamp": 1695539655, "time_this_iter_s": 19.838075876235962, "time_total_s": 2053.588382959366, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dd8b010>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1dd509d0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1dd50a60>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2053.588382959366, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 5.379411764705884, "ram_util_percent": 25.07058823529412}, "win_rate": 0.75, "league_size": 72}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3132930676142376, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.014052940584466949, "policy_loss": -0.049926116773470613, "vf_loss": 0.11579375675646589, "vf_explained_var": 0.8920034550130367, "kl": 0.016735243865635616, "entropy": 1.4486805602908135, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 99360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "sampler_results": {"episode_reward_max": 4.49610522563234, "episode_reward_min": 0.4248281250000001, "episode_reward_mean": 2.3208114028338382, "episode_len_mean": 67.18, "episode_media": {}, "episodes_this_iter": 52, "policy_reward_min": {"blue": -2.0109999999999997, "red": -0.6489999999999999, "red_v40": -2.100999999999993, "red_v45": -0.565, "red_v31": 0.5001030335440549, "red_v46": 0.423, "red_v19": -0.728, "red_v20": -2.0539999999999967, "red_v12": -0.002, "red_v60": -2.057999999999994, "red_v38": -2.001, "red_v39": -1.5099999999999998, "red_v68": -2.0089999999999995, "red_v53": -2.005, "red_v54": 0.45869323781616966, "red_v36": -0.14900000000000002, "red_v58": -2.003, "red_v56": -2.0069999999999997, "red_v7": -1.0079999999999998, "red_v27": -1.0129999999999995, "red_v67": -2.002, "red_v16": -1.0359999999999987, "red_v43": -0.012, "red_v33": -1.5070000000000001, "red_v22": 0.447, "red_v14": -0.5159999999999999, "red_v59": -2.0119999999999996, "red_v24": -2.0409999999999986, "red_v9": -1.0359999999999994, "red_v5": -1.0039999999999998, "red_v51": 1.5066932378161697, "red_v42": 1.5046932378161704, "red_v64": -0.572, "red_v70": -2.001, "red_v65": 0.49669323781617025, "red_v48": -2.001, "red_v57": -2.0059999999999993, "red_v11": -2.0119999999999987, "red_v23": 0.444, "red_v47": -0.557, "red_v66": -1.004, "red_v15": -1.231}, "policy_reward_max": {"blue": 1.9656875, "red": 3.9975561585440547, "red_v40": 1.4976932378161705, "red_v45": 0.4996932378161705, "red_v31": 0.5026932378161703, "red_v46": 0.423, "red_v19": -0.728, "red_v20": 0.4836925427729417, "red_v12": -0.002, "red_v60": -2.057999999999994, "red_v38": -1.0169999999999995, "red_v39": -1.5099999999999998, "red_v68": -2.0089999999999995, "red_v53": -2.005, "red_v54": 0.45869323781616966, "red_v36": -0.14900000000000002, "red_v58": -2.003, "red_v56": -2.0069999999999997, "red_v7": -1.0079999999999998, "red_v27": -1.0129999999999995, "red_v67": -2.002, "red_v16": -0.516, "red_v43": 1.5056932378161703, "red_v33": -1.5070000000000001, "red_v22": 0.447, "red_v14": 0.39428360500000026, "red_v59": 0.44181250000000005, "red_v24": 1.3588182378161728, "red_v9": -1.0359999999999994, "red_v5": -1.0039999999999998, "red_v51": 1.5066932378161697, "red_v42": 1.6065994878161702, "red_v64": -0.572, "red_v70": -2.001, "red_v65": 0.49669323781617025, "red_v48": -2.001, "red_v57": -2.0059999999999993, "red_v11": -2.0119999999999987, "red_v23": 0.444, "red_v47": -0.557, "red_v66": -1.004, "red_v15": -1.231}, "policy_reward_mean": {"blue": -1.2658980978260865, "red": 3.2306090423608884, "red_v40": -0.5377689207279407, "red_v45": -0.032653381091914735, "red_v31": 0.5013981356801126, "red_v46": 0.423, "red_v19": -0.728, "red_v20": -0.7851537286135275, "red_v12": -0.002, "red_v60": -2.057999999999994, "red_v38": -1.5089999999999997, "red_v39": -1.5099999999999998, "red_v68": -2.0089999999999995, "red_v53": -2.005, "red_v54": 0.45869323781616966, "red_v36": -0.14900000000000002, "red_v58": -2.003, "red_v56": -2.0069999999999997, "red_v7": -1.0079999999999998, "red_v27": -1.0129999999999995, "red_v67": -2.002, "red_v16": -0.7759999999999994, "red_v43": 0.9947954918774472, "red_v33": -1.5070000000000001, "red_v22": 0.447, "red_v14": -0.06085819749999982, "red_v59": -1.1917291666666665, "red_v24": -0.3410908810919129, "red_v9": -1.0359999999999994, "red_v5": -1.0039999999999998, "red_v51": 1.5066932378161697, "red_v42": 1.5556463628161703, "red_v64": -0.572, "red_v70": -2.001, "red_v65": 0.49669323781617025, "red_v48": -2.001, "red_v57": -2.0059999999999993, "red_v11": -2.0119999999999987, "red_v23": 0.444, "red_v47": -0.557, "red_v66": -1.004, "red_v15": -1.231}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.4743807378161704, 1.2913182378161805, 3.9727458506323408, 4.458933350632342, 3.9812962713602262, 2.4328026128161726, 2.4834119878161705, 0.9145994878161703, 3.3826932378161723, 2.810193237816197, 3.929245155589112, 0.4248281250000001, 2.9938530335440547, 2.962271362816171, 1.3454744878161762, 2.455458862816171, 1.3957401128161733, 1.3682557378161784, 0.9207869878161704, 1.4588338628161708, 1.9879276128161703, 2.6251521006323593, 3.3412244878152038, 1.98681823781617, 1.9905561585440552, 1.8838461050000006, 2.4701932378161713, 2.48141198781617, 2.4613494878161704, 2.447427612816171, 1.3789242300000004, 2.3789242300000004, 2.4225057378161727, 4.467721602258763, 1.8199554800000008, 0.9695682378161706, 2.2329119878161787, 0.9144276128161698, 1.3686273550000005, 3.33133048, 2.485446783544055, 1.4754901128161706, 3.8851018428161703, 1.47038073781617, 0.9425057378161705, 2.48122448781617, 1.839511475632365, 2.4682713628161705, 2.389646362816173, 2.896786987816174, 2.4426932378161714, 2.488337408544055, 2.487040533544055, 1.9744901128161703, 4.49610522563234, 3.4532401128161707, 0.9537244878161704, 2.899724487816171, 1.8833304800000001, 1.3803304800000005, 2.468380042772942, 3.98266772563234, 1.9887394177729418, 4.48496460063234, 1.9844467835440551, 1.973005737816171, 2.453943237816171, 1.9763026128161707, 2.8847244878161726, 2.4481307378161707, 2.4841151128161703, 1.9825213628161704, 2.4701932378161704, 2.4438096144425936, 2.1072927256323473, 1.3166875000000005, 1.9923338628152039, 3.9668239756323405, 1.9327557378161715, 1.8864398550000006, 1.9921499085440548, 2.4820405335440547, 1.4689744878161708, 2.4541619878161702, 2.47981823781617, 1.4483182378161712, 4.453605225632341, 1.9673807378152046, 1.4777088628152046, 2.642253125, 1.9811144177729416, 1.98030261281617, 2.484520667772942, 1.3431562500000003, 3.4305994878161705, 2.9301151128161704, 1.6650968750000004, 2.4730838628161704, 1.937724487815204, 1.5494276128161857], "episode_lengths": [36, 120, 45, 49, 32, 61, 26, 94, 64, 416, 77, 23, 16, 39, 134, 43, 81, 588, 98, 51, 21, 299, 22, 24, 15, 12, 32, 26, 46, 53, 19, 19, 60, 34, 73, 40, 250, 117, 18, 17, 18, 33, 24, 36, 60, 22, 600, 39, 111, 98, 64, 21, 20, 33, 26, 49, 54, 54, 17, 17, 36, 38, 17, 39, 18, 28, 48, 29, 54, 52, 25, 23, 32, 40, 478, 36, 19, 52, 44, 14, 17, 20, 38, 42, 24, 56, 58, 36, 27, 31, 25, 29, 23, 14, 30, 25, 17, 35, 54, 309], "policy_blue_reward": [-2.0069999999999997, -1.0189999999999988, -1.0039999999999998, -1.527, -2.008, -0.015000000000000006, -0.712, -2.0049999999999994, -1.0119999999999987, -1.0189999999999988, -1.003, -1.508, -1.0639999999999945, -2.0109999999999997, -1.0059999999999996, -2.008, -2.008, -1.0059999999999998, -1.0099999999999996, -0.533, -1.0179999999999985, -1.006, -2.0109999999999992, 0.486, -1.5099999999999998, -2.002, -2.005, -1.009, -2.0069999999999997, -2.0109999999999992, -1.013, -2.01, -1.0149999999999992, -1.0059999999999996, -2.0059999999999993, -1.0079999999999996, -1.0149999999999986, 1.9656875, -2.002, -1.0079999999999998, -1.009, -0.505, -2.0060000000000002, -2.0069999999999997, -1.005, -2.0039999999999996], "policy_red_v40_reward": [-2.100999999999993, 1.4976932378161705, -1.0099999999999996], "policy_red_v45_reward": [0.4996932378161705, -0.565], "policy_red_v31_reward": [0.5001030335440549, 0.5026932378161703], "policy_red_v46_reward": [0.423], "policy_red_v19_reward": [-0.728], "policy_red_v20_reward": [0.4836925427729417, -2.0539999999999967], "policy_red_v12_reward": [-0.002], "policy_red_v60_reward": [-2.057999999999994], "policy_red_v38_reward": [-1.0169999999999995, -2.001], "policy_red_v39_reward": [-1.5099999999999998], "policy_red_v68_reward": [-2.0089999999999995], "policy_red_v53_reward": [-2.005], "policy_red_v54_reward": [0.45869323781616966], "policy_red_v36_reward": [-0.14900000000000002], "policy_red_v58_reward": [-2.003], "policy_red_v56_reward": [-2.0069999999999997], "policy_red_v7_reward": [-1.0079999999999998], "policy_red_v27_reward": [-1.0129999999999995], "policy_red_v67_reward": [-2.002], "policy_red_v16_reward": [-1.0359999999999987, -0.516], "policy_red_v43_reward": [1.5056932378161703, 1.4906932378161712, -0.012], "policy_red_v33_reward": [-1.5070000000000001], "policy_red_v22_reward": [0.447], "policy_red_v14_reward": [0.39428360500000026, -0.5159999999999999], "policy_red_v59_reward": [0.44181250000000005, -2.005, -2.0119999999999996], "policy_red_v24_reward": [1.3588182378161728, -2.0409999999999986], "policy_red_v9_reward": [-1.0359999999999994], "policy_red_v5_reward": [-1.0039999999999998], "policy_red_v51_reward": [1.5066932378161697], "policy_red_v42_reward": [1.5046932378161704, 1.6065994878161702], "policy_red_v64_reward": [-0.572], "policy_red_v70_reward": [-2.001], "policy_red_v65_reward": [0.49669323781617025], "policy_red_v48_reward": [-2.001], "policy_red_v57_reward": [-2.0059999999999993], "policy_red_v11_reward": [-2.0119999999999987], "policy_red_v23_reward": [0.444], "policy_red_v47_reward": [-0.557], "policy_red_v66_reward": [-1.004], "policy_red_v15_reward": [-1.231]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.818972134762588, "mean_inference_ms": 7.709904050868612, "mean_action_processing_ms": 0.2931947923086668, "mean_env_wait_ms": 0.3899056970685485, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10174918174743652, "StateBufferConnector_ms": 0.0042656660079956055, "ViewRequirementAgentConnector_ms": 0.11829125881195068}}, "episode_reward_max": 4.49610522563234, "episode_reward_min": 0.4248281250000001, "episode_reward_mean": 2.3208114028338382, "episode_len_mean": 67.18, "episodes_this_iter": 52, "policy_reward_min": {"blue": -2.0109999999999997, "red": -0.6489999999999999, "red_v40": -2.100999999999993, "red_v45": -0.565, "red_v31": 0.5001030335440549, "red_v46": 0.423, "red_v19": -0.728, "red_v20": -2.0539999999999967, "red_v12": -0.002, "red_v60": -2.057999999999994, "red_v38": -2.001, "red_v39": -1.5099999999999998, "red_v68": -2.0089999999999995, "red_v53": -2.005, "red_v54": 0.45869323781616966, "red_v36": -0.14900000000000002, "red_v58": -2.003, "red_v56": -2.0069999999999997, "red_v7": -1.0079999999999998, "red_v27": -1.0129999999999995, "red_v67": -2.002, "red_v16": -1.0359999999999987, "red_v43": -0.012, "red_v33": -1.5070000000000001, "red_v22": 0.447, "red_v14": -0.5159999999999999, "red_v59": -2.0119999999999996, "red_v24": -2.0409999999999986, "red_v9": -1.0359999999999994, "red_v5": -1.0039999999999998, "red_v51": 1.5066932378161697, "red_v42": 1.5046932378161704, "red_v64": -0.572, "red_v70": -2.001, "red_v65": 0.49669323781617025, "red_v48": -2.001, "red_v57": -2.0059999999999993, "red_v11": -2.0119999999999987, "red_v23": 0.444, "red_v47": -0.557, "red_v66": -1.004, "red_v15": -1.231}, "policy_reward_max": {"blue": 1.9656875, "red": 3.9975561585440547, "red_v40": 1.4976932378161705, "red_v45": 0.4996932378161705, "red_v31": 0.5026932378161703, "red_v46": 0.423, "red_v19": -0.728, "red_v20": 0.4836925427729417, "red_v12": -0.002, "red_v60": -2.057999999999994, "red_v38": -1.0169999999999995, "red_v39": -1.5099999999999998, "red_v68": -2.0089999999999995, "red_v53": -2.005, "red_v54": 0.45869323781616966, "red_v36": -0.14900000000000002, "red_v58": -2.003, "red_v56": -2.0069999999999997, "red_v7": -1.0079999999999998, "red_v27": -1.0129999999999995, "red_v67": -2.002, "red_v16": -0.516, "red_v43": 1.5056932378161703, "red_v33": -1.5070000000000001, "red_v22": 0.447, "red_v14": 0.39428360500000026, "red_v59": 0.44181250000000005, "red_v24": 1.3588182378161728, "red_v9": -1.0359999999999994, "red_v5": -1.0039999999999998, "red_v51": 1.5066932378161697, "red_v42": 1.6065994878161702, "red_v64": -0.572, "red_v70": -2.001, "red_v65": 0.49669323781617025, "red_v48": -2.001, "red_v57": -2.0059999999999993, "red_v11": -2.0119999999999987, "red_v23": 0.444, "red_v47": -0.557, "red_v66": -1.004, "red_v15": -1.231}, "policy_reward_mean": {"blue": -1.2658980978260865, "red": 3.2306090423608884, "red_v40": -0.5377689207279407, "red_v45": -0.032653381091914735, "red_v31": 0.5013981356801126, "red_v46": 0.423, "red_v19": -0.728, "red_v20": -0.7851537286135275, "red_v12": -0.002, "red_v60": -2.057999999999994, "red_v38": -1.5089999999999997, "red_v39": -1.5099999999999998, "red_v68": -2.0089999999999995, "red_v53": -2.005, "red_v54": 0.45869323781616966, "red_v36": -0.14900000000000002, "red_v58": -2.003, "red_v56": -2.0069999999999997, "red_v7": -1.0079999999999998, "red_v27": -1.0129999999999995, "red_v67": -2.002, "red_v16": -0.7759999999999994, "red_v43": 0.9947954918774472, "red_v33": -1.5070000000000001, "red_v22": 0.447, "red_v14": -0.06085819749999982, "red_v59": -1.1917291666666665, "red_v24": -0.3410908810919129, "red_v9": -1.0359999999999994, "red_v5": -1.0039999999999998, "red_v51": 1.5066932378161697, "red_v42": 1.5556463628161703, "red_v64": -0.572, "red_v70": -2.001, "red_v65": 0.49669323781617025, "red_v48": -2.001, "red_v57": -2.0059999999999993, "red_v11": -2.0119999999999987, "red_v23": 0.444, "red_v47": -0.557, "red_v66": -1.004, "red_v15": -1.231}, "hist_stats": {"episode_reward": [1.4743807378161704, 1.2913182378161805, 3.9727458506323408, 4.458933350632342, 3.9812962713602262, 2.4328026128161726, 2.4834119878161705, 0.9145994878161703, 3.3826932378161723, 2.810193237816197, 3.929245155589112, 0.4248281250000001, 2.9938530335440547, 2.962271362816171, 1.3454744878161762, 2.455458862816171, 1.3957401128161733, 1.3682557378161784, 0.9207869878161704, 1.4588338628161708, 1.9879276128161703, 2.6251521006323593, 3.3412244878152038, 1.98681823781617, 1.9905561585440552, 1.8838461050000006, 2.4701932378161713, 2.48141198781617, 2.4613494878161704, 2.447427612816171, 1.3789242300000004, 2.3789242300000004, 2.4225057378161727, 4.467721602258763, 1.8199554800000008, 0.9695682378161706, 2.2329119878161787, 0.9144276128161698, 1.3686273550000005, 3.33133048, 2.485446783544055, 1.4754901128161706, 3.8851018428161703, 1.47038073781617, 0.9425057378161705, 2.48122448781617, 1.839511475632365, 2.4682713628161705, 2.389646362816173, 2.896786987816174, 2.4426932378161714, 2.488337408544055, 2.487040533544055, 1.9744901128161703, 4.49610522563234, 3.4532401128161707, 0.9537244878161704, 2.899724487816171, 1.8833304800000001, 1.3803304800000005, 2.468380042772942, 3.98266772563234, 1.9887394177729418, 4.48496460063234, 1.9844467835440551, 1.973005737816171, 2.453943237816171, 1.9763026128161707, 2.8847244878161726, 2.4481307378161707, 2.4841151128161703, 1.9825213628161704, 2.4701932378161704, 2.4438096144425936, 2.1072927256323473, 1.3166875000000005, 1.9923338628152039, 3.9668239756323405, 1.9327557378161715, 1.8864398550000006, 1.9921499085440548, 2.4820405335440547, 1.4689744878161708, 2.4541619878161702, 2.47981823781617, 1.4483182378161712, 4.453605225632341, 1.9673807378152046, 1.4777088628152046, 2.642253125, 1.9811144177729416, 1.98030261281617, 2.484520667772942, 1.3431562500000003, 3.4305994878161705, 2.9301151128161704, 1.6650968750000004, 2.4730838628161704, 1.937724487815204, 1.5494276128161857], "episode_lengths": [36, 120, 45, 49, 32, 61, 26, 94, 64, 416, 77, 23, 16, 39, 134, 43, 81, 588, 98, 51, 21, 299, 22, 24, 15, 12, 32, 26, 46, 53, 19, 19, 60, 34, 73, 40, 250, 117, 18, 17, 18, 33, 24, 36, 60, 22, 600, 39, 111, 98, 64, 21, 20, 33, 26, 49, 54, 54, 17, 17, 36, 38, 17, 39, 18, 28, 48, 29, 54, 52, 25, 23, 32, 40, 478, 36, 19, 52, 44, 14, 17, 20, 38, 42, 24, 56, 58, 36, 27, 31, 25, 29, 23, 14, 30, 25, 17, 35, 54, 309], "policy_blue_reward": [-2.0069999999999997, -1.0189999999999988, -1.0039999999999998, -1.527, -2.008, -0.015000000000000006, -0.712, -2.0049999999999994, -1.0119999999999987, -1.0189999999999988, -1.003, -1.508, -1.0639999999999945, -2.0109999999999997, -1.0059999999999996, -2.008, -2.008, -1.0059999999999998, -1.0099999999999996, -0.533, -1.0179999999999985, -1.006, -2.0109999999999992, 0.486, -1.5099999999999998, -2.002, -2.005, -1.009, -2.0069999999999997, -2.0109999999999992, -1.013, -2.01, -1.0149999999999992, -1.0059999999999996, -2.0059999999999993, -1.0079999999999996, -1.0149999999999986, 1.9656875, -2.002, -1.0079999999999998, -1.009, -0.505, -2.0060000000000002, -2.0069999999999997, -1.005, -2.0039999999999996], "policy_red_v40_reward": [-2.100999999999993, 1.4976932378161705, -1.0099999999999996], "policy_red_v45_reward": [0.4996932378161705, -0.565], "policy_red_v31_reward": [0.5001030335440549, 0.5026932378161703], "policy_red_v46_reward": [0.423], "policy_red_v19_reward": [-0.728], "policy_red_v20_reward": [0.4836925427729417, -2.0539999999999967], "policy_red_v12_reward": [-0.002], "policy_red_v60_reward": [-2.057999999999994], "policy_red_v38_reward": [-1.0169999999999995, -2.001], "policy_red_v39_reward": [-1.5099999999999998], "policy_red_v68_reward": [-2.0089999999999995], "policy_red_v53_reward": [-2.005], "policy_red_v54_reward": [0.45869323781616966], "policy_red_v36_reward": [-0.14900000000000002], "policy_red_v58_reward": [-2.003], "policy_red_v56_reward": [-2.0069999999999997], "policy_red_v7_reward": [-1.0079999999999998], "policy_red_v27_reward": [-1.0129999999999995], "policy_red_v67_reward": [-2.002], "policy_red_v16_reward": [-1.0359999999999987, -0.516], "policy_red_v43_reward": [1.5056932378161703, 1.4906932378161712, -0.012], "policy_red_v33_reward": [-1.5070000000000001], "policy_red_v22_reward": [0.447], "policy_red_v14_reward": [0.39428360500000026, -0.5159999999999999], "policy_red_v59_reward": [0.44181250000000005, -2.005, -2.0119999999999996], "policy_red_v24_reward": [1.3588182378161728, -2.0409999999999986], "policy_red_v9_reward": [-1.0359999999999994], "policy_red_v5_reward": [-1.0039999999999998], "policy_red_v51_reward": [1.5066932378161697], "policy_red_v42_reward": [1.5046932378161704, 1.6065994878161702], "policy_red_v64_reward": [-0.572], "policy_red_v70_reward": [-2.001], "policy_red_v65_reward": [0.49669323781617025], "policy_red_v48_reward": [-2.001], "policy_red_v57_reward": [-2.0059999999999993], "policy_red_v11_reward": [-2.0119999999999987], "policy_red_v23_reward": [0.444], "policy_red_v47_reward": [-0.557], "policy_red_v66_reward": [-1.004], "policy_red_v15_reward": [-1.231]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.818972134762588, "mean_inference_ms": 7.709904050868612, "mean_action_processing_ms": 0.2931947923086668, "mean_env_wait_ms": 0.3899056970685485, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10174918174743652, "StateBufferConnector_ms": 0.0042656660079956055, "ViewRequirementAgentConnector_ms": 0.11829125881195068}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 196.03491566266328, "num_env_steps_trained_throughput_per_sec": 196.03491566266328, "timesteps_total": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 19825.395, "sample_time_ms": 1161.085, "learn_time_ms": 18580.565, "learn_throughput": 215.279, "synch_weights_time_ms": 80.33}, "counters": {"num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "episodes_total": 1984, "training_iteration": 104, "trial_id": "a9680_00000", "date": "2023-09-24_03-14-40", "timestamp": 1695539680, "time_this_iter_s": 20.415613412857056, "time_total_s": 2074.003996372223, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dd89360>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1de41480>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1de416c0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2074.003996372223, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 5.232352941176471, "ram_util_percent": 25.179411764705886}, "win_rate": 0.8, "league_size": 73}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.371162352338433, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.029658566466969204, "policy_loss": -0.04197116407740396, "vf_loss": 0.1322911511757411, "vf_explained_var": 0.8832124245663484, "kl": 0.015404655334312642, "entropy": 1.447939025859038, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 100320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_agent_steps_sampled": 840000, "num_agent_steps_trained": 840000}, "sampler_results": {"episode_reward_max": 4.49610522563234, "episode_reward_min": 0.9509432378161704, "episode_reward_mean": 2.3243253026142314, "episode_len_mean": 58.19, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"red_v51": 1.5066932378161697, "red": -0.6489999999999999, "blue": -2.020999999999998, "red_v45": -0.565, "red_v31": 0.4879346144425925, "red_v59": -2.0119999999999996, "red_v42": 1.5046932378161704, "red_v64": -0.572, "red_v70": -2.001, "red_v65": 0.49669323781617025, "red_v24": -2.0409999999999986, "red_v48": -2.001, "red_v57": -2.0059999999999993, "red_v40": -1.0099999999999996, "red_v43": -0.012, "red_v11": -2.0119999999999987, "red_v38": -2.001, "red_v23": 0.444, "red_v47": -0.557, "red_v66": -1.004, "red_v14": -2.0109999999999992, "red_v15": -1.231, "red_v50": -0.047306762183829676, "red_v22": -0.5559999999999996, "red_v29": -1.0039999999999998, "red_v7": -1.0169999999999988, "red_v2": -1.0109999999999995, "red_v19": -2.0099999999999993, "red_v58": -2.016999999999999, "red_v18": -0.5549999999999999, "red_v27": 0.5071030335440548, "red_v36": -1.015999999999999, "red_v39": 3.340017980000002, "red_v61": -1.0239999999999996, "red_v13": -2.0149999999999997, "red_v35": -1.011, "red_v32": 0.4906932378161706}, "policy_reward_max": {"red_v51": 1.5066932378161697, "red": 3.99503698781617, "blue": 1.9656875, "red_v45": -0.565, "red_v31": 0.5026932378161703, "red_v59": 1.93153125, "red_v42": 1.6065994878161702, "red_v64": -0.572, "red_v70": -2.001, "red_v65": 0.49669323781617025, "red_v24": -2.0409999999999986, "red_v48": -0.003, "red_v57": -2.0059999999999993, "red_v40": -1.0099999999999996, "red_v43": 1.4906932378161712, "red_v11": -2.0119999999999987, "red_v38": -2.001, "red_v23": 0.444, "red_v47": -0.557, "red_v66": -1.004, "red_v14": -0.5159999999999999, "red_v15": -1.231, "red_v50": -0.010000000000000002, "red_v22": -0.5559999999999996, "red_v29": -1.0039999999999998, "red_v7": -1.0169999999999988, "red_v2": -1.0109999999999995, "red_v19": -2.0060000000000002, "red_v58": -2.016999999999999, "red_v18": -0.5549999999999999, "red_v27": 0.5071030335440548, "red_v36": -1.015999999999999, "red_v39": 3.340017980000002, "red_v61": -1.0239999999999996, "red_v13": -0.5629999999999998, "red_v35": -1.011, "red_v32": 0.4906932378161706}, "policy_reward_mean": {"red_v51": 1.5066932378161697, "red": 3.3025175373090705, "blue": -1.3093567129629629, "red_v45": -0.565, "red_v31": 0.4953139261293814, "red_v59": -1.0216171874999997, "red_v42": 1.5556463628161703, "red_v64": -0.572, "red_v70": -2.001, "red_v65": 0.49669323781617025, "red_v24": -2.0409999999999986, "red_v48": -1.002, "red_v57": -2.0059999999999993, "red_v40": -1.0099999999999996, "red_v43": 0.7393466189080856, "red_v11": -2.0119999999999987, "red_v38": -2.001, "red_v23": 0.444, "red_v47": -0.557, "red_v66": -1.004, "red_v14": -1.2634999999999996, "red_v15": -1.231, "red_v50": -0.02865338109191484, "red_v22": -0.5559999999999996, "red_v29": -1.0039999999999998, "red_v7": -1.0169999999999988, "red_v2": -1.0109999999999995, "red_v19": -2.008, "red_v58": -2.016999999999999, "red_v18": -0.5549999999999999, "red_v27": 0.5071030335440548, "red_v36": -1.015999999999999, "red_v39": 3.340017980000002, "red_v61": -1.0239999999999996, "red_v13": -1.2889999999999997, "red_v35": -1.011, "red_v32": 0.4906932378161706}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.49610522563234, 3.4532401128161707, 0.9537244878161704, 2.899724487816171, 1.8833304800000001, 1.3803304800000005, 2.468380042772942, 3.98266772563234, 1.9887394177729418, 4.48496460063234, 1.9844467835440551, 1.973005737816171, 2.453943237816171, 1.9763026128161707, 2.8847244878161726, 2.4481307378161707, 2.4841151128161703, 1.9825213628161704, 2.4701932378161704, 2.4438096144425936, 2.1072927256323473, 1.3166875000000005, 1.9923338628152039, 3.9668239756323405, 1.9327557378161715, 1.8864398550000006, 1.9921499085440548, 2.4820405335440547, 1.4689744878161708, 2.4541619878161702, 2.47981823781617, 1.4483182378161712, 4.453605225632341, 1.9673807378152046, 1.4777088628152046, 2.642253125, 1.9811144177729416, 1.98030261281617, 2.484520667772942, 1.3431562500000003, 3.4305994878161705, 2.9301151128161704, 1.6650968750000004, 2.4730838628161704, 1.937724487815204, 1.5494276128161857, 2.9791151128161704, 2.464161987816171, 1.9751932378161705, 1.7397432378162123, 2.9335213628161707, 2.4707557378161704, 3.648105225632358, 2.4371776128161713, 2.4658651128161706, 2.459384283544056, 1.9277401128161715, 1.1518781250000003, 2.462677612816172, 2.4663807378161713, 2.4866307378161703, 1.4787088628161702, 2.4845213628152036, 1.4316932378161722, 1.3787367300000004, 1.66620625, 1.963490112816171, 1.33334375, 3.978455977258762, 2.92919323781617, 4.005248701316997, 2.459458862816171, 3.339711217816173, 2.4647088628161704, 1.9775994878161707, 1.99003698781617, 2.48211511281617, 2.4402869878161715, 1.4713019177729425, 1.9929276128161701, 1.16620625, 2.387740112816174, 0.9509432378161704, 1.9486533644425923, 1.471896362816171, 2.98470886281617, 2.9247088628161713, 2.379627355, 2.97659948781617, 2.4713807378161703, 2.46456823781617, 2.4778963628161703, 1.4649744878161708, 2.47711511281617, 1.9653807378161703, 2.4269901128161724, 2.466568237816171, 2.858605225632342, 1.9713807378161703, 1.9242244878161716], "episode_lengths": [26, 49, 54, 54, 17, 17, 36, 38, 17, 39, 18, 28, 48, 29, 54, 52, 25, 23, 32, 40, 478, 36, 19, 52, 44, 14, 17, 20, 38, 42, 24, 56, 58, 36, 27, 31, 25, 29, 23, 14, 30, 25, 17, 35, 54, 309, 25, 42, 32, 1280, 23, 44, 282, 69, 41, 38, 81, 23, 37, 36, 20, 27, 23, 64, 15, 14, 33, 18, 23, 32, 15, 43, 53, 27, 30, 18, 25, 66, 29, 21, 14, 81, 48, 26, 31, 27, 27, 18, 30, 36, 40, 31, 38, 25, 36, 65, 40, 186, 36, 86], "policy_red_v51_reward": [1.5066932378161697], "policy_blue_reward": [0.486, -1.5099999999999998, -2.002, -2.005, -1.009, -2.0069999999999997, -2.0109999999999992, -1.013, -2.01, -1.0149999999999992, -1.0059999999999996, -2.0059999999999993, -1.0079999999999996, -1.0149999999999986, 1.9656875, -2.002, -1.0079999999999998, -1.009, -0.505, -2.0060000000000002, -2.0069999999999997, -1.005, -2.0039999999999996, -1.0099999999999996, -2.0069999999999997, 0.8470499999999999, -1.0159999999999996, -1.0119999999999991, -1.0179999999999987, -2.020999999999998, -2.004, -1.0059999999999998, -2.009, -1.005, -2.017999999999999, -2.005, -2.004, -2.007999999999999, -2.005, -1.008, -1.0179999999999985, -2.003, -1.0359999999999983, -1.5189999999999995, -2.007999999999999, -1.003, -0.009000000000000001, -1.0089999999999997, -1.0119999999999996, -1.005, -2.012999999999999, -1.0289999999999988, -1.010999999999999, -2.0099999999999993], "policy_red_v45_reward": [-0.565], "policy_red_v31_reward": [0.5026932378161703, 0.4879346144425925], "policy_red_v59_reward": [-2.005, -2.0119999999999996, -2.001, 1.93153125], "policy_red_v42_reward": [1.5046932378161704, 1.6065994878161702], "policy_red_v64_reward": [-0.572], "policy_red_v70_reward": [-2.001], "policy_red_v65_reward": [0.49669323781617025], "policy_red_v24_reward": [-2.0409999999999986], "policy_red_v48_reward": [-2.001, -0.003], "policy_red_v57_reward": [-2.0059999999999993], "policy_red_v40_reward": [-1.0099999999999996], "policy_red_v43_reward": [1.4906932378161712, -0.012], "policy_red_v11_reward": [-2.0119999999999987], "policy_red_v38_reward": [-2.001], "policy_red_v23_reward": [0.444], "policy_red_v47_reward": [-0.557], "policy_red_v66_reward": [-1.004], "policy_red_v14_reward": [-0.5159999999999999, -2.0109999999999992], "policy_red_v15_reward": [-1.231], "policy_red_v50_reward": [-0.010000000000000002, -0.047306762183829676], "policy_red_v22_reward": [-0.5559999999999996], "policy_red_v29_reward": [-1.0039999999999998], "policy_red_v7_reward": [-1.0169999999999988], "policy_red_v2_reward": [-1.0109999999999995], "policy_red_v19_reward": [-2.0060000000000002, -2.0099999999999993], "policy_red_v58_reward": [-2.016999999999999], "policy_red_v18_reward": [-0.5549999999999999], "policy_red_v27_reward": [0.5071030335440548], "policy_red_v36_reward": [-1.015999999999999], "policy_red_v39_reward": [3.340017980000002], "policy_red_v61_reward": [-1.0239999999999996], "policy_red_v13_reward": [-2.0149999999999997, -0.5629999999999998], "policy_red_v35_reward": [-1.011], "policy_red_v32_reward": [0.4906932378161706]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8209189334836176, "mean_inference_ms": 7.723294697842621, "mean_action_processing_ms": 0.2935497669605594, "mean_env_wait_ms": 0.3907574719112005, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09958267211914062, "StateBufferConnector_ms": 0.004181027412414551, "ViewRequirementAgentConnector_ms": 0.11590385437011719}}, "episode_reward_max": 4.49610522563234, "episode_reward_min": 0.9509432378161704, "episode_reward_mean": 2.3243253026142314, "episode_len_mean": 58.19, "episodes_this_iter": 54, "policy_reward_min": {"red_v51": 1.5066932378161697, "red": -0.6489999999999999, "blue": -2.020999999999998, "red_v45": -0.565, "red_v31": 0.4879346144425925, "red_v59": -2.0119999999999996, "red_v42": 1.5046932378161704, "red_v64": -0.572, "red_v70": -2.001, "red_v65": 0.49669323781617025, "red_v24": -2.0409999999999986, "red_v48": -2.001, "red_v57": -2.0059999999999993, "red_v40": -1.0099999999999996, "red_v43": -0.012, "red_v11": -2.0119999999999987, "red_v38": -2.001, "red_v23": 0.444, "red_v47": -0.557, "red_v66": -1.004, "red_v14": -2.0109999999999992, "red_v15": -1.231, "red_v50": -0.047306762183829676, "red_v22": -0.5559999999999996, "red_v29": -1.0039999999999998, "red_v7": -1.0169999999999988, "red_v2": -1.0109999999999995, "red_v19": -2.0099999999999993, "red_v58": -2.016999999999999, "red_v18": -0.5549999999999999, "red_v27": 0.5071030335440548, "red_v36": -1.015999999999999, "red_v39": 3.340017980000002, "red_v61": -1.0239999999999996, "red_v13": -2.0149999999999997, "red_v35": -1.011, "red_v32": 0.4906932378161706}, "policy_reward_max": {"red_v51": 1.5066932378161697, "red": 3.99503698781617, "blue": 1.9656875, "red_v45": -0.565, "red_v31": 0.5026932378161703, "red_v59": 1.93153125, "red_v42": 1.6065994878161702, "red_v64": -0.572, "red_v70": -2.001, "red_v65": 0.49669323781617025, "red_v24": -2.0409999999999986, "red_v48": -0.003, "red_v57": -2.0059999999999993, "red_v40": -1.0099999999999996, "red_v43": 1.4906932378161712, "red_v11": -2.0119999999999987, "red_v38": -2.001, "red_v23": 0.444, "red_v47": -0.557, "red_v66": -1.004, "red_v14": -0.5159999999999999, "red_v15": -1.231, "red_v50": -0.010000000000000002, "red_v22": -0.5559999999999996, "red_v29": -1.0039999999999998, "red_v7": -1.0169999999999988, "red_v2": -1.0109999999999995, "red_v19": -2.0060000000000002, "red_v58": -2.016999999999999, "red_v18": -0.5549999999999999, "red_v27": 0.5071030335440548, "red_v36": -1.015999999999999, "red_v39": 3.340017980000002, "red_v61": -1.0239999999999996, "red_v13": -0.5629999999999998, "red_v35": -1.011, "red_v32": 0.4906932378161706}, "policy_reward_mean": {"red_v51": 1.5066932378161697, "red": 3.3025175373090705, "blue": -1.3093567129629629, "red_v45": -0.565, "red_v31": 0.4953139261293814, "red_v59": -1.0216171874999997, "red_v42": 1.5556463628161703, "red_v64": -0.572, "red_v70": -2.001, "red_v65": 0.49669323781617025, "red_v24": -2.0409999999999986, "red_v48": -1.002, "red_v57": -2.0059999999999993, "red_v40": -1.0099999999999996, "red_v43": 0.7393466189080856, "red_v11": -2.0119999999999987, "red_v38": -2.001, "red_v23": 0.444, "red_v47": -0.557, "red_v66": -1.004, "red_v14": -1.2634999999999996, "red_v15": -1.231, "red_v50": -0.02865338109191484, "red_v22": -0.5559999999999996, "red_v29": -1.0039999999999998, "red_v7": -1.0169999999999988, "red_v2": -1.0109999999999995, "red_v19": -2.008, "red_v58": -2.016999999999999, "red_v18": -0.5549999999999999, "red_v27": 0.5071030335440548, "red_v36": -1.015999999999999, "red_v39": 3.340017980000002, "red_v61": -1.0239999999999996, "red_v13": -1.2889999999999997, "red_v35": -1.011, "red_v32": 0.4906932378161706}, "hist_stats": {"episode_reward": [4.49610522563234, 3.4532401128161707, 0.9537244878161704, 2.899724487816171, 1.8833304800000001, 1.3803304800000005, 2.468380042772942, 3.98266772563234, 1.9887394177729418, 4.48496460063234, 1.9844467835440551, 1.973005737816171, 2.453943237816171, 1.9763026128161707, 2.8847244878161726, 2.4481307378161707, 2.4841151128161703, 1.9825213628161704, 2.4701932378161704, 2.4438096144425936, 2.1072927256323473, 1.3166875000000005, 1.9923338628152039, 3.9668239756323405, 1.9327557378161715, 1.8864398550000006, 1.9921499085440548, 2.4820405335440547, 1.4689744878161708, 2.4541619878161702, 2.47981823781617, 1.4483182378161712, 4.453605225632341, 1.9673807378152046, 1.4777088628152046, 2.642253125, 1.9811144177729416, 1.98030261281617, 2.484520667772942, 1.3431562500000003, 3.4305994878161705, 2.9301151128161704, 1.6650968750000004, 2.4730838628161704, 1.937724487815204, 1.5494276128161857, 2.9791151128161704, 2.464161987816171, 1.9751932378161705, 1.7397432378162123, 2.9335213628161707, 2.4707557378161704, 3.648105225632358, 2.4371776128161713, 2.4658651128161706, 2.459384283544056, 1.9277401128161715, 1.1518781250000003, 2.462677612816172, 2.4663807378161713, 2.4866307378161703, 1.4787088628161702, 2.4845213628152036, 1.4316932378161722, 1.3787367300000004, 1.66620625, 1.963490112816171, 1.33334375, 3.978455977258762, 2.92919323781617, 4.005248701316997, 2.459458862816171, 3.339711217816173, 2.4647088628161704, 1.9775994878161707, 1.99003698781617, 2.48211511281617, 2.4402869878161715, 1.4713019177729425, 1.9929276128161701, 1.16620625, 2.387740112816174, 0.9509432378161704, 1.9486533644425923, 1.471896362816171, 2.98470886281617, 2.9247088628161713, 2.379627355, 2.97659948781617, 2.4713807378161703, 2.46456823781617, 2.4778963628161703, 1.4649744878161708, 2.47711511281617, 1.9653807378161703, 2.4269901128161724, 2.466568237816171, 2.858605225632342, 1.9713807378161703, 1.9242244878161716], "episode_lengths": [26, 49, 54, 54, 17, 17, 36, 38, 17, 39, 18, 28, 48, 29, 54, 52, 25, 23, 32, 40, 478, 36, 19, 52, 44, 14, 17, 20, 38, 42, 24, 56, 58, 36, 27, 31, 25, 29, 23, 14, 30, 25, 17, 35, 54, 309, 25, 42, 32, 1280, 23, 44, 282, 69, 41, 38, 81, 23, 37, 36, 20, 27, 23, 64, 15, 14, 33, 18, 23, 32, 15, 43, 53, 27, 30, 18, 25, 66, 29, 21, 14, 81, 48, 26, 31, 27, 27, 18, 30, 36, 40, 31, 38, 25, 36, 65, 40, 186, 36, 86], "policy_red_v51_reward": [1.5066932378161697], "policy_blue_reward": [0.486, -1.5099999999999998, -2.002, -2.005, -1.009, -2.0069999999999997, -2.0109999999999992, -1.013, -2.01, -1.0149999999999992, -1.0059999999999996, -2.0059999999999993, -1.0079999999999996, -1.0149999999999986, 1.9656875, -2.002, -1.0079999999999998, -1.009, -0.505, -2.0060000000000002, -2.0069999999999997, -1.005, -2.0039999999999996, -1.0099999999999996, -2.0069999999999997, 0.8470499999999999, -1.0159999999999996, -1.0119999999999991, -1.0179999999999987, -2.020999999999998, -2.004, -1.0059999999999998, -2.009, -1.005, -2.017999999999999, -2.005, -2.004, -2.007999999999999, -2.005, -1.008, -1.0179999999999985, -2.003, -1.0359999999999983, -1.5189999999999995, -2.007999999999999, -1.003, -0.009000000000000001, -1.0089999999999997, -1.0119999999999996, -1.005, -2.012999999999999, -1.0289999999999988, -1.010999999999999, -2.0099999999999993], "policy_red_v45_reward": [-0.565], "policy_red_v31_reward": [0.5026932378161703, 0.4879346144425925], "policy_red_v59_reward": [-2.005, -2.0119999999999996, -2.001, 1.93153125], "policy_red_v42_reward": [1.5046932378161704, 1.6065994878161702], "policy_red_v64_reward": [-0.572], "policy_red_v70_reward": [-2.001], "policy_red_v65_reward": [0.49669323781617025], "policy_red_v24_reward": [-2.0409999999999986], "policy_red_v48_reward": [-2.001, -0.003], "policy_red_v57_reward": [-2.0059999999999993], "policy_red_v40_reward": [-1.0099999999999996], "policy_red_v43_reward": [1.4906932378161712, -0.012], "policy_red_v11_reward": [-2.0119999999999987], "policy_red_v38_reward": [-2.001], "policy_red_v23_reward": [0.444], "policy_red_v47_reward": [-0.557], "policy_red_v66_reward": [-1.004], "policy_red_v14_reward": [-0.5159999999999999, -2.0109999999999992], "policy_red_v15_reward": [-1.231], "policy_red_v50_reward": [-0.010000000000000002, -0.047306762183829676], "policy_red_v22_reward": [-0.5559999999999996], "policy_red_v29_reward": [-1.0039999999999998], "policy_red_v7_reward": [-1.0169999999999988], "policy_red_v2_reward": [-1.0109999999999995], "policy_red_v19_reward": [-2.0060000000000002, -2.0099999999999993], "policy_red_v58_reward": [-2.016999999999999], "policy_red_v18_reward": [-0.5549999999999999], "policy_red_v27_reward": [0.5071030335440548], "policy_red_v36_reward": [-1.015999999999999], "policy_red_v39_reward": [3.340017980000002], "policy_red_v61_reward": [-1.0239999999999996], "policy_red_v13_reward": [-2.0149999999999997, -0.5629999999999998], "policy_red_v35_reward": [-1.011], "policy_red_v32_reward": [0.4906932378161706]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8209189334836176, "mean_inference_ms": 7.723294697842621, "mean_action_processing_ms": 0.2935497669605594, "mean_env_wait_ms": 0.3907574719112005, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09958267211914062, "StateBufferConnector_ms": 0.004181027412414551, "ViewRequirementAgentConnector_ms": 0.11590385437011719}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 840000, "num_agent_steps_trained": 840000, "num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 197.30812939953714, "num_env_steps_trained_throughput_per_sec": 197.30812939953714, "timesteps_total": 420000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 840000, "timers": {"training_iteration_time_ms": 19907.64, "sample_time_ms": 1165.705, "learn_time_ms": 18658.111, "learn_throughput": 214.384, "synch_weights_time_ms": 80.305}, "counters": {"num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_agent_steps_sampled": 840000, "num_agent_steps_trained": 840000}, "done": false, "episodes_total": 2038, "training_iteration": 105, "trial_id": "a9680_00000", "date": "2023-09-24_03-15-05", "timestamp": 1695539705, "time_this_iter_s": 20.28391170501709, "time_total_s": 2094.28790807724, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1df3ce50>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1dd52a70>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1dd52b00>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2094.28790807724, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 5.223529411764707, "ram_util_percent": 25.285294117647055}, "win_rate": 0.85, "league_size": 74}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.205639084925254, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.037483587376482316, "policy_loss": -0.04816064187034499, "vf_loss": 0.16051233109319582, "vf_explained_var": 0.8221019749219219, "kl": 0.015080815746947944, "entropy": 1.3983027043441931, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 101280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "sampler_results": {"episode_reward_max": 4.532743237816175, "episode_reward_min": -1.5093749999999908, "episode_reward_mean": 2.3549557758388695, "episode_len_mean": 82.28, "episode_media": {}, "episodes_this_iter": 56, "policy_reward_min": {"blue": -2.020999999999998, "red": -0.29037499999999583, "red_v7": -1.0169999999999988, "red_v2": -1.0109999999999995, "red_v19": -2.0099999999999993, "red_v58": -2.016999999999999, "red_v31": 0.4879346144425925, "red_v18": -0.5549999999999999, "red_v27": 0.5071030335440548, "red_v36": -1.015999999999999, "red_v39": 3.340017980000002, "red_v61": -1.0239999999999996, "red_v14": -2.1259999999999897, "red_v59": -2.001, "red_v13": -2.0149999999999997, "red_v48": -0.003, "red_v35": -1.011, "red_v32": 0.4906932378161706, "red_v10": -2.020999999999999, "red_v64": -1.0089999999999995, "red_v12": -2.0079999999999996, "red_v46": -2.0189999999999997, "red_v30": 0.4996925427729423, "red_v16": 0.5026932378161699, "red_v33": -0.49589696645594494, "red_v50": 0.5026932378152038, "red_v70": -0.553, "red_v26": -1.0139999999999998, "red_v4": -1.001, "red_v9": 0.438, "red_v41": 0.4906932378161707, "red_v22": -0.6080000000000001, "red_v52": 0.9326932378161705, "red_v24": 0.439, "red_v68": -2.001, "red_v56": 1.4976932378161705, "red_v25": 0.39328360500000037, "red_v8": -1.527, "red_v54": 0.17805000000000026, "red_v15": -0.011000000000000003, "red_v23": 0.45869323781617355}, "policy_reward_max": {"blue": 1.6530500000000004, "red": 3.99503698781617, "red_v7": -1.0169999999999988, "red_v2": -1.0109999999999995, "red_v19": 1.4926932378161706, "red_v58": -2.016999999999999, "red_v31": 0.4879346144425925, "red_v18": -0.5549999999999999, "red_v27": 0.5071030335440548, "red_v36": -1.015999999999999, "red_v39": 3.340017980000002, "red_v61": -1.0059999999999998, "red_v14": -2.0109999999999992, "red_v59": 1.93153125, "red_v13": -0.5629999999999998, "red_v48": -0.003, "red_v35": -1.011, "red_v32": 0.4906932378161706, "red_v10": -2.0199999999999996, "red_v64": -1.0089999999999995, "red_v12": 0.4639346144425939, "red_v46": -2.0189999999999997, "red_v30": 0.4996925427729423, "red_v16": 0.5026932378161699, "red_v33": 0.482046875, "red_v50": 0.5026932378152038, "red_v70": -0.553, "red_v26": -0.1549999999999998, "red_v4": -1.001, "red_v9": 0.438, "red_v41": 0.4906932378161707, "red_v22": -0.6080000000000001, "red_v52": 0.9326932378161705, "red_v24": 0.439, "red_v68": -1.006, "red_v56": 1.4976932378161705, "red_v25": 0.39328360500000037, "red_v8": -1.527, "red_v54": 0.17805000000000026, "red_v15": -0.011000000000000003, "red_v23": 0.45869323781617355}, "policy_reward_mean": {"blue": -1.2896585106382974, "red": 3.1883709951816956, "red_v7": -1.0169999999999988, "red_v2": -1.0109999999999995, "red_v19": -0.5403430369353077, "red_v58": -2.016999999999999, "red_v31": 0.4879346144425925, "red_v18": -0.5549999999999999, "red_v27": 0.5071030335440548, "red_v36": -1.015999999999999, "red_v39": 3.340017980000002, "red_v61": -1.0149999999999997, "red_v14": -2.0684999999999945, "red_v59": -0.034734374999999984, "red_v13": -1.2889999999999997, "red_v48": -0.003, "red_v35": -1.011, "red_v32": 0.4906932378161706, "red_v10": -2.0204999999999993, "red_v64": -1.0089999999999995, "red_v12": -0.39127179518580163, "red_v46": -2.0189999999999997, "red_v30": 0.4996925427729423, "red_v16": 0.5026932378161699, "red_v33": -0.05395003048531496, "red_v50": 0.5026932378152038, "red_v70": -0.553, "red_v26": -0.5844999999999998, "red_v4": -1.001, "red_v9": 0.438, "red_v41": 0.4906932378161707, "red_v22": -0.6080000000000001, "red_v52": 0.9326932378161705, "red_v24": 0.439, "red_v68": -1.5034999999999998, "red_v56": 1.4976932378161705, "red_v25": 0.39328360500000037, "red_v8": -1.527, "red_v54": 0.17805000000000026, "red_v15": -0.011000000000000003, "red_v23": 0.45869323781617355}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.9277401128161715, 1.1518781250000003, 2.462677612816172, 2.4663807378161713, 2.4866307378161703, 1.4787088628161702, 2.4845213628152036, 1.4316932378161722, 1.3787367300000004, 1.66620625, 1.963490112816171, 1.33334375, 3.978455977258762, 2.92919323781617, 4.005248701316997, 2.459458862816171, 3.339711217816173, 2.4647088628161704, 1.9775994878161707, 1.99003698781617, 2.48211511281617, 2.4402869878161715, 1.4713019177729425, 1.9929276128161701, 1.16620625, 2.387740112816174, 0.9509432378161704, 1.9486533644425923, 1.471896362816171, 2.98470886281617, 2.9247088628161713, 2.379627355, 2.97659948781617, 2.4713807378161703, 2.46456823781617, 2.4778963628161703, 1.4649744878161708, 2.47711511281617, 1.9653807378161703, 2.4269901128161724, 2.466568237816171, 2.858605225632342, 1.9713807378161703, 1.9242244878161716, 2.3735682378161753, 4.422596602258764, 1.4702237927729422, 1.4856619878161743, 2.47308386281617, 1.4669744878161706, 4.532743237816175, 0.8559432378161784, 0.9383182378161722, 2.4824112927729423, 1.9790057378161703, 2.4784119878161706, 2.4659744878161702, 1.459974487816171, 2.9816342835440546, 3.70517472725878, 2.4518026128161705, 3.9783701555891127, 3.9779646006323404, 2.394630737816175, 3.3344901128161704, 3.9592771006313745, 2.972749396360226, 3.9254716022587655, 1.9651151128161704, 0.9815249085440553, 2.9235994878161695, 3.331228033544056, 2.4871499085440547, 2.4591619878161706, 2.48419323781617, -1.5093749999999908, 2.473005042772942, 3.4021307378161714, 3.960120850632342, 2.8351151128161747, 2.42038647563235, 3.4309276128161708, 1.6414406250000009, 2.45383386281617, 1.16839375, 0.659096875000001, 1.9730838628161702, 0.9440057378161886, 4.4730427256323395, 0.44278698781617143, 2.4308494878161713, 2.4529432378161715, 1.4937394177729417, 2.48270886281617, 3.876586217816171, 0.6005343750000007, 3.655734614442592, 2.9775213628161703, 1.7424276128161815, 3.892886475632345], "episode_lengths": [81, 23, 37, 36, 20, 27, 23, 64, 15, 14, 33, 18, 23, 32, 15, 43, 53, 27, 30, 18, 25, 66, 29, 21, 14, 81, 48, 26, 31, 27, 27, 18, 30, 36, 40, 31, 38, 25, 36, 65, 40, 186, 36, 86, 104, 74, 22, 394, 35, 38, 128, 560, 56, 26, 28, 26, 38, 38, 22, 177, 61, 37, 39, 84, 33, 67, 47, 50, 25, 25, 30, 24, 17, 42, 32, 760, 28, 52, 53, 89, 1280, 21, 35, 51, 18, 17, 35, 540, 46, 546, 78, 48, 17, 27, 29, 69, 16, 23, 181, 96], "policy_blue_reward": [-2.020999999999998, -2.004, -1.0059999999999998, -2.009, -1.005, -2.017999999999999, -2.005, -2.004, -2.007999999999999, -2.005, -1.008, -1.0179999999999985, -2.003, -1.0359999999999983, -1.5189999999999995, -2.007999999999999, -1.003, -0.009000000000000001, -1.0089999999999997, -1.0119999999999996, -1.005, -2.012999999999999, -1.0289999999999988, -1.010999999999999, -2.0099999999999993, -1.036999999999997, -0.7389999999999999, -2.013, 1.6530500000000004, -1.517, -1.0049999999999994, -2.006, -1.0049999999999997, -1.0129999999999992, -0.007, -1.0329999999999997, -1.5039999999999998, -1.0069999999999997, -1.015999999999999, -1.219, -1.0079999999999996, -2.0119999999999996, -1.009999999999999, -1.157, -1.1640000000000001, -1.014999999999999, -2.002], "policy_red_v7_reward": [-1.0169999999999988], "policy_red_v2_reward": [-1.0109999999999995], "policy_red_v19_reward": [-2.0060000000000002, -2.0099999999999993, 1.4926932378161706, 0.36193461444259867], "policy_red_v58_reward": [-2.016999999999999], "policy_red_v31_reward": [0.4879346144425925], "policy_red_v18_reward": [-0.5549999999999999], "policy_red_v27_reward": [0.5071030335440548], "policy_red_v36_reward": [-1.015999999999999], "policy_red_v39_reward": [3.340017980000002], "policy_red_v61_reward": [-1.0239999999999996, -1.0059999999999998], "policy_red_v14_reward": [-2.0109999999999992, -2.1259999999999897], "policy_red_v59_reward": [-2.001, 1.93153125], "policy_red_v13_reward": [-2.0149999999999997, -0.5629999999999998], "policy_red_v48_reward": [-0.003], "policy_red_v35_reward": [-1.011], "policy_red_v32_reward": [0.4906932378161706], "policy_red_v10_reward": [-2.0199999999999996, -2.020999999999999], "policy_red_v64_reward": [-1.0089999999999995], "policy_red_v12_reward": [0.37025000000000075, 0.4639346144425939, -2.0079999999999996], "policy_red_v46_reward": [-2.0189999999999997], "policy_red_v30_reward": [0.4996925427729423], "policy_red_v16_reward": [0.5026932378161699], "policy_red_v33_reward": [-0.1479999999999999, -0.49589696645594494, 0.482046875], "policy_red_v50_reward": [0.5026932378152038], "policy_red_v70_reward": [-0.553], "policy_red_v26_reward": [-0.1549999999999998, -1.0139999999999998], "policy_red_v4_reward": [-1.001], "policy_red_v9_reward": [0.438], "policy_red_v41_reward": [0.4906932378161707], "policy_red_v22_reward": [-0.6080000000000001], "policy_red_v52_reward": [0.9326932378161705], "policy_red_v24_reward": [0.439], "policy_red_v68_reward": [-2.001, -1.006], "policy_red_v56_reward": [1.4976932378161705], "policy_red_v25_reward": [0.39328360500000037], "policy_red_v8_reward": [-1.527], "policy_red_v54_reward": [0.17805000000000026], "policy_red_v15_reward": [-0.011000000000000003], "policy_red_v23_reward": [0.45869323781617355]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8214168176158398, "mean_inference_ms": 7.731415630110723, "mean_action_processing_ms": 0.293926128725789, "mean_env_wait_ms": 0.39203114964139407, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09590089321136475, "StateBufferConnector_ms": 0.004011273384094238, "ViewRequirementAgentConnector_ms": 0.11168122291564941}}, "episode_reward_max": 4.532743237816175, "episode_reward_min": -1.5093749999999908, "episode_reward_mean": 2.3549557758388695, "episode_len_mean": 82.28, "episodes_this_iter": 56, "policy_reward_min": {"blue": -2.020999999999998, "red": -0.29037499999999583, "red_v7": -1.0169999999999988, "red_v2": -1.0109999999999995, "red_v19": -2.0099999999999993, "red_v58": -2.016999999999999, "red_v31": 0.4879346144425925, "red_v18": -0.5549999999999999, "red_v27": 0.5071030335440548, "red_v36": -1.015999999999999, "red_v39": 3.340017980000002, "red_v61": -1.0239999999999996, "red_v14": -2.1259999999999897, "red_v59": -2.001, "red_v13": -2.0149999999999997, "red_v48": -0.003, "red_v35": -1.011, "red_v32": 0.4906932378161706, "red_v10": -2.020999999999999, "red_v64": -1.0089999999999995, "red_v12": -2.0079999999999996, "red_v46": -2.0189999999999997, "red_v30": 0.4996925427729423, "red_v16": 0.5026932378161699, "red_v33": -0.49589696645594494, "red_v50": 0.5026932378152038, "red_v70": -0.553, "red_v26": -1.0139999999999998, "red_v4": -1.001, "red_v9": 0.438, "red_v41": 0.4906932378161707, "red_v22": -0.6080000000000001, "red_v52": 0.9326932378161705, "red_v24": 0.439, "red_v68": -2.001, "red_v56": 1.4976932378161705, "red_v25": 0.39328360500000037, "red_v8": -1.527, "red_v54": 0.17805000000000026, "red_v15": -0.011000000000000003, "red_v23": 0.45869323781617355}, "policy_reward_max": {"blue": 1.6530500000000004, "red": 3.99503698781617, "red_v7": -1.0169999999999988, "red_v2": -1.0109999999999995, "red_v19": 1.4926932378161706, "red_v58": -2.016999999999999, "red_v31": 0.4879346144425925, "red_v18": -0.5549999999999999, "red_v27": 0.5071030335440548, "red_v36": -1.015999999999999, "red_v39": 3.340017980000002, "red_v61": -1.0059999999999998, "red_v14": -2.0109999999999992, "red_v59": 1.93153125, "red_v13": -0.5629999999999998, "red_v48": -0.003, "red_v35": -1.011, "red_v32": 0.4906932378161706, "red_v10": -2.0199999999999996, "red_v64": -1.0089999999999995, "red_v12": 0.4639346144425939, "red_v46": -2.0189999999999997, "red_v30": 0.4996925427729423, "red_v16": 0.5026932378161699, "red_v33": 0.482046875, "red_v50": 0.5026932378152038, "red_v70": -0.553, "red_v26": -0.1549999999999998, "red_v4": -1.001, "red_v9": 0.438, "red_v41": 0.4906932378161707, "red_v22": -0.6080000000000001, "red_v52": 0.9326932378161705, "red_v24": 0.439, "red_v68": -1.006, "red_v56": 1.4976932378161705, "red_v25": 0.39328360500000037, "red_v8": -1.527, "red_v54": 0.17805000000000026, "red_v15": -0.011000000000000003, "red_v23": 0.45869323781617355}, "policy_reward_mean": {"blue": -1.2896585106382974, "red": 3.1883709951816956, "red_v7": -1.0169999999999988, "red_v2": -1.0109999999999995, "red_v19": -0.5403430369353077, "red_v58": -2.016999999999999, "red_v31": 0.4879346144425925, "red_v18": -0.5549999999999999, "red_v27": 0.5071030335440548, "red_v36": -1.015999999999999, "red_v39": 3.340017980000002, "red_v61": -1.0149999999999997, "red_v14": -2.0684999999999945, "red_v59": -0.034734374999999984, "red_v13": -1.2889999999999997, "red_v48": -0.003, "red_v35": -1.011, "red_v32": 0.4906932378161706, "red_v10": -2.0204999999999993, "red_v64": -1.0089999999999995, "red_v12": -0.39127179518580163, "red_v46": -2.0189999999999997, "red_v30": 0.4996925427729423, "red_v16": 0.5026932378161699, "red_v33": -0.05395003048531496, "red_v50": 0.5026932378152038, "red_v70": -0.553, "red_v26": -0.5844999999999998, "red_v4": -1.001, "red_v9": 0.438, "red_v41": 0.4906932378161707, "red_v22": -0.6080000000000001, "red_v52": 0.9326932378161705, "red_v24": 0.439, "red_v68": -1.5034999999999998, "red_v56": 1.4976932378161705, "red_v25": 0.39328360500000037, "red_v8": -1.527, "red_v54": 0.17805000000000026, "red_v15": -0.011000000000000003, "red_v23": 0.45869323781617355}, "hist_stats": {"episode_reward": [1.9277401128161715, 1.1518781250000003, 2.462677612816172, 2.4663807378161713, 2.4866307378161703, 1.4787088628161702, 2.4845213628152036, 1.4316932378161722, 1.3787367300000004, 1.66620625, 1.963490112816171, 1.33334375, 3.978455977258762, 2.92919323781617, 4.005248701316997, 2.459458862816171, 3.339711217816173, 2.4647088628161704, 1.9775994878161707, 1.99003698781617, 2.48211511281617, 2.4402869878161715, 1.4713019177729425, 1.9929276128161701, 1.16620625, 2.387740112816174, 0.9509432378161704, 1.9486533644425923, 1.471896362816171, 2.98470886281617, 2.9247088628161713, 2.379627355, 2.97659948781617, 2.4713807378161703, 2.46456823781617, 2.4778963628161703, 1.4649744878161708, 2.47711511281617, 1.9653807378161703, 2.4269901128161724, 2.466568237816171, 2.858605225632342, 1.9713807378161703, 1.9242244878161716, 2.3735682378161753, 4.422596602258764, 1.4702237927729422, 1.4856619878161743, 2.47308386281617, 1.4669744878161706, 4.532743237816175, 0.8559432378161784, 0.9383182378161722, 2.4824112927729423, 1.9790057378161703, 2.4784119878161706, 2.4659744878161702, 1.459974487816171, 2.9816342835440546, 3.70517472725878, 2.4518026128161705, 3.9783701555891127, 3.9779646006323404, 2.394630737816175, 3.3344901128161704, 3.9592771006313745, 2.972749396360226, 3.9254716022587655, 1.9651151128161704, 0.9815249085440553, 2.9235994878161695, 3.331228033544056, 2.4871499085440547, 2.4591619878161706, 2.48419323781617, -1.5093749999999908, 2.473005042772942, 3.4021307378161714, 3.960120850632342, 2.8351151128161747, 2.42038647563235, 3.4309276128161708, 1.6414406250000009, 2.45383386281617, 1.16839375, 0.659096875000001, 1.9730838628161702, 0.9440057378161886, 4.4730427256323395, 0.44278698781617143, 2.4308494878161713, 2.4529432378161715, 1.4937394177729417, 2.48270886281617, 3.876586217816171, 0.6005343750000007, 3.655734614442592, 2.9775213628161703, 1.7424276128161815, 3.892886475632345], "episode_lengths": [81, 23, 37, 36, 20, 27, 23, 64, 15, 14, 33, 18, 23, 32, 15, 43, 53, 27, 30, 18, 25, 66, 29, 21, 14, 81, 48, 26, 31, 27, 27, 18, 30, 36, 40, 31, 38, 25, 36, 65, 40, 186, 36, 86, 104, 74, 22, 394, 35, 38, 128, 560, 56, 26, 28, 26, 38, 38, 22, 177, 61, 37, 39, 84, 33, 67, 47, 50, 25, 25, 30, 24, 17, 42, 32, 760, 28, 52, 53, 89, 1280, 21, 35, 51, 18, 17, 35, 540, 46, 546, 78, 48, 17, 27, 29, 69, 16, 23, 181, 96], "policy_blue_reward": [-2.020999999999998, -2.004, -1.0059999999999998, -2.009, -1.005, -2.017999999999999, -2.005, -2.004, -2.007999999999999, -2.005, -1.008, -1.0179999999999985, -2.003, -1.0359999999999983, -1.5189999999999995, -2.007999999999999, -1.003, -0.009000000000000001, -1.0089999999999997, -1.0119999999999996, -1.005, -2.012999999999999, -1.0289999999999988, -1.010999999999999, -2.0099999999999993, -1.036999999999997, -0.7389999999999999, -2.013, 1.6530500000000004, -1.517, -1.0049999999999994, -2.006, -1.0049999999999997, -1.0129999999999992, -0.007, -1.0329999999999997, -1.5039999999999998, -1.0069999999999997, -1.015999999999999, -1.219, -1.0079999999999996, -2.0119999999999996, -1.009999999999999, -1.157, -1.1640000000000001, -1.014999999999999, -2.002], "policy_red_v7_reward": [-1.0169999999999988], "policy_red_v2_reward": [-1.0109999999999995], "policy_red_v19_reward": [-2.0060000000000002, -2.0099999999999993, 1.4926932378161706, 0.36193461444259867], "policy_red_v58_reward": [-2.016999999999999], "policy_red_v31_reward": [0.4879346144425925], "policy_red_v18_reward": [-0.5549999999999999], "policy_red_v27_reward": [0.5071030335440548], "policy_red_v36_reward": [-1.015999999999999], "policy_red_v39_reward": [3.340017980000002], "policy_red_v61_reward": [-1.0239999999999996, -1.0059999999999998], "policy_red_v14_reward": [-2.0109999999999992, -2.1259999999999897], "policy_red_v59_reward": [-2.001, 1.93153125], "policy_red_v13_reward": [-2.0149999999999997, -0.5629999999999998], "policy_red_v48_reward": [-0.003], "policy_red_v35_reward": [-1.011], "policy_red_v32_reward": [0.4906932378161706], "policy_red_v10_reward": [-2.0199999999999996, -2.020999999999999], "policy_red_v64_reward": [-1.0089999999999995], "policy_red_v12_reward": [0.37025000000000075, 0.4639346144425939, -2.0079999999999996], "policy_red_v46_reward": [-2.0189999999999997], "policy_red_v30_reward": [0.4996925427729423], "policy_red_v16_reward": [0.5026932378161699], "policy_red_v33_reward": [-0.1479999999999999, -0.49589696645594494, 0.482046875], "policy_red_v50_reward": [0.5026932378152038], "policy_red_v70_reward": [-0.553], "policy_red_v26_reward": [-0.1549999999999998, -1.0139999999999998], "policy_red_v4_reward": [-1.001], "policy_red_v9_reward": [0.438], "policy_red_v41_reward": [0.4906932378161707], "policy_red_v22_reward": [-0.6080000000000001], "policy_red_v52_reward": [0.9326932378161705], "policy_red_v24_reward": [0.439], "policy_red_v68_reward": [-2.001, -1.006], "policy_red_v56_reward": [1.4976932378161705], "policy_red_v25_reward": [0.39328360500000037], "policy_red_v8_reward": [-1.527], "policy_red_v54_reward": [0.17805000000000026], "policy_red_v15_reward": [-0.011000000000000003], "policy_red_v23_reward": [0.45869323781617355]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8214168176158398, "mean_inference_ms": 7.731415630110723, "mean_action_processing_ms": 0.293926128725789, "mean_env_wait_ms": 0.39203114964139407, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09590089321136475, "StateBufferConnector_ms": 0.004011273384094238, "ViewRequirementAgentConnector_ms": 0.11168122291564941}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.6489091379386, "num_env_steps_trained_throughput_per_sec": 200.6489091379386, "timesteps_total": 424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 19912.95, "sample_time_ms": 1176.244, "learn_time_ms": 18653.105, "learn_throughput": 214.442, "synch_weights_time_ms": 80.088}, "counters": {"num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "episodes_total": 2094, "training_iteration": 106, "trial_id": "a9680_00000", "date": "2023-09-24_03-15-29", "timestamp": 1695539729, "time_this_iter_s": 19.94521188735962, "time_total_s": 2114.2331199645996, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dd60ee0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1dd53760>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1dd537f0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2114.2331199645996, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 5.669696969696971, "ram_util_percent": 25.387878787878787}, "win_rate": 0.78, "league_size": 75}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3694048995772996, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.05283691144674473, "policy_loss": -0.042346215462263595, "vf_loss": 0.18007584721393263, "vf_explained_var": 0.8362379430482785, "kl": 0.01437792352084936, "entropy": 1.3248614168415467, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 102240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_agent_steps_sampled": 856000, "num_agent_steps_trained": 856000}, "sampler_results": {"episode_reward_max": 4.4730427256323395, "episode_reward_min": -1.5093749999999908, "episode_reward_mean": 2.335686999876508, "episode_len_mean": 102.4, "episode_media": {}, "episodes_this_iter": 61, "policy_reward_min": {"red_v30": 0.4996925427729423, "red": -0.6569999999999999, "red_v16": 0.5026932378161699, "blue": -2.017999999999999, "red_v33": -1.032999999999998, "red_v50": -0.9530000000000003, "red_v12": -2.0079999999999996, "red_v10": -2.020999999999999, "red_v70": -2.001, "red_v26": -1.0139999999999998, "red_v4": -2.005, "red_v9": 0.438, "red_v41": 0.4906932378161707, "red_v22": -0.6080000000000001, "red_v52": 0.9326932378161705, "red_v24": 0.439, "red_v68": -2.001, "red_v56": 1.4976932378161705, "red_v25": 0.39328360500000037, "red_v8": -1.527, "red_v54": 0.17805000000000026, "red_v15": -0.011000000000000003, "red_v14": -2.1259999999999897, "red_v23": 0.45869323781617355, "red_v55": -2.0109999999999992, "red_v63": -2.0089999999999995, "red_v34": -0.5559999999999997, "red_v35": -2.0249999999999995, "red_v31": 1.949770667772942, "red_v57": -1.004, "red_v66": 0.4490781250000001, "red_v62": -2.005, "red_v6": -2.0140000000000002, "red_v53": -2.0109999999999992, "red_v19": -2.01, "red_v71": -2.003, "red_v28": 0.4869346144425924, "red_v49": 0.39428360500000026, "red_v42": -1.0109999999999992, "red_v58": -1.0089999999999992, "red_v5": -1.007, "red_v13": -2.054999999999996, "red_v51": -2.009, "red_v21": -0.7020000000000004, "red_v2": 1.4849346144425921, "red_v48": 0.502692542772942}, "policy_reward_max": {"red_v30": 0.4996925427729423, "red": 3.9936307378152036, "red_v16": 0.5026932378161699, "blue": -1.0049999999999994, "red_v33": 0.482046875, "red_v50": 0.5026932378152038, "red_v12": 0.4639346144425939, "red_v10": -2.020999999999999, "red_v70": -0.553, "red_v26": -0.1549999999999998, "red_v4": -1.001, "red_v9": 0.438, "red_v41": 0.4906932378161707, "red_v22": -0.6080000000000001, "red_v52": 0.9326932378161705, "red_v24": 0.439, "red_v68": -1.006, "red_v56": 1.4976932378161705, "red_v25": 0.48569323781520557, "red_v8": -1.527, "red_v54": 0.17805000000000026, "red_v15": -0.011000000000000003, "red_v14": -2.1259999999999897, "red_v23": 0.45869323781617355, "red_v55": -0.5109999999999997, "red_v63": -2.0029999999999997, "red_v34": 0.4956932378161703, "red_v35": -2.0249999999999995, "red_v31": 1.949770667772942, "red_v57": 0.46069323781616967, "red_v66": 0.4490781250000001, "red_v62": 1.97571875, "red_v6": 0.8390000000000001, "red_v53": -2.0109999999999992, "red_v19": 0.4976932378161706, "red_v71": -2.003, "red_v28": 0.4869346144425924, "red_v49": 0.39428360500000026, "red_v42": 0.4829346144425924, "red_v58": -1.0089999999999992, "red_v5": -1.007, "red_v13": -2.054999999999996, "red_v51": -2.009, "red_v21": -0.7020000000000004, "red_v2": 1.4849346144425921, "red_v48": 0.502692542772942}, "policy_reward_mean": {"red_v30": 0.4996925427729423, "red": 3.161003094048577, "red_v16": 0.5026932378161699, "blue": -1.3924722222222214, "red_v33": -0.2987125228639857, "red_v50": -0.3351022540615988, "red_v12": -0.7720326927787029, "red_v10": -2.020999999999999, "red_v70": -1.277, "red_v26": -0.5844999999999998, "red_v4": -1.3386666666666667, "red_v9": 0.438, "red_v41": 0.4906932378161707, "red_v22": -0.6080000000000001, "red_v52": 0.9326932378161705, "red_v24": 0.439, "red_v68": -1.5034999999999998, "red_v56": 1.4976932378161705, "red_v25": 0.43948842140760297, "red_v8": -1.527, "red_v54": 0.17805000000000026, "red_v15": -0.011000000000000003, "red_v14": -2.1259999999999897, "red_v23": 0.45869323781617355, "red_v55": -1.2609999999999995, "red_v63": -2.0059999999999993, "red_v34": -0.030153381091914705, "red_v35": -2.0249999999999995, "red_v31": 1.949770667772942, "red_v57": -0.27165338109191517, "red_v66": 0.4490781250000001, "red_v62": -0.014640624999999963, "red_v6": -0.5875000000000001, "red_v53": -2.0109999999999992, "red_v19": -0.7561533810919145, "red_v71": -2.003, "red_v28": 0.4869346144425924, "red_v49": 0.39428360500000026, "red_v42": -0.26403269277870345, "red_v58": -1.0089999999999992, "red_v5": -1.007, "red_v13": -2.054999999999996, "red_v51": -2.009, "red_v21": -0.7020000000000004, "red_v2": 1.4849346144425921, "red_v48": 0.502692542772942}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.9783701555891127, 3.9779646006323404, 2.394630737816175, 3.3344901128161704, 3.9592771006313745, 2.972749396360226, 3.9254716022587655, 1.9651151128161704, 0.9815249085440553, 2.9235994878161695, 3.331228033544056, 2.4871499085440547, 2.4591619878161706, 2.48419323781617, -1.5093749999999908, 2.473005042772942, 3.4021307378161714, 3.960120850632342, 2.8351151128161747, 2.42038647563235, 3.4309276128161708, 1.6414406250000009, 2.45383386281617, 1.16839375, 0.659096875000001, 1.9730838628161702, 0.9440057378161886, 4.4730427256323395, 0.44278698781617143, 2.4308494878161713, 2.4529432378161715, 1.4937394177729417, 2.48270886281617, 3.876586217816171, 0.6005343750000007, 3.655734614442592, 2.9775213628161703, 1.7424276128161815, 3.892886475632345, 2.48622448781617, 2.4548408644425934, 1.601168989442602, 1.97838073781617, 1.9535369878161708, 1.449243658544057, 0.719552612816181, 2.4458338628161718, 1.9580213628161713, 1.471302612815204, 1.4844467835440551, 2.939853033544055, 1.424396362816172, 2.4484639055891133, 2.4634588628161707, 2.444583862816171, 2.478114417772942, 2.48500573781617, 2.914943237816171, 0.9527713628161707, 1.3773304800000004, 1.163690625, 1.3654086050000007, 1.97541198781617, 2.4867436585440554, 2.4439744878161713, 1.469302612816171, 1.3318593750000003, 1.31871875, 3.9610114756323407, 1.3783304800000002, 1.968677612816171, 3.787395667772945, 3.9784559772587627, 3.8826210135440555, 2.4717869878161705, 0.8418593750000001, 2.4708651128161705, 0.5386932378161704, 2.4873338628161705, 1.8823338628161754, 2.4856307378161704, 3.9419802256313763, 1.9886307378152035, 2.278646362816179, 1.4820405335440552, 0.28069323781621847, 3.878198975632343, 1.9778963628161703, 2.4559432378161707, 1.490149908544055, 3.974381397986647, 1.4293437500000001, 1.9705994878152042, 1.8740336050000004, 4.470830977258762, 2.47878698781617, 3.996025710545884, 3.9757771006323406, 1.97841198781617, 2.47589636281617], "episode_lengths": [37, 39, 84, 33, 67, 47, 50, 25, 25, 30, 24, 17, 42, 32, 760, 28, 52, 53, 89, 1280, 21, 35, 51, 18, 17, 35, 540, 46, 546, 78, 48, 17, 27, 29, 69, 16, 23, 181, 96, 22, 30, 597, 36, 50, 51, 205, 51, 55, 29, 18, 16, 63, 71, 43, 67, 25, 28, 48, 71, 17, 19, 24, 26, 19, 38, 29, 13, 26, 56, 17, 37, 63, 23, 21, 34, 13, 41, 1280, 19, 83, 20, 66, 20, 175, 20, 1280, 124, 31, 48, 17, 18, 18, 30, 16, 31, 34, 19, 35, 26, 31], "policy_red_v30_reward": [0.4996925427729423], "policy_red_v16_reward": [0.5026932378161699], "policy_blue_reward": [-1.0329999999999997, -1.5039999999999998, -1.0069999999999997, -1.015999999999999, -1.219, -1.0079999999999996, -2.0119999999999996, -1.009999999999999, -1.157, -1.1640000000000001, -1.014999999999999, -2.002, -1.0059999999999993, -1.0109999999999995, -1.1629999999999843, -2.0119999999999987, -2.017999999999999, -1.5529999999999968, -1.0199999999999991, -2.0079999999999996, -1.0119999999999991, -1.011999999999999, -1.0089999999999997, -2.0079999999999996, -2.009, -1.0059999999999996, -2.0139999999999993, -2.0109999999999992, -1.0079999999999993, -1.0529999999999986, -2.0059999999999993, -1.013999999999999, -2.005, -1.0059999999999996, -2.013, -1.0049999999999994], "policy_red_v33_reward": [-0.1479999999999999, -0.49589696645594494, 0.482046875, -1.032999999999998], "policy_red_v50_reward": [0.5026932378152038, -0.5549999999999999, -0.9530000000000003], "policy_red_v12_reward": [0.4639346144425939, -2.0079999999999996], "policy_red_v10_reward": [-2.020999999999999], "policy_red_v70_reward": [-0.553, -2.001], "policy_red_v26_reward": [-0.1549999999999998, -1.0139999999999998], "policy_red_v4_reward": [-1.001, -2.005, -1.0099999999999998], "policy_red_v9_reward": [0.438], "policy_red_v41_reward": [0.4906932378161707], "policy_red_v22_reward": [-0.6080000000000001], "policy_red_v52_reward": [0.9326932378161705], "policy_red_v24_reward": [0.439], "policy_red_v68_reward": [-2.001, -1.006], "policy_red_v56_reward": [1.4976932378161705], "policy_red_v25_reward": [0.39328360500000037, 0.48569323781520557], "policy_red_v8_reward": [-1.527], "policy_red_v54_reward": [0.17805000000000026], "policy_red_v15_reward": [-0.011000000000000003], "policy_red_v14_reward": [-2.1259999999999897], "policy_red_v23_reward": [0.45869323781617355], "policy_red_v55_reward": [-0.5109999999999997, -2.0109999999999992], "policy_red_v63_reward": [-2.0089999999999995, -2.0029999999999997], "policy_red_v34_reward": [-0.5559999999999997, 0.4956932378161703], "policy_red_v35_reward": [-2.0249999999999995], "policy_red_v31_reward": [1.949770667772942], "policy_red_v57_reward": [-1.004, 0.46069323781616967], "policy_red_v66_reward": [0.4490781250000001], "policy_red_v62_reward": [-2.005, 1.97571875], "policy_red_v6_reward": [-2.0140000000000002, 0.8390000000000001], "policy_red_v53_reward": [-2.0109999999999992], "policy_red_v19_reward": [0.4976932378161706, -2.01], "policy_red_v71_reward": [-2.003], "policy_red_v28_reward": [0.4869346144425924], "policy_red_v49_reward": [0.39428360500000026], "policy_red_v42_reward": [-1.0109999999999992, 0.4829346144425924], "policy_red_v58_reward": [-1.0089999999999992], "policy_red_v5_reward": [-1.007], "policy_red_v13_reward": [-2.054999999999996], "policy_red_v51_reward": [-2.009], "policy_red_v21_reward": [-0.7020000000000004], "policy_red_v2_reward": [1.4849346144425921], "policy_red_v48_reward": [0.502692542772942]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.818822417790982, "mean_inference_ms": 7.689174988662652, "mean_action_processing_ms": 0.2923521653222996, "mean_env_wait_ms": 0.3900020458953407, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09781932830810547, "StateBufferConnector_ms": 0.004031777381896973, "ViewRequirementAgentConnector_ms": 0.11246109008789062}}, "episode_reward_max": 4.4730427256323395, "episode_reward_min": -1.5093749999999908, "episode_reward_mean": 2.335686999876508, "episode_len_mean": 102.4, "episodes_this_iter": 61, "policy_reward_min": {"red_v30": 0.4996925427729423, "red": -0.6569999999999999, "red_v16": 0.5026932378161699, "blue": -2.017999999999999, "red_v33": -1.032999999999998, "red_v50": -0.9530000000000003, "red_v12": -2.0079999999999996, "red_v10": -2.020999999999999, "red_v70": -2.001, "red_v26": -1.0139999999999998, "red_v4": -2.005, "red_v9": 0.438, "red_v41": 0.4906932378161707, "red_v22": -0.6080000000000001, "red_v52": 0.9326932378161705, "red_v24": 0.439, "red_v68": -2.001, "red_v56": 1.4976932378161705, "red_v25": 0.39328360500000037, "red_v8": -1.527, "red_v54": 0.17805000000000026, "red_v15": -0.011000000000000003, "red_v14": -2.1259999999999897, "red_v23": 0.45869323781617355, "red_v55": -2.0109999999999992, "red_v63": -2.0089999999999995, "red_v34": -0.5559999999999997, "red_v35": -2.0249999999999995, "red_v31": 1.949770667772942, "red_v57": -1.004, "red_v66": 0.4490781250000001, "red_v62": -2.005, "red_v6": -2.0140000000000002, "red_v53": -2.0109999999999992, "red_v19": -2.01, "red_v71": -2.003, "red_v28": 0.4869346144425924, "red_v49": 0.39428360500000026, "red_v42": -1.0109999999999992, "red_v58": -1.0089999999999992, "red_v5": -1.007, "red_v13": -2.054999999999996, "red_v51": -2.009, "red_v21": -0.7020000000000004, "red_v2": 1.4849346144425921, "red_v48": 0.502692542772942}, "policy_reward_max": {"red_v30": 0.4996925427729423, "red": 3.9936307378152036, "red_v16": 0.5026932378161699, "blue": -1.0049999999999994, "red_v33": 0.482046875, "red_v50": 0.5026932378152038, "red_v12": 0.4639346144425939, "red_v10": -2.020999999999999, "red_v70": -0.553, "red_v26": -0.1549999999999998, "red_v4": -1.001, "red_v9": 0.438, "red_v41": 0.4906932378161707, "red_v22": -0.6080000000000001, "red_v52": 0.9326932378161705, "red_v24": 0.439, "red_v68": -1.006, "red_v56": 1.4976932378161705, "red_v25": 0.48569323781520557, "red_v8": -1.527, "red_v54": 0.17805000000000026, "red_v15": -0.011000000000000003, "red_v14": -2.1259999999999897, "red_v23": 0.45869323781617355, "red_v55": -0.5109999999999997, "red_v63": -2.0029999999999997, "red_v34": 0.4956932378161703, "red_v35": -2.0249999999999995, "red_v31": 1.949770667772942, "red_v57": 0.46069323781616967, "red_v66": 0.4490781250000001, "red_v62": 1.97571875, "red_v6": 0.8390000000000001, "red_v53": -2.0109999999999992, "red_v19": 0.4976932378161706, "red_v71": -2.003, "red_v28": 0.4869346144425924, "red_v49": 0.39428360500000026, "red_v42": 0.4829346144425924, "red_v58": -1.0089999999999992, "red_v5": -1.007, "red_v13": -2.054999999999996, "red_v51": -2.009, "red_v21": -0.7020000000000004, "red_v2": 1.4849346144425921, "red_v48": 0.502692542772942}, "policy_reward_mean": {"red_v30": 0.4996925427729423, "red": 3.161003094048577, "red_v16": 0.5026932378161699, "blue": -1.3924722222222214, "red_v33": -0.2987125228639857, "red_v50": -0.3351022540615988, "red_v12": -0.7720326927787029, "red_v10": -2.020999999999999, "red_v70": -1.277, "red_v26": -0.5844999999999998, "red_v4": -1.3386666666666667, "red_v9": 0.438, "red_v41": 0.4906932378161707, "red_v22": -0.6080000000000001, "red_v52": 0.9326932378161705, "red_v24": 0.439, "red_v68": -1.5034999999999998, "red_v56": 1.4976932378161705, "red_v25": 0.43948842140760297, "red_v8": -1.527, "red_v54": 0.17805000000000026, "red_v15": -0.011000000000000003, "red_v14": -2.1259999999999897, "red_v23": 0.45869323781617355, "red_v55": -1.2609999999999995, "red_v63": -2.0059999999999993, "red_v34": -0.030153381091914705, "red_v35": -2.0249999999999995, "red_v31": 1.949770667772942, "red_v57": -0.27165338109191517, "red_v66": 0.4490781250000001, "red_v62": -0.014640624999999963, "red_v6": -0.5875000000000001, "red_v53": -2.0109999999999992, "red_v19": -0.7561533810919145, "red_v71": -2.003, "red_v28": 0.4869346144425924, "red_v49": 0.39428360500000026, "red_v42": -0.26403269277870345, "red_v58": -1.0089999999999992, "red_v5": -1.007, "red_v13": -2.054999999999996, "red_v51": -2.009, "red_v21": -0.7020000000000004, "red_v2": 1.4849346144425921, "red_v48": 0.502692542772942}, "hist_stats": {"episode_reward": [3.9783701555891127, 3.9779646006323404, 2.394630737816175, 3.3344901128161704, 3.9592771006313745, 2.972749396360226, 3.9254716022587655, 1.9651151128161704, 0.9815249085440553, 2.9235994878161695, 3.331228033544056, 2.4871499085440547, 2.4591619878161706, 2.48419323781617, -1.5093749999999908, 2.473005042772942, 3.4021307378161714, 3.960120850632342, 2.8351151128161747, 2.42038647563235, 3.4309276128161708, 1.6414406250000009, 2.45383386281617, 1.16839375, 0.659096875000001, 1.9730838628161702, 0.9440057378161886, 4.4730427256323395, 0.44278698781617143, 2.4308494878161713, 2.4529432378161715, 1.4937394177729417, 2.48270886281617, 3.876586217816171, 0.6005343750000007, 3.655734614442592, 2.9775213628161703, 1.7424276128161815, 3.892886475632345, 2.48622448781617, 2.4548408644425934, 1.601168989442602, 1.97838073781617, 1.9535369878161708, 1.449243658544057, 0.719552612816181, 2.4458338628161718, 1.9580213628161713, 1.471302612815204, 1.4844467835440551, 2.939853033544055, 1.424396362816172, 2.4484639055891133, 2.4634588628161707, 2.444583862816171, 2.478114417772942, 2.48500573781617, 2.914943237816171, 0.9527713628161707, 1.3773304800000004, 1.163690625, 1.3654086050000007, 1.97541198781617, 2.4867436585440554, 2.4439744878161713, 1.469302612816171, 1.3318593750000003, 1.31871875, 3.9610114756323407, 1.3783304800000002, 1.968677612816171, 3.787395667772945, 3.9784559772587627, 3.8826210135440555, 2.4717869878161705, 0.8418593750000001, 2.4708651128161705, 0.5386932378161704, 2.4873338628161705, 1.8823338628161754, 2.4856307378161704, 3.9419802256313763, 1.9886307378152035, 2.278646362816179, 1.4820405335440552, 0.28069323781621847, 3.878198975632343, 1.9778963628161703, 2.4559432378161707, 1.490149908544055, 3.974381397986647, 1.4293437500000001, 1.9705994878152042, 1.8740336050000004, 4.470830977258762, 2.47878698781617, 3.996025710545884, 3.9757771006323406, 1.97841198781617, 2.47589636281617], "episode_lengths": [37, 39, 84, 33, 67, 47, 50, 25, 25, 30, 24, 17, 42, 32, 760, 28, 52, 53, 89, 1280, 21, 35, 51, 18, 17, 35, 540, 46, 546, 78, 48, 17, 27, 29, 69, 16, 23, 181, 96, 22, 30, 597, 36, 50, 51, 205, 51, 55, 29, 18, 16, 63, 71, 43, 67, 25, 28, 48, 71, 17, 19, 24, 26, 19, 38, 29, 13, 26, 56, 17, 37, 63, 23, 21, 34, 13, 41, 1280, 19, 83, 20, 66, 20, 175, 20, 1280, 124, 31, 48, 17, 18, 18, 30, 16, 31, 34, 19, 35, 26, 31], "policy_red_v30_reward": [0.4996925427729423], "policy_red_v16_reward": [0.5026932378161699], "policy_blue_reward": [-1.0329999999999997, -1.5039999999999998, -1.0069999999999997, -1.015999999999999, -1.219, -1.0079999999999996, -2.0119999999999996, -1.009999999999999, -1.157, -1.1640000000000001, -1.014999999999999, -2.002, -1.0059999999999993, -1.0109999999999995, -1.1629999999999843, -2.0119999999999987, -2.017999999999999, -1.5529999999999968, -1.0199999999999991, -2.0079999999999996, -1.0119999999999991, -1.011999999999999, -1.0089999999999997, -2.0079999999999996, -2.009, -1.0059999999999996, -2.0139999999999993, -2.0109999999999992, -1.0079999999999993, -1.0529999999999986, -2.0059999999999993, -1.013999999999999, -2.005, -1.0059999999999996, -2.013, -1.0049999999999994], "policy_red_v33_reward": [-0.1479999999999999, -0.49589696645594494, 0.482046875, -1.032999999999998], "policy_red_v50_reward": [0.5026932378152038, -0.5549999999999999, -0.9530000000000003], "policy_red_v12_reward": [0.4639346144425939, -2.0079999999999996], "policy_red_v10_reward": [-2.020999999999999], "policy_red_v70_reward": [-0.553, -2.001], "policy_red_v26_reward": [-0.1549999999999998, -1.0139999999999998], "policy_red_v4_reward": [-1.001, -2.005, -1.0099999999999998], "policy_red_v9_reward": [0.438], "policy_red_v41_reward": [0.4906932378161707], "policy_red_v22_reward": [-0.6080000000000001], "policy_red_v52_reward": [0.9326932378161705], "policy_red_v24_reward": [0.439], "policy_red_v68_reward": [-2.001, -1.006], "policy_red_v56_reward": [1.4976932378161705], "policy_red_v25_reward": [0.39328360500000037, 0.48569323781520557], "policy_red_v8_reward": [-1.527], "policy_red_v54_reward": [0.17805000000000026], "policy_red_v15_reward": [-0.011000000000000003], "policy_red_v14_reward": [-2.1259999999999897], "policy_red_v23_reward": [0.45869323781617355], "policy_red_v55_reward": [-0.5109999999999997, -2.0109999999999992], "policy_red_v63_reward": [-2.0089999999999995, -2.0029999999999997], "policy_red_v34_reward": [-0.5559999999999997, 0.4956932378161703], "policy_red_v35_reward": [-2.0249999999999995], "policy_red_v31_reward": [1.949770667772942], "policy_red_v57_reward": [-1.004, 0.46069323781616967], "policy_red_v66_reward": [0.4490781250000001], "policy_red_v62_reward": [-2.005, 1.97571875], "policy_red_v6_reward": [-2.0140000000000002, 0.8390000000000001], "policy_red_v53_reward": [-2.0109999999999992], "policy_red_v19_reward": [0.4976932378161706, -2.01], "policy_red_v71_reward": [-2.003], "policy_red_v28_reward": [0.4869346144425924], "policy_red_v49_reward": [0.39428360500000026], "policy_red_v42_reward": [-1.0109999999999992, 0.4829346144425924], "policy_red_v58_reward": [-1.0089999999999992], "policy_red_v5_reward": [-1.007], "policy_red_v13_reward": [-2.054999999999996], "policy_red_v51_reward": [-2.009], "policy_red_v21_reward": [-0.7020000000000004], "policy_red_v2_reward": [1.4849346144425921], "policy_red_v48_reward": [0.502692542772942]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.818822417790982, "mean_inference_ms": 7.689174988662652, "mean_action_processing_ms": 0.2923521653222996, "mean_env_wait_ms": 0.3900020458953407, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09781932830810547, "StateBufferConnector_ms": 0.004031777381896973, "ViewRequirementAgentConnector_ms": 0.11246109008789062}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 856000, "num_agent_steps_trained": 856000, "num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 196.4361850956511, "num_env_steps_trained_throughput_per_sec": 196.4361850956511, "timesteps_total": 428000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 856000, "timers": {"training_iteration_time_ms": 20000.921, "sample_time_ms": 1179.435, "learn_time_ms": 18737.097, "learn_throughput": 213.48, "synch_weights_time_ms": 80.861}, "counters": {"num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_agent_steps_sampled": 856000, "num_agent_steps_trained": 856000}, "done": false, "episodes_total": 2155, "training_iteration": 107, "trial_id": "a9680_00000", "date": "2023-09-24_03-15-54", "timestamp": 1695539754, "time_this_iter_s": 20.373288869857788, "time_total_s": 2134.6064088344574, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dd634f0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1dd51120>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1dd511b0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2134.6064088344574, "iterations_since_restore": 107, "perf": {"cpu_util_percent": 5.365714285714286, "ram_util_percent": 25.48857142857143}, "win_rate": 0.74, "league_size": 76}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.477030970528722, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.06211099363717949, "policy_loss": -0.04600895055239865, "vf_loss": 0.20603758197976277, "vf_explained_var": 0.7893329132969181, "kl": 0.01439240184205725, "entropy": 1.3754271278778711, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 103200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "sampler_results": {"episode_reward_max": 4.494104530589111, "episode_reward_min": -1.2149999999999783, "episode_reward_mean": 2.4902154353498194, "episode_len_mean": 79.82, "episode_media": {}, "episodes_this_iter": 61, "policy_reward_min": {"red_v6": -2.0140000000000002, "red": -1.2699999999999712, "blue": -2.020999999999999, "red_v33": -1.032999999999998, "red_v53": -2.0109999999999992, "red_v62": 1.97571875, "red_v19": -2.01, "red_v71": -2.003, "red_v28": 0.4869346144425924, "red_v49": 0.39428360500000026, "red_v42": -1.0109999999999992, "red_v63": -2.0029999999999997, "red_v58": -2.012999999999999, "red_v50": -0.9530000000000003, "red_v5": -1.007, "red_v13": -2.054999999999996, "red_v25": 0.39428360500000026, "red_v4": -2.005, "red_v51": -2.009, "red_v21": -1.0179999999999996, "red_v57": 0.46069323781616967, "red_v55": -2.0109999999999992, "red_v2": -1.013999999999999, "red_v48": 0.46569323781617056, "red_v34": 0.054999999999999605, "red_v67": -2.025999999999997, "red_v59": -1.0099999999999998, "red_v44": -2.017999999999999, "red_v70": -2.01, "red_v73": -1.001, "red_v29": 0.4476932378161762, "red_v32": -2.009, "red_v35": -2.013, "red_v1": -1.0099999999999996, "red_v39": -0.011000000000000003, "red_v20": 0.4736932378161708, "red_v9": 1.4832343749999999, "red_v47": -1.0239999999999991, "red_v27": -1.0139999999999998, "red_v14": -0.506, "red_v72": -2.0599999999999934, "red_v56": 0.48569323781617024}, "policy_reward_max": {"red_v6": 0.8390000000000001, "red": 3.9936307378152036, "blue": -0.011000000000000003, "red_v33": -1.032999999999998, "red_v53": -2.0109999999999992, "red_v62": 1.97571875, "red_v19": 0.4976932378161706, "red_v71": -2.003, "red_v28": 0.4869346144425924, "red_v49": 0.39428360500000026, "red_v42": 0.4829346144425924, "red_v63": 0.4896932378152038, "red_v58": -1.0089999999999992, "red_v50": 1.5016932378161703, "red_v5": -1.007, "red_v13": -2.054999999999996, "red_v25": 0.847, "red_v4": 1.93478125, "red_v51": 0.4926932378161709, "red_v21": 0.4896932378161709, "red_v57": 0.46069323781616967, "red_v55": -2.0109999999999992, "red_v2": 1.4849346144425921, "red_v48": 0.502692542772942, "red_v34": 0.503692542772942, "red_v67": -2.025999999999997, "red_v59": -1.0099999999999998, "red_v44": -1.0039999999999998, "red_v70": 1.5036925427729417, "red_v73": -1.001, "red_v29": 0.9819346144425923, "red_v32": 1.3912836050000006, "red_v35": 1.959359375, "red_v1": -1.0099999999999996, "red_v39": -0.011000000000000003, "red_v20": 0.4736932378161708, "red_v9": 1.4832343749999999, "red_v47": -1.0239999999999991, "red_v27": -1.0139999999999998, "red_v14": -0.506, "red_v72": -2.0599999999999934, "red_v56": 0.48569323781617024}, "policy_reward_mean": {"red_v6": -0.7263333333333333, "red": 3.1887446403010045, "blue": -1.29185294117647, "red_v33": -1.032999999999998, "red_v53": -2.0109999999999992, "red_v62": 1.97571875, "red_v19": -0.7561533810919145, "red_v71": -2.003, "red_v28": 0.4869346144425924, "red_v49": 0.39428360500000026, "red_v42": -0.26403269277870345, "red_v63": -0.7566533810923979, "red_v58": -1.5109999999999992, "red_v50": 0.13256441260539006, "red_v5": -1.007, "red_v13": -2.054999999999996, "red_v25": 0.5756589476050685, "red_v4": -0.3600729166666666, "red_v51": -0.7581533810919145, "red_v21": -0.4101022540612764, "red_v57": 0.46069323781616967, "red_v55": -2.0109999999999992, "red_v2": 0.2354673072212966, "red_v48": 0.48419289029455626, "red_v34": 0.3514619268630373, "red_v67": -2.025999999999997, "red_v59": -1.0099999999999998, "red_v44": -1.5109999999999992, "red_v70": -0.5104358190756856, "red_v73": -1.001, "red_v29": 0.7148139261293842, "red_v32": -0.2559054649999997, "red_v35": -0.026820312499999943, "red_v1": -1.0099999999999996, "red_v39": -0.011000000000000003, "red_v20": 0.4736932378161708, "red_v9": 1.4832343749999999, "red_v47": -1.0239999999999991, "red_v27": -1.0139999999999998, "red_v14": -0.506, "red_v72": -2.0599999999999934, "red_v56": 0.48569323781617024}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.3654086050000007, 1.97541198781617, 2.4867436585440554, 2.4439744878161713, 1.469302612816171, 1.3318593750000003, 1.31871875, 3.9610114756323407, 1.3783304800000002, 1.968677612816171, 3.787395667772945, 3.9784559772587627, 3.8826210135440555, 2.4717869878161705, 0.8418593750000001, 2.4708651128161705, 0.5386932378161704, 2.4873338628161705, 1.8823338628161754, 2.4856307378161704, 3.9419802256313763, 1.9886307378152035, 2.278646362816179, 1.4820405335440552, 0.28069323781621847, 3.878198975632343, 1.9778963628161703, 2.4559432378161707, 1.490149908544055, 3.974381397986647, 1.4293437500000001, 1.9705994878152042, 1.8740336050000004, 4.470830977258762, 2.47878698781617, 3.996025710545884, 3.9757771006323406, 1.97841198781617, 2.47589636281617, 1.8978338628161724, 1.4720057378161706, 2.475490112815204, 1.9647869878161706, 4.494104530589111, 4.47796460063234, 2.4469119878161703, 1.943130737816172, 2.4786846144425922, 3.3335994878161705, 3.8848042727729415, 4.452987227258763, 2.4810057378152037, 2.4531307378161715, 4.370367467816171, 2.484223792772942, 0.834640625, 1.9546533644425925, 1.9639814894425927, 2.47208386281617, 2.4580596144425924, 2.9637557378161707, 2.9655682378161705, 2.48370886281617, 2.4231776128161706, 3.9459489756323416, 1.4625682378161708, 1.9570526128161712, 3.9407146006323424, 3.9973232805881453, 3.7236677256323487, 2.457755737816171, 1.4711689894425926, 1.4694901128161708, 1.158284375000001, 3.8347088628161705, 2.458896362816171, 2.477743658544055, 1.9652706677729423, 2.850730225632347, 1.4743026128161705, 1.8737367300000005, 2.27953698781618, 2.1566906250000004, 1.9792244878161702, 2.439911987816172, -1.2149999999999783, 3.3377088628161697, 3.942980225631375, 2.484115112815204, 3.9693708506323415, 1.9800057378161706, 1.941474487816171, 2.4777869878161702, 2.9549432378161713, 2.4504588628161708, 2.4728963628161704, 2.4724901128161703, 2.48681823781617, 1.388333862816176, 3.947089600632341], "episode_lengths": [24, 26, 19, 38, 29, 13, 26, 56, 17, 37, 63, 23, 21, 34, 13, 41, 1280, 19, 83, 20, 66, 20, 175, 20, 1280, 124, 31, 48, 17, 18, 18, 30, 16, 31, 34, 19, 35, 26, 31, 115, 28, 33, 34, 26, 39, 58, 52, 16, 30, 23, 45, 28, 52, 35, 22, 19, 26, 17, 35, 24, 44, 40, 27, 69, 76, 40, 45, 55, 20, 294, 44, 21, 33, 21, 27, 31, 19, 39, 146, 29, 15, 178, 19, 22, 58, 1280, 27, 66, 25, 37, 28, 70, 34, 48, 43, 31, 33, 24, 83, 63], "policy_red_v6_reward": [-2.0140000000000002, 0.8390000000000001, -1.0039999999999996], "policy_blue_reward": [-2.009, -1.0059999999999996, -2.0139999999999993, -2.0109999999999992, -1.0079999999999993, -1.0529999999999986, -2.0059999999999993, -1.013999999999999, -2.005, -1.0059999999999996, -2.013, -1.0049999999999994, -2.014999999999999, -1.013999999999999, -2.020999999999999, -1.0049999999999997, -1.007, -2.0039999999999996, -1.0049999999999997, -0.011000000000000003, -1.0049999999999997, -1.0239999999999996, -1.017, -1.0119999999999991, -2.004, -2.008, -2.0119999999999996, -1.0499999999999952, -1.0059999999999998, -0.5039999999999998, -1.0059999999999998, -0.02000000000000001, -1.0109999999999997, -1.0119999999999998], "policy_red_v33_reward": [-1.032999999999998], "policy_red_v53_reward": [-2.0109999999999992], "policy_red_v62_reward": [1.97571875], "policy_red_v19_reward": [0.4976932378161706, -2.01], "policy_red_v71_reward": [-2.003], "policy_red_v28_reward": [0.4869346144425924], "policy_red_v49_reward": [0.39428360500000026], "policy_red_v42_reward": [-1.0109999999999992, 0.4829346144425924], "policy_red_v63_reward": [-2.0029999999999997, 0.4896932378152038], "policy_red_v58_reward": [-1.0089999999999992, -2.012999999999999], "policy_red_v50_reward": [-0.9530000000000003, 1.5016932378161703, -0.1509999999999998], "policy_red_v5_reward": [-1.007], "policy_red_v13_reward": [-2.054999999999996], "policy_red_v25_reward": [0.48569323781520557, 0.39428360500000026, 0.847], "policy_red_v4_reward": [-2.005, -1.0099999999999998, 1.93478125], "policy_red_v51_reward": [-2.009, 0.4926932378161709], "policy_red_v21_reward": [-0.7020000000000004, 0.4896932378161709, -1.0179999999999996], "policy_red_v57_reward": [0.46069323781616967], "policy_red_v55_reward": [-2.0109999999999992], "policy_red_v2_reward": [1.4849346144425921, -1.013999999999999], "policy_red_v48_reward": [0.502692542772942, 0.46569323781617056], "policy_red_v34_reward": [0.4956932378161703, 0.503692542772942, 0.054999999999999605], "policy_red_v67_reward": [-2.025999999999997], "policy_red_v59_reward": [-1.0099999999999998], "policy_red_v44_reward": [-2.017999999999999, -1.0039999999999998], "policy_red_v70_reward": [1.5036925427729417, -2.01, -1.0249999999999988], "policy_red_v73_reward": [-1.001], "policy_red_v29_reward": [0.9819346144425923, 0.4476932378161762], "policy_red_v32_reward": [1.3912836050000006, -2.009, -0.1499999999999999], "policy_red_v35_reward": [-2.013, 1.959359375], "policy_red_v1_reward": [-1.0099999999999996], "policy_red_v39_reward": [-0.011000000000000003], "policy_red_v20_reward": [0.4736932378161708], "policy_red_v9_reward": [1.4832343749999999], "policy_red_v47_reward": [-1.0239999999999991], "policy_red_v27_reward": [-1.0139999999999998], "policy_red_v14_reward": [-0.506], "policy_red_v72_reward": [-2.0599999999999934], "policy_red_v56_reward": [0.48569323781617024]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8177076115422082, "mean_inference_ms": 7.66249081423907, "mean_action_processing_ms": 0.29156681721448235, "mean_env_wait_ms": 0.3887013555548409, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10235035419464111, "StateBufferConnector_ms": 0.004335165023803711, "ViewRequirementAgentConnector_ms": 0.11867737770080566}}, "episode_reward_max": 4.494104530589111, "episode_reward_min": -1.2149999999999783, "episode_reward_mean": 2.4902154353498194, "episode_len_mean": 79.82, "episodes_this_iter": 61, "policy_reward_min": {"red_v6": -2.0140000000000002, "red": -1.2699999999999712, "blue": -2.020999999999999, "red_v33": -1.032999999999998, "red_v53": -2.0109999999999992, "red_v62": 1.97571875, "red_v19": -2.01, "red_v71": -2.003, "red_v28": 0.4869346144425924, "red_v49": 0.39428360500000026, "red_v42": -1.0109999999999992, "red_v63": -2.0029999999999997, "red_v58": -2.012999999999999, "red_v50": -0.9530000000000003, "red_v5": -1.007, "red_v13": -2.054999999999996, "red_v25": 0.39428360500000026, "red_v4": -2.005, "red_v51": -2.009, "red_v21": -1.0179999999999996, "red_v57": 0.46069323781616967, "red_v55": -2.0109999999999992, "red_v2": -1.013999999999999, "red_v48": 0.46569323781617056, "red_v34": 0.054999999999999605, "red_v67": -2.025999999999997, "red_v59": -1.0099999999999998, "red_v44": -2.017999999999999, "red_v70": -2.01, "red_v73": -1.001, "red_v29": 0.4476932378161762, "red_v32": -2.009, "red_v35": -2.013, "red_v1": -1.0099999999999996, "red_v39": -0.011000000000000003, "red_v20": 0.4736932378161708, "red_v9": 1.4832343749999999, "red_v47": -1.0239999999999991, "red_v27": -1.0139999999999998, "red_v14": -0.506, "red_v72": -2.0599999999999934, "red_v56": 0.48569323781617024}, "policy_reward_max": {"red_v6": 0.8390000000000001, "red": 3.9936307378152036, "blue": -0.011000000000000003, "red_v33": -1.032999999999998, "red_v53": -2.0109999999999992, "red_v62": 1.97571875, "red_v19": 0.4976932378161706, "red_v71": -2.003, "red_v28": 0.4869346144425924, "red_v49": 0.39428360500000026, "red_v42": 0.4829346144425924, "red_v63": 0.4896932378152038, "red_v58": -1.0089999999999992, "red_v50": 1.5016932378161703, "red_v5": -1.007, "red_v13": -2.054999999999996, "red_v25": 0.847, "red_v4": 1.93478125, "red_v51": 0.4926932378161709, "red_v21": 0.4896932378161709, "red_v57": 0.46069323781616967, "red_v55": -2.0109999999999992, "red_v2": 1.4849346144425921, "red_v48": 0.502692542772942, "red_v34": 0.503692542772942, "red_v67": -2.025999999999997, "red_v59": -1.0099999999999998, "red_v44": -1.0039999999999998, "red_v70": 1.5036925427729417, "red_v73": -1.001, "red_v29": 0.9819346144425923, "red_v32": 1.3912836050000006, "red_v35": 1.959359375, "red_v1": -1.0099999999999996, "red_v39": -0.011000000000000003, "red_v20": 0.4736932378161708, "red_v9": 1.4832343749999999, "red_v47": -1.0239999999999991, "red_v27": -1.0139999999999998, "red_v14": -0.506, "red_v72": -2.0599999999999934, "red_v56": 0.48569323781617024}, "policy_reward_mean": {"red_v6": -0.7263333333333333, "red": 3.1887446403010045, "blue": -1.29185294117647, "red_v33": -1.032999999999998, "red_v53": -2.0109999999999992, "red_v62": 1.97571875, "red_v19": -0.7561533810919145, "red_v71": -2.003, "red_v28": 0.4869346144425924, "red_v49": 0.39428360500000026, "red_v42": -0.26403269277870345, "red_v63": -0.7566533810923979, "red_v58": -1.5109999999999992, "red_v50": 0.13256441260539006, "red_v5": -1.007, "red_v13": -2.054999999999996, "red_v25": 0.5756589476050685, "red_v4": -0.3600729166666666, "red_v51": -0.7581533810919145, "red_v21": -0.4101022540612764, "red_v57": 0.46069323781616967, "red_v55": -2.0109999999999992, "red_v2": 0.2354673072212966, "red_v48": 0.48419289029455626, "red_v34": 0.3514619268630373, "red_v67": -2.025999999999997, "red_v59": -1.0099999999999998, "red_v44": -1.5109999999999992, "red_v70": -0.5104358190756856, "red_v73": -1.001, "red_v29": 0.7148139261293842, "red_v32": -0.2559054649999997, "red_v35": -0.026820312499999943, "red_v1": -1.0099999999999996, "red_v39": -0.011000000000000003, "red_v20": 0.4736932378161708, "red_v9": 1.4832343749999999, "red_v47": -1.0239999999999991, "red_v27": -1.0139999999999998, "red_v14": -0.506, "red_v72": -2.0599999999999934, "red_v56": 0.48569323781617024}, "hist_stats": {"episode_reward": [1.3654086050000007, 1.97541198781617, 2.4867436585440554, 2.4439744878161713, 1.469302612816171, 1.3318593750000003, 1.31871875, 3.9610114756323407, 1.3783304800000002, 1.968677612816171, 3.787395667772945, 3.9784559772587627, 3.8826210135440555, 2.4717869878161705, 0.8418593750000001, 2.4708651128161705, 0.5386932378161704, 2.4873338628161705, 1.8823338628161754, 2.4856307378161704, 3.9419802256313763, 1.9886307378152035, 2.278646362816179, 1.4820405335440552, 0.28069323781621847, 3.878198975632343, 1.9778963628161703, 2.4559432378161707, 1.490149908544055, 3.974381397986647, 1.4293437500000001, 1.9705994878152042, 1.8740336050000004, 4.470830977258762, 2.47878698781617, 3.996025710545884, 3.9757771006323406, 1.97841198781617, 2.47589636281617, 1.8978338628161724, 1.4720057378161706, 2.475490112815204, 1.9647869878161706, 4.494104530589111, 4.47796460063234, 2.4469119878161703, 1.943130737816172, 2.4786846144425922, 3.3335994878161705, 3.8848042727729415, 4.452987227258763, 2.4810057378152037, 2.4531307378161715, 4.370367467816171, 2.484223792772942, 0.834640625, 1.9546533644425925, 1.9639814894425927, 2.47208386281617, 2.4580596144425924, 2.9637557378161707, 2.9655682378161705, 2.48370886281617, 2.4231776128161706, 3.9459489756323416, 1.4625682378161708, 1.9570526128161712, 3.9407146006323424, 3.9973232805881453, 3.7236677256323487, 2.457755737816171, 1.4711689894425926, 1.4694901128161708, 1.158284375000001, 3.8347088628161705, 2.458896362816171, 2.477743658544055, 1.9652706677729423, 2.850730225632347, 1.4743026128161705, 1.8737367300000005, 2.27953698781618, 2.1566906250000004, 1.9792244878161702, 2.439911987816172, -1.2149999999999783, 3.3377088628161697, 3.942980225631375, 2.484115112815204, 3.9693708506323415, 1.9800057378161706, 1.941474487816171, 2.4777869878161702, 2.9549432378161713, 2.4504588628161708, 2.4728963628161704, 2.4724901128161703, 2.48681823781617, 1.388333862816176, 3.947089600632341], "episode_lengths": [24, 26, 19, 38, 29, 13, 26, 56, 17, 37, 63, 23, 21, 34, 13, 41, 1280, 19, 83, 20, 66, 20, 175, 20, 1280, 124, 31, 48, 17, 18, 18, 30, 16, 31, 34, 19, 35, 26, 31, 115, 28, 33, 34, 26, 39, 58, 52, 16, 30, 23, 45, 28, 52, 35, 22, 19, 26, 17, 35, 24, 44, 40, 27, 69, 76, 40, 45, 55, 20, 294, 44, 21, 33, 21, 27, 31, 19, 39, 146, 29, 15, 178, 19, 22, 58, 1280, 27, 66, 25, 37, 28, 70, 34, 48, 43, 31, 33, 24, 83, 63], "policy_red_v6_reward": [-2.0140000000000002, 0.8390000000000001, -1.0039999999999996], "policy_blue_reward": [-2.009, -1.0059999999999996, -2.0139999999999993, -2.0109999999999992, -1.0079999999999993, -1.0529999999999986, -2.0059999999999993, -1.013999999999999, -2.005, -1.0059999999999996, -2.013, -1.0049999999999994, -2.014999999999999, -1.013999999999999, -2.020999999999999, -1.0049999999999997, -1.007, -2.0039999999999996, -1.0049999999999997, -0.011000000000000003, -1.0049999999999997, -1.0239999999999996, -1.017, -1.0119999999999991, -2.004, -2.008, -2.0119999999999996, -1.0499999999999952, -1.0059999999999998, -0.5039999999999998, -1.0059999999999998, -0.02000000000000001, -1.0109999999999997, -1.0119999999999998], "policy_red_v33_reward": [-1.032999999999998], "policy_red_v53_reward": [-2.0109999999999992], "policy_red_v62_reward": [1.97571875], "policy_red_v19_reward": [0.4976932378161706, -2.01], "policy_red_v71_reward": [-2.003], "policy_red_v28_reward": [0.4869346144425924], "policy_red_v49_reward": [0.39428360500000026], "policy_red_v42_reward": [-1.0109999999999992, 0.4829346144425924], "policy_red_v63_reward": [-2.0029999999999997, 0.4896932378152038], "policy_red_v58_reward": [-1.0089999999999992, -2.012999999999999], "policy_red_v50_reward": [-0.9530000000000003, 1.5016932378161703, -0.1509999999999998], "policy_red_v5_reward": [-1.007], "policy_red_v13_reward": [-2.054999999999996], "policy_red_v25_reward": [0.48569323781520557, 0.39428360500000026, 0.847], "policy_red_v4_reward": [-2.005, -1.0099999999999998, 1.93478125], "policy_red_v51_reward": [-2.009, 0.4926932378161709], "policy_red_v21_reward": [-0.7020000000000004, 0.4896932378161709, -1.0179999999999996], "policy_red_v57_reward": [0.46069323781616967], "policy_red_v55_reward": [-2.0109999999999992], "policy_red_v2_reward": [1.4849346144425921, -1.013999999999999], "policy_red_v48_reward": [0.502692542772942, 0.46569323781617056], "policy_red_v34_reward": [0.4956932378161703, 0.503692542772942, 0.054999999999999605], "policy_red_v67_reward": [-2.025999999999997], "policy_red_v59_reward": [-1.0099999999999998], "policy_red_v44_reward": [-2.017999999999999, -1.0039999999999998], "policy_red_v70_reward": [1.5036925427729417, -2.01, -1.0249999999999988], "policy_red_v73_reward": [-1.001], "policy_red_v29_reward": [0.9819346144425923, 0.4476932378161762], "policy_red_v32_reward": [1.3912836050000006, -2.009, -0.1499999999999999], "policy_red_v35_reward": [-2.013, 1.959359375], "policy_red_v1_reward": [-1.0099999999999996], "policy_red_v39_reward": [-0.011000000000000003], "policy_red_v20_reward": [0.4736932378161708], "policy_red_v9_reward": [1.4832343749999999], "policy_red_v47_reward": [-1.0239999999999991], "policy_red_v27_reward": [-1.0139999999999998], "policy_red_v14_reward": [-0.506], "policy_red_v72_reward": [-2.0599999999999934], "policy_red_v56_reward": [0.48569323781617024]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8177076115422082, "mean_inference_ms": 7.66249081423907, "mean_action_processing_ms": 0.29156681721448235, "mean_env_wait_ms": 0.3887013555548409, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10235035419464111, "StateBufferConnector_ms": 0.004335165023803711, "ViewRequirementAgentConnector_ms": 0.11867737770080566}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.07914296138094, "num_env_steps_trained_throughput_per_sec": 199.07914296138094, "timesteps_total": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 19995.752, "sample_time_ms": 1175.279, "learn_time_ms": 18735.623, "learn_throughput": 213.497, "synch_weights_time_ms": 81.27}, "counters": {"num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "episodes_total": 2216, "training_iteration": 108, "trial_id": "a9680_00000", "date": "2023-09-24_03-16-18", "timestamp": 1695539778, "time_this_iter_s": 20.10527515411377, "time_total_s": 2154.711683988571, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dee57b0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1dd50d30>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1dd50af0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2154.711683988571, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 6.0470588235294125, "ram_util_percent": 25.66764705882353}, "win_rate": 0.71, "league_size": 77}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0403245466450852, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.013497644116190107, "policy_loss": -0.047644176096461405, "vf_loss": 0.10904574920035277, "vf_explained_var": 0.8740324834982555, "kl": 0.017582199272616585, "entropy": 1.2930438789228598, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 104160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_agent_steps_sampled": 872000, "num_agent_steps_trained": 872000}, "sampler_results": {"episode_reward_max": 4.4895150213602255, "episode_reward_min": -4.104104332227031, "episode_reward_mean": 2.4428948427596966, "episode_len_mean": 67.44, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"blue": -2.0169999999999995, "red": -6.8301043322270765, "red_v32": -2.009, "red_v35": -2.013, "red_v1": -1.0099999999999996, "red_v39": -1.0199999999999985, "red_v51": 0.4926932378161709, "red_v20": 0.4736932378161708, "red_v34": 0.054999999999999605, "red_v48": 0.46569323781617056, "red_v70": -2.01, "red_v9": 1.4832343749999999, "red_v25": 0.847, "red_v47": -1.0239999999999991, "red_v27": -1.0139999999999998, "red_v14": -0.506, "red_v29": -1.505, "red_v58": -2.012999999999999, "red_v63": -2.025999999999999, "red_v6": -1.0039999999999996, "red_v21": -1.0179999999999996, "red_v4": 1.93478125, "red_v44": -1.0039999999999998, "red_v72": -2.0599999999999934, "red_v56": 0.48569323781617024, "red_v5": -1.0069999999999997, "red_v11": -0.5099999999999999, "red_v12": 0.49469323781617014, "red_v41": 1.5021030335440553, "red_v3": -2.002, "red_v45": -1.007, "red_v60": 0.36828360500000024, "red_v17": -1.005, "red_v13": -2.005, "red_v61": -1.5069999999999997, "red_v55": -0.007, "red_v23": 0.836, "red_v59": -1.004, "red_v53": 0.48193461444259245, "red_v52": 0.48969323781617113}, "policy_reward_max": {"blue": 2.72600000000002, "red": 3.993743658544055, "red_v32": -0.1499999999999999, "red_v35": 1.959359375, "red_v1": -1.0099999999999996, "red_v39": -0.011000000000000003, "red_v51": 0.4926932378161709, "red_v20": 0.4736932378161708, "red_v34": 0.503692542772942, "red_v48": 1.4966932378161701, "red_v70": -1.0249999999999988, "red_v9": 1.4832343749999999, "red_v25": 0.847, "red_v47": 0.49469323781617125, "red_v27": 0.4899346144425925, "red_v14": -0.506, "red_v29": 0.4476932378161762, "red_v58": -1.005, "red_v63": 0.5021030335440553, "red_v6": -1.0039999999999996, "red_v21": 0.4896932378161709, "red_v4": 1.93478125, "red_v44": -0.5330653855574066, "red_v72": -2.0599999999999934, "red_v56": 0.48569323781617024, "red_v5": -1.0069999999999997, "red_v11": -0.5099999999999999, "red_v12": 0.49469323781617014, "red_v41": 1.5021030335440553, "red_v3": -2.002, "red_v45": 0.39028360500000026, "red_v60": 0.36828360500000024, "red_v17": -1.005, "red_v13": 0.38128360500000025, "red_v61": -1.5069999999999997, "red_v55": -0.007, "red_v23": 0.836, "red_v59": -1.004, "red_v53": 0.48193461444259245, "red_v52": 0.48969323781617113}, "policy_reward_mean": {"blue": -1.1953999999999991, "red": 3.1419293039180376, "red_v32": -1.0795, "red_v35": -0.026820312499999943, "red_v1": -1.0099999999999996, "red_v39": -0.5154999999999992, "red_v51": 0.4926932378161709, "red_v20": 0.4736932378161708, "red_v34": 0.2793462713864708, "red_v48": 0.9811932378161703, "red_v70": -1.5174999999999992, "red_v9": 1.4832343749999999, "red_v25": 0.847, "red_v47": -0.26465338109191394, "red_v27": -0.26203269277870367, "red_v14": -0.506, "red_v29": -0.5286533810919118, "red_v58": -1.5089999999999995, "red_v63": -0.3447345762135799, "red_v6": -1.0039999999999996, "red_v21": -0.26415338109191433, "red_v4": 1.93478125, "red_v44": -0.7685326927787032, "red_v72": -2.0599999999999934, "red_v56": 0.48569323781617024, "red_v5": -1.0069999999999997, "red_v11": -0.5099999999999999, "red_v12": 0.49469323781617014, "red_v41": 1.5021030335440553, "red_v3": -2.002, "red_v45": -0.2562387983333332, "red_v60": 0.36828360500000024, "red_v17": -1.005, "red_v13": -0.8118581974999999, "red_v61": -1.5069999999999997, "red_v55": -0.007, "red_v23": 0.836, "red_v59": -1.004, "red_v53": 0.48193461444259245, "red_v52": 0.48969323781617113}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.484223792772942, 0.834640625, 1.9546533644425925, 1.9639814894425927, 2.47208386281617, 2.4580596144425924, 2.9637557378161707, 2.9655682378161705, 2.48370886281617, 2.4231776128161706, 3.9459489756323416, 1.4625682378161708, 1.9570526128161712, 3.9407146006323424, 3.9973232805881453, 3.7236677256323487, 2.457755737816171, 1.4711689894425926, 1.4694901128161708, 1.158284375000001, 3.8347088628161705, 2.458896362816171, 2.477743658544055, 1.9652706677729423, 2.850730225632347, 1.4743026128161705, 1.8737367300000005, 2.27953698781618, 2.1566906250000004, 1.9792244878161702, 2.439911987816172, -1.2149999999999783, 3.3377088628161697, 3.942980225631375, 2.484115112815204, 3.9693708506323415, 1.9800057378161706, 1.941474487816171, 2.4777869878161702, 2.9549432378161713, 2.4504588628161708, 2.4728963628161704, 2.4724901128161703, 2.48681823781617, 1.388333862816176, 3.947089600632341, 2.479009283544055, 2.4630526128161705, 2.4795994878161705, 4.4504646006323405, 2.969568237816171, 1.38713073781617, 2.921802612816172, 3.9662302256323407, 4.4895150213602255, 1.4720838628161705, 1.4445057378161714, 3.983381397986647, 2.4546151128161706, 1.97970886281617, 2.426552612816171, 1.9917436585440549, 2.4636533644425924, 3.876804272772942, 3.954198975632342, 2.4728651128161703, 3.842226842816172, -4.104104332227031, 2.4925561585440548, 0.42634375, 1.8349375, 1.9814119878161705, 0.8763304800000002, 2.292896362816179, 1.9530838628161709, 1.9716846144425924, 2.9778963628161703, 2.907080977258766, 2.4804119878161703, 3.8068651128152053, 2.4723807378161706, 1.9785249085440548, 2.48189636281617, 2.4685752394425924, 2.4793026128161704, 1.4773026128161701, 3.9700497272587625, 1.9487557378161717, 2.432880737816172, 1.9832237927729421, 3.32727136281617, 3.858148717816171, 1.98611511281617, 3.9436521006323413, 3.9823743963602247, 2.451615112816171, 2.4254432378161725, 0.9618338628161699, 1.9561619878152046, 2.367814855], "episode_lengths": [22, 19, 26, 17, 35, 24, 44, 40, 27, 69, 76, 40, 45, 55, 20, 294, 44, 21, 33, 21, 27, 31, 19, 39, 146, 29, 15, 178, 19, 22, 58, 1280, 27, 66, 25, 37, 28, 70, 34, 48, 43, 31, 33, 24, 83, 63, 30, 45, 30, 71, 40, 116, 61, 50, 26, 35, 60, 18, 57, 27, 77, 19, 26, 23, 60, 41, 48, 1055, 15, 18, 20, 26, 17, 159, 35, 16, 31, 79, 26, 41, 36, 25, 31, 19, 29, 29, 25, 44, 68, 22, 39, 41, 25, 75, 39, 57, 80, 51, 42, 22], "policy_blue_reward": [-1.007, -2.0039999999999996, -1.0049999999999997, -0.011000000000000003, -1.0049999999999997, -1.0239999999999996, -1.017, -1.0119999999999991, -2.004, -2.008, -2.0119999999999996, -1.0499999999999952, -1.0059999999999998, -0.5039999999999998, -1.0059999999999998, -0.02000000000000001, -1.0109999999999997, -1.0119999999999998, -1.0069999999999992, -1.0079999999999993, -1.5319999999999998, -0.01900000000000001, -2.0079999999999996, -2.0119999999999996, -1.010999999999999, -2.006, -1.0209999999999988, -1.0069999999999997, 2.72600000000002, -1.002, -2.0069999999999997, -1.038999999999997, -2.0049999999999994, -1.0069999999999997, -1.0069999999999997, -2.009, -1.0069999999999997, -2.007999999999999, -2.0169999999999995, -2.008, -2.0039999999999996, -1.0119999999999993, -1.0229999999999977, -2.0109999999999997, -1.0039999999999998], "policy_red_v32_reward": [-2.009, -0.1499999999999999], "policy_red_v35_reward": [-2.013, 1.959359375], "policy_red_v1_reward": [-1.0099999999999996], "policy_red_v39_reward": [-0.011000000000000003, -1.0199999999999985], "policy_red_v51_reward": [0.4926932378161709], "policy_red_v20_reward": [0.4736932378161708], "policy_red_v34_reward": [0.503692542772942, 0.054999999999999605], "policy_red_v48_reward": [0.46569323781617056, 1.4966932378161701], "policy_red_v70_reward": [-2.01, -1.0249999999999988], "policy_red_v9_reward": [1.4832343749999999], "policy_red_v25_reward": [0.847], "policy_red_v47_reward": [-1.0239999999999991, 0.49469323781617125], "policy_red_v27_reward": [-1.0139999999999998, 0.4899346144425925], "policy_red_v14_reward": [-0.506], "policy_red_v29_reward": [0.4476932378161762, -1.505], "policy_red_v58_reward": [-2.012999999999999, -1.005], "policy_red_v63_reward": [0.4896932378152038, -2.025999999999999, 0.5021030335440553], "policy_red_v6_reward": [-1.0039999999999996], "policy_red_v21_reward": [0.4896932378161709, -1.0179999999999996], "policy_red_v4_reward": [1.93478125], "policy_red_v44_reward": [-1.0039999999999998, -0.5330653855574066], "policy_red_v72_reward": [-2.0599999999999934], "policy_red_v56_reward": [0.48569323781617024], "policy_red_v5_reward": [-1.0069999999999997], "policy_red_v11_reward": [-0.5099999999999999], "policy_red_v12_reward": [0.49469323781617014], "policy_red_v41_reward": [1.5021030335440553], "policy_red_v3_reward": [-2.002], "policy_red_v45_reward": [0.39028360500000026, -1.007, -0.1519999999999999], "policy_red_v60_reward": [0.36828360500000024], "policy_red_v17_reward": [-1.005], "policy_red_v13_reward": [-2.005, 0.38128360500000025], "policy_red_v61_reward": [-1.5069999999999997], "policy_red_v55_reward": [-0.007], "policy_red_v23_reward": [0.836], "policy_red_v59_reward": [-1.004], "policy_red_v53_reward": [0.48193461444259245], "policy_red_v52_reward": [0.48969323781617113]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8196905922149544, "mean_inference_ms": 7.672190027200711, "mean_action_processing_ms": 0.29262797275066427, "mean_env_wait_ms": 0.3902456661453704, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10213851928710938, "StateBufferConnector_ms": 0.0043849945068359375, "ViewRequirementAgentConnector_ms": 0.11937332153320312}}, "episode_reward_max": 4.4895150213602255, "episode_reward_min": -4.104104332227031, "episode_reward_mean": 2.4428948427596966, "episode_len_mean": 67.44, "episodes_this_iter": 54, "policy_reward_min": {"blue": -2.0169999999999995, "red": -6.8301043322270765, "red_v32": -2.009, "red_v35": -2.013, "red_v1": -1.0099999999999996, "red_v39": -1.0199999999999985, "red_v51": 0.4926932378161709, "red_v20": 0.4736932378161708, "red_v34": 0.054999999999999605, "red_v48": 0.46569323781617056, "red_v70": -2.01, "red_v9": 1.4832343749999999, "red_v25": 0.847, "red_v47": -1.0239999999999991, "red_v27": -1.0139999999999998, "red_v14": -0.506, "red_v29": -1.505, "red_v58": -2.012999999999999, "red_v63": -2.025999999999999, "red_v6": -1.0039999999999996, "red_v21": -1.0179999999999996, "red_v4": 1.93478125, "red_v44": -1.0039999999999998, "red_v72": -2.0599999999999934, "red_v56": 0.48569323781617024, "red_v5": -1.0069999999999997, "red_v11": -0.5099999999999999, "red_v12": 0.49469323781617014, "red_v41": 1.5021030335440553, "red_v3": -2.002, "red_v45": -1.007, "red_v60": 0.36828360500000024, "red_v17": -1.005, "red_v13": -2.005, "red_v61": -1.5069999999999997, "red_v55": -0.007, "red_v23": 0.836, "red_v59": -1.004, "red_v53": 0.48193461444259245, "red_v52": 0.48969323781617113}, "policy_reward_max": {"blue": 2.72600000000002, "red": 3.993743658544055, "red_v32": -0.1499999999999999, "red_v35": 1.959359375, "red_v1": -1.0099999999999996, "red_v39": -0.011000000000000003, "red_v51": 0.4926932378161709, "red_v20": 0.4736932378161708, "red_v34": 0.503692542772942, "red_v48": 1.4966932378161701, "red_v70": -1.0249999999999988, "red_v9": 1.4832343749999999, "red_v25": 0.847, "red_v47": 0.49469323781617125, "red_v27": 0.4899346144425925, "red_v14": -0.506, "red_v29": 0.4476932378161762, "red_v58": -1.005, "red_v63": 0.5021030335440553, "red_v6": -1.0039999999999996, "red_v21": 0.4896932378161709, "red_v4": 1.93478125, "red_v44": -0.5330653855574066, "red_v72": -2.0599999999999934, "red_v56": 0.48569323781617024, "red_v5": -1.0069999999999997, "red_v11": -0.5099999999999999, "red_v12": 0.49469323781617014, "red_v41": 1.5021030335440553, "red_v3": -2.002, "red_v45": 0.39028360500000026, "red_v60": 0.36828360500000024, "red_v17": -1.005, "red_v13": 0.38128360500000025, "red_v61": -1.5069999999999997, "red_v55": -0.007, "red_v23": 0.836, "red_v59": -1.004, "red_v53": 0.48193461444259245, "red_v52": 0.48969323781617113}, "policy_reward_mean": {"blue": -1.1953999999999991, "red": 3.1419293039180376, "red_v32": -1.0795, "red_v35": -0.026820312499999943, "red_v1": -1.0099999999999996, "red_v39": -0.5154999999999992, "red_v51": 0.4926932378161709, "red_v20": 0.4736932378161708, "red_v34": 0.2793462713864708, "red_v48": 0.9811932378161703, "red_v70": -1.5174999999999992, "red_v9": 1.4832343749999999, "red_v25": 0.847, "red_v47": -0.26465338109191394, "red_v27": -0.26203269277870367, "red_v14": -0.506, "red_v29": -0.5286533810919118, "red_v58": -1.5089999999999995, "red_v63": -0.3447345762135799, "red_v6": -1.0039999999999996, "red_v21": -0.26415338109191433, "red_v4": 1.93478125, "red_v44": -0.7685326927787032, "red_v72": -2.0599999999999934, "red_v56": 0.48569323781617024, "red_v5": -1.0069999999999997, "red_v11": -0.5099999999999999, "red_v12": 0.49469323781617014, "red_v41": 1.5021030335440553, "red_v3": -2.002, "red_v45": -0.2562387983333332, "red_v60": 0.36828360500000024, "red_v17": -1.005, "red_v13": -0.8118581974999999, "red_v61": -1.5069999999999997, "red_v55": -0.007, "red_v23": 0.836, "red_v59": -1.004, "red_v53": 0.48193461444259245, "red_v52": 0.48969323781617113}, "hist_stats": {"episode_reward": [2.484223792772942, 0.834640625, 1.9546533644425925, 1.9639814894425927, 2.47208386281617, 2.4580596144425924, 2.9637557378161707, 2.9655682378161705, 2.48370886281617, 2.4231776128161706, 3.9459489756323416, 1.4625682378161708, 1.9570526128161712, 3.9407146006323424, 3.9973232805881453, 3.7236677256323487, 2.457755737816171, 1.4711689894425926, 1.4694901128161708, 1.158284375000001, 3.8347088628161705, 2.458896362816171, 2.477743658544055, 1.9652706677729423, 2.850730225632347, 1.4743026128161705, 1.8737367300000005, 2.27953698781618, 2.1566906250000004, 1.9792244878161702, 2.439911987816172, -1.2149999999999783, 3.3377088628161697, 3.942980225631375, 2.484115112815204, 3.9693708506323415, 1.9800057378161706, 1.941474487816171, 2.4777869878161702, 2.9549432378161713, 2.4504588628161708, 2.4728963628161704, 2.4724901128161703, 2.48681823781617, 1.388333862816176, 3.947089600632341, 2.479009283544055, 2.4630526128161705, 2.4795994878161705, 4.4504646006323405, 2.969568237816171, 1.38713073781617, 2.921802612816172, 3.9662302256323407, 4.4895150213602255, 1.4720838628161705, 1.4445057378161714, 3.983381397986647, 2.4546151128161706, 1.97970886281617, 2.426552612816171, 1.9917436585440549, 2.4636533644425924, 3.876804272772942, 3.954198975632342, 2.4728651128161703, 3.842226842816172, -4.104104332227031, 2.4925561585440548, 0.42634375, 1.8349375, 1.9814119878161705, 0.8763304800000002, 2.292896362816179, 1.9530838628161709, 1.9716846144425924, 2.9778963628161703, 2.907080977258766, 2.4804119878161703, 3.8068651128152053, 2.4723807378161706, 1.9785249085440548, 2.48189636281617, 2.4685752394425924, 2.4793026128161704, 1.4773026128161701, 3.9700497272587625, 1.9487557378161717, 2.432880737816172, 1.9832237927729421, 3.32727136281617, 3.858148717816171, 1.98611511281617, 3.9436521006323413, 3.9823743963602247, 2.451615112816171, 2.4254432378161725, 0.9618338628161699, 1.9561619878152046, 2.367814855], "episode_lengths": [22, 19, 26, 17, 35, 24, 44, 40, 27, 69, 76, 40, 45, 55, 20, 294, 44, 21, 33, 21, 27, 31, 19, 39, 146, 29, 15, 178, 19, 22, 58, 1280, 27, 66, 25, 37, 28, 70, 34, 48, 43, 31, 33, 24, 83, 63, 30, 45, 30, 71, 40, 116, 61, 50, 26, 35, 60, 18, 57, 27, 77, 19, 26, 23, 60, 41, 48, 1055, 15, 18, 20, 26, 17, 159, 35, 16, 31, 79, 26, 41, 36, 25, 31, 19, 29, 29, 25, 44, 68, 22, 39, 41, 25, 75, 39, 57, 80, 51, 42, 22], "policy_blue_reward": [-1.007, -2.0039999999999996, -1.0049999999999997, -0.011000000000000003, -1.0049999999999997, -1.0239999999999996, -1.017, -1.0119999999999991, -2.004, -2.008, -2.0119999999999996, -1.0499999999999952, -1.0059999999999998, -0.5039999999999998, -1.0059999999999998, -0.02000000000000001, -1.0109999999999997, -1.0119999999999998, -1.0069999999999992, -1.0079999999999993, -1.5319999999999998, -0.01900000000000001, -2.0079999999999996, -2.0119999999999996, -1.010999999999999, -2.006, -1.0209999999999988, -1.0069999999999997, 2.72600000000002, -1.002, -2.0069999999999997, -1.038999999999997, -2.0049999999999994, -1.0069999999999997, -1.0069999999999997, -2.009, -1.0069999999999997, -2.007999999999999, -2.0169999999999995, -2.008, -2.0039999999999996, -1.0119999999999993, -1.0229999999999977, -2.0109999999999997, -1.0039999999999998], "policy_red_v32_reward": [-2.009, -0.1499999999999999], "policy_red_v35_reward": [-2.013, 1.959359375], "policy_red_v1_reward": [-1.0099999999999996], "policy_red_v39_reward": [-0.011000000000000003, -1.0199999999999985], "policy_red_v51_reward": [0.4926932378161709], "policy_red_v20_reward": [0.4736932378161708], "policy_red_v34_reward": [0.503692542772942, 0.054999999999999605], "policy_red_v48_reward": [0.46569323781617056, 1.4966932378161701], "policy_red_v70_reward": [-2.01, -1.0249999999999988], "policy_red_v9_reward": [1.4832343749999999], "policy_red_v25_reward": [0.847], "policy_red_v47_reward": [-1.0239999999999991, 0.49469323781617125], "policy_red_v27_reward": [-1.0139999999999998, 0.4899346144425925], "policy_red_v14_reward": [-0.506], "policy_red_v29_reward": [0.4476932378161762, -1.505], "policy_red_v58_reward": [-2.012999999999999, -1.005], "policy_red_v63_reward": [0.4896932378152038, -2.025999999999999, 0.5021030335440553], "policy_red_v6_reward": [-1.0039999999999996], "policy_red_v21_reward": [0.4896932378161709, -1.0179999999999996], "policy_red_v4_reward": [1.93478125], "policy_red_v44_reward": [-1.0039999999999998, -0.5330653855574066], "policy_red_v72_reward": [-2.0599999999999934], "policy_red_v56_reward": [0.48569323781617024], "policy_red_v5_reward": [-1.0069999999999997], "policy_red_v11_reward": [-0.5099999999999999], "policy_red_v12_reward": [0.49469323781617014], "policy_red_v41_reward": [1.5021030335440553], "policy_red_v3_reward": [-2.002], "policy_red_v45_reward": [0.39028360500000026, -1.007, -0.1519999999999999], "policy_red_v60_reward": [0.36828360500000024], "policy_red_v17_reward": [-1.005], "policy_red_v13_reward": [-2.005, 0.38128360500000025], "policy_red_v61_reward": [-1.5069999999999997], "policy_red_v55_reward": [-0.007], "policy_red_v23_reward": [0.836], "policy_red_v59_reward": [-1.004], "policy_red_v53_reward": [0.48193461444259245], "policy_red_v52_reward": [0.48969323781617113]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8196905922149544, "mean_inference_ms": 7.672190027200711, "mean_action_processing_ms": 0.29262797275066427, "mean_env_wait_ms": 0.3902456661453704, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10213851928710938, "StateBufferConnector_ms": 0.0043849945068359375, "ViewRequirementAgentConnector_ms": 0.11937332153320312}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 872000, "num_agent_steps_trained": 872000, "num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.85852957215945, "num_env_steps_trained_throughput_per_sec": 199.85852957215945, "timesteps_total": 436000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 872000, "timers": {"training_iteration_time_ms": 20051.19, "sample_time_ms": 1177.096, "learn_time_ms": 18790.321, "learn_throughput": 212.876, "synch_weights_time_ms": 80.116}, "counters": {"num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_agent_steps_sampled": 872000, "num_agent_steps_trained": 872000}, "done": false, "episodes_total": 2270, "training_iteration": 109, "trial_id": "a9680_00000", "date": "2023-09-24_03-16-43", "timestamp": 1695539803, "time_this_iter_s": 20.024780750274658, "time_total_s": 2174.736464738846, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dd62e00>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1de40a60>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1de42b00>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2174.736464738846, "iterations_since_restore": 109, "perf": {"cpu_util_percent": 5.391176470588235, "ram_util_percent": 25.773529411764706}, "win_rate": 0.74, "league_size": 78}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.253574193641543, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.04030087481078226, "policy_loss": -0.0353325692883421, "vf_loss": 0.1398380779273187, "vf_explained_var": 0.8593590270106991, "kl": 0.015672583102449757, "entropy": 1.3382566440850496, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 105120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "sampler_results": {"episode_reward_max": 4.49110522563234, "episode_reward_min": -4.104104332227031, "episode_reward_mean": 2.351207176912714, "episode_len_mean": 69.47, "episode_media": {}, "episodes_this_iter": 61, "policy_reward_min": {"red_v3": -2.002, "red": -6.8301043322270765, "blue": -2.0169999999999995, "red_v45": -1.007, "red_v47": 0.49469323781617125, "red_v60": 0.36828360500000024, "red_v17": -1.005, "red_v13": -2.005, "red_v61": -1.5069999999999997, "red_v63": -2.025999999999999, "red_v55": -2.0089999999999995, "red_v44": -0.5330653855574066, "red_v23": 0.836, "red_v59": -2.0329999999999995, "red_v58": -1.005, "red_v53": 0.48193461444259245, "red_v39": -1.0199999999999985, "red_v52": -0.5273067621838291, "red_v29": -1.505, "red_v33": -0.048000000000000036, "red_v41": 1.49169323781617, "red_v57": 0.9556932378152037, "red_v65": -1.5359999999999991, "red_v28": -1.9890000000000003, "red_v35": -1.0039999999999998, "red_v30": -2.14599999999999, "red_v40": 1.8571776128161743, "red_v49": 1.4779346144425922, "red_v48": -1.0059999999999998, "red_v20": -2.0079999999999996, "red_v32": 0.4876932378161709, "red_v8": -2.0189999999999984, "red_v38": -1.0019999999999998, "red_v12": -1.024999999999999, "red_v18": -1.0229999999999997, "red_v36": -2.023999999999999}, "policy_reward_max": {"red_v3": -2.002, "red": 3.993743658544055, "blue": 2.72600000000002, "red_v45": 0.39028360500000026, "red_v47": 0.49469323781617125, "red_v60": 0.36828360500000024, "red_v17": 1.604050000000002, "red_v13": 0.38128360500000025, "red_v61": -1.5069999999999997, "red_v63": 0.5021030335440553, "red_v55": 0.15805000000000102, "red_v44": 0.4986932378161699, "red_v23": 0.836, "red_v59": -1.004, "red_v58": -1.005, "red_v53": 0.48193461444259245, "red_v39": -1.0199999999999985, "red_v52": 0.48969323781617113, "red_v29": 1.5026932378161701, "red_v33": -0.048000000000000036, "red_v41": 1.49169323781617, "red_v57": 0.9556932378152037, "red_v65": -1.5359999999999991, "red_v28": -1.9890000000000003, "red_v35": -1.0039999999999998, "red_v30": 0.5046932378161698, "red_v40": 1.8571776128161743, "red_v49": 1.4779346144425922, "red_v48": -1.0059999999999998, "red_v20": -2.0079999999999996, "red_v32": 0.4876932378161709, "red_v8": -2.0189999999999984, "red_v38": -1.0019999999999998, "red_v12": 0.17205000000000015, "red_v18": -1.0229999999999997, "red_v36": -2.023999999999999}, "policy_reward_mean": {"red_v3": -2.002, "red": 3.2372568776623867, "blue": -1.3218453776041659, "red_v45": -0.1929290987499999, "red_v47": 0.49469323781617125, "red_v60": 0.36828360500000024, "red_v17": 0.29952500000000104, "red_v13": -0.8118581974999999, "red_v61": -1.5069999999999997, "red_v63": -1.176632322151981, "red_v55": -0.6193166666666662, "red_v44": -0.017186073870618324, "red_v23": 0.836, "red_v59": -1.5184999999999997, "red_v58": -1.005, "red_v53": 0.48193461444259245, "red_v39": -1.0199999999999985, "red_v52": -0.018806762183828984, "red_v29": 0.13165894760539013, "red_v33": -0.048000000000000036, "red_v41": 1.49169323781617, "red_v57": 0.9556932378152037, "red_v65": -1.5359999999999991, "red_v28": -1.9890000000000003, "red_v35": -1.0039999999999998, "red_v30": -0.8206533810919101, "red_v40": 1.8571776128161743, "red_v49": 1.4779346144425922, "red_v48": -1.0059999999999998, "red_v20": -2.0079999999999996, "red_v32": 0.4876932378161709, "red_v8": -2.0189999999999984, "red_v38": -1.0019999999999998, "red_v12": -0.7187374999999996, "red_v18": -1.0229999999999997, "red_v36": -2.023999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.9917436585440549, 2.4636533644425924, 3.876804272772942, 3.954198975632342, 2.4728651128161703, 3.842226842816172, -4.104104332227031, 2.4925561585440548, 0.42634375, 1.8349375, 1.9814119878161705, 0.8763304800000002, 2.292896362816179, 1.9530838628161709, 1.9716846144425924, 2.9778963628161703, 2.907080977258766, 2.4804119878161703, 3.8068651128152053, 2.4723807378161706, 1.9785249085440548, 2.48189636281617, 2.4685752394425924, 2.4793026128161704, 1.4773026128161701, 3.9700497272587625, 1.9487557378161717, 2.432880737816172, 1.9832237927729421, 3.32727136281617, 3.858148717816171, 1.98611511281617, 3.9436521006323413, 3.9823743963602247, 2.451615112816171, 2.4254432378161725, 0.9618338628161699, 1.9561619878152046, 2.367814855, 0.7701151128161916, 2.855208862816175, 4.451980225632342, 4.169495850631381, 2.455240112816171, 0.912177612816171, 2.8334646006323494, 1.9550994878161707, 1.4200994878161728, 1.9874467835440548, 1.4839276128152037, 0.551474487816172, 3.9556833506323406, 2.4636463628161707, 2.477899908544055, 2.485708862815204, 1.4404744878161715, 3.89161746781617, 1.83875, 2.3668148550000003, 3.621477612816174, 2.469271362816171, 4.49110522563234, 1.4874467835440552, 1.7291307378161804, 2.48892761281617, 0.9354744878161704, 2.349870850632347, 1.1623937500000006, 1.9828182378161705, 4.4561278522587635, 0.9628651128161702, 2.47749011281617, 1.98252136281617, 1.4658651128161706, 3.9906989756323403, 3.9407614756323417, 2.488630737815204, 1.9623494878161705, 1.9498338628161715, 2.98611511281617, 2.9790057378161707, 1.493259283544055, 2.492739417772942, 2.4219658644425937, 2.4698963628161703, 2.48122448781617, 1.4665682378161708, 2.459974487816171, 2.4440526128161717, 1.9658651128161706, 2.3437523550000012, 2.47811511281617, 1.4710838628161707, 2.0987432378161746, 2.4751151128161704, 2.4453182378161715, 1.9441307378161712, 3.6473213628161707, 2.4581307378161705, 1.4847436585440552], "episode_lengths": [19, 26, 23, 60, 41, 48, 1055, 15, 18, 20, 26, 17, 159, 35, 16, 31, 79, 26, 41, 36, 25, 31, 19, 29, 29, 25, 44, 68, 22, 39, 41, 25, 75, 39, 57, 80, 51, 42, 22, 729, 123, 66, 381, 49, 69, 135, 62, 62, 18, 21, 646, 65, 47, 33, 27, 70, 19, 16, 22, 53, 39, 26, 18, 180, 21, 70, 133, 18, 24, 32, 41, 33, 23, 41, 28, 72, 20, 46, 51, 25, 28, 14, 17, 54, 31, 22, 40, 38, 45, 41, 42, 25, 35, 64, 25, 56, 52, 39, 52, 19], "policy_red_v3_reward": [-2.002], "policy_blue_reward": [-1.0069999999999997, 2.72600000000002, -1.002, -2.0069999999999997, -1.038999999999997, -2.0049999999999994, -1.0069999999999997, -1.0069999999999997, -2.009, -1.0069999999999997, -2.007999999999999, -2.0169999999999995, -2.008, -2.0039999999999996, -1.0119999999999993, -1.0229999999999977, -2.0109999999999997, -1.0039999999999998, 0.2654218749999997, -1.0129999999999992, -2.005, -2.0060000000000002, -1.009999999999999, -1.0029999999999997, -2.015999999999999, -1.002, -1.005, -1.0079999999999998, -2.0069999999999997, -1.0049999999999997, -1.5219999999999998, -2.0069999999999997, -2.0059999999999993, -1.513, -2.01, -1.005, -2.01, -0.009000000000000001, -2.005, -1.015999999999999, -1.0099999999999996, -2.0099999999999993, -1.0119999999999996, -1.0079999999999998, -2.01, -1.0129999999999995, -1.0109999999999992, -2.006], "policy_red_v45_reward": [0.39028360500000026, -1.007, -0.1519999999999999, -0.003], "policy_red_v47_reward": [0.49469323781617125], "policy_red_v60_reward": [0.36828360500000024], "policy_red_v17_reward": [-1.005, 1.604050000000002], "policy_red_v13_reward": [-2.005, 0.38128360500000025], "policy_red_v61_reward": [-1.5069999999999997], "policy_red_v63_reward": [-2.025999999999999, 0.5021030335440553, -2.0059999999999993], "policy_red_v55_reward": [-0.007, -2.0089999999999995, 0.15805000000000102], "policy_red_v44_reward": [-0.5330653855574066, 0.4986932378161699], "policy_red_v23_reward": [0.836], "policy_red_v59_reward": [-1.004, -2.0329999999999995], "policy_red_v58_reward": [-1.005], "policy_red_v53_reward": [0.48193461444259245], "policy_red_v39_reward": [-1.0199999999999985], "policy_red_v52_reward": [0.48969323781617113, -0.5273067621838291], "policy_red_v29_reward": [-1.505, 0.39728360500000015, 1.5026932378161701], "policy_red_v33_reward": [-0.048000000000000036], "policy_red_v41_reward": [1.49169323781617], "policy_red_v57_reward": [0.9556932378152037], "policy_red_v65_reward": [-1.5359999999999991], "policy_red_v28_reward": [-1.9890000000000003], "policy_red_v35_reward": [-1.0039999999999998], "policy_red_v30_reward": [-2.14599999999999, 0.5046932378161698], "policy_red_v40_reward": [1.8571776128161743], "policy_red_v49_reward": [1.4779346144425922], "policy_red_v48_reward": [-1.0059999999999998], "policy_red_v20_reward": [-2.0079999999999996], "policy_red_v32_reward": [0.4876932378161709], "policy_red_v8_reward": [-2.0189999999999984], "policy_red_v38_reward": [-1.0019999999999998], "policy_red_v12_reward": [-1.009, -1.0129999999999992, -1.024999999999999, 0.17205000000000015], "policy_red_v18_reward": [-1.0229999999999997], "policy_red_v36_reward": [-2.023999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8207543221112644, "mean_inference_ms": 7.673350169291809, "mean_action_processing_ms": 0.29309747955030374, "mean_env_wait_ms": 0.3914452203315133, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10060286521911621, "StateBufferConnector_ms": 0.004244089126586914, "ViewRequirementAgentConnector_ms": 0.11714482307434082}}, "episode_reward_max": 4.49110522563234, "episode_reward_min": -4.104104332227031, "episode_reward_mean": 2.351207176912714, "episode_len_mean": 69.47, "episodes_this_iter": 61, "policy_reward_min": {"red_v3": -2.002, "red": -6.8301043322270765, "blue": -2.0169999999999995, "red_v45": -1.007, "red_v47": 0.49469323781617125, "red_v60": 0.36828360500000024, "red_v17": -1.005, "red_v13": -2.005, "red_v61": -1.5069999999999997, "red_v63": -2.025999999999999, "red_v55": -2.0089999999999995, "red_v44": -0.5330653855574066, "red_v23": 0.836, "red_v59": -2.0329999999999995, "red_v58": -1.005, "red_v53": 0.48193461444259245, "red_v39": -1.0199999999999985, "red_v52": -0.5273067621838291, "red_v29": -1.505, "red_v33": -0.048000000000000036, "red_v41": 1.49169323781617, "red_v57": 0.9556932378152037, "red_v65": -1.5359999999999991, "red_v28": -1.9890000000000003, "red_v35": -1.0039999999999998, "red_v30": -2.14599999999999, "red_v40": 1.8571776128161743, "red_v49": 1.4779346144425922, "red_v48": -1.0059999999999998, "red_v20": -2.0079999999999996, "red_v32": 0.4876932378161709, "red_v8": -2.0189999999999984, "red_v38": -1.0019999999999998, "red_v12": -1.024999999999999, "red_v18": -1.0229999999999997, "red_v36": -2.023999999999999}, "policy_reward_max": {"red_v3": -2.002, "red": 3.993743658544055, "blue": 2.72600000000002, "red_v45": 0.39028360500000026, "red_v47": 0.49469323781617125, "red_v60": 0.36828360500000024, "red_v17": 1.604050000000002, "red_v13": 0.38128360500000025, "red_v61": -1.5069999999999997, "red_v63": 0.5021030335440553, "red_v55": 0.15805000000000102, "red_v44": 0.4986932378161699, "red_v23": 0.836, "red_v59": -1.004, "red_v58": -1.005, "red_v53": 0.48193461444259245, "red_v39": -1.0199999999999985, "red_v52": 0.48969323781617113, "red_v29": 1.5026932378161701, "red_v33": -0.048000000000000036, "red_v41": 1.49169323781617, "red_v57": 0.9556932378152037, "red_v65": -1.5359999999999991, "red_v28": -1.9890000000000003, "red_v35": -1.0039999999999998, "red_v30": 0.5046932378161698, "red_v40": 1.8571776128161743, "red_v49": 1.4779346144425922, "red_v48": -1.0059999999999998, "red_v20": -2.0079999999999996, "red_v32": 0.4876932378161709, "red_v8": -2.0189999999999984, "red_v38": -1.0019999999999998, "red_v12": 0.17205000000000015, "red_v18": -1.0229999999999997, "red_v36": -2.023999999999999}, "policy_reward_mean": {"red_v3": -2.002, "red": 3.2372568776623867, "blue": -1.3218453776041659, "red_v45": -0.1929290987499999, "red_v47": 0.49469323781617125, "red_v60": 0.36828360500000024, "red_v17": 0.29952500000000104, "red_v13": -0.8118581974999999, "red_v61": -1.5069999999999997, "red_v63": -1.176632322151981, "red_v55": -0.6193166666666662, "red_v44": -0.017186073870618324, "red_v23": 0.836, "red_v59": -1.5184999999999997, "red_v58": -1.005, "red_v53": 0.48193461444259245, "red_v39": -1.0199999999999985, "red_v52": -0.018806762183828984, "red_v29": 0.13165894760539013, "red_v33": -0.048000000000000036, "red_v41": 1.49169323781617, "red_v57": 0.9556932378152037, "red_v65": -1.5359999999999991, "red_v28": -1.9890000000000003, "red_v35": -1.0039999999999998, "red_v30": -0.8206533810919101, "red_v40": 1.8571776128161743, "red_v49": 1.4779346144425922, "red_v48": -1.0059999999999998, "red_v20": -2.0079999999999996, "red_v32": 0.4876932378161709, "red_v8": -2.0189999999999984, "red_v38": -1.0019999999999998, "red_v12": -0.7187374999999996, "red_v18": -1.0229999999999997, "red_v36": -2.023999999999999}, "hist_stats": {"episode_reward": [1.9917436585440549, 2.4636533644425924, 3.876804272772942, 3.954198975632342, 2.4728651128161703, 3.842226842816172, -4.104104332227031, 2.4925561585440548, 0.42634375, 1.8349375, 1.9814119878161705, 0.8763304800000002, 2.292896362816179, 1.9530838628161709, 1.9716846144425924, 2.9778963628161703, 2.907080977258766, 2.4804119878161703, 3.8068651128152053, 2.4723807378161706, 1.9785249085440548, 2.48189636281617, 2.4685752394425924, 2.4793026128161704, 1.4773026128161701, 3.9700497272587625, 1.9487557378161717, 2.432880737816172, 1.9832237927729421, 3.32727136281617, 3.858148717816171, 1.98611511281617, 3.9436521006323413, 3.9823743963602247, 2.451615112816171, 2.4254432378161725, 0.9618338628161699, 1.9561619878152046, 2.367814855, 0.7701151128161916, 2.855208862816175, 4.451980225632342, 4.169495850631381, 2.455240112816171, 0.912177612816171, 2.8334646006323494, 1.9550994878161707, 1.4200994878161728, 1.9874467835440548, 1.4839276128152037, 0.551474487816172, 3.9556833506323406, 2.4636463628161707, 2.477899908544055, 2.485708862815204, 1.4404744878161715, 3.89161746781617, 1.83875, 2.3668148550000003, 3.621477612816174, 2.469271362816171, 4.49110522563234, 1.4874467835440552, 1.7291307378161804, 2.48892761281617, 0.9354744878161704, 2.349870850632347, 1.1623937500000006, 1.9828182378161705, 4.4561278522587635, 0.9628651128161702, 2.47749011281617, 1.98252136281617, 1.4658651128161706, 3.9906989756323403, 3.9407614756323417, 2.488630737815204, 1.9623494878161705, 1.9498338628161715, 2.98611511281617, 2.9790057378161707, 1.493259283544055, 2.492739417772942, 2.4219658644425937, 2.4698963628161703, 2.48122448781617, 1.4665682378161708, 2.459974487816171, 2.4440526128161717, 1.9658651128161706, 2.3437523550000012, 2.47811511281617, 1.4710838628161707, 2.0987432378161746, 2.4751151128161704, 2.4453182378161715, 1.9441307378161712, 3.6473213628161707, 2.4581307378161705, 1.4847436585440552], "episode_lengths": [19, 26, 23, 60, 41, 48, 1055, 15, 18, 20, 26, 17, 159, 35, 16, 31, 79, 26, 41, 36, 25, 31, 19, 29, 29, 25, 44, 68, 22, 39, 41, 25, 75, 39, 57, 80, 51, 42, 22, 729, 123, 66, 381, 49, 69, 135, 62, 62, 18, 21, 646, 65, 47, 33, 27, 70, 19, 16, 22, 53, 39, 26, 18, 180, 21, 70, 133, 18, 24, 32, 41, 33, 23, 41, 28, 72, 20, 46, 51, 25, 28, 14, 17, 54, 31, 22, 40, 38, 45, 41, 42, 25, 35, 64, 25, 56, 52, 39, 52, 19], "policy_red_v3_reward": [-2.002], "policy_blue_reward": [-1.0069999999999997, 2.72600000000002, -1.002, -2.0069999999999997, -1.038999999999997, -2.0049999999999994, -1.0069999999999997, -1.0069999999999997, -2.009, -1.0069999999999997, -2.007999999999999, -2.0169999999999995, -2.008, -2.0039999999999996, -1.0119999999999993, -1.0229999999999977, -2.0109999999999997, -1.0039999999999998, 0.2654218749999997, -1.0129999999999992, -2.005, -2.0060000000000002, -1.009999999999999, -1.0029999999999997, -2.015999999999999, -1.002, -1.005, -1.0079999999999998, -2.0069999999999997, -1.0049999999999997, -1.5219999999999998, -2.0069999999999997, -2.0059999999999993, -1.513, -2.01, -1.005, -2.01, -0.009000000000000001, -2.005, -1.015999999999999, -1.0099999999999996, -2.0099999999999993, -1.0119999999999996, -1.0079999999999998, -2.01, -1.0129999999999995, -1.0109999999999992, -2.006], "policy_red_v45_reward": [0.39028360500000026, -1.007, -0.1519999999999999, -0.003], "policy_red_v47_reward": [0.49469323781617125], "policy_red_v60_reward": [0.36828360500000024], "policy_red_v17_reward": [-1.005, 1.604050000000002], "policy_red_v13_reward": [-2.005, 0.38128360500000025], "policy_red_v61_reward": [-1.5069999999999997], "policy_red_v63_reward": [-2.025999999999999, 0.5021030335440553, -2.0059999999999993], "policy_red_v55_reward": [-0.007, -2.0089999999999995, 0.15805000000000102], "policy_red_v44_reward": [-0.5330653855574066, 0.4986932378161699], "policy_red_v23_reward": [0.836], "policy_red_v59_reward": [-1.004, -2.0329999999999995], "policy_red_v58_reward": [-1.005], "policy_red_v53_reward": [0.48193461444259245], "policy_red_v39_reward": [-1.0199999999999985], "policy_red_v52_reward": [0.48969323781617113, -0.5273067621838291], "policy_red_v29_reward": [-1.505, 0.39728360500000015, 1.5026932378161701], "policy_red_v33_reward": [-0.048000000000000036], "policy_red_v41_reward": [1.49169323781617], "policy_red_v57_reward": [0.9556932378152037], "policy_red_v65_reward": [-1.5359999999999991], "policy_red_v28_reward": [-1.9890000000000003], "policy_red_v35_reward": [-1.0039999999999998], "policy_red_v30_reward": [-2.14599999999999, 0.5046932378161698], "policy_red_v40_reward": [1.8571776128161743], "policy_red_v49_reward": [1.4779346144425922], "policy_red_v48_reward": [-1.0059999999999998], "policy_red_v20_reward": [-2.0079999999999996], "policy_red_v32_reward": [0.4876932378161709], "policy_red_v8_reward": [-2.0189999999999984], "policy_red_v38_reward": [-1.0019999999999998], "policy_red_v12_reward": [-1.009, -1.0129999999999992, -1.024999999999999, 0.17205000000000015], "policy_red_v18_reward": [-1.0229999999999997], "policy_red_v36_reward": [-2.023999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8207543221112644, "mean_inference_ms": 7.673350169291809, "mean_action_processing_ms": 0.29309747955030374, "mean_env_wait_ms": 0.3914452203315133, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10060286521911621, "StateBufferConnector_ms": 0.004244089126586914, "ViewRequirementAgentConnector_ms": 0.11714482307434082}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 204.69871761326883, "num_env_steps_trained_throughput_per_sec": 204.69871761326883, "timesteps_total": 440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 20010.818, "sample_time_ms": 1177.838, "learn_time_ms": 18749.134, "learn_throughput": 213.343, "synch_weights_time_ms": 80.269}, "counters": {"num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "episodes_total": 2331, "training_iteration": 110, "trial_id": "a9680_00000", "date": "2023-09-24_03-17-07", "timestamp": 1695539827, "time_this_iter_s": 19.550904035568237, "time_total_s": 2194.287368774414, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dc78b20>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1ddc0f70>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1ddc0790>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2194.287368774414, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 5.514705882352941, "ram_util_percent": 25.870588235294115}, "win_rate": 0.78, "league_size": 79}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2771090218176444, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0242022580843089, "policy_loss": -0.05026772135558228, "vf_loss": 0.13631700431384766, "vf_explained_var": 0.8287297572319706, "kl": 0.0168992850032699, "entropy": 1.293200595366458, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 106080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_agent_steps_sampled": 888000, "num_agent_steps_trained": 888000}, "sampler_results": {"episode_reward_max": 4.49110522563234, "episode_reward_min": 0.7411898550000002, "episode_reward_mean": 2.4812392215333103, "episode_len_mean": 58.17, "episode_media": {}, "episodes_this_iter": 55, "policy_reward_min": {"blue": -2.0169999999999986, "red": 0.49269323781617036, "red_v29": 0.1740500000000006, "red_v55": 0.15805000000000102, "red_v30": -2.14599999999999, "red_v40": 1.8571776128161743, "red_v49": 1.4779346144425922, "red_v48": -1.0059999999999998, "red_v20": -2.0079999999999996, "red_v32": 0.4876932378161709, "red_v8": -2.0189999999999984, "red_v45": -1.0059999999999998, "red_v38": -1.0079999999999996, "red_v12": -1.024999999999999, "red_v63": -2.0059999999999993, "red_v17": -1.0119999999999998, "red_v18": -1.0229999999999997, "red_v36": -2.023999999999999, "red_v15": -1.0099999999999996, "red_v27": 0.49169323781617136, "red_v43": -1.001, "red_v46": -0.5509999999999999, "red_v25": 0.822, "red_v70": -2.003, "red_v14": -2.011, "red_v26": -0.1489999999999998, "red_v23": 0.48293461444259234, "red_v35": 1.4986932378161701, "red_v2": -2.022999999999999, "red_v76": -2.0139999999999993, "red_v74": -2.0039999999999996, "red_v52": 0.4819346144425925, "red_v16": 0.476103033544055, "red_v59": 0.49769323781617025, "red_v50": -1.0139999999999998, "red_v53": 0.49469323781617036}, "policy_reward_max": {"blue": 0.492, "red": 3.99233386281617, "red_v29": 1.5026932378161701, "red_v55": 0.15805000000000102, "red_v30": 0.5046932378161698, "red_v40": 1.8571776128161743, "red_v49": 1.4779346144425922, "red_v48": -1.0059999999999998, "red_v20": 0.43369323781617003, "red_v32": 0.4876932378161709, "red_v8": -1.0119999999999998, "red_v45": -0.003, "red_v38": -1.0019999999999998, "red_v12": 0.17205000000000015, "red_v63": 2.3447557378161727, "red_v17": 1.604050000000002, "red_v18": -1.0229999999999997, "red_v36": -2.023999999999999, "red_v15": -0.6960000000000001, "red_v27": 0.49169323781617136, "red_v43": -1.001, "red_v46": 0.475, "red_v25": 0.822, "red_v70": 1.4419346144425922, "red_v14": 1.4801030335440573, "red_v26": -0.1489999999999998, "red_v23": 0.48293461444259234, "red_v35": 1.5026932378161701, "red_v2": -2.0069999999999997, "red_v76": -0.563, "red_v74": -2.0039999999999996, "red_v52": 0.4819346144425925, "red_v16": 1.9719346144425938, "red_v59": 0.49769323781617025, "red_v50": -1.0139999999999998, "red_v53": 0.49469323781617036}, "policy_reward_mean": {"blue": -1.361279069767441, "red": 3.2337638691805197, "red_v29": 0.6913422809387236, "red_v55": 0.15805000000000102, "red_v30": -0.8206533810919101, "red_v40": 1.8571776128161743, "red_v49": 1.4779346144425922, "red_v48": -1.0059999999999998, "red_v20": -0.7871533810919148, "red_v32": 0.4876932378161709, "red_v8": -1.515499999999999, "red_v45": -0.5044999999999998, "red_v38": -1.0049999999999997, "red_v12": -0.7187374999999996, "red_v63": 0.1693778689080867, "red_v17": 0.2960250000000011, "red_v18": -1.0229999999999997, "red_v36": -2.023999999999999, "red_v15": -0.8529999999999998, "red_v27": 0.49169323781617136, "red_v43": -1.001, "red_v46": -0.03799999999999998, "red_v25": 0.822, "red_v70": -0.28053269277870396, "red_v14": -0.27447424161398565, "red_v26": -0.1489999999999998, "red_v23": 0.48293461444259234, "red_v35": 1.5006932378161701, "red_v2": -2.0146666666666664, "red_v76": -1.2884999999999995, "red_v74": -2.0039999999999996, "red_v52": 0.4819346144425925, "red_v16": 1.2240188239933243, "red_v59": 0.49769323781617025, "red_v50": -1.0139999999999998, "red_v53": 0.49469323781617036}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.4404744878161715, 3.89161746781617, 1.83875, 2.3668148550000003, 3.621477612816174, 2.469271362816171, 4.49110522563234, 1.4874467835440552, 1.7291307378161804, 2.48892761281617, 0.9354744878161704, 2.349870850632347, 1.1623937500000006, 1.9828182378161705, 4.4561278522587635, 0.9628651128161702, 2.47749011281617, 1.98252136281617, 1.4658651128161706, 3.9906989756323403, 3.9407614756323417, 2.488630737815204, 1.9623494878161705, 1.9498338628161715, 2.98611511281617, 2.9790057378161707, 1.493259283544055, 2.492739417772942, 2.4219658644425937, 2.4698963628161703, 2.48122448781617, 1.4665682378161708, 2.459974487816171, 2.4440526128161717, 1.9658651128161706, 2.3437523550000012, 2.47811511281617, 1.4710838628161707, 2.0987432378161746, 2.4751151128161704, 2.4453182378161715, 1.9441307378161712, 3.6473213628161707, 2.4581307378161705, 1.4847436585440552, 2.4713807378161707, 3.959308350632342, 2.4913338628152037, 3.4275526128161715, 1.5366593750000157, 1.9559744878161713, 2.851448975632344, 3.7835057378161725, 2.4627869878161714, 2.47470886281617, 2.454833862816172, 4.398924727258766, 2.8243304800000004, 3.3418182378161703, 3.9713466022587633, 4.47533960063234, 1.4767869878161703, 2.9251151128161705, 2.9865213628161698, 2.481818237816171, 2.4660838628161708, 1.4637557378161707, 2.4577557378161714, 1.1588000000000003, 0.956536987816171, 4.477261475632341, 2.9598338628161702, 0.841453125, 1.9863338628161706, 2.4312869878161703, 1.16620625, 2.47411511281617, 3.9687528522587625, 0.8436718750000001, 3.6331487927729436, 2.4828182378161703, 3.931034102258764, 1.956786987816171, 0.7411898550000002, 1.4704119878152049, 3.9648239756323407, 1.3344531250000005, 2.460755737816171, 1.9630838628161706, 1.8691898550000003, 1.328234375, 3.860230225632348, 2.940926917772942, 3.961011475632341, 1.3418593749999999, 3.922733771360228, 0.7956932378161725, 2.4490213628161714, 4.402546271360231, 2.4707869878161706], "episode_lengths": [70, 19, 16, 22, 53, 39, 26, 18, 180, 21, 70, 133, 18, 24, 32, 41, 33, 23, 41, 28, 72, 20, 46, 51, 25, 28, 14, 17, 54, 31, 22, 40, 38, 45, 41, 42, 25, 35, 64, 25, 56, 52, 39, 52, 19, 36, 57, 19, 77, 413, 38, 172, 60, 34, 27, 51, 65, 17, 24, 26, 47, 34, 25, 23, 24, 35, 44, 44, 16, 50, 40, 51, 15, 19, 66, 14, 25, 24, 9, 62, 24, 62, 34, 94, 26, 52, 15, 44, 35, 30, 21, 114, 21, 56, 13, 84, 1280, 55, 80, 34], "policy_blue_reward": [-2.015999999999999, -1.002, -1.005, -1.0079999999999998, -2.0069999999999997, -1.0049999999999997, -1.5219999999999998, -2.0069999999999997, -2.0059999999999993, -1.513, -2.01, -1.005, -2.01, -0.009000000000000001, -2.005, -1.015999999999999, -1.0099999999999996, -2.0099999999999993, -1.0119999999999996, -1.0079999999999998, -2.01, -1.0129999999999995, -1.0109999999999992, -2.006, -1.1269999999999887, -2.0169999999999986, 0.492, -1.0109999999999992, -0.002, -1.0089999999999992, -1.0129999999999992, -2.0109999999999992, -1.0099999999999993, -1.509, -2.0059999999999993, -1.0169999999999992, -2.005, -1.5219999999999998, -2.0089999999999995, -2.0069999999999997, -0.5059999999999999, -2.003, -1.0169999999999986], "policy_red_v29_reward": [0.39728360500000015, 1.5026932378161701, 0.1740500000000006], "policy_red_v55_reward": [0.15805000000000102], "policy_red_v30_reward": [-2.14599999999999, 0.5046932378161698], "policy_red_v40_reward": [1.8571776128161743], "policy_red_v49_reward": [1.4779346144425922], "policy_red_v48_reward": [-1.0059999999999998], "policy_red_v20_reward": [-2.0079999999999996, 0.43369323781617003], "policy_red_v32_reward": [0.4876932378161709], "policy_red_v8_reward": [-2.0189999999999984, -1.0119999999999998], "policy_red_v45_reward": [-0.003, -1.0059999999999998], "policy_red_v38_reward": [-1.0019999999999998, -1.0079999999999996], "policy_red_v12_reward": [-1.009, -1.0129999999999992, -1.024999999999999, 0.17205000000000015], "policy_red_v63_reward": [-2.0059999999999993, 2.3447557378161727], "policy_red_v17_reward": [1.604050000000002, -1.0119999999999998], "policy_red_v18_reward": [-1.0229999999999997], "policy_red_v36_reward": [-2.023999999999999], "policy_red_v15_reward": [-1.0099999999999996, -0.6960000000000001], "policy_red_v27_reward": [0.49169323781617136], "policy_red_v43_reward": [-1.001], "policy_red_v46_reward": [0.475, -0.5509999999999999], "policy_red_v25_reward": [0.822], "policy_red_v70_reward": [1.4419346144425922, -2.003], "policy_red_v14_reward": [-0.557, -2.011, -0.010000000000000002, 1.4801030335440573], "policy_red_v26_reward": [-0.1489999999999998], "policy_red_v23_reward": [0.48293461444259234], "policy_red_v35_reward": [1.5026932378161701, 1.4986932378161701], "policy_red_v2_reward": [-2.0069999999999997, -2.022999999999999, -2.014], "policy_red_v76_reward": [-0.563, -2.0139999999999993], "policy_red_v74_reward": [-2.0039999999999996], "policy_red_v52_reward": [0.4819346144425925], "policy_red_v16_reward": [1.9719346144425938, 0.476103033544055], "policy_red_v59_reward": [0.49769323781617025], "policy_red_v50_reward": [-1.0139999999999998], "policy_red_v53_reward": [0.49469323781617036]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8220656182343754, "mean_inference_ms": 7.6863964598451044, "mean_action_processing_ms": 0.29324984267965265, "mean_env_wait_ms": 0.39266158776521576, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10205256938934326, "StateBufferConnector_ms": 0.004368901252746582, "ViewRequirementAgentConnector_ms": 0.11797118186950684}}, "episode_reward_max": 4.49110522563234, "episode_reward_min": 0.7411898550000002, "episode_reward_mean": 2.4812392215333103, "episode_len_mean": 58.17, "episodes_this_iter": 55, "policy_reward_min": {"blue": -2.0169999999999986, "red": 0.49269323781617036, "red_v29": 0.1740500000000006, "red_v55": 0.15805000000000102, "red_v30": -2.14599999999999, "red_v40": 1.8571776128161743, "red_v49": 1.4779346144425922, "red_v48": -1.0059999999999998, "red_v20": -2.0079999999999996, "red_v32": 0.4876932378161709, "red_v8": -2.0189999999999984, "red_v45": -1.0059999999999998, "red_v38": -1.0079999999999996, "red_v12": -1.024999999999999, "red_v63": -2.0059999999999993, "red_v17": -1.0119999999999998, "red_v18": -1.0229999999999997, "red_v36": -2.023999999999999, "red_v15": -1.0099999999999996, "red_v27": 0.49169323781617136, "red_v43": -1.001, "red_v46": -0.5509999999999999, "red_v25": 0.822, "red_v70": -2.003, "red_v14": -2.011, "red_v26": -0.1489999999999998, "red_v23": 0.48293461444259234, "red_v35": 1.4986932378161701, "red_v2": -2.022999999999999, "red_v76": -2.0139999999999993, "red_v74": -2.0039999999999996, "red_v52": 0.4819346144425925, "red_v16": 0.476103033544055, "red_v59": 0.49769323781617025, "red_v50": -1.0139999999999998, "red_v53": 0.49469323781617036}, "policy_reward_max": {"blue": 0.492, "red": 3.99233386281617, "red_v29": 1.5026932378161701, "red_v55": 0.15805000000000102, "red_v30": 0.5046932378161698, "red_v40": 1.8571776128161743, "red_v49": 1.4779346144425922, "red_v48": -1.0059999999999998, "red_v20": 0.43369323781617003, "red_v32": 0.4876932378161709, "red_v8": -1.0119999999999998, "red_v45": -0.003, "red_v38": -1.0019999999999998, "red_v12": 0.17205000000000015, "red_v63": 2.3447557378161727, "red_v17": 1.604050000000002, "red_v18": -1.0229999999999997, "red_v36": -2.023999999999999, "red_v15": -0.6960000000000001, "red_v27": 0.49169323781617136, "red_v43": -1.001, "red_v46": 0.475, "red_v25": 0.822, "red_v70": 1.4419346144425922, "red_v14": 1.4801030335440573, "red_v26": -0.1489999999999998, "red_v23": 0.48293461444259234, "red_v35": 1.5026932378161701, "red_v2": -2.0069999999999997, "red_v76": -0.563, "red_v74": -2.0039999999999996, "red_v52": 0.4819346144425925, "red_v16": 1.9719346144425938, "red_v59": 0.49769323781617025, "red_v50": -1.0139999999999998, "red_v53": 0.49469323781617036}, "policy_reward_mean": {"blue": -1.361279069767441, "red": 3.2337638691805197, "red_v29": 0.6913422809387236, "red_v55": 0.15805000000000102, "red_v30": -0.8206533810919101, "red_v40": 1.8571776128161743, "red_v49": 1.4779346144425922, "red_v48": -1.0059999999999998, "red_v20": -0.7871533810919148, "red_v32": 0.4876932378161709, "red_v8": -1.515499999999999, "red_v45": -0.5044999999999998, "red_v38": -1.0049999999999997, "red_v12": -0.7187374999999996, "red_v63": 0.1693778689080867, "red_v17": 0.2960250000000011, "red_v18": -1.0229999999999997, "red_v36": -2.023999999999999, "red_v15": -0.8529999999999998, "red_v27": 0.49169323781617136, "red_v43": -1.001, "red_v46": -0.03799999999999998, "red_v25": 0.822, "red_v70": -0.28053269277870396, "red_v14": -0.27447424161398565, "red_v26": -0.1489999999999998, "red_v23": 0.48293461444259234, "red_v35": 1.5006932378161701, "red_v2": -2.0146666666666664, "red_v76": -1.2884999999999995, "red_v74": -2.0039999999999996, "red_v52": 0.4819346144425925, "red_v16": 1.2240188239933243, "red_v59": 0.49769323781617025, "red_v50": -1.0139999999999998, "red_v53": 0.49469323781617036}, "hist_stats": {"episode_reward": [1.4404744878161715, 3.89161746781617, 1.83875, 2.3668148550000003, 3.621477612816174, 2.469271362816171, 4.49110522563234, 1.4874467835440552, 1.7291307378161804, 2.48892761281617, 0.9354744878161704, 2.349870850632347, 1.1623937500000006, 1.9828182378161705, 4.4561278522587635, 0.9628651128161702, 2.47749011281617, 1.98252136281617, 1.4658651128161706, 3.9906989756323403, 3.9407614756323417, 2.488630737815204, 1.9623494878161705, 1.9498338628161715, 2.98611511281617, 2.9790057378161707, 1.493259283544055, 2.492739417772942, 2.4219658644425937, 2.4698963628161703, 2.48122448781617, 1.4665682378161708, 2.459974487816171, 2.4440526128161717, 1.9658651128161706, 2.3437523550000012, 2.47811511281617, 1.4710838628161707, 2.0987432378161746, 2.4751151128161704, 2.4453182378161715, 1.9441307378161712, 3.6473213628161707, 2.4581307378161705, 1.4847436585440552, 2.4713807378161707, 3.959308350632342, 2.4913338628152037, 3.4275526128161715, 1.5366593750000157, 1.9559744878161713, 2.851448975632344, 3.7835057378161725, 2.4627869878161714, 2.47470886281617, 2.454833862816172, 4.398924727258766, 2.8243304800000004, 3.3418182378161703, 3.9713466022587633, 4.47533960063234, 1.4767869878161703, 2.9251151128161705, 2.9865213628161698, 2.481818237816171, 2.4660838628161708, 1.4637557378161707, 2.4577557378161714, 1.1588000000000003, 0.956536987816171, 4.477261475632341, 2.9598338628161702, 0.841453125, 1.9863338628161706, 2.4312869878161703, 1.16620625, 2.47411511281617, 3.9687528522587625, 0.8436718750000001, 3.6331487927729436, 2.4828182378161703, 3.931034102258764, 1.956786987816171, 0.7411898550000002, 1.4704119878152049, 3.9648239756323407, 1.3344531250000005, 2.460755737816171, 1.9630838628161706, 1.8691898550000003, 1.328234375, 3.860230225632348, 2.940926917772942, 3.961011475632341, 1.3418593749999999, 3.922733771360228, 0.7956932378161725, 2.4490213628161714, 4.402546271360231, 2.4707869878161706], "episode_lengths": [70, 19, 16, 22, 53, 39, 26, 18, 180, 21, 70, 133, 18, 24, 32, 41, 33, 23, 41, 28, 72, 20, 46, 51, 25, 28, 14, 17, 54, 31, 22, 40, 38, 45, 41, 42, 25, 35, 64, 25, 56, 52, 39, 52, 19, 36, 57, 19, 77, 413, 38, 172, 60, 34, 27, 51, 65, 17, 24, 26, 47, 34, 25, 23, 24, 35, 44, 44, 16, 50, 40, 51, 15, 19, 66, 14, 25, 24, 9, 62, 24, 62, 34, 94, 26, 52, 15, 44, 35, 30, 21, 114, 21, 56, 13, 84, 1280, 55, 80, 34], "policy_blue_reward": [-2.015999999999999, -1.002, -1.005, -1.0079999999999998, -2.0069999999999997, -1.0049999999999997, -1.5219999999999998, -2.0069999999999997, -2.0059999999999993, -1.513, -2.01, -1.005, -2.01, -0.009000000000000001, -2.005, -1.015999999999999, -1.0099999999999996, -2.0099999999999993, -1.0119999999999996, -1.0079999999999998, -2.01, -1.0129999999999995, -1.0109999999999992, -2.006, -1.1269999999999887, -2.0169999999999986, 0.492, -1.0109999999999992, -0.002, -1.0089999999999992, -1.0129999999999992, -2.0109999999999992, -1.0099999999999993, -1.509, -2.0059999999999993, -1.0169999999999992, -2.005, -1.5219999999999998, -2.0089999999999995, -2.0069999999999997, -0.5059999999999999, -2.003, -1.0169999999999986], "policy_red_v29_reward": [0.39728360500000015, 1.5026932378161701, 0.1740500000000006], "policy_red_v55_reward": [0.15805000000000102], "policy_red_v30_reward": [-2.14599999999999, 0.5046932378161698], "policy_red_v40_reward": [1.8571776128161743], "policy_red_v49_reward": [1.4779346144425922], "policy_red_v48_reward": [-1.0059999999999998], "policy_red_v20_reward": [-2.0079999999999996, 0.43369323781617003], "policy_red_v32_reward": [0.4876932378161709], "policy_red_v8_reward": [-2.0189999999999984, -1.0119999999999998], "policy_red_v45_reward": [-0.003, -1.0059999999999998], "policy_red_v38_reward": [-1.0019999999999998, -1.0079999999999996], "policy_red_v12_reward": [-1.009, -1.0129999999999992, -1.024999999999999, 0.17205000000000015], "policy_red_v63_reward": [-2.0059999999999993, 2.3447557378161727], "policy_red_v17_reward": [1.604050000000002, -1.0119999999999998], "policy_red_v18_reward": [-1.0229999999999997], "policy_red_v36_reward": [-2.023999999999999], "policy_red_v15_reward": [-1.0099999999999996, -0.6960000000000001], "policy_red_v27_reward": [0.49169323781617136], "policy_red_v43_reward": [-1.001], "policy_red_v46_reward": [0.475, -0.5509999999999999], "policy_red_v25_reward": [0.822], "policy_red_v70_reward": [1.4419346144425922, -2.003], "policy_red_v14_reward": [-0.557, -2.011, -0.010000000000000002, 1.4801030335440573], "policy_red_v26_reward": [-0.1489999999999998], "policy_red_v23_reward": [0.48293461444259234], "policy_red_v35_reward": [1.5026932378161701, 1.4986932378161701], "policy_red_v2_reward": [-2.0069999999999997, -2.022999999999999, -2.014], "policy_red_v76_reward": [-0.563, -2.0139999999999993], "policy_red_v74_reward": [-2.0039999999999996], "policy_red_v52_reward": [0.4819346144425925], "policy_red_v16_reward": [1.9719346144425938, 0.476103033544055], "policy_red_v59_reward": [0.49769323781617025], "policy_red_v50_reward": [-1.0139999999999998], "policy_red_v53_reward": [0.49469323781617036]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8220656182343754, "mean_inference_ms": 7.6863964598451044, "mean_action_processing_ms": 0.29324984267965265, "mean_env_wait_ms": 0.39266158776521576, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10205256938934326, "StateBufferConnector_ms": 0.004368901252746582, "ViewRequirementAgentConnector_ms": 0.11797118186950684}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 888000, "num_agent_steps_trained": 888000, "num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 198.66001595393334, "num_env_steps_trained_throughput_per_sec": 198.66001595393334, "timesteps_total": 444000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 888000, "timers": {"training_iteration_time_ms": 20063.189, "sample_time_ms": 1174.949, "learn_time_ms": 18804.85, "learn_throughput": 212.711, "synch_weights_time_ms": 79.791}, "counters": {"num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_agent_steps_sampled": 888000, "num_agent_steps_trained": 888000}, "done": false, "episodes_total": 2386, "training_iteration": 111, "trial_id": "a9680_00000", "date": "2023-09-24_03-17-36", "timestamp": 1695539856, "time_this_iter_s": 20.147632122039795, "time_total_s": 2214.435000896454, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dc7b7f0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1ddc1ab0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1ddc1b40>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2214.435000896454, "iterations_since_restore": 111, "perf": {"cpu_util_percent": 4.775, "ram_util_percent": 25.98}, "win_rate": 0.74, "league_size": 80}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.291180624937018, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.04320298377424479, "policy_loss": -0.03781236665187559, "vf_loss": 0.1535472995446374, "vf_explained_var": 0.8004029162848989, "kl": 0.012500530090500206, "entropy": 1.3835376544545095, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 107040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "sampler_results": {"episode_reward_max": 4.48166772563234, "episode_reward_min": 0.7411898550000002, "episode_reward_mean": 2.599997130927294, "episode_len_mean": 57.4, "episode_media": {}, "episodes_this_iter": 47, "policy_reward_min": {"red_v43": -1.001, "red": 0.004693237816169926, "red_v46": -0.5509999999999999, "blue": -2.0169999999999986, "red_v63": 2.3447557378161727, "red_v25": 0.822, "red_v8": -1.0119999999999998, "red_v70": -2.003, "red_v14": -2.011, "red_v26": -0.1489999999999998, "red_v23": 0.48293461444259234, "red_v35": 1.4986932378161701, "red_v2": -2.022999999999999, "red_v76": -2.0139999999999993, "red_v74": -2.0039999999999996, "red_v17": -1.0119999999999998, "red_v52": 0.1740500000000007, "red_v29": 0.1740500000000006, "red_v45": -1.0059999999999998, "red_v16": -1.002, "red_v59": 0.49769323781617025, "red_v50": -1.0139999999999998, "red_v20": 0.43369323781617003, "red_v53": -2.0119999999999987, "red_v15": -0.6960000000000001, "red_v38": -1.0079999999999996, "red_v34": -1.064999999999997, "red_v3": -2.01, "red_v51": 0.17505000000000015, "red_v66": 2.9587244878161707, "red_v57": 0.5011030335440552, "red_v54": -1.0119999999999996, "red_v78": -0.14900000000000002, "red_v37": -2.0089999999999995, "red_v58": -1.0229999999999997, "red_v40": -0.06299999999999994, "red_v30": -1.011999999999999, "red_v22": 1.4789346144425923, "red_v60": -1.019, "red_v68": -2.006, "red_v31": -0.037000000000000026}, "policy_reward_max": {"red_v43": -1.001, "red": 3.99233386281617, "red_v46": 1.4886932378161715, "blue": 0.492, "red_v63": 2.3447557378161727, "red_v25": 0.822, "red_v8": -1.0119999999999998, "red_v70": 1.4419346144425922, "red_v14": 1.4801030335440573, "red_v26": -0.1489999999999998, "red_v23": 0.48293461444259234, "red_v35": 1.5026932378161701, "red_v2": -2.0069999999999997, "red_v76": -0.563, "red_v74": -2.0039999999999996, "red_v17": -1.0119999999999998, "red_v52": 0.4819346144425925, "red_v29": 0.1740500000000006, "red_v45": -1.0059999999999998, "red_v16": 1.9719346144425938, "red_v59": 0.49769323781617025, "red_v50": 0.4879346144425923, "red_v20": 0.43369323781617003, "red_v53": 0.49469323781617036, "red_v15": -0.6960000000000001, "red_v38": -1.0079999999999996, "red_v34": -1.0069999999999997, "red_v3": -2.01, "red_v51": 1.5016932378161703, "red_v66": 2.9587244878161707, "red_v57": 0.5011030335440552, "red_v54": -1.0119999999999996, "red_v78": -0.14900000000000002, "red_v37": 0.1720500000000002, "red_v58": -1.0229999999999997, "red_v40": -0.06299999999999994, "red_v30": -1.011999999999999, "red_v22": 1.4789346144425923, "red_v60": -1.019, "red_v68": -2.006, "red_v31": -0.037000000000000026}, "policy_reward_mean": {"red_v43": -1.001, "red": 3.2171187763450693, "red_v46": 0.47089774593872386, "blue": -1.1632499999999992, "red_v63": 2.3447557378161727, "red_v25": 0.822, "red_v8": -1.0119999999999998, "red_v70": -0.28053269277870396, "red_v14": -0.3228408847365999, "red_v26": -0.1489999999999998, "red_v23": 0.48293461444259234, "red_v35": 1.5006932378161701, "red_v2": -2.0146666666666664, "red_v76": -1.2884999999999995, "red_v74": -2.0039999999999996, "red_v17": -1.0119999999999998, "red_v52": 0.3279923072212966, "red_v29": 0.1740500000000006, "red_v45": -1.0059999999999998, "red_v16": 0.4820125493288829, "red_v59": 0.49769323781617025, "red_v50": -0.2630326927787038, "red_v20": 0.43369323781617003, "red_v53": -0.7586533810919142, "red_v15": -0.6960000000000001, "red_v38": -1.0079999999999996, "red_v34": -1.0359999999999983, "red_v3": -2.01, "red_v51": 0.7198121585441143, "red_v66": 2.9587244878161707, "red_v57": 0.5011030335440552, "red_v54": -1.0119999999999996, "red_v78": -0.14900000000000002, "red_v37": -0.8069833333333332, "red_v58": -1.0229999999999997, "red_v40": -0.06299999999999994, "red_v30": -1.011999999999999, "red_v22": 1.4789346144425923, "red_v60": -1.019, "red_v68": -2.006, "red_v31": -0.037000000000000026}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.4913338628152037, 3.4275526128161715, 1.5366593750000157, 1.9559744878161713, 2.851448975632344, 3.7835057378161725, 2.4627869878161714, 2.47470886281617, 2.454833862816172, 4.398924727258766, 2.8243304800000004, 3.3418182378161703, 3.9713466022587633, 4.47533960063234, 1.4767869878161703, 2.9251151128161705, 2.9865213628161698, 2.481818237816171, 2.4660838628161708, 1.4637557378161707, 2.4577557378161714, 1.1588000000000003, 0.956536987816171, 4.477261475632341, 2.9598338628161702, 0.841453125, 1.9863338628161706, 2.4312869878161703, 1.16620625, 2.47411511281617, 3.9687528522587625, 0.8436718750000001, 3.6331487927729436, 2.4828182378161703, 3.931034102258764, 1.956786987816171, 0.7411898550000002, 1.4704119878152049, 3.9648239756323407, 1.3344531250000005, 2.460755737816171, 1.9630838628161706, 1.8691898550000003, 1.328234375, 3.860230225632348, 2.940926917772942, 3.961011475632341, 1.3418593749999999, 3.922733771360228, 0.7956932378161725, 2.4490213628161714, 4.402546271360231, 2.4707869878161706, 2.480821783544055, 2.4811151128152042, 2.456615112816171, 4.451605225632342, 1.9861151128161698, 0.8311562500000002, 1.484630042772942, 3.432276405589114, 2.480149908544055, 2.9441377394425925, 2.96967761281617, 0.8542679800000001, 1.4802244878161703, 1.9663807378161708, 4.48166772563234, 1.9879276128161703, 2.96341772563234, 3.990515021360225, 1.81009375, 1.98352136281617, 3.659649487816171, 3.34322448781617, 1.4754901128161702, 2.48178698781617, 3.9300271006323424, 2.959755737816171, 3.6615713628161703, 2.3753182378161735, 1.9778963628161699, 2.4562713628161714, 2.4171932378161713, 3.4685682378161706, 3.9686122272587627, 2.3618929800000017, 2.3909588628161718, 4.462018477258763, 2.389255737816173, 2.9650838628161704, 2.4811151128152042, 2.4684901128161716, 1.4770057378161705, 2.8661776128161733, 2.48452136281617, 2.4697088628161703, 3.653430737816171, 1.6676125000000006, 2.9173651128161726], "episode_lengths": [19, 77, 413, 38, 172, 60, 34, 27, 51, 65, 17, 24, 26, 47, 34, 25, 23, 24, 35, 44, 44, 16, 50, 40, 51, 15, 19, 66, 14, 25, 24, 9, 62, 24, 62, 34, 94, 26, 52, 15, 44, 35, 30, 21, 114, 21, 56, 13, 84, 1280, 55, 80, 34, 26, 25, 57, 58, 25, 14, 20, 67, 17, 31, 37, 37, 22, 36, 38, 21, 54, 26, 34, 23, 30, 22, 33, 34, 83, 44, 23, 120, 31, 39, 32, 40, 37, 29, 139, 35, 76, 35, 25, 33, 28, 69, 23, 27, 36, 12, 73], "policy_red_v43_reward": [-1.001], "policy_red_v46_reward": [0.475, -0.5509999999999999, 1.4886932378161715], "policy_blue_reward": [-1.1269999999999887, -2.0169999999999986, 0.492, -1.0109999999999992, -0.002, -1.0089999999999992, -1.0129999999999992, -2.0109999999999992, -1.0099999999999993, -1.509, -2.0059999999999993, -1.0169999999999992, -2.005, -1.5219999999999998, -2.0089999999999995, -2.0069999999999997, -0.5059999999999999, -2.003, -1.0169999999999986, -1.0059999999999996, -1.0099999999999991, -2.0029999999999997, -2.0069999999999997, -1.0109999999999997, -0.010000000000000002, -0.51, -1.513, -2.008, -2.0039999999999996, -2.0059999999999993, -2.0089999999999995, -0.016000000000000007, -1.0389999999999997, -2.0069999999999997, 0.49, 0.488, -0.013000000000000001, -1.0069999999999997, -1.0119999999999998, -1.0079999999999998], "policy_red_v63_reward": [2.3447557378161727], "policy_red_v25_reward": [0.822], "policy_red_v8_reward": [-1.0119999999999998], "policy_red_v70_reward": [1.4419346144425922, -2.003], "policy_red_v14_reward": [-0.557, -2.011, -0.010000000000000002, 1.4801030335440573, -0.5163074572270567], "policy_red_v26_reward": [-0.1489999999999998], "policy_red_v23_reward": [0.48293461444259234], "policy_red_v35_reward": [1.5026932378161701, 1.4986932378161701], "policy_red_v2_reward": [-2.0069999999999997, -2.022999999999999, -2.014], "policy_red_v76_reward": [-0.563, -2.0139999999999993], "policy_red_v74_reward": [-2.0039999999999996], "policy_red_v17_reward": [-1.0119999999999998], "policy_red_v52_reward": [0.4819346144425925, 0.1740500000000007], "policy_red_v29_reward": [0.1740500000000006], "policy_red_v45_reward": [-1.0059999999999998], "policy_red_v16_reward": [1.9719346144425938, 0.476103033544055, -1.002], "policy_red_v59_reward": [0.49769323781617025], "policy_red_v50_reward": [-1.0139999999999998, 0.4879346144425923], "policy_red_v20_reward": [0.43369323781617003], "policy_red_v53_reward": [0.49469323781617036, -2.0119999999999987], "policy_red_v15_reward": [-0.6960000000000001], "policy_red_v38_reward": [-1.0079999999999996], "policy_red_v34_reward": [-1.0069999999999997, -1.064999999999997], "policy_red_v3_reward": [-2.01], "policy_red_v51_reward": [1.5016932378161703, 0.48269323781617224, 0.17505000000000015], "policy_red_v66_reward": [2.9587244878161707], "policy_red_v57_reward": [0.5011030335440552], "policy_red_v54_reward": [-1.0119999999999996], "policy_red_v78_reward": [-0.14900000000000002], "policy_red_v37_reward": [0.1720500000000002, -2.0089999999999995, -0.5840000000000001], "policy_red_v58_reward": [-1.0229999999999997], "policy_red_v40_reward": [-0.06299999999999994], "policy_red_v30_reward": [-1.011999999999999], "policy_red_v22_reward": [1.4789346144425923], "policy_red_v60_reward": [-1.019], "policy_red_v68_reward": [-2.006], "policy_red_v31_reward": [-0.037000000000000026]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8215702799094582, "mean_inference_ms": 7.68127200758953, "mean_action_processing_ms": 0.29284849464804297, "mean_env_wait_ms": 0.39398776376920913, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10206460952758789, "StateBufferConnector_ms": 0.004360198974609375, "ViewRequirementAgentConnector_ms": 0.1167062520980835}}, "episode_reward_max": 4.48166772563234, "episode_reward_min": 0.7411898550000002, "episode_reward_mean": 2.599997130927294, "episode_len_mean": 57.4, "episodes_this_iter": 47, "policy_reward_min": {"red_v43": -1.001, "red": 0.004693237816169926, "red_v46": -0.5509999999999999, "blue": -2.0169999999999986, "red_v63": 2.3447557378161727, "red_v25": 0.822, "red_v8": -1.0119999999999998, "red_v70": -2.003, "red_v14": -2.011, "red_v26": -0.1489999999999998, "red_v23": 0.48293461444259234, "red_v35": 1.4986932378161701, "red_v2": -2.022999999999999, "red_v76": -2.0139999999999993, "red_v74": -2.0039999999999996, "red_v17": -1.0119999999999998, "red_v52": 0.1740500000000007, "red_v29": 0.1740500000000006, "red_v45": -1.0059999999999998, "red_v16": -1.002, "red_v59": 0.49769323781617025, "red_v50": -1.0139999999999998, "red_v20": 0.43369323781617003, "red_v53": -2.0119999999999987, "red_v15": -0.6960000000000001, "red_v38": -1.0079999999999996, "red_v34": -1.064999999999997, "red_v3": -2.01, "red_v51": 0.17505000000000015, "red_v66": 2.9587244878161707, "red_v57": 0.5011030335440552, "red_v54": -1.0119999999999996, "red_v78": -0.14900000000000002, "red_v37": -2.0089999999999995, "red_v58": -1.0229999999999997, "red_v40": -0.06299999999999994, "red_v30": -1.011999999999999, "red_v22": 1.4789346144425923, "red_v60": -1.019, "red_v68": -2.006, "red_v31": -0.037000000000000026}, "policy_reward_max": {"red_v43": -1.001, "red": 3.99233386281617, "red_v46": 1.4886932378161715, "blue": 0.492, "red_v63": 2.3447557378161727, "red_v25": 0.822, "red_v8": -1.0119999999999998, "red_v70": 1.4419346144425922, "red_v14": 1.4801030335440573, "red_v26": -0.1489999999999998, "red_v23": 0.48293461444259234, "red_v35": 1.5026932378161701, "red_v2": -2.0069999999999997, "red_v76": -0.563, "red_v74": -2.0039999999999996, "red_v17": -1.0119999999999998, "red_v52": 0.4819346144425925, "red_v29": 0.1740500000000006, "red_v45": -1.0059999999999998, "red_v16": 1.9719346144425938, "red_v59": 0.49769323781617025, "red_v50": 0.4879346144425923, "red_v20": 0.43369323781617003, "red_v53": 0.49469323781617036, "red_v15": -0.6960000000000001, "red_v38": -1.0079999999999996, "red_v34": -1.0069999999999997, "red_v3": -2.01, "red_v51": 1.5016932378161703, "red_v66": 2.9587244878161707, "red_v57": 0.5011030335440552, "red_v54": -1.0119999999999996, "red_v78": -0.14900000000000002, "red_v37": 0.1720500000000002, "red_v58": -1.0229999999999997, "red_v40": -0.06299999999999994, "red_v30": -1.011999999999999, "red_v22": 1.4789346144425923, "red_v60": -1.019, "red_v68": -2.006, "red_v31": -0.037000000000000026}, "policy_reward_mean": {"red_v43": -1.001, "red": 3.2171187763450693, "red_v46": 0.47089774593872386, "blue": -1.1632499999999992, "red_v63": 2.3447557378161727, "red_v25": 0.822, "red_v8": -1.0119999999999998, "red_v70": -0.28053269277870396, "red_v14": -0.3228408847365999, "red_v26": -0.1489999999999998, "red_v23": 0.48293461444259234, "red_v35": 1.5006932378161701, "red_v2": -2.0146666666666664, "red_v76": -1.2884999999999995, "red_v74": -2.0039999999999996, "red_v17": -1.0119999999999998, "red_v52": 0.3279923072212966, "red_v29": 0.1740500000000006, "red_v45": -1.0059999999999998, "red_v16": 0.4820125493288829, "red_v59": 0.49769323781617025, "red_v50": -0.2630326927787038, "red_v20": 0.43369323781617003, "red_v53": -0.7586533810919142, "red_v15": -0.6960000000000001, "red_v38": -1.0079999999999996, "red_v34": -1.0359999999999983, "red_v3": -2.01, "red_v51": 0.7198121585441143, "red_v66": 2.9587244878161707, "red_v57": 0.5011030335440552, "red_v54": -1.0119999999999996, "red_v78": -0.14900000000000002, "red_v37": -0.8069833333333332, "red_v58": -1.0229999999999997, "red_v40": -0.06299999999999994, "red_v30": -1.011999999999999, "red_v22": 1.4789346144425923, "red_v60": -1.019, "red_v68": -2.006, "red_v31": -0.037000000000000026}, "hist_stats": {"episode_reward": [2.4913338628152037, 3.4275526128161715, 1.5366593750000157, 1.9559744878161713, 2.851448975632344, 3.7835057378161725, 2.4627869878161714, 2.47470886281617, 2.454833862816172, 4.398924727258766, 2.8243304800000004, 3.3418182378161703, 3.9713466022587633, 4.47533960063234, 1.4767869878161703, 2.9251151128161705, 2.9865213628161698, 2.481818237816171, 2.4660838628161708, 1.4637557378161707, 2.4577557378161714, 1.1588000000000003, 0.956536987816171, 4.477261475632341, 2.9598338628161702, 0.841453125, 1.9863338628161706, 2.4312869878161703, 1.16620625, 2.47411511281617, 3.9687528522587625, 0.8436718750000001, 3.6331487927729436, 2.4828182378161703, 3.931034102258764, 1.956786987816171, 0.7411898550000002, 1.4704119878152049, 3.9648239756323407, 1.3344531250000005, 2.460755737816171, 1.9630838628161706, 1.8691898550000003, 1.328234375, 3.860230225632348, 2.940926917772942, 3.961011475632341, 1.3418593749999999, 3.922733771360228, 0.7956932378161725, 2.4490213628161714, 4.402546271360231, 2.4707869878161706, 2.480821783544055, 2.4811151128152042, 2.456615112816171, 4.451605225632342, 1.9861151128161698, 0.8311562500000002, 1.484630042772942, 3.432276405589114, 2.480149908544055, 2.9441377394425925, 2.96967761281617, 0.8542679800000001, 1.4802244878161703, 1.9663807378161708, 4.48166772563234, 1.9879276128161703, 2.96341772563234, 3.990515021360225, 1.81009375, 1.98352136281617, 3.659649487816171, 3.34322448781617, 1.4754901128161702, 2.48178698781617, 3.9300271006323424, 2.959755737816171, 3.6615713628161703, 2.3753182378161735, 1.9778963628161699, 2.4562713628161714, 2.4171932378161713, 3.4685682378161706, 3.9686122272587627, 2.3618929800000017, 2.3909588628161718, 4.462018477258763, 2.389255737816173, 2.9650838628161704, 2.4811151128152042, 2.4684901128161716, 1.4770057378161705, 2.8661776128161733, 2.48452136281617, 2.4697088628161703, 3.653430737816171, 1.6676125000000006, 2.9173651128161726], "episode_lengths": [19, 77, 413, 38, 172, 60, 34, 27, 51, 65, 17, 24, 26, 47, 34, 25, 23, 24, 35, 44, 44, 16, 50, 40, 51, 15, 19, 66, 14, 25, 24, 9, 62, 24, 62, 34, 94, 26, 52, 15, 44, 35, 30, 21, 114, 21, 56, 13, 84, 1280, 55, 80, 34, 26, 25, 57, 58, 25, 14, 20, 67, 17, 31, 37, 37, 22, 36, 38, 21, 54, 26, 34, 23, 30, 22, 33, 34, 83, 44, 23, 120, 31, 39, 32, 40, 37, 29, 139, 35, 76, 35, 25, 33, 28, 69, 23, 27, 36, 12, 73], "policy_red_v43_reward": [-1.001], "policy_red_v46_reward": [0.475, -0.5509999999999999, 1.4886932378161715], "policy_blue_reward": [-1.1269999999999887, -2.0169999999999986, 0.492, -1.0109999999999992, -0.002, -1.0089999999999992, -1.0129999999999992, -2.0109999999999992, -1.0099999999999993, -1.509, -2.0059999999999993, -1.0169999999999992, -2.005, -1.5219999999999998, -2.0089999999999995, -2.0069999999999997, -0.5059999999999999, -2.003, -1.0169999999999986, -1.0059999999999996, -1.0099999999999991, -2.0029999999999997, -2.0069999999999997, -1.0109999999999997, -0.010000000000000002, -0.51, -1.513, -2.008, -2.0039999999999996, -2.0059999999999993, -2.0089999999999995, -0.016000000000000007, -1.0389999999999997, -2.0069999999999997, 0.49, 0.488, -0.013000000000000001, -1.0069999999999997, -1.0119999999999998, -1.0079999999999998], "policy_red_v63_reward": [2.3447557378161727], "policy_red_v25_reward": [0.822], "policy_red_v8_reward": [-1.0119999999999998], "policy_red_v70_reward": [1.4419346144425922, -2.003], "policy_red_v14_reward": [-0.557, -2.011, -0.010000000000000002, 1.4801030335440573, -0.5163074572270567], "policy_red_v26_reward": [-0.1489999999999998], "policy_red_v23_reward": [0.48293461444259234], "policy_red_v35_reward": [1.5026932378161701, 1.4986932378161701], "policy_red_v2_reward": [-2.0069999999999997, -2.022999999999999, -2.014], "policy_red_v76_reward": [-0.563, -2.0139999999999993], "policy_red_v74_reward": [-2.0039999999999996], "policy_red_v17_reward": [-1.0119999999999998], "policy_red_v52_reward": [0.4819346144425925, 0.1740500000000007], "policy_red_v29_reward": [0.1740500000000006], "policy_red_v45_reward": [-1.0059999999999998], "policy_red_v16_reward": [1.9719346144425938, 0.476103033544055, -1.002], "policy_red_v59_reward": [0.49769323781617025], "policy_red_v50_reward": [-1.0139999999999998, 0.4879346144425923], "policy_red_v20_reward": [0.43369323781617003], "policy_red_v53_reward": [0.49469323781617036, -2.0119999999999987], "policy_red_v15_reward": [-0.6960000000000001], "policy_red_v38_reward": [-1.0079999999999996], "policy_red_v34_reward": [-1.0069999999999997, -1.064999999999997], "policy_red_v3_reward": [-2.01], "policy_red_v51_reward": [1.5016932378161703, 0.48269323781617224, 0.17505000000000015], "policy_red_v66_reward": [2.9587244878161707], "policy_red_v57_reward": [0.5011030335440552], "policy_red_v54_reward": [-1.0119999999999996], "policy_red_v78_reward": [-0.14900000000000002], "policy_red_v37_reward": [0.1720500000000002, -2.0089999999999995, -0.5840000000000001], "policy_red_v58_reward": [-1.0229999999999997], "policy_red_v40_reward": [-0.06299999999999994], "policy_red_v30_reward": [-1.011999999999999], "policy_red_v22_reward": [1.4789346144425923], "policy_red_v60_reward": [-1.019], "policy_red_v68_reward": [-2.006], "policy_red_v31_reward": [-0.037000000000000026]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8215702799094582, "mean_inference_ms": 7.68127200758953, "mean_action_processing_ms": 0.29284849464804297, "mean_env_wait_ms": 0.39398776376920913, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10206460952758789, "StateBufferConnector_ms": 0.004360198974609375, "ViewRequirementAgentConnector_ms": 0.1167062520980835}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.6463463102022, "num_env_steps_trained_throughput_per_sec": 200.6463463102022, "timesteps_total": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 20052.023, "sample_time_ms": 1186.561, "learn_time_ms": 18781.843, "learn_throughput": 212.972, "synch_weights_time_ms": 80.091}, "counters": {"num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "episodes_total": 2433, "training_iteration": 112, "trial_id": "a9680_00000", "date": "2023-09-24_03-18-01", "timestamp": 1695539881, "time_this_iter_s": 19.94756555557251, "time_total_s": 2234.3825664520264, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dc79090>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1ddc25f0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1ddc2680>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2234.3825664520264, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 5.757142857142858, "ram_util_percent": 26.17428571428572}, "win_rate": 0.72, "league_size": 81}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.144109388316671, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.015208876724985505, "policy_loss": -0.04809548228610462, "vf_loss": 0.11275526391109451, "vf_explained_var": 0.8688162352268894, "kl": 0.018513764795951224, "entropy": 1.4044673416763545, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 108000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_agent_steps_sampled": 904000, "num_agent_steps_trained": 904000}, "sampler_results": {"episode_reward_max": 4.4885896006323405, "episode_reward_min": 0.45456823781616973, "episode_reward_mean": 2.550090408292492, "episode_len_mean": 60.61, "episode_media": {}, "episodes_this_iter": 45, "policy_reward_min": {"red_v46": -0.5509999999999999, "red": -0.31794999999999973, "red_v53": -2.0119999999999987, "blue": -2.011999999999999, "red_v16": -1.002, "red_v15": -0.6960000000000001, "red_v14": -0.5163074572270567, "red_v38": -1.0079999999999996, "red_v34": -1.064999999999997, "red_v3": -2.01, "red_v51": -1.5179999999999998, "red_v66": 2.9587244878161707, "red_v57": 0.5011030335440552, "red_v54": -1.0119999999999996, "red_v52": 0.1740500000000007, "red_v78": -0.14900000000000002, "red_v37": -2.0089999999999995, "red_v58": -1.0229999999999997, "red_v40": -0.06299999999999994, "red_v50": 0.4879346144425923, "red_v30": -1.011999999999999, "red_v22": 1.4789346144425923, "red_v60": -1.019, "red_v68": -2.006, "red_v31": -0.037000000000000026, "red_v39": -0.556, "red_v6": -2.006, "red_v8": -1.0139999999999998, "red_v28": -2.0039999999999996, "red_v18": -1.5950000000000002, "red_v79": 0.4916932378161706, "red_v24": -2.5409999999999737, "red_v10": -1.038999999999997, "red_v42": 0.459692542772946, "red_v69": -2.01, "red_v4": -1.0089999999999992, "red_v61": -0.5539999999999999, "red_v45": 1.5056932378161698}, "policy_reward_max": {"red_v46": 1.4886932378161715, "red": 3.992333167772942, "red_v53": 0.49469323781617036, "blue": 0.49, "red_v16": 0.476103033544055, "red_v15": -0.6960000000000001, "red_v14": 1.977125, "red_v38": -1.0079999999999996, "red_v34": -1.0069999999999997, "red_v3": -2.01, "red_v51": 1.5016932378161703, "red_v66": 2.9587244878161707, "red_v57": 0.5011030335440552, "red_v54": -0.559, "red_v52": 0.1740500000000007, "red_v78": -0.14900000000000002, "red_v37": 0.1720500000000002, "red_v58": -1.0059999999999998, "red_v40": -0.06299999999999994, "red_v50": 0.4879346144425923, "red_v30": 2.024255737816178, "red_v22": 1.4789346144425923, "red_v60": -1.0039999999999998, "red_v68": -1.0049999999999997, "red_v31": 1.5036932378161698, "red_v39": -0.556, "red_v6": -2.006, "red_v8": -1.0139999999999998, "red_v28": -2.0039999999999996, "red_v18": -1.5950000000000002, "red_v79": 0.4916932378161706, "red_v24": -2.5409999999999737, "red_v10": -1.038999999999997, "red_v42": 0.459692542772946, "red_v69": -2.01, "red_v4": -1.0089999999999992, "red_v61": -0.5539999999999999, "red_v45": 1.5056932378161698}, "policy_reward_mean": {"red_v46": 0.46884661890808577, "red": 3.2143507679820895, "red_v53": -0.8394355873946093, "blue": -1.092524857954545, "red_v16": -0.2629484832279725, "red_v15": -0.6960000000000001, "red_v14": 0.9803068587723335, "red_v38": -1.0079999999999996, "red_v34": -1.0359999999999983, "red_v3": -2.01, "red_v51": 0.16035911890808574, "red_v66": 2.9587244878161707, "red_v57": 0.5011030335440552, "red_v54": -0.7854999999999999, "red_v52": 0.1740500000000007, "red_v78": -0.14900000000000002, "red_v37": -0.8069833333333332, "red_v58": -1.0144999999999997, "red_v40": -0.06299999999999994, "red_v50": 0.4879346144425923, "red_v30": 0.5059829918774498, "red_v22": 1.4789346144425923, "red_v60": -1.0114999999999998, "red_v68": -1.5054999999999996, "red_v31": 0.6581288252104579, "red_v39": -0.556, "red_v6": -2.006, "red_v8": -1.0139999999999998, "red_v28": -2.0039999999999996, "red_v18": -1.5950000000000002, "red_v79": 0.4916932378161706, "red_v24": -2.5409999999999737, "red_v10": -1.038999999999997, "red_v42": 0.459692542772946, "red_v69": -2.01, "red_v4": -1.0089999999999992, "red_v61": -0.5539999999999999, "red_v45": 1.5056932378161698}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.940926917772942, 3.961011475632341, 1.3418593749999999, 3.922733771360228, 0.7956932378161725, 2.4490213628161714, 4.402546271360231, 2.4707869878161706, 2.480821783544055, 2.4811151128152042, 2.456615112816171, 4.451605225632342, 1.9861151128161698, 0.8311562500000002, 1.484630042772942, 3.432276405589114, 2.480149908544055, 2.9441377394425925, 2.96967761281617, 0.8542679800000001, 1.4802244878161703, 1.9663807378161708, 4.48166772563234, 1.9879276128161703, 2.96341772563234, 3.990515021360225, 1.81009375, 1.98352136281617, 3.659649487816171, 3.34322448781617, 1.4754901128161702, 2.48178698781617, 3.9300271006323424, 2.959755737816171, 3.6615713628161703, 2.3753182378161735, 1.9778963628161699, 2.4562713628161714, 2.4171932378161713, 3.4685682378161706, 3.9686122272587627, 2.3618929800000017, 2.3909588628161718, 4.462018477258763, 2.389255737816173, 2.9650838628161704, 2.4811151128152042, 2.4684901128161716, 1.4770057378161705, 2.8661776128161733, 2.48452136281617, 2.4697088628161703, 3.653430737816171, 1.6676125000000006, 2.9173651128161726, 0.91759948781617, 0.45456823781616973, 2.48000573781617, 2.93181823781617, 4.4885896006323405, 2.472083862816171, 4.000733771359259, 0.8370468750000002, 1.9840057378161706, 1.98711511281617, 2.9189814894425923, 1.9710838628161707, 2.472896362816171, 2.37692423, 1.988333167772942, 2.9145213628161724, 2.489630737815204, 2.4688721144425925, 2.476302612815204, 2.890990112816172, 1.290568237816171, 2.4681619878161705, 3.9444646006323416, 1.1364744878161945, 2.960943237816171, 2.426615112816173, 3.908432655589116, 2.1648, 0.950130737816171, 2.48670886281617, 2.489333862815204, 2.3773304800000004, 2.4661619878161707, 3.99129272563234, 0.9550526128161713, 1.48992761281617, 2.468974487816171, 1.476926917772942, 2.4989489756323597, 2.4826300427729424, 2.4760057378161706, 1.6591750000000003, 2.479228033544055, 2.92519323781617, 4.48255835063234], "episode_lengths": [21, 56, 13, 84, 1280, 55, 80, 34, 26, 25, 57, 58, 25, 14, 20, 67, 17, 31, 37, 37, 22, 36, 38, 21, 54, 26, 34, 23, 30, 22, 33, 34, 83, 44, 23, 120, 31, 39, 32, 40, 37, 29, 139, 35, 76, 35, 25, 33, 28, 69, 23, 27, 36, 12, 73, 94, 40, 28, 24, 31, 35, 20, 17, 28, 25, 17, 35, 31, 19, 19, 87, 20, 20, 29, 65, 168, 42, 71, 454, 48, 57, 81, 16, 52, 27, 19, 17, 42, 30, 45, 21, 38, 21, 460, 20, 28, 24, 24, 32, 41], "policy_red_v46_reward": [-0.5509999999999999, 1.4886932378161715], "policy_red_v53_reward": [0.49469323781617036, -2.0119999999999987, -1.001], "policy_blue_reward": [-2.003, -1.0169999999999986, -1.0059999999999996, -1.0099999999999991, -2.0029999999999997, -2.0069999999999997, -1.0109999999999997, -0.010000000000000002, -0.51, -1.513, -2.008, -2.0039999999999996, -2.0059999999999993, -2.0089999999999995, -0.016000000000000007, -1.0389999999999997, -2.0069999999999997, 0.49, 0.488, -0.013000000000000001, -1.0069999999999997, -1.0119999999999998, -1.0079999999999998, 0.4099062499999999, -1.518, -1.0069999999999995, -1.009, -2.0039999999999996, -2.0029999999999997, -2.011999999999999, -0.026000000000000016, -1.0039999999999998, -1.0019999999999998, -1.0079999999999998, -0.5679999999999996, -1.0069999999999992, -0.511, -1.515999999999999, -1.003, -1.0089999999999997, -2.003, -1.010999999999999, -1.0089999999999997, -1.0099999999999998], "policy_red_v16_reward": [0.476103033544055, -1.002], "policy_red_v15_reward": [-0.6960000000000001], "policy_red_v14_reward": [1.4801030335440573, -0.5163074572270567, 1.977125], "policy_red_v38_reward": [-1.0079999999999996], "policy_red_v34_reward": [-1.0069999999999997, -1.064999999999997], "policy_red_v3_reward": [-2.01], "policy_red_v51_reward": [1.5016932378161703, 0.48269323781617224, 0.17505000000000015, -1.5179999999999998], "policy_red_v66_reward": [2.9587244878161707], "policy_red_v57_reward": [0.5011030335440552], "policy_red_v54_reward": [-1.0119999999999996, -0.559], "policy_red_v52_reward": [0.1740500000000007], "policy_red_v78_reward": [-0.14900000000000002], "policy_red_v37_reward": [0.1720500000000002, -2.0089999999999995, -0.5840000000000001], "policy_red_v58_reward": [-1.0229999999999997, -1.0059999999999998], "policy_red_v40_reward": [-0.06299999999999994], "policy_red_v50_reward": [0.4879346144425923], "policy_red_v30_reward": [-1.011999999999999, 0.50569323781617, 2.024255737816178], "policy_red_v22_reward": [1.4789346144425923], "policy_red_v60_reward": [-1.019, -1.0039999999999998], "policy_red_v68_reward": [-2.006, -1.0049999999999997], "policy_red_v31_reward": [-0.037000000000000026, 1.5036932378161698, 0.5076932378152038], "policy_red_v39_reward": [-0.556], "policy_red_v6_reward": [-2.006], "policy_red_v8_reward": [-1.0139999999999998], "policy_red_v28_reward": [-2.0039999999999996], "policy_red_v18_reward": [-1.5950000000000002], "policy_red_v79_reward": [0.4916932378161706], "policy_red_v24_reward": [-2.5409999999999737], "policy_red_v10_reward": [-1.038999999999997], "policy_red_v42_reward": [0.459692542772946], "policy_red_v69_reward": [-2.01], "policy_red_v4_reward": [-1.0089999999999992], "policy_red_v61_reward": [-0.5539999999999999], "policy_red_v45_reward": [1.5056932378161698]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8201475310292632, "mean_inference_ms": 7.649567975208892, "mean_action_processing_ms": 0.291974366953213, "mean_env_wait_ms": 0.3934862444937503, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10257089138031006, "StateBufferConnector_ms": 0.004245638847351074, "ViewRequirementAgentConnector_ms": 0.1167147159576416}}, "episode_reward_max": 4.4885896006323405, "episode_reward_min": 0.45456823781616973, "episode_reward_mean": 2.550090408292492, "episode_len_mean": 60.61, "episodes_this_iter": 45, "policy_reward_min": {"red_v46": -0.5509999999999999, "red": -0.31794999999999973, "red_v53": -2.0119999999999987, "blue": -2.011999999999999, "red_v16": -1.002, "red_v15": -0.6960000000000001, "red_v14": -0.5163074572270567, "red_v38": -1.0079999999999996, "red_v34": -1.064999999999997, "red_v3": -2.01, "red_v51": -1.5179999999999998, "red_v66": 2.9587244878161707, "red_v57": 0.5011030335440552, "red_v54": -1.0119999999999996, "red_v52": 0.1740500000000007, "red_v78": -0.14900000000000002, "red_v37": -2.0089999999999995, "red_v58": -1.0229999999999997, "red_v40": -0.06299999999999994, "red_v50": 0.4879346144425923, "red_v30": -1.011999999999999, "red_v22": 1.4789346144425923, "red_v60": -1.019, "red_v68": -2.006, "red_v31": -0.037000000000000026, "red_v39": -0.556, "red_v6": -2.006, "red_v8": -1.0139999999999998, "red_v28": -2.0039999999999996, "red_v18": -1.5950000000000002, "red_v79": 0.4916932378161706, "red_v24": -2.5409999999999737, "red_v10": -1.038999999999997, "red_v42": 0.459692542772946, "red_v69": -2.01, "red_v4": -1.0089999999999992, "red_v61": -0.5539999999999999, "red_v45": 1.5056932378161698}, "policy_reward_max": {"red_v46": 1.4886932378161715, "red": 3.992333167772942, "red_v53": 0.49469323781617036, "blue": 0.49, "red_v16": 0.476103033544055, "red_v15": -0.6960000000000001, "red_v14": 1.977125, "red_v38": -1.0079999999999996, "red_v34": -1.0069999999999997, "red_v3": -2.01, "red_v51": 1.5016932378161703, "red_v66": 2.9587244878161707, "red_v57": 0.5011030335440552, "red_v54": -0.559, "red_v52": 0.1740500000000007, "red_v78": -0.14900000000000002, "red_v37": 0.1720500000000002, "red_v58": -1.0059999999999998, "red_v40": -0.06299999999999994, "red_v50": 0.4879346144425923, "red_v30": 2.024255737816178, "red_v22": 1.4789346144425923, "red_v60": -1.0039999999999998, "red_v68": -1.0049999999999997, "red_v31": 1.5036932378161698, "red_v39": -0.556, "red_v6": -2.006, "red_v8": -1.0139999999999998, "red_v28": -2.0039999999999996, "red_v18": -1.5950000000000002, "red_v79": 0.4916932378161706, "red_v24": -2.5409999999999737, "red_v10": -1.038999999999997, "red_v42": 0.459692542772946, "red_v69": -2.01, "red_v4": -1.0089999999999992, "red_v61": -0.5539999999999999, "red_v45": 1.5056932378161698}, "policy_reward_mean": {"red_v46": 0.46884661890808577, "red": 3.2143507679820895, "red_v53": -0.8394355873946093, "blue": -1.092524857954545, "red_v16": -0.2629484832279725, "red_v15": -0.6960000000000001, "red_v14": 0.9803068587723335, "red_v38": -1.0079999999999996, "red_v34": -1.0359999999999983, "red_v3": -2.01, "red_v51": 0.16035911890808574, "red_v66": 2.9587244878161707, "red_v57": 0.5011030335440552, "red_v54": -0.7854999999999999, "red_v52": 0.1740500000000007, "red_v78": -0.14900000000000002, "red_v37": -0.8069833333333332, "red_v58": -1.0144999999999997, "red_v40": -0.06299999999999994, "red_v50": 0.4879346144425923, "red_v30": 0.5059829918774498, "red_v22": 1.4789346144425923, "red_v60": -1.0114999999999998, "red_v68": -1.5054999999999996, "red_v31": 0.6581288252104579, "red_v39": -0.556, "red_v6": -2.006, "red_v8": -1.0139999999999998, "red_v28": -2.0039999999999996, "red_v18": -1.5950000000000002, "red_v79": 0.4916932378161706, "red_v24": -2.5409999999999737, "red_v10": -1.038999999999997, "red_v42": 0.459692542772946, "red_v69": -2.01, "red_v4": -1.0089999999999992, "red_v61": -0.5539999999999999, "red_v45": 1.5056932378161698}, "hist_stats": {"episode_reward": [2.940926917772942, 3.961011475632341, 1.3418593749999999, 3.922733771360228, 0.7956932378161725, 2.4490213628161714, 4.402546271360231, 2.4707869878161706, 2.480821783544055, 2.4811151128152042, 2.456615112816171, 4.451605225632342, 1.9861151128161698, 0.8311562500000002, 1.484630042772942, 3.432276405589114, 2.480149908544055, 2.9441377394425925, 2.96967761281617, 0.8542679800000001, 1.4802244878161703, 1.9663807378161708, 4.48166772563234, 1.9879276128161703, 2.96341772563234, 3.990515021360225, 1.81009375, 1.98352136281617, 3.659649487816171, 3.34322448781617, 1.4754901128161702, 2.48178698781617, 3.9300271006323424, 2.959755737816171, 3.6615713628161703, 2.3753182378161735, 1.9778963628161699, 2.4562713628161714, 2.4171932378161713, 3.4685682378161706, 3.9686122272587627, 2.3618929800000017, 2.3909588628161718, 4.462018477258763, 2.389255737816173, 2.9650838628161704, 2.4811151128152042, 2.4684901128161716, 1.4770057378161705, 2.8661776128161733, 2.48452136281617, 2.4697088628161703, 3.653430737816171, 1.6676125000000006, 2.9173651128161726, 0.91759948781617, 0.45456823781616973, 2.48000573781617, 2.93181823781617, 4.4885896006323405, 2.472083862816171, 4.000733771359259, 0.8370468750000002, 1.9840057378161706, 1.98711511281617, 2.9189814894425923, 1.9710838628161707, 2.472896362816171, 2.37692423, 1.988333167772942, 2.9145213628161724, 2.489630737815204, 2.4688721144425925, 2.476302612815204, 2.890990112816172, 1.290568237816171, 2.4681619878161705, 3.9444646006323416, 1.1364744878161945, 2.960943237816171, 2.426615112816173, 3.908432655589116, 2.1648, 0.950130737816171, 2.48670886281617, 2.489333862815204, 2.3773304800000004, 2.4661619878161707, 3.99129272563234, 0.9550526128161713, 1.48992761281617, 2.468974487816171, 1.476926917772942, 2.4989489756323597, 2.4826300427729424, 2.4760057378161706, 1.6591750000000003, 2.479228033544055, 2.92519323781617, 4.48255835063234], "episode_lengths": [21, 56, 13, 84, 1280, 55, 80, 34, 26, 25, 57, 58, 25, 14, 20, 67, 17, 31, 37, 37, 22, 36, 38, 21, 54, 26, 34, 23, 30, 22, 33, 34, 83, 44, 23, 120, 31, 39, 32, 40, 37, 29, 139, 35, 76, 35, 25, 33, 28, 69, 23, 27, 36, 12, 73, 94, 40, 28, 24, 31, 35, 20, 17, 28, 25, 17, 35, 31, 19, 19, 87, 20, 20, 29, 65, 168, 42, 71, 454, 48, 57, 81, 16, 52, 27, 19, 17, 42, 30, 45, 21, 38, 21, 460, 20, 28, 24, 24, 32, 41], "policy_red_v46_reward": [-0.5509999999999999, 1.4886932378161715], "policy_red_v53_reward": [0.49469323781617036, -2.0119999999999987, -1.001], "policy_blue_reward": [-2.003, -1.0169999999999986, -1.0059999999999996, -1.0099999999999991, -2.0029999999999997, -2.0069999999999997, -1.0109999999999997, -0.010000000000000002, -0.51, -1.513, -2.008, -2.0039999999999996, -2.0059999999999993, -2.0089999999999995, -0.016000000000000007, -1.0389999999999997, -2.0069999999999997, 0.49, 0.488, -0.013000000000000001, -1.0069999999999997, -1.0119999999999998, -1.0079999999999998, 0.4099062499999999, -1.518, -1.0069999999999995, -1.009, -2.0039999999999996, -2.0029999999999997, -2.011999999999999, -0.026000000000000016, -1.0039999999999998, -1.0019999999999998, -1.0079999999999998, -0.5679999999999996, -1.0069999999999992, -0.511, -1.515999999999999, -1.003, -1.0089999999999997, -2.003, -1.010999999999999, -1.0089999999999997, -1.0099999999999998], "policy_red_v16_reward": [0.476103033544055, -1.002], "policy_red_v15_reward": [-0.6960000000000001], "policy_red_v14_reward": [1.4801030335440573, -0.5163074572270567, 1.977125], "policy_red_v38_reward": [-1.0079999999999996], "policy_red_v34_reward": [-1.0069999999999997, -1.064999999999997], "policy_red_v3_reward": [-2.01], "policy_red_v51_reward": [1.5016932378161703, 0.48269323781617224, 0.17505000000000015, -1.5179999999999998], "policy_red_v66_reward": [2.9587244878161707], "policy_red_v57_reward": [0.5011030335440552], "policy_red_v54_reward": [-1.0119999999999996, -0.559], "policy_red_v52_reward": [0.1740500000000007], "policy_red_v78_reward": [-0.14900000000000002], "policy_red_v37_reward": [0.1720500000000002, -2.0089999999999995, -0.5840000000000001], "policy_red_v58_reward": [-1.0229999999999997, -1.0059999999999998], "policy_red_v40_reward": [-0.06299999999999994], "policy_red_v50_reward": [0.4879346144425923], "policy_red_v30_reward": [-1.011999999999999, 0.50569323781617, 2.024255737816178], "policy_red_v22_reward": [1.4789346144425923], "policy_red_v60_reward": [-1.019, -1.0039999999999998], "policy_red_v68_reward": [-2.006, -1.0049999999999997], "policy_red_v31_reward": [-0.037000000000000026, 1.5036932378161698, 0.5076932378152038], "policy_red_v39_reward": [-0.556], "policy_red_v6_reward": [-2.006], "policy_red_v8_reward": [-1.0139999999999998], "policy_red_v28_reward": [-2.0039999999999996], "policy_red_v18_reward": [-1.5950000000000002], "policy_red_v79_reward": [0.4916932378161706], "policy_red_v24_reward": [-2.5409999999999737], "policy_red_v10_reward": [-1.038999999999997], "policy_red_v42_reward": [0.459692542772946], "policy_red_v69_reward": [-2.01], "policy_red_v4_reward": [-1.0089999999999992], "policy_red_v61_reward": [-0.5539999999999999], "policy_red_v45_reward": [1.5056932378161698]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8201475310292632, "mean_inference_ms": 7.649567975208892, "mean_action_processing_ms": 0.291974366953213, "mean_env_wait_ms": 0.3934862444937503, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10257089138031006, "StateBufferConnector_ms": 0.004245638847351074, "ViewRequirementAgentConnector_ms": 0.1167147159576416}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 904000, "num_agent_steps_trained": 904000, "num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 202.4695683479683, "num_env_steps_trained_throughput_per_sec": 202.4695683479683, "timesteps_total": 452000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 904000, "timers": {"training_iteration_time_ms": 20044.926, "sample_time_ms": 1184.078, "learn_time_ms": 18775.316, "learn_throughput": 213.046, "synch_weights_time_ms": 82.016}, "counters": {"num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_agent_steps_sampled": 904000, "num_agent_steps_trained": 904000}, "done": false, "episodes_total": 2478, "training_iteration": 113, "trial_id": "a9680_00000", "date": "2023-09-24_03-18-25", "timestamp": 1695539905, "time_this_iter_s": 19.767815351486206, "time_total_s": 2254.1503818035126, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dc780a0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1ddc3250>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1ddc32e0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2254.1503818035126, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 5.373529411764706, "ram_util_percent": 26.35}, "win_rate": 0.76, "league_size": 82}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2770600389689206, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.033261797311812794, "policy_loss": -0.04620528447703691, "vf_loss": 0.14893665534521763, "vf_explained_var": 0.8282452767714858, "kl": 0.014317417238107834, "entropy": 1.4440832665810983, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 108960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "sampler_results": {"episode_reward_max": 4.4885896006323405, "episode_reward_min": -0.5713750000000001, "episode_reward_mean": 2.3584244344341467, "episode_len_mean": 57.77, "episode_media": {}, "episodes_this_iter": 43, "policy_reward_min": {"red_v22": 1.4789346144425923, "red": -1.49330676218383, "red_v34": -1.064999999999997, "blue": -2.011999999999999, "red_v37": -2.0089999999999995, "red_v60": -2.0059999999999993, "red_v51": -1.5179999999999998, "red_v68": -2.006, "red_v31": -0.037000000000000026, "red_v39": -0.556, "red_v6": -2.006, "red_v54": -0.559, "red_v8": -1.0139999999999998, "red_v28": -2.0039999999999996, "red_v18": -1.5950000000000002, "red_v79": 0.4814218750000001, "red_v24": -2.5409999999999737, "red_v10": -2.0139999999999993, "red_v42": 0.459692542772946, "red_v58": -1.0059999999999998, "red_v53": -1.001, "red_v30": 0.50569323781617, "red_v69": -2.01, "red_v4": -1.0089999999999992, "red_v14": 1.977125, "red_v61": -2.0089999999999995, "red_v45": 1.5056932378161698, "red_v56": -1.005, "red_v72": -1.509, "red_v52": -1.0049999999999994, "red_v50": -0.5539999999999999, "red_v12": -1.023, "red_v33": -0.1549999999999998, "red_v46": 0.503103033544055, "red_v47": 0.449, "red_v77": -0.1549999999999998, "red_v65": -2.001, "red_v7": -1.0039999999999998, "red_v29": 1.5026932378161701}, "policy_reward_max": {"red_v22": 1.4789346144425923, "red": 3.9933338628152035, "red_v34": -1.0089999999999992, "blue": 1.7633281250000008, "red_v37": -0.001, "red_v60": -1.0039999999999998, "red_v51": 0.17505000000000015, "red_v68": -1.0049999999999997, "red_v31": 1.5036932378161698, "red_v39": -0.556, "red_v6": -2.006, "red_v54": -0.559, "red_v8": -1.0139999999999998, "red_v28": -1.007, "red_v18": -1.5950000000000002, "red_v79": 0.498103033544055, "red_v24": -2.5409999999999737, "red_v10": -1.038999999999997, "red_v42": 0.459692542772946, "red_v58": -1.0059999999999998, "red_v53": -1.001, "red_v30": 2.024255737816178, "red_v69": -1.0059999999999998, "red_v4": -1.0089999999999992, "red_v14": 1.977125, "red_v61": -0.5539999999999999, "red_v45": 1.5056932378161698, "red_v56": -1.005, "red_v72": -1.509, "red_v52": 0.48310303354405637, "red_v50": -0.5539999999999999, "red_v12": -0.5139999999999999, "red_v33": -0.1549999999999998, "red_v46": 0.503103033544055, "red_v47": 0.4956932378161706, "red_v77": -0.1549999999999998, "red_v65": -2.001, "red_v7": -1.0039999999999998, "red_v29": 1.5026932378161701}, "policy_reward_mean": {"red_v22": 1.4789346144425923, "red": 3.122876737830385, "red_v34": -1.0369999999999981, "blue": -1.031810973837209, "red_v37": -0.8646666666666665, "red_v60": -1.3429999999999997, "red_v51": -0.6714749999999998, "red_v68": -1.5054999999999996, "red_v31": 0.6581288252104579, "red_v39": -0.556, "red_v6": -2.006, "red_v54": -0.559, "red_v8": -1.0139999999999998, "red_v28": -1.5054999999999996, "red_v18": -1.5950000000000002, "red_v79": 0.4904060487867419, "red_v24": -2.5409999999999737, "red_v10": -1.5264999999999982, "red_v42": 0.459692542772946, "red_v58": -1.0059999999999998, "red_v53": -1.001, "red_v30": 1.2649744878161742, "red_v69": -1.5079999999999998, "red_v4": -1.0089999999999992, "red_v14": 1.977125, "red_v61": -1.5216666666666665, "red_v45": 1.5056932378161698, "red_v56": -1.005, "red_v72": -1.509, "red_v52": -0.26094848322797154, "red_v50": -0.5539999999999999, "red_v12": -0.7685, "red_v33": -0.1549999999999998, "red_v46": 0.503103033544055, "red_v47": 0.47234661890808527, "red_v77": -0.1549999999999998, "red_v65": -2.001, "red_v7": -1.0039999999999998, "red_v29": 1.5026932378161701}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.462018477258763, 2.389255737816173, 2.9650838628161704, 2.4811151128152042, 2.4684901128161716, 1.4770057378161705, 2.8661776128161733, 2.48452136281617, 2.4697088628161703, 3.653430737816171, 1.6676125000000006, 2.9173651128161726, 0.91759948781617, 0.45456823781616973, 2.48000573781617, 2.93181823781617, 4.4885896006323405, 2.472083862816171, 4.000733771359259, 0.8370468750000002, 1.9840057378161706, 1.98711511281617, 2.9189814894425923, 1.9710838628161707, 2.472896362816171, 2.37692423, 1.988333167772942, 2.9145213628161724, 2.489630737815204, 2.4688721144425925, 2.476302612815204, 2.890990112816172, 1.290568237816171, 2.4681619878161705, 3.9444646006323416, 1.1364744878161945, 2.960943237816171, 2.426615112816173, 3.908432655589116, 2.1648, 0.950130737816171, 2.48670886281617, 2.489333862815204, 2.3773304800000004, 2.4661619878161707, 3.99129272563234, 0.9550526128161713, 1.48992761281617, 2.468974487816171, 1.476926917772942, 2.4989489756323597, 2.4826300427729424, 2.4760057378161706, 1.6591750000000003, 2.479228033544055, 2.92519323781617, 4.48255835063234, 0.6860994878161704, 1.154175000000001, 1.8046619878161743, 2.3764086050000004, -0.5713750000000001, 2.98781823781617, 1.48463073781617, 2.48411511281617, 3.8911868963602307, 2.9389276128161703, 0.2700213628161725, 2.4788963628161698, 3.9745618963602247, 1.9903338628152039, 1.9628651128161703, 0.17989374999999974, 2.469677612816171, 2.436615112816172, 1.4764901128161705, 1.4720092835440557, 2.468271362816171, 3.3333026128161705, 1.4510994878161707, 2.4761151128161702, 2.4807088628161704, 2.470974487816171, 3.9922181463602247, 1.9828963628161698, 2.4781151128161705, 2.4602401128161704, 3.9670427256323406, 3.32878698781617, 1.4703494878161698, 2.4544901128161705, 2.4841151128161703, 2.483223792772942, 2.4577557378161714, 4.4784489756323405, 1.48681823781617, 2.4730838628161704, 1.4872237927729421, 0.329421875, 3.1198], "episode_lengths": [35, 76, 35, 25, 33, 28, 69, 23, 27, 36, 12, 73, 94, 40, 28, 24, 31, 35, 20, 17, 28, 25, 17, 35, 31, 19, 19, 87, 20, 20, 29, 65, 168, 42, 71, 454, 48, 57, 81, 16, 52, 27, 19, 17, 42, 30, 45, 21, 38, 21, 460, 20, 28, 24, 24, 32, 41, 254, 24, 202, 24, 56, 24, 20, 25, 99, 21, 247, 31, 43, 19, 41, 690, 37, 57, 33, 30, 39, 29, 62, 25, 27, 38, 25, 31, 25, 49, 46, 34, 46, 33, 25, 22, 44, 44, 24, 35, 22, 25, 16], "policy_red_v22_reward": [1.4789346144425923], "policy_red_v34_reward": [-1.064999999999997, -1.0089999999999992], "policy_blue_reward": [-0.013000000000000001, -1.0069999999999997, -1.0119999999999998, -1.0079999999999998, 0.4099062499999999, -1.518, -1.0069999999999995, -1.009, -2.0039999999999996, -2.0029999999999997, -2.011999999999999, -0.026000000000000016, -1.0039999999999998, -1.0019999999999998, -1.0079999999999998, -0.5679999999999996, -1.0069999999999992, -0.511, -1.515999999999999, -1.003, -1.0089999999999997, -2.003, -1.010999999999999, -1.0089999999999997, -1.0099999999999998, -1.5739999999999998, -2.005, -1.059, 1.7633281250000008, -2.003, 1.4948937500000012, -1.0089999999999997, -1.0229999999999992, -2.0069999999999997, -1.0109999999999992, -1.0079999999999996, -1.0059999999999993, -1.009999999999999, -1.0119999999999998, -1.0069999999999995, -1.0129999999999995, -2.0039999999999996, -2.005], "policy_red_v37_reward": [-2.0089999999999995, -0.5840000000000001, -0.001], "policy_red_v60_reward": [-1.019, -1.0039999999999998, -2.0059999999999993], "policy_red_v51_reward": [0.17505000000000015, -1.5179999999999998], "policy_red_v68_reward": [-2.006, -1.0049999999999997], "policy_red_v31_reward": [-0.037000000000000026, 1.5036932378161698, 0.5076932378152038], "policy_red_v39_reward": [-0.556], "policy_red_v6_reward": [-2.006], "policy_red_v54_reward": [-0.559], "policy_red_v8_reward": [-1.0139999999999998], "policy_red_v28_reward": [-2.0039999999999996, -1.007], "policy_red_v18_reward": [-1.5950000000000002], "policy_red_v79_reward": [0.4916932378161706, 0.498103033544055, 0.4814218750000001], "policy_red_v24_reward": [-2.5409999999999737], "policy_red_v10_reward": [-1.038999999999997, -2.0139999999999993], "policy_red_v42_reward": [0.459692542772946], "policy_red_v58_reward": [-1.0059999999999998], "policy_red_v53_reward": [-1.001], "policy_red_v30_reward": [0.50569323781617, 2.024255737816178], "policy_red_v69_reward": [-2.01, -1.0059999999999998], "policy_red_v4_reward": [-1.0089999999999992], "policy_red_v14_reward": [1.977125], "policy_red_v61_reward": [-0.5539999999999999, -2.0089999999999995, -2.002], "policy_red_v45_reward": [1.5056932378161698], "policy_red_v56_reward": [-1.005], "policy_red_v72_reward": [-1.509], "policy_red_v52_reward": [0.48310303354405637, -1.0049999999999994], "policy_red_v50_reward": [-0.5539999999999999], "policy_red_v12_reward": [-0.5139999999999999, -1.023], "policy_red_v33_reward": [-0.1549999999999998], "policy_red_v46_reward": [0.503103033544055], "policy_red_v47_reward": [0.4956932378161706, 0.449], "policy_red_v77_reward": [-0.1549999999999998], "policy_red_v65_reward": [-2.001], "policy_red_v7_reward": [-1.0039999999999998], "policy_red_v29_reward": [1.5026932378161701]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8197301866124858, "mean_inference_ms": 7.640394562172828, "mean_action_processing_ms": 0.29188444692690335, "mean_env_wait_ms": 0.39283054362333225, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10044419765472412, "StateBufferConnector_ms": 0.0042160749435424805, "ViewRequirementAgentConnector_ms": 0.11600387096405029}}, "episode_reward_max": 4.4885896006323405, "episode_reward_min": -0.5713750000000001, "episode_reward_mean": 2.3584244344341467, "episode_len_mean": 57.77, "episodes_this_iter": 43, "policy_reward_min": {"red_v22": 1.4789346144425923, "red": -1.49330676218383, "red_v34": -1.064999999999997, "blue": -2.011999999999999, "red_v37": -2.0089999999999995, "red_v60": -2.0059999999999993, "red_v51": -1.5179999999999998, "red_v68": -2.006, "red_v31": -0.037000000000000026, "red_v39": -0.556, "red_v6": -2.006, "red_v54": -0.559, "red_v8": -1.0139999999999998, "red_v28": -2.0039999999999996, "red_v18": -1.5950000000000002, "red_v79": 0.4814218750000001, "red_v24": -2.5409999999999737, "red_v10": -2.0139999999999993, "red_v42": 0.459692542772946, "red_v58": -1.0059999999999998, "red_v53": -1.001, "red_v30": 0.50569323781617, "red_v69": -2.01, "red_v4": -1.0089999999999992, "red_v14": 1.977125, "red_v61": -2.0089999999999995, "red_v45": 1.5056932378161698, "red_v56": -1.005, "red_v72": -1.509, "red_v52": -1.0049999999999994, "red_v50": -0.5539999999999999, "red_v12": -1.023, "red_v33": -0.1549999999999998, "red_v46": 0.503103033544055, "red_v47": 0.449, "red_v77": -0.1549999999999998, "red_v65": -2.001, "red_v7": -1.0039999999999998, "red_v29": 1.5026932378161701}, "policy_reward_max": {"red_v22": 1.4789346144425923, "red": 3.9933338628152035, "red_v34": -1.0089999999999992, "blue": 1.7633281250000008, "red_v37": -0.001, "red_v60": -1.0039999999999998, "red_v51": 0.17505000000000015, "red_v68": -1.0049999999999997, "red_v31": 1.5036932378161698, "red_v39": -0.556, "red_v6": -2.006, "red_v54": -0.559, "red_v8": -1.0139999999999998, "red_v28": -1.007, "red_v18": -1.5950000000000002, "red_v79": 0.498103033544055, "red_v24": -2.5409999999999737, "red_v10": -1.038999999999997, "red_v42": 0.459692542772946, "red_v58": -1.0059999999999998, "red_v53": -1.001, "red_v30": 2.024255737816178, "red_v69": -1.0059999999999998, "red_v4": -1.0089999999999992, "red_v14": 1.977125, "red_v61": -0.5539999999999999, "red_v45": 1.5056932378161698, "red_v56": -1.005, "red_v72": -1.509, "red_v52": 0.48310303354405637, "red_v50": -0.5539999999999999, "red_v12": -0.5139999999999999, "red_v33": -0.1549999999999998, "red_v46": 0.503103033544055, "red_v47": 0.4956932378161706, "red_v77": -0.1549999999999998, "red_v65": -2.001, "red_v7": -1.0039999999999998, "red_v29": 1.5026932378161701}, "policy_reward_mean": {"red_v22": 1.4789346144425923, "red": 3.122876737830385, "red_v34": -1.0369999999999981, "blue": -1.031810973837209, "red_v37": -0.8646666666666665, "red_v60": -1.3429999999999997, "red_v51": -0.6714749999999998, "red_v68": -1.5054999999999996, "red_v31": 0.6581288252104579, "red_v39": -0.556, "red_v6": -2.006, "red_v54": -0.559, "red_v8": -1.0139999999999998, "red_v28": -1.5054999999999996, "red_v18": -1.5950000000000002, "red_v79": 0.4904060487867419, "red_v24": -2.5409999999999737, "red_v10": -1.5264999999999982, "red_v42": 0.459692542772946, "red_v58": -1.0059999999999998, "red_v53": -1.001, "red_v30": 1.2649744878161742, "red_v69": -1.5079999999999998, "red_v4": -1.0089999999999992, "red_v14": 1.977125, "red_v61": -1.5216666666666665, "red_v45": 1.5056932378161698, "red_v56": -1.005, "red_v72": -1.509, "red_v52": -0.26094848322797154, "red_v50": -0.5539999999999999, "red_v12": -0.7685, "red_v33": -0.1549999999999998, "red_v46": 0.503103033544055, "red_v47": 0.47234661890808527, "red_v77": -0.1549999999999998, "red_v65": -2.001, "red_v7": -1.0039999999999998, "red_v29": 1.5026932378161701}, "hist_stats": {"episode_reward": [4.462018477258763, 2.389255737816173, 2.9650838628161704, 2.4811151128152042, 2.4684901128161716, 1.4770057378161705, 2.8661776128161733, 2.48452136281617, 2.4697088628161703, 3.653430737816171, 1.6676125000000006, 2.9173651128161726, 0.91759948781617, 0.45456823781616973, 2.48000573781617, 2.93181823781617, 4.4885896006323405, 2.472083862816171, 4.000733771359259, 0.8370468750000002, 1.9840057378161706, 1.98711511281617, 2.9189814894425923, 1.9710838628161707, 2.472896362816171, 2.37692423, 1.988333167772942, 2.9145213628161724, 2.489630737815204, 2.4688721144425925, 2.476302612815204, 2.890990112816172, 1.290568237816171, 2.4681619878161705, 3.9444646006323416, 1.1364744878161945, 2.960943237816171, 2.426615112816173, 3.908432655589116, 2.1648, 0.950130737816171, 2.48670886281617, 2.489333862815204, 2.3773304800000004, 2.4661619878161707, 3.99129272563234, 0.9550526128161713, 1.48992761281617, 2.468974487816171, 1.476926917772942, 2.4989489756323597, 2.4826300427729424, 2.4760057378161706, 1.6591750000000003, 2.479228033544055, 2.92519323781617, 4.48255835063234, 0.6860994878161704, 1.154175000000001, 1.8046619878161743, 2.3764086050000004, -0.5713750000000001, 2.98781823781617, 1.48463073781617, 2.48411511281617, 3.8911868963602307, 2.9389276128161703, 0.2700213628161725, 2.4788963628161698, 3.9745618963602247, 1.9903338628152039, 1.9628651128161703, 0.17989374999999974, 2.469677612816171, 2.436615112816172, 1.4764901128161705, 1.4720092835440557, 2.468271362816171, 3.3333026128161705, 1.4510994878161707, 2.4761151128161702, 2.4807088628161704, 2.470974487816171, 3.9922181463602247, 1.9828963628161698, 2.4781151128161705, 2.4602401128161704, 3.9670427256323406, 3.32878698781617, 1.4703494878161698, 2.4544901128161705, 2.4841151128161703, 2.483223792772942, 2.4577557378161714, 4.4784489756323405, 1.48681823781617, 2.4730838628161704, 1.4872237927729421, 0.329421875, 3.1198], "episode_lengths": [35, 76, 35, 25, 33, 28, 69, 23, 27, 36, 12, 73, 94, 40, 28, 24, 31, 35, 20, 17, 28, 25, 17, 35, 31, 19, 19, 87, 20, 20, 29, 65, 168, 42, 71, 454, 48, 57, 81, 16, 52, 27, 19, 17, 42, 30, 45, 21, 38, 21, 460, 20, 28, 24, 24, 32, 41, 254, 24, 202, 24, 56, 24, 20, 25, 99, 21, 247, 31, 43, 19, 41, 690, 37, 57, 33, 30, 39, 29, 62, 25, 27, 38, 25, 31, 25, 49, 46, 34, 46, 33, 25, 22, 44, 44, 24, 35, 22, 25, 16], "policy_red_v22_reward": [1.4789346144425923], "policy_red_v34_reward": [-1.064999999999997, -1.0089999999999992], "policy_blue_reward": [-0.013000000000000001, -1.0069999999999997, -1.0119999999999998, -1.0079999999999998, 0.4099062499999999, -1.518, -1.0069999999999995, -1.009, -2.0039999999999996, -2.0029999999999997, -2.011999999999999, -0.026000000000000016, -1.0039999999999998, -1.0019999999999998, -1.0079999999999998, -0.5679999999999996, -1.0069999999999992, -0.511, -1.515999999999999, -1.003, -1.0089999999999997, -2.003, -1.010999999999999, -1.0089999999999997, -1.0099999999999998, -1.5739999999999998, -2.005, -1.059, 1.7633281250000008, -2.003, 1.4948937500000012, -1.0089999999999997, -1.0229999999999992, -2.0069999999999997, -1.0109999999999992, -1.0079999999999996, -1.0059999999999993, -1.009999999999999, -1.0119999999999998, -1.0069999999999995, -1.0129999999999995, -2.0039999999999996, -2.005], "policy_red_v37_reward": [-2.0089999999999995, -0.5840000000000001, -0.001], "policy_red_v60_reward": [-1.019, -1.0039999999999998, -2.0059999999999993], "policy_red_v51_reward": [0.17505000000000015, -1.5179999999999998], "policy_red_v68_reward": [-2.006, -1.0049999999999997], "policy_red_v31_reward": [-0.037000000000000026, 1.5036932378161698, 0.5076932378152038], "policy_red_v39_reward": [-0.556], "policy_red_v6_reward": [-2.006], "policy_red_v54_reward": [-0.559], "policy_red_v8_reward": [-1.0139999999999998], "policy_red_v28_reward": [-2.0039999999999996, -1.007], "policy_red_v18_reward": [-1.5950000000000002], "policy_red_v79_reward": [0.4916932378161706, 0.498103033544055, 0.4814218750000001], "policy_red_v24_reward": [-2.5409999999999737], "policy_red_v10_reward": [-1.038999999999997, -2.0139999999999993], "policy_red_v42_reward": [0.459692542772946], "policy_red_v58_reward": [-1.0059999999999998], "policy_red_v53_reward": [-1.001], "policy_red_v30_reward": [0.50569323781617, 2.024255737816178], "policy_red_v69_reward": [-2.01, -1.0059999999999998], "policy_red_v4_reward": [-1.0089999999999992], "policy_red_v14_reward": [1.977125], "policy_red_v61_reward": [-0.5539999999999999, -2.0089999999999995, -2.002], "policy_red_v45_reward": [1.5056932378161698], "policy_red_v56_reward": [-1.005], "policy_red_v72_reward": [-1.509], "policy_red_v52_reward": [0.48310303354405637, -1.0049999999999994], "policy_red_v50_reward": [-0.5539999999999999], "policy_red_v12_reward": [-0.5139999999999999, -1.023], "policy_red_v33_reward": [-0.1549999999999998], "policy_red_v46_reward": [0.503103033544055], "policy_red_v47_reward": [0.4956932378161706, 0.449], "policy_red_v77_reward": [-0.1549999999999998], "policy_red_v65_reward": [-2.001], "policy_red_v7_reward": [-1.0039999999999998], "policy_red_v29_reward": [1.5026932378161701]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8197301866124858, "mean_inference_ms": 7.640394562172828, "mean_action_processing_ms": 0.29188444692690335, "mean_env_wait_ms": 0.39283054362333225, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10044419765472412, "StateBufferConnector_ms": 0.0042160749435424805, "ViewRequirementAgentConnector_ms": 0.11600387096405029}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.51149863302433, "num_env_steps_trained_throughput_per_sec": 199.51149863302433, "timesteps_total": 456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 20009.371, "sample_time_ms": 1179.961, "learn_time_ms": 18744.037, "learn_throughput": 213.401, "synch_weights_time_ms": 81.86}, "counters": {"num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "episodes_total": 2521, "training_iteration": 114, "trial_id": "a9680_00000", "date": "2023-09-24_03-18-50", "timestamp": 1695539930, "time_this_iter_s": 20.060514211654663, "time_total_s": 2274.2108960151672, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dc7e5c0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1ddc1120>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1ddc09d0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2274.2108960151672, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 5.431428571428572, "ram_util_percent": 26.468571428571426}, "win_rate": 0.8, "league_size": 83}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.222003649547696, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.02310242770399782, "policy_loss": -0.04415186422023301, "vf_loss": 0.12297586522375543, "vf_explained_var": 0.8564712958410382, "kl": 0.01608191440353086, "entropy": 1.4705017565439145, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 109920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_agent_steps_sampled": 920000, "num_agent_steps_trained": 920000}, "sampler_results": {"episode_reward_max": 4.489995850632339, "episode_reward_min": -1.0937163949999824, "episode_reward_mean": 2.2775459133139653, "episode_len_mean": 113.24, "episode_media": {}, "episodes_this_iter": 47, "policy_reward_min": {"blue": -2.019999999999998, "red": -3.684716394999999, "red_v69": -2.01, "red_v30": 2.024255737816178, "red_v4": -1.0089999999999992, "red_v14": 1.977125, "red_v61": -2.0089999999999995, "red_v45": 0.8143281249999998, "red_v56": -1.005, "red_v72": -1.509, "red_v37": -0.001, "red_v52": -1.0049999999999994, "red_v50": -0.5539999999999999, "red_v28": -1.007, "red_v79": 0.4814218750000001, "red_v12": -1.023, "red_v10": -2.0139999999999993, "red_v33": -0.1549999999999998, "red_v60": -2.0059999999999993, "red_v46": 0.503103033544055, "red_v34": -1.0089999999999992, "red_v47": 0.449, "red_v77": -0.1549999999999998, "red_v65": -2.001, "red_v7": -1.0039999999999998, "red_v29": 1.5026932378161701, "red_v8": -1.0079999999999996, "red_v68": 0.790283605000001, "red_v23": -0.01989696645594452, "red_v54": 0.49169323781617036, "red_v38": 0.5041030335440548, "red_v13": -1.0129999999999997, "red_v2": -2.0060000000000002, "red_v25": -1.506, "red_v71": -1.5099999999999993, "red_v42": -1.0159999999999996, "red_v17": -1.008, "red_v53": 0.4986932378152039, "red_v35": 1.50469323781617, "red_v64": -0.07294999999997742, "red_v78": -2.003, "red_v55": 1.5056932378161703, "red_v31": 2.3683494878161744, "red_v70": -1.0059999999999996}, "policy_reward_max": {"blue": 2.591000000000031, "red": 3.9933338628152035, "red_v69": -1.0059999999999998, "red_v30": 2.024255737816178, "red_v4": -1.0089999999999992, "red_v14": 1.977125, "red_v61": -0.5539999999999999, "red_v45": 1.5056932378161698, "red_v56": 1.1956932378162006, "red_v72": -1.509, "red_v37": -0.001, "red_v52": 2.4180405335440573, "red_v50": -0.5539999999999999, "red_v28": -1.007, "red_v79": 0.498103033544055, "red_v12": -0.5139999999999999, "red_v10": -2.0139999999999993, "red_v33": -0.1549999999999998, "red_v60": -2.0059999999999993, "red_v46": 0.503103033544055, "red_v34": -1.0089999999999992, "red_v47": 0.4956932378161706, "red_v77": -0.1549999999999998, "red_v65": 1.8990369878161784, "red_v7": -1.0039999999999998, "red_v29": 1.5026932378161701, "red_v8": -1.0079999999999996, "red_v68": 0.790283605000001, "red_v23": -0.01989696645594452, "red_v54": 0.49169323781617036, "red_v38": 0.5041030335440548, "red_v13": -0.5579999999999999, "red_v2": -2.0060000000000002, "red_v25": 0.5051030335440551, "red_v71": -1.0449999999999955, "red_v42": -1.0159999999999996, "red_v17": -1.008, "red_v53": 0.4986932378152039, "red_v35": 1.50469323781617, "red_v64": -0.07294999999997742, "red_v78": -2.003, "red_v55": 1.5056932378161703, "red_v31": 2.3683494878161744, "red_v70": -1.0059999999999996}, "policy_reward_mean": {"blue": -0.85121504360465, "red": 2.777777827506111, "red_v69": -1.5079999999999998, "red_v30": 2.024255737816178, "red_v4": -1.0089999999999992, "red_v14": 1.977125, "red_v61": -1.5216666666666665, "red_v45": 1.1600106814080848, "red_v56": 0.09534661890810037, "red_v72": -1.509, "red_v37": -0.001, "red_v52": 0.3457858917720286, "red_v50": -0.5539999999999999, "red_v28": -1.007, "red_v79": 0.4897624542720276, "red_v12": -0.7685, "red_v10": -2.0139999999999993, "red_v33": -0.1549999999999998, "red_v60": -2.0059999999999993, "red_v46": 0.503103033544055, "red_v34": -1.0089999999999992, "red_v47": 0.47234661890808527, "red_v77": -0.1549999999999998, "red_v65": -0.05098150609191077, "red_v7": -1.0039999999999998, "red_v29": 1.5026932378161701, "red_v8": -1.0079999999999996, "red_v68": 0.790283605000001, "red_v23": -0.01989696645594452, "red_v54": 0.49169323781617036, "red_v38": 0.5041030335440548, "red_v13": -0.7854999999999999, "red_v2": -2.0060000000000002, "red_v25": -0.5004484832279725, "red_v71": -1.2774999999999974, "red_v42": -1.0159999999999996, "red_v17": -1.008, "red_v53": 0.4986932378152039, "red_v35": 1.50469323781617, "red_v64": -0.07294999999997742, "red_v78": -2.003, "red_v55": 1.5056932378161703, "red_v31": 2.3683494878161744, "red_v70": -1.0059999999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.48992761281617, 2.468974487816171, 1.476926917772942, 2.4989489756323597, 2.4826300427729424, 2.4760057378161706, 1.6591750000000003, 2.479228033544055, 2.92519323781617, 4.48255835063234, 0.6860994878161704, 1.154175000000001, 1.8046619878161743, 2.3764086050000004, -0.5713750000000001, 2.98781823781617, 1.48463073781617, 2.48411511281617, 3.8911868963602307, 2.9389276128161703, 0.2700213628161725, 2.4788963628161698, 3.9745618963602247, 1.9903338628152039, 1.9628651128161703, 0.17989374999999974, 2.469677612816171, 2.436615112816172, 1.4764901128161705, 1.4720092835440557, 2.468271362816171, 3.3333026128161705, 1.4510994878161707, 2.4761151128161702, 2.4807088628161704, 2.470974487816171, 3.9922181463602247, 1.9828963628161698, 2.4781151128161705, 2.4602401128161704, 3.9670427256323406, 3.32878698781617, 1.4703494878161698, 2.4544901128161705, 2.4841151128161703, 2.483223792772942, 2.4577557378161714, 4.4784489756323405, 1.48681823781617, 2.4730838628161704, 1.4872237927729421, 0.329421875, 3.1198, -1.0937163949999824, 2.4830405335440555, 2.288976842816183, 2.4136712713602275, 1.9642713628161712, 3.918839600632342, 2.970083862816171, 3.998030646360225, -0.6187968750000005, 2.1668000000000003, 2.9244119878161703, 1.1686125000000005, 0.9733026128161705, 2.2664432378161794, 2.4648963628161704, 2.9227337713602277, 2.4792244878161704, 1.9841151128161703, 1.9470213628161714, 2.313471105, 2.4293963628161728, 2.1643864756324325, 2.4501307378161705, 2.4805213628161704, 3.987511475631374, 4.489995850632339, 0.9228281250000002, 1.9537244878161713, 0.7668182378161715, 2.4532401128161725, 2.4865213628161698, 2.480853033544055, 2.8675179800000006, 2.193305737816199, 2.485634283544055, 0.778021362816173, 2.4726776128161707, 2.464270667772942, 2.382730225632353, 1.9590213628161708, 3.991218146359259, 1.4869276128161695, 2.9882244878152036, 4.48940210063234, 2.867042725632347, 0.8420369878161705, 2.4831151128161704], "episode_lengths": [21, 38, 21, 460, 20, 28, 24, 24, 32, 41, 254, 24, 202, 24, 56, 24, 20, 25, 99, 21, 247, 31, 43, 19, 41, 690, 37, 57, 33, 30, 39, 29, 62, 25, 27, 38, 25, 31, 25, 49, 46, 34, 46, 33, 25, 22, 44, 44, 24, 35, 22, 25, 16, 1280, 20, 1280, 104, 39, 79, 35, 21, 799, 16, 26, 12, 29, 208, 31, 84, 22, 25, 55, 68, 63, 1280, 52, 23, 24, 29, 23, 54, 216, 49, 23, 16, 21, 332, 22, 119, 37, 39, 722, 55, 25, 21, 22, 27, 110, 210, 25], "policy_blue_reward": [-2.003, -1.010999999999999, -1.0089999999999997, -1.0099999999999998, -1.5739999999999998, -2.005, -1.059, 1.7633281250000008, -2.003, 1.4948937500000012, -1.0089999999999997, -1.0229999999999992, -2.0069999999999997, -1.0109999999999992, -1.0079999999999996, -1.0059999999999993, -1.009999999999999, -1.0119999999999998, -1.0069999999999995, -1.0129999999999995, -2.0039999999999996, -2.005, 2.591000000000031, -2.014999999999999, -0.008, 0.6402031250000001, -1.002, -2.0069999999999992, -2.019999999999998, -1.016999999999999, -1.0179999999999998, -1.0119999999999993, -1.0099999999999993, -0.5079999999999999, -1.584, -1.0179999999999985, -1.0039999999999998, -0.010000000000000002, -1.005, -1.0079999999999993, -1.0059999999999998, 1.9523281250000002, -0.003], "policy_red_v69_reward": [-2.01, -1.0059999999999998], "policy_red_v30_reward": [2.024255737816178], "policy_red_v4_reward": [-1.0089999999999992], "policy_red_v14_reward": [1.977125], "policy_red_v61_reward": [-0.5539999999999999, -2.0089999999999995, -2.002], "policy_red_v45_reward": [1.5056932378161698, 0.8143281249999998], "policy_red_v56_reward": [-1.005, 1.1956932378162006], "policy_red_v72_reward": [-1.509], "policy_red_v37_reward": [-0.001], "policy_red_v52_reward": [0.48310303354405637, -1.0049999999999994, 2.4180405335440573, -0.5129999999999997], "policy_red_v50_reward": [-0.5539999999999999], "policy_red_v28_reward": [-1.007], "policy_red_v79_reward": [0.498103033544055, 0.4814218750000001], "policy_red_v12_reward": [-0.5139999999999999, -1.023], "policy_red_v10_reward": [-2.0139999999999993], "policy_red_v33_reward": [-0.1549999999999998], "policy_red_v60_reward": [-2.0059999999999993], "policy_red_v46_reward": [0.503103033544055], "policy_red_v34_reward": [-1.0089999999999992], "policy_red_v47_reward": [0.4956932378161706, 0.449], "policy_red_v77_reward": [-0.1549999999999998], "policy_red_v65_reward": [-2.001, 1.8990369878161784], "policy_red_v7_reward": [-1.0039999999999998], "policy_red_v29_reward": [1.5026932378161701], "policy_red_v8_reward": [-1.0079999999999996], "policy_red_v68_reward": [0.790283605000001], "policy_red_v23_reward": [-0.01989696645594452], "policy_red_v54_reward": [0.49169323781617036], "policy_red_v38_reward": [0.5041030335440548], "policy_red_v13_reward": [-0.5579999999999999, -1.0129999999999997], "policy_red_v2_reward": [-2.0060000000000002], "policy_red_v25_reward": [-1.506, 0.5051030335440551], "policy_red_v71_reward": [-1.0449999999999955, -1.5099999999999993], "policy_red_v42_reward": [-1.0159999999999996], "policy_red_v17_reward": [-1.008], "policy_red_v53_reward": [0.4986932378152039], "policy_red_v35_reward": [1.50469323781617], "policy_red_v64_reward": [-0.07294999999997742], "policy_red_v78_reward": [-2.003], "policy_red_v55_reward": [1.5056932378161703], "policy_red_v31_reward": [2.3683494878161744], "policy_red_v70_reward": [-1.0059999999999996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8205551269852627, "mean_inference_ms": 7.6608641184626745, "mean_action_processing_ms": 0.2924872004785526, "mean_env_wait_ms": 0.39304506367022307, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09936881065368652, "StateBufferConnector_ms": 0.0041893720626831055, "ViewRequirementAgentConnector_ms": 0.11466062068939209}}, "episode_reward_max": 4.489995850632339, "episode_reward_min": -1.0937163949999824, "episode_reward_mean": 2.2775459133139653, "episode_len_mean": 113.24, "episodes_this_iter": 47, "policy_reward_min": {"blue": -2.019999999999998, "red": -3.684716394999999, "red_v69": -2.01, "red_v30": 2.024255737816178, "red_v4": -1.0089999999999992, "red_v14": 1.977125, "red_v61": -2.0089999999999995, "red_v45": 0.8143281249999998, "red_v56": -1.005, "red_v72": -1.509, "red_v37": -0.001, "red_v52": -1.0049999999999994, "red_v50": -0.5539999999999999, "red_v28": -1.007, "red_v79": 0.4814218750000001, "red_v12": -1.023, "red_v10": -2.0139999999999993, "red_v33": -0.1549999999999998, "red_v60": -2.0059999999999993, "red_v46": 0.503103033544055, "red_v34": -1.0089999999999992, "red_v47": 0.449, "red_v77": -0.1549999999999998, "red_v65": -2.001, "red_v7": -1.0039999999999998, "red_v29": 1.5026932378161701, "red_v8": -1.0079999999999996, "red_v68": 0.790283605000001, "red_v23": -0.01989696645594452, "red_v54": 0.49169323781617036, "red_v38": 0.5041030335440548, "red_v13": -1.0129999999999997, "red_v2": -2.0060000000000002, "red_v25": -1.506, "red_v71": -1.5099999999999993, "red_v42": -1.0159999999999996, "red_v17": -1.008, "red_v53": 0.4986932378152039, "red_v35": 1.50469323781617, "red_v64": -0.07294999999997742, "red_v78": -2.003, "red_v55": 1.5056932378161703, "red_v31": 2.3683494878161744, "red_v70": -1.0059999999999996}, "policy_reward_max": {"blue": 2.591000000000031, "red": 3.9933338628152035, "red_v69": -1.0059999999999998, "red_v30": 2.024255737816178, "red_v4": -1.0089999999999992, "red_v14": 1.977125, "red_v61": -0.5539999999999999, "red_v45": 1.5056932378161698, "red_v56": 1.1956932378162006, "red_v72": -1.509, "red_v37": -0.001, "red_v52": 2.4180405335440573, "red_v50": -0.5539999999999999, "red_v28": -1.007, "red_v79": 0.498103033544055, "red_v12": -0.5139999999999999, "red_v10": -2.0139999999999993, "red_v33": -0.1549999999999998, "red_v60": -2.0059999999999993, "red_v46": 0.503103033544055, "red_v34": -1.0089999999999992, "red_v47": 0.4956932378161706, "red_v77": -0.1549999999999998, "red_v65": 1.8990369878161784, "red_v7": -1.0039999999999998, "red_v29": 1.5026932378161701, "red_v8": -1.0079999999999996, "red_v68": 0.790283605000001, "red_v23": -0.01989696645594452, "red_v54": 0.49169323781617036, "red_v38": 0.5041030335440548, "red_v13": -0.5579999999999999, "red_v2": -2.0060000000000002, "red_v25": 0.5051030335440551, "red_v71": -1.0449999999999955, "red_v42": -1.0159999999999996, "red_v17": -1.008, "red_v53": 0.4986932378152039, "red_v35": 1.50469323781617, "red_v64": -0.07294999999997742, "red_v78": -2.003, "red_v55": 1.5056932378161703, "red_v31": 2.3683494878161744, "red_v70": -1.0059999999999996}, "policy_reward_mean": {"blue": -0.85121504360465, "red": 2.777777827506111, "red_v69": -1.5079999999999998, "red_v30": 2.024255737816178, "red_v4": -1.0089999999999992, "red_v14": 1.977125, "red_v61": -1.5216666666666665, "red_v45": 1.1600106814080848, "red_v56": 0.09534661890810037, "red_v72": -1.509, "red_v37": -0.001, "red_v52": 0.3457858917720286, "red_v50": -0.5539999999999999, "red_v28": -1.007, "red_v79": 0.4897624542720276, "red_v12": -0.7685, "red_v10": -2.0139999999999993, "red_v33": -0.1549999999999998, "red_v60": -2.0059999999999993, "red_v46": 0.503103033544055, "red_v34": -1.0089999999999992, "red_v47": 0.47234661890808527, "red_v77": -0.1549999999999998, "red_v65": -0.05098150609191077, "red_v7": -1.0039999999999998, "red_v29": 1.5026932378161701, "red_v8": -1.0079999999999996, "red_v68": 0.790283605000001, "red_v23": -0.01989696645594452, "red_v54": 0.49169323781617036, "red_v38": 0.5041030335440548, "red_v13": -0.7854999999999999, "red_v2": -2.0060000000000002, "red_v25": -0.5004484832279725, "red_v71": -1.2774999999999974, "red_v42": -1.0159999999999996, "red_v17": -1.008, "red_v53": 0.4986932378152039, "red_v35": 1.50469323781617, "red_v64": -0.07294999999997742, "red_v78": -2.003, "red_v55": 1.5056932378161703, "red_v31": 2.3683494878161744, "red_v70": -1.0059999999999996}, "hist_stats": {"episode_reward": [1.48992761281617, 2.468974487816171, 1.476926917772942, 2.4989489756323597, 2.4826300427729424, 2.4760057378161706, 1.6591750000000003, 2.479228033544055, 2.92519323781617, 4.48255835063234, 0.6860994878161704, 1.154175000000001, 1.8046619878161743, 2.3764086050000004, -0.5713750000000001, 2.98781823781617, 1.48463073781617, 2.48411511281617, 3.8911868963602307, 2.9389276128161703, 0.2700213628161725, 2.4788963628161698, 3.9745618963602247, 1.9903338628152039, 1.9628651128161703, 0.17989374999999974, 2.469677612816171, 2.436615112816172, 1.4764901128161705, 1.4720092835440557, 2.468271362816171, 3.3333026128161705, 1.4510994878161707, 2.4761151128161702, 2.4807088628161704, 2.470974487816171, 3.9922181463602247, 1.9828963628161698, 2.4781151128161705, 2.4602401128161704, 3.9670427256323406, 3.32878698781617, 1.4703494878161698, 2.4544901128161705, 2.4841151128161703, 2.483223792772942, 2.4577557378161714, 4.4784489756323405, 1.48681823781617, 2.4730838628161704, 1.4872237927729421, 0.329421875, 3.1198, -1.0937163949999824, 2.4830405335440555, 2.288976842816183, 2.4136712713602275, 1.9642713628161712, 3.918839600632342, 2.970083862816171, 3.998030646360225, -0.6187968750000005, 2.1668000000000003, 2.9244119878161703, 1.1686125000000005, 0.9733026128161705, 2.2664432378161794, 2.4648963628161704, 2.9227337713602277, 2.4792244878161704, 1.9841151128161703, 1.9470213628161714, 2.313471105, 2.4293963628161728, 2.1643864756324325, 2.4501307378161705, 2.4805213628161704, 3.987511475631374, 4.489995850632339, 0.9228281250000002, 1.9537244878161713, 0.7668182378161715, 2.4532401128161725, 2.4865213628161698, 2.480853033544055, 2.8675179800000006, 2.193305737816199, 2.485634283544055, 0.778021362816173, 2.4726776128161707, 2.464270667772942, 2.382730225632353, 1.9590213628161708, 3.991218146359259, 1.4869276128161695, 2.9882244878152036, 4.48940210063234, 2.867042725632347, 0.8420369878161705, 2.4831151128161704], "episode_lengths": [21, 38, 21, 460, 20, 28, 24, 24, 32, 41, 254, 24, 202, 24, 56, 24, 20, 25, 99, 21, 247, 31, 43, 19, 41, 690, 37, 57, 33, 30, 39, 29, 62, 25, 27, 38, 25, 31, 25, 49, 46, 34, 46, 33, 25, 22, 44, 44, 24, 35, 22, 25, 16, 1280, 20, 1280, 104, 39, 79, 35, 21, 799, 16, 26, 12, 29, 208, 31, 84, 22, 25, 55, 68, 63, 1280, 52, 23, 24, 29, 23, 54, 216, 49, 23, 16, 21, 332, 22, 119, 37, 39, 722, 55, 25, 21, 22, 27, 110, 210, 25], "policy_blue_reward": [-2.003, -1.010999999999999, -1.0089999999999997, -1.0099999999999998, -1.5739999999999998, -2.005, -1.059, 1.7633281250000008, -2.003, 1.4948937500000012, -1.0089999999999997, -1.0229999999999992, -2.0069999999999997, -1.0109999999999992, -1.0079999999999996, -1.0059999999999993, -1.009999999999999, -1.0119999999999998, -1.0069999999999995, -1.0129999999999995, -2.0039999999999996, -2.005, 2.591000000000031, -2.014999999999999, -0.008, 0.6402031250000001, -1.002, -2.0069999999999992, -2.019999999999998, -1.016999999999999, -1.0179999999999998, -1.0119999999999993, -1.0099999999999993, -0.5079999999999999, -1.584, -1.0179999999999985, -1.0039999999999998, -0.010000000000000002, -1.005, -1.0079999999999993, -1.0059999999999998, 1.9523281250000002, -0.003], "policy_red_v69_reward": [-2.01, -1.0059999999999998], "policy_red_v30_reward": [2.024255737816178], "policy_red_v4_reward": [-1.0089999999999992], "policy_red_v14_reward": [1.977125], "policy_red_v61_reward": [-0.5539999999999999, -2.0089999999999995, -2.002], "policy_red_v45_reward": [1.5056932378161698, 0.8143281249999998], "policy_red_v56_reward": [-1.005, 1.1956932378162006], "policy_red_v72_reward": [-1.509], "policy_red_v37_reward": [-0.001], "policy_red_v52_reward": [0.48310303354405637, -1.0049999999999994, 2.4180405335440573, -0.5129999999999997], "policy_red_v50_reward": [-0.5539999999999999], "policy_red_v28_reward": [-1.007], "policy_red_v79_reward": [0.498103033544055, 0.4814218750000001], "policy_red_v12_reward": [-0.5139999999999999, -1.023], "policy_red_v10_reward": [-2.0139999999999993], "policy_red_v33_reward": [-0.1549999999999998], "policy_red_v60_reward": [-2.0059999999999993], "policy_red_v46_reward": [0.503103033544055], "policy_red_v34_reward": [-1.0089999999999992], "policy_red_v47_reward": [0.4956932378161706, 0.449], "policy_red_v77_reward": [-0.1549999999999998], "policy_red_v65_reward": [-2.001, 1.8990369878161784], "policy_red_v7_reward": [-1.0039999999999998], "policy_red_v29_reward": [1.5026932378161701], "policy_red_v8_reward": [-1.0079999999999996], "policy_red_v68_reward": [0.790283605000001], "policy_red_v23_reward": [-0.01989696645594452], "policy_red_v54_reward": [0.49169323781617036], "policy_red_v38_reward": [0.5041030335440548], "policy_red_v13_reward": [-0.5579999999999999, -1.0129999999999997], "policy_red_v2_reward": [-2.0060000000000002], "policy_red_v25_reward": [-1.506, 0.5051030335440551], "policy_red_v71_reward": [-1.0449999999999955, -1.5099999999999993], "policy_red_v42_reward": [-1.0159999999999996], "policy_red_v17_reward": [-1.008], "policy_red_v53_reward": [0.4986932378152039], "policy_red_v35_reward": [1.50469323781617], "policy_red_v64_reward": [-0.07294999999997742], "policy_red_v78_reward": [-2.003], "policy_red_v55_reward": [1.5056932378161703], "policy_red_v31_reward": [2.3683494878161744], "policy_red_v70_reward": [-1.0059999999999996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8205551269852627, "mean_inference_ms": 7.6608641184626745, "mean_action_processing_ms": 0.2924872004785526, "mean_env_wait_ms": 0.39304506367022307, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09936881065368652, "StateBufferConnector_ms": 0.0041893720626831055, "ViewRequirementAgentConnector_ms": 0.11466062068939209}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 920000, "num_agent_steps_trained": 920000, "num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 203.61302455104314, "num_env_steps_trained_throughput_per_sec": 203.61302455104314, "timesteps_total": 460000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 920000, "timers": {"training_iteration_time_ms": 19946.597, "sample_time_ms": 1185.544, "learn_time_ms": 18676.002, "learn_throughput": 214.179, "synch_weights_time_ms": 81.63}, "counters": {"num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_agent_steps_sampled": 920000, "num_agent_steps_trained": 920000}, "done": false, "episodes_total": 2568, "training_iteration": 115, "trial_id": "a9680_00000", "date": "2023-09-24_03-19-14", "timestamp": 1695539954, "time_this_iter_s": 19.655949115753174, "time_total_s": 2293.8668451309204, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dc7c340>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1dc65b40>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1dc65bd0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2293.8668451309204, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 5.411764705882353, "ram_util_percent": 26.57058823529412}, "win_rate": 0.73, "league_size": 84}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.411305969208479, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.06747790879547513, "policy_loss": -0.03830590248592974, "vf_loss": 0.20147022719029337, "vf_explained_var": 0.7815719558546941, "kl": 0.014234548510088037, "entropy": 1.356849042698741, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 110880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "sampler_results": {"episode_reward_max": 4.489995850632339, "episode_reward_min": -0.6187968750000005, "episode_reward_mean": 2.2959785264692893, "episode_len_mean": 90.88, "episode_media": {}, "episodes_this_iter": 58, "policy_reward_min": {"red_v54": 0.49169323781617036, "red": -1.2590000000000001, "blue": -2.019999999999998, "red_v38": -2.033999999999998, "red_v13": -1.0129999999999997, "red_v2": -2.0060000000000002, "red_v25": -1.506, "red_v71": -1.522, "red_v42": -1.0159999999999996, "red_v52": -0.5129999999999997, "red_v17": -1.008, "red_v56": 1.1956932378162006, "red_v53": 0.4986932378152039, "red_v35": 1.50469323781617, "red_v64": -2.002, "red_v45": 0.8143281249999998, "red_v65": 1.8990369878161784, "red_v78": -2.0479999999999947, "red_v55": 1.5056932378161703, "red_v31": 2.3683494878161744, "red_v70": -1.0059999999999996, "red_v62": 0.39328360500000026, "red_v5": -1.0119999999999993, "red_v43": 0.5036932378161698, "red_v75": -2.0060000000000002, "red_v33": -0.026000000000000016, "red_v41": -0.005, "red_v51": 0.34076562500000007, "red_v37": -2.0299999999999994, "red_v66": -0.002, "red_v32": -1.006, "red_v23": -1.8160000000000003, "red_v73": -2.005, "red_v79": -2.0079999999999996, "red_v44": 1.4849346144425921, "red_v22": -0.5619999999999999}, "policy_reward_max": {"red_v54": 0.5001030335440549, "red": 3.99533386281617, "blue": 1.9523281250000002, "red_v38": 0.5041030335440548, "red_v13": -0.5579999999999999, "red_v2": -2.006, "red_v25": 0.5051030335440551, "red_v71": -1.0449999999999955, "red_v42": -1.0159999999999996, "red_v52": 2.4180405335440573, "red_v17": -1.008, "red_v56": 1.1956932378162006, "red_v53": 0.4986932378152039, "red_v35": 1.9656093749999999, "red_v64": -0.07294999999997742, "red_v45": 0.8143281249999998, "red_v65": 1.8990369878161784, "red_v78": -2.003, "red_v55": 1.5056932378161703, "red_v31": 2.3683494878161744, "red_v70": -1.0059999999999996, "red_v62": 0.49869323781617003, "red_v5": -1.0119999999999993, "red_v43": 1.5001030335440555, "red_v75": -0.15499999999999992, "red_v33": 0.5046932378161699, "red_v41": -0.002, "red_v51": 0.34076562500000007, "red_v37": -2.0299999999999994, "red_v66": -0.002, "red_v32": -1.006, "red_v23": -1.8160000000000003, "red_v73": -1.0089999999999992, "red_v79": -1.505, "red_v44": 1.4849346144425921, "red_v22": -0.5619999999999999}, "policy_reward_mean": {"red_v54": 0.49589813568011265, "red": 2.945659650066052, "blue": -1.0071841032608693, "red_v38": -0.8449656554853143, "red_v13": -0.8609999999999998, "red_v2": -2.0060000000000002, "red_v25": -0.5004484832279725, "red_v71": -1.3589999999999982, "red_v42": -1.0159999999999996, "red_v52": 0.9525202667720288, "red_v17": -1.008, "red_v56": 1.1956932378162006, "red_v53": 0.4986932378152039, "red_v35": 1.7351513064080848, "red_v64": -1.0374749999999886, "red_v45": 0.8143281249999998, "red_v65": 1.8990369878161784, "red_v78": -2.0254999999999974, "red_v55": 1.5056932378161703, "red_v31": 2.3683494878161744, "red_v70": -1.0059999999999996, "red_v62": 0.44598842140808515, "red_v5": -1.0119999999999993, "red_v43": 1.0018981356801127, "red_v75": -1.0805, "red_v33": 0.23934661890808495, "red_v41": -0.0035, "red_v51": 0.34076562500000007, "red_v37": -2.0299999999999994, "red_v66": -0.002, "red_v32": -1.006, "red_v23": -1.8160000000000003, "red_v73": -1.5069999999999997, "red_v79": -1.7564999999999997, "red_v44": 1.4849346144425921, "red_v22": -0.5619999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.918839600632342, 2.970083862816171, 3.998030646360225, -0.6187968750000005, 2.1668000000000003, 2.9244119878161703, 1.1686125000000005, 0.9733026128161705, 2.2664432378161794, 2.4648963628161704, 2.9227337713602277, 2.4792244878161704, 1.9841151128161703, 1.9470213628161714, 2.313471105, 2.4293963628161728, 2.1643864756324325, 2.4501307378161705, 2.4805213628161704, 3.987511475631374, 4.489995850632339, 0.9228281250000002, 1.9537244878161713, 0.7668182378161715, 2.4532401128161725, 2.4865213628161698, 2.480853033544055, 2.8675179800000006, 2.193305737816199, 2.485634283544055, 0.778021362816173, 2.4726776128161707, 2.464270667772942, 2.382730225632353, 1.9590213628161708, 3.991218146359259, 1.4869276128161695, 2.9882244878152036, 4.48940210063234, 2.867042725632347, 0.8420369878161705, 2.4831151128161704, 1.9814901128161704, 3.9818864756323404, 2.4629744878161715, 2.4753026128161704, 2.4506151128161715, 4.486405646360226, 2.478005737816171, 1.9876307378161702, 1.40128125, 1.9888182378161698, 2.445427612816173, 3.885730388544055, 1.4903338628152039, 1.3787367300000004, 1.9903338628161702, 1.9299432378161718, 1.6692088628161785, 3.99240210063234, 1.9713026128161704, 2.3810336050000007, 2.9788963628161698, 0.47367761281617593, 0.840458862816172, 3.980593146360226, 1.312724487816175, 1.443380737816172, 2.98230261281617, 1.485743658544055, 1.6652062500000002, 1.471599487816171, 2.4631689894425923, 0.9048487927729424, 2.9825213628161706, 2.4188807378161727, 2.480708167772942, 2.46956823781617, 2.4795994878161705, 2.9404276128161726, 2.4803026128161703, 1.9695682378161707, 2.3626932378161754, -0.11919738718382922, 1.83534375, 1.4891499085440552, 3.9857771006323404, 2.455021362816171, 2.487520667772942, 3.3314119878161703, 2.492739417772942, 1.8878461050000006, -0.530578125, 4.467237227258763, 2.98000573781617, 2.9177869878161706, 0.832640625, 1.4790057378161707, 2.1573937499999998, 2.3367500000000003], "episode_lengths": [79, 35, 21, 799, 16, 26, 12, 29, 208, 31, 84, 22, 25, 55, 68, 63, 1280, 52, 23, 24, 29, 23, 54, 216, 49, 23, 16, 21, 332, 22, 119, 37, 39, 722, 55, 25, 21, 22, 27, 110, 210, 25, 33, 32, 38, 29, 57, 29, 28, 20, 38, 24, 53, 18, 19, 15, 19, 48, 699, 27, 29, 16, 31, 549, 171, 33, 182, 36, 29, 19, 14, 30, 21, 78, 23, 68, 27, 40, 30, 53, 29, 40, 128, 637, 18, 17, 35, 55, 23, 26, 17, 12, 25, 29, 28, 34, 19, 28, 18, 16], "policy_red_v54_reward": [0.49169323781617036, 0.5001030335440549], "policy_blue_reward": [-0.008, 0.6402031250000001, -1.002, -2.0069999999999992, -2.019999999999998, -1.016999999999999, -1.0179999999999998, -1.0119999999999993, -1.0099999999999993, -0.5079999999999999, -1.584, -1.0179999999999985, -1.0039999999999998, -0.010000000000000002, -1.005, -1.0079999999999993, -1.0059999999999998, 1.9523281250000002, -0.003, -1.0119999999999993, -1.0129999999999992, -1.006, -2.006, 0.494, -2.002, -1.013999999999999, -2.003, -2.005, -0.3390000000000002, -1.0039999999999996, -1.6430000000000002, -2.0060000000000002, -2.0119999999999996, -1.0069999999999995, -1.0189999999999997, -1.0069999999999997, -1.0059999999999996, -2.008999999999999, -1.0299999999999978, -1.0049999999999997, -1.005, -1.003, -2.002, -0.008, -2.0069999999999997, -0.004], "policy_red_v38_reward": [0.5041030335440548, -2.033999999999998, -1.005], "policy_red_v13_reward": [-0.5579999999999999, -1.0129999999999997, -1.0119999999999998], "policy_red_v2_reward": [-2.0060000000000002, -2.006], "policy_red_v25_reward": [-1.506, 0.5051030335440551], "policy_red_v71_reward": [-1.0449999999999955, -1.5099999999999993, -1.522], "policy_red_v42_reward": [-1.0159999999999996], "policy_red_v52_reward": [2.4180405335440573, -0.5129999999999997], "policy_red_v17_reward": [-1.008], "policy_red_v56_reward": [1.1956932378162006], "policy_red_v53_reward": [0.4986932378152039], "policy_red_v35_reward": [1.50469323781617, 1.9656093749999999], "policy_red_v64_reward": [-0.07294999999997742, -2.002], "policy_red_v45_reward": [0.8143281249999998], "policy_red_v65_reward": [1.8990369878161784], "policy_red_v78_reward": [-2.003, -2.0479999999999947], "policy_red_v55_reward": [1.5056932378161703], "policy_red_v31_reward": [2.3683494878161744], "policy_red_v70_reward": [-1.0059999999999996], "policy_red_v62_reward": [0.49869323781617003, 0.39328360500000026], "policy_red_v5_reward": [-1.0119999999999993], "policy_red_v43_reward": [1.5001030335440555, 0.5036932378161698], "policy_red_v75_reward": [-2.0060000000000002, -0.15499999999999992], "policy_red_v33_reward": [0.5046932378161699, -0.026000000000000016], "policy_red_v41_reward": [-0.002, -0.005], "policy_red_v51_reward": [0.34076562500000007], "policy_red_v37_reward": [-2.0299999999999994], "policy_red_v66_reward": [-0.002], "policy_red_v32_reward": [-1.006], "policy_red_v23_reward": [-1.8160000000000003], "policy_red_v73_reward": [-2.005, -1.0089999999999992], "policy_red_v79_reward": [-1.505, -2.0079999999999996], "policy_red_v44_reward": [1.4849346144425921], "policy_red_v22_reward": [-0.5619999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8235352890213722, "mean_inference_ms": 7.713415051876318, "mean_action_processing_ms": 0.29395569804908817, "mean_env_wait_ms": 0.3939082044842116, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10064589977264404, "StateBufferConnector_ms": 0.004244327545166016, "ViewRequirementAgentConnector_ms": 0.11618030071258545}}, "episode_reward_max": 4.489995850632339, "episode_reward_min": -0.6187968750000005, "episode_reward_mean": 2.2959785264692893, "episode_len_mean": 90.88, "episodes_this_iter": 58, "policy_reward_min": {"red_v54": 0.49169323781617036, "red": -1.2590000000000001, "blue": -2.019999999999998, "red_v38": -2.033999999999998, "red_v13": -1.0129999999999997, "red_v2": -2.0060000000000002, "red_v25": -1.506, "red_v71": -1.522, "red_v42": -1.0159999999999996, "red_v52": -0.5129999999999997, "red_v17": -1.008, "red_v56": 1.1956932378162006, "red_v53": 0.4986932378152039, "red_v35": 1.50469323781617, "red_v64": -2.002, "red_v45": 0.8143281249999998, "red_v65": 1.8990369878161784, "red_v78": -2.0479999999999947, "red_v55": 1.5056932378161703, "red_v31": 2.3683494878161744, "red_v70": -1.0059999999999996, "red_v62": 0.39328360500000026, "red_v5": -1.0119999999999993, "red_v43": 0.5036932378161698, "red_v75": -2.0060000000000002, "red_v33": -0.026000000000000016, "red_v41": -0.005, "red_v51": 0.34076562500000007, "red_v37": -2.0299999999999994, "red_v66": -0.002, "red_v32": -1.006, "red_v23": -1.8160000000000003, "red_v73": -2.005, "red_v79": -2.0079999999999996, "red_v44": 1.4849346144425921, "red_v22": -0.5619999999999999}, "policy_reward_max": {"red_v54": 0.5001030335440549, "red": 3.99533386281617, "blue": 1.9523281250000002, "red_v38": 0.5041030335440548, "red_v13": -0.5579999999999999, "red_v2": -2.006, "red_v25": 0.5051030335440551, "red_v71": -1.0449999999999955, "red_v42": -1.0159999999999996, "red_v52": 2.4180405335440573, "red_v17": -1.008, "red_v56": 1.1956932378162006, "red_v53": 0.4986932378152039, "red_v35": 1.9656093749999999, "red_v64": -0.07294999999997742, "red_v45": 0.8143281249999998, "red_v65": 1.8990369878161784, "red_v78": -2.003, "red_v55": 1.5056932378161703, "red_v31": 2.3683494878161744, "red_v70": -1.0059999999999996, "red_v62": 0.49869323781617003, "red_v5": -1.0119999999999993, "red_v43": 1.5001030335440555, "red_v75": -0.15499999999999992, "red_v33": 0.5046932378161699, "red_v41": -0.002, "red_v51": 0.34076562500000007, "red_v37": -2.0299999999999994, "red_v66": -0.002, "red_v32": -1.006, "red_v23": -1.8160000000000003, "red_v73": -1.0089999999999992, "red_v79": -1.505, "red_v44": 1.4849346144425921, "red_v22": -0.5619999999999999}, "policy_reward_mean": {"red_v54": 0.49589813568011265, "red": 2.945659650066052, "blue": -1.0071841032608693, "red_v38": -0.8449656554853143, "red_v13": -0.8609999999999998, "red_v2": -2.0060000000000002, "red_v25": -0.5004484832279725, "red_v71": -1.3589999999999982, "red_v42": -1.0159999999999996, "red_v52": 0.9525202667720288, "red_v17": -1.008, "red_v56": 1.1956932378162006, "red_v53": 0.4986932378152039, "red_v35": 1.7351513064080848, "red_v64": -1.0374749999999886, "red_v45": 0.8143281249999998, "red_v65": 1.8990369878161784, "red_v78": -2.0254999999999974, "red_v55": 1.5056932378161703, "red_v31": 2.3683494878161744, "red_v70": -1.0059999999999996, "red_v62": 0.44598842140808515, "red_v5": -1.0119999999999993, "red_v43": 1.0018981356801127, "red_v75": -1.0805, "red_v33": 0.23934661890808495, "red_v41": -0.0035, "red_v51": 0.34076562500000007, "red_v37": -2.0299999999999994, "red_v66": -0.002, "red_v32": -1.006, "red_v23": -1.8160000000000003, "red_v73": -1.5069999999999997, "red_v79": -1.7564999999999997, "red_v44": 1.4849346144425921, "red_v22": -0.5619999999999999}, "hist_stats": {"episode_reward": [3.918839600632342, 2.970083862816171, 3.998030646360225, -0.6187968750000005, 2.1668000000000003, 2.9244119878161703, 1.1686125000000005, 0.9733026128161705, 2.2664432378161794, 2.4648963628161704, 2.9227337713602277, 2.4792244878161704, 1.9841151128161703, 1.9470213628161714, 2.313471105, 2.4293963628161728, 2.1643864756324325, 2.4501307378161705, 2.4805213628161704, 3.987511475631374, 4.489995850632339, 0.9228281250000002, 1.9537244878161713, 0.7668182378161715, 2.4532401128161725, 2.4865213628161698, 2.480853033544055, 2.8675179800000006, 2.193305737816199, 2.485634283544055, 0.778021362816173, 2.4726776128161707, 2.464270667772942, 2.382730225632353, 1.9590213628161708, 3.991218146359259, 1.4869276128161695, 2.9882244878152036, 4.48940210063234, 2.867042725632347, 0.8420369878161705, 2.4831151128161704, 1.9814901128161704, 3.9818864756323404, 2.4629744878161715, 2.4753026128161704, 2.4506151128161715, 4.486405646360226, 2.478005737816171, 1.9876307378161702, 1.40128125, 1.9888182378161698, 2.445427612816173, 3.885730388544055, 1.4903338628152039, 1.3787367300000004, 1.9903338628161702, 1.9299432378161718, 1.6692088628161785, 3.99240210063234, 1.9713026128161704, 2.3810336050000007, 2.9788963628161698, 0.47367761281617593, 0.840458862816172, 3.980593146360226, 1.312724487816175, 1.443380737816172, 2.98230261281617, 1.485743658544055, 1.6652062500000002, 1.471599487816171, 2.4631689894425923, 0.9048487927729424, 2.9825213628161706, 2.4188807378161727, 2.480708167772942, 2.46956823781617, 2.4795994878161705, 2.9404276128161726, 2.4803026128161703, 1.9695682378161707, 2.3626932378161754, -0.11919738718382922, 1.83534375, 1.4891499085440552, 3.9857771006323404, 2.455021362816171, 2.487520667772942, 3.3314119878161703, 2.492739417772942, 1.8878461050000006, -0.530578125, 4.467237227258763, 2.98000573781617, 2.9177869878161706, 0.832640625, 1.4790057378161707, 2.1573937499999998, 2.3367500000000003], "episode_lengths": [79, 35, 21, 799, 16, 26, 12, 29, 208, 31, 84, 22, 25, 55, 68, 63, 1280, 52, 23, 24, 29, 23, 54, 216, 49, 23, 16, 21, 332, 22, 119, 37, 39, 722, 55, 25, 21, 22, 27, 110, 210, 25, 33, 32, 38, 29, 57, 29, 28, 20, 38, 24, 53, 18, 19, 15, 19, 48, 699, 27, 29, 16, 31, 549, 171, 33, 182, 36, 29, 19, 14, 30, 21, 78, 23, 68, 27, 40, 30, 53, 29, 40, 128, 637, 18, 17, 35, 55, 23, 26, 17, 12, 25, 29, 28, 34, 19, 28, 18, 16], "policy_red_v54_reward": [0.49169323781617036, 0.5001030335440549], "policy_blue_reward": [-0.008, 0.6402031250000001, -1.002, -2.0069999999999992, -2.019999999999998, -1.016999999999999, -1.0179999999999998, -1.0119999999999993, -1.0099999999999993, -0.5079999999999999, -1.584, -1.0179999999999985, -1.0039999999999998, -0.010000000000000002, -1.005, -1.0079999999999993, -1.0059999999999998, 1.9523281250000002, -0.003, -1.0119999999999993, -1.0129999999999992, -1.006, -2.006, 0.494, -2.002, -1.013999999999999, -2.003, -2.005, -0.3390000000000002, -1.0039999999999996, -1.6430000000000002, -2.0060000000000002, -2.0119999999999996, -1.0069999999999995, -1.0189999999999997, -1.0069999999999997, -1.0059999999999996, -2.008999999999999, -1.0299999999999978, -1.0049999999999997, -1.005, -1.003, -2.002, -0.008, -2.0069999999999997, -0.004], "policy_red_v38_reward": [0.5041030335440548, -2.033999999999998, -1.005], "policy_red_v13_reward": [-0.5579999999999999, -1.0129999999999997, -1.0119999999999998], "policy_red_v2_reward": [-2.0060000000000002, -2.006], "policy_red_v25_reward": [-1.506, 0.5051030335440551], "policy_red_v71_reward": [-1.0449999999999955, -1.5099999999999993, -1.522], "policy_red_v42_reward": [-1.0159999999999996], "policy_red_v52_reward": [2.4180405335440573, -0.5129999999999997], "policy_red_v17_reward": [-1.008], "policy_red_v56_reward": [1.1956932378162006], "policy_red_v53_reward": [0.4986932378152039], "policy_red_v35_reward": [1.50469323781617, 1.9656093749999999], "policy_red_v64_reward": [-0.07294999999997742, -2.002], "policy_red_v45_reward": [0.8143281249999998], "policy_red_v65_reward": [1.8990369878161784], "policy_red_v78_reward": [-2.003, -2.0479999999999947], "policy_red_v55_reward": [1.5056932378161703], "policy_red_v31_reward": [2.3683494878161744], "policy_red_v70_reward": [-1.0059999999999996], "policy_red_v62_reward": [0.49869323781617003, 0.39328360500000026], "policy_red_v5_reward": [-1.0119999999999993], "policy_red_v43_reward": [1.5001030335440555, 0.5036932378161698], "policy_red_v75_reward": [-2.0060000000000002, -0.15499999999999992], "policy_red_v33_reward": [0.5046932378161699, -0.026000000000000016], "policy_red_v41_reward": [-0.002, -0.005], "policy_red_v51_reward": [0.34076562500000007], "policy_red_v37_reward": [-2.0299999999999994], "policy_red_v66_reward": [-0.002], "policy_red_v32_reward": [-1.006], "policy_red_v23_reward": [-1.8160000000000003], "policy_red_v73_reward": [-2.005, -1.0089999999999992], "policy_red_v79_reward": [-1.505, -2.0079999999999996], "policy_red_v44_reward": [1.4849346144425921], "policy_red_v22_reward": [-0.5619999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8235352890213722, "mean_inference_ms": 7.713415051876318, "mean_action_processing_ms": 0.29395569804908817, "mean_env_wait_ms": 0.3939082044842116, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10064589977264404, "StateBufferConnector_ms": 0.004244327545166016, "ViewRequirementAgentConnector_ms": 0.11618030071258545}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 195.14163940385293, "num_env_steps_trained_throughput_per_sec": 195.14163940385293, "timesteps_total": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 20002.859, "sample_time_ms": 1191.148, "learn_time_ms": 18725.555, "learn_throughput": 213.612, "synch_weights_time_ms": 82.734}, "counters": {"num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "episodes_total": 2626, "training_iteration": 116, "trial_id": "a9680_00000", "date": "2023-09-24_03-19-40", "timestamp": 1695539980, "time_this_iter_s": 20.50859546661377, "time_total_s": 2314.375440597534, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1db335b0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1dc664d0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1dc66560>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2314.375440597534, "iterations_since_restore": 116, "perf": {"cpu_util_percent": 5.685714285714287, "ram_util_percent": 26.671428571428578}, "win_rate": 0.77, "league_size": 85}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1257211594531933, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.028800116460236797, "policy_loss": -0.04580788298141367, "vf_loss": 0.13757075821243536, "vf_explained_var": 0.8311667149886489, "kl": 0.01592762214196158, "entropy": 1.3448091237495343, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 111840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_agent_steps_sampled": 936000, "num_agent_steps_trained": 936000}, "sampler_results": {"episode_reward_max": 4.467237227258763, "episode_reward_min": -2.637948082227053, "episode_reward_mean": 2.17628900235337, "episode_len_mean": 68.88, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"blue": -2.022999999999998, "red": -3.9789480822270633, "red_v62": 0.39328360500000026, "red_v75": -2.0060000000000002, "red_v38": -2.033999999999998, "red_v33": -0.026000000000000016, "red_v35": 1.9656093749999999, "red_v41": -0.005, "red_v51": 0.34076562500000007, "red_v54": 0.5001030335440549, "red_v78": -2.0479999999999947, "red_v37": -2.0299999999999994, "red_v66": -0.002, "red_v2": -2.006, "red_v71": -2.0159999999999987, "red_v32": -1.006, "red_v23": -1.8160000000000003, "red_v73": -2.0799999999999925, "red_v43": 0.5036932378161698, "red_v79": -2.0079999999999996, "red_v44": 1.1490500000000026, "red_v22": -0.5619999999999999, "red_v13": -1.0119999999999998, "red_v58": -2.007999999999999, "red_v67": -2.0819999999999923, "red_v82": -0.15799999999999992, "red_v28": -0.16599999999999993, "red_v50": -2.002, "red_v1": -2.007999999999999, "red_v80": -2.0, "red_v69": 0.4926932378161707, "red_v29": -0.5559999999999998, "red_v25": -0.003, "red_v7": -2.0059999999999993, "red_v81": -2.0059999999999993, "red_v20": 1.4866932378161715, "red_v52": -0.1529999999999999}, "policy_reward_max": {"blue": 1.3410000000000024, "red": 3.99533386281617, "red_v62": 0.39328360500000026, "red_v75": -0.15499999999999992, "red_v38": -1.005, "red_v33": 0.5046932378161699, "red_v35": 1.9656093749999999, "red_v41": -0.002, "red_v51": 0.34076562500000007, "red_v54": 0.5001030335440549, "red_v78": -2.0479999999999947, "red_v37": -2.0299999999999994, "red_v66": -0.002, "red_v2": -2.006, "red_v71": -1.0119999999999993, "red_v32": -1.006, "red_v23": 0.5041030335440548, "red_v73": -1.0089999999999992, "red_v43": 0.5036932378161698, "red_v79": -1.505, "red_v44": 1.4849346144425921, "red_v22": -0.5619999999999999, "red_v13": -1.0119999999999998, "red_v58": -2.007999999999999, "red_v67": -2.0819999999999923, "red_v82": 1.98575, "red_v28": -0.16599999999999993, "red_v50": -2.002, "red_v1": -2.007999999999999, "red_v80": -2.0, "red_v69": 0.4926932378161707, "red_v29": -0.5559999999999998, "red_v25": -0.003, "red_v7": -2.0059999999999993, "red_v81": -2.0059999999999993, "red_v20": 1.4866932378161715, "red_v52": -0.1529999999999999}, "policy_reward_mean": {"blue": -1.066434194711538, "red": 3.0730110612254156, "red_v62": 0.39328360500000026, "red_v75": -1.0805, "red_v38": -1.519499999999999, "red_v33": 0.23934661890808495, "red_v35": 1.9656093749999999, "red_v41": -0.0035, "red_v51": 0.34076562500000007, "red_v54": 0.5001030335440549, "red_v78": -2.0479999999999947, "red_v37": -2.0299999999999994, "red_v66": -0.002, "red_v2": -2.006, "red_v71": -1.5147499999999996, "red_v32": -1.006, "red_v23": -0.6559484832279727, "red_v73": -1.6979999999999975, "red_v43": 0.5036932378161698, "red_v79": -1.7564999999999997, "red_v44": 1.3169923072212972, "red_v22": -0.5619999999999999, "red_v13": -1.0119999999999998, "red_v58": -2.007999999999999, "red_v67": -2.0819999999999923, "red_v82": 0.913875, "red_v28": -0.16599999999999993, "red_v50": -2.002, "red_v1": -2.007999999999999, "red_v80": -2.0, "red_v69": 0.4926932378161707, "red_v29": -0.5559999999999998, "red_v25": -0.003, "red_v7": -2.0059999999999993, "red_v81": -2.0059999999999993, "red_v20": 1.4866932378161715, "red_v52": -0.1529999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.40128125, 1.9888182378161698, 2.445427612816173, 3.885730388544055, 1.4903338628152039, 1.3787367300000004, 1.9903338628161702, 1.9299432378161718, 1.6692088628161785, 3.99240210063234, 1.9713026128161704, 2.3810336050000007, 2.9788963628161698, 0.47367761281617593, 0.840458862816172, 3.980593146360226, 1.312724487816175, 1.443380737816172, 2.98230261281617, 1.485743658544055, 1.6652062500000002, 1.471599487816171, 2.4631689894425923, 0.9048487927729424, 2.9825213628161706, 2.4188807378161727, 2.480708167772942, 2.46956823781617, 2.4795994878161705, 2.9404276128161726, 2.4803026128161703, 1.9695682378161707, 2.3626932378161754, -0.11919738718382922, 1.83534375, 1.4891499085440552, 3.9857771006323404, 2.455021362816171, 2.487520667772942, 3.3314119878161703, 2.492739417772942, 1.8878461050000006, -0.530578125, 4.467237227258763, 2.98000573781617, 2.9177869878161706, 0.832640625, 1.4790057378161707, 2.1573937499999998, 2.3367500000000003, 3.976749396360225, 1.4308807378161719, 2.9712783644425924, 2.447021362816172, 1.9779276128161707, 2.48441198781617, 1.2272401128161803, 0.607115112816172, 3.3068651128161712, 1.4623807378152036, 2.490739417772942, 3.2895057378161727, 2.98681823781617, 1.9488338628161714, 1.4735682378161703, 2.942427612816172, 4.100930737816174, 1.9270369878161722, 1.987853033544055, 2.8807367300000006, 2.38473673, 2.4872244878152037, 1.9719744878161705, 1.4550526128161714, -2.637948082227053, 1.9814119878161702, 2.454349487816171, 1.9807939894425923, -0.16442187499999983, 3.949198975632342, 2.937333167772942, 1.952755737816171, 2.463458862816171, 2.4577244878161704, 1.3700336050000004, 2.960056158544056, 1.8777367300000005, 0.9274744878161714, 1.4780057378161704, 1.4656463628161704, 3.4681619878161705, 1.9910362927729417, 2.48470886281617, 4.446605225632341, 3.3379276128152036, 1.9693807378161707, 2.4808182378152037, 2.485333862815204, 2.4682713628161705, 1.2264588628161814], "episode_lengths": [38, 24, 53, 18, 19, 15, 19, 48, 699, 27, 29, 16, 31, 549, 171, 33, 182, 36, 29, 19, 14, 30, 21, 78, 23, 68, 27, 40, 30, 53, 29, 40, 128, 637, 18, 17, 35, 55, 23, 26, 17, 12, 25, 29, 28, 34, 19, 28, 18, 16, 47, 68, 18, 55, 21, 26, 241, 409, 41, 36, 17, 60, 24, 51, 40, 53, 68, 82, 16, 15, 15, 22, 38, 45, 557, 26, 46, 13, 103, 60, 19, 44, 43, 54, 16, 47, 15, 70, 28, 47, 42, 18, 27, 58, 21, 36, 24, 19, 39, 235], "policy_blue_reward": [0.494, -2.002, -1.013999999999999, -2.003, -2.005, -0.3390000000000002, -1.0039999999999996, -1.6430000000000002, -2.0060000000000002, -2.0119999999999996, -1.0069999999999995, -1.0189999999999997, -1.0069999999999997, -1.0059999999999996, -2.008999999999999, -1.0299999999999978, -1.0049999999999997, -1.005, -1.003, -2.002, -0.008, -2.0069999999999997, -0.004, -0.004, -1.0119999999999998, -2.0119999999999996, -1.0049999999999997, 0.10842187500000133, -2.01, -1.0049999999999997, -0.004, -2.022999999999998, -0.018000000000000006, -0.006, -1.0029999999999997, -1.0039999999999998, -2.012999999999999, 1.3410000000000024, -2.0089999999999995, -1.0139999999999991, -0.5159999999999999, -1.010999999999999, -2.01, -1.5219999999999998, -2.0099999999999993, 0.492, -0.502, -1.004, -2.0109999999999992, -1.006, -1.0079999999999991, -1.0079999999999998], "policy_red_v62_reward": [0.39328360500000026], "policy_red_v75_reward": [-2.0060000000000002, -0.15499999999999992], "policy_red_v38_reward": [-2.033999999999998, -1.005], "policy_red_v33_reward": [0.5046932378161699, -0.026000000000000016], "policy_red_v35_reward": [1.9656093749999999], "policy_red_v41_reward": [-0.002, -0.005], "policy_red_v51_reward": [0.34076562500000007], "policy_red_v54_reward": [0.5001030335440549], "policy_red_v78_reward": [-2.0479999999999947], "policy_red_v37_reward": [-2.0299999999999994], "policy_red_v66_reward": [-0.002], "policy_red_v2_reward": [-2.006], "policy_red_v71_reward": [-1.522, -2.0159999999999987, -1.509, -1.0119999999999993], "policy_red_v32_reward": [-1.006], "policy_red_v23_reward": [-1.8160000000000003, 0.5041030335440548], "policy_red_v73_reward": [-2.005, -1.0089999999999992, -2.0799999999999925], "policy_red_v43_reward": [0.5036932378161698], "policy_red_v79_reward": [-1.505, -2.0079999999999996], "policy_red_v44_reward": [1.4849346144425921, 1.1490500000000026], "policy_red_v22_reward": [-0.5619999999999999], "policy_red_v13_reward": [-1.0119999999999998], "policy_red_v58_reward": [-2.007999999999999], "policy_red_v67_reward": [-2.0819999999999923], "policy_red_v82_reward": [-0.15799999999999992, 1.98575], "policy_red_v28_reward": [-0.16599999999999993], "policy_red_v50_reward": [-2.002], "policy_red_v1_reward": [-2.007999999999999], "policy_red_v80_reward": [-2.0], "policy_red_v69_reward": [0.4926932378161707], "policy_red_v29_reward": [-0.5559999999999998], "policy_red_v25_reward": [-0.003], "policy_red_v7_reward": [-2.0059999999999993], "policy_red_v81_reward": [-2.0059999999999993], "policy_red_v20_reward": [1.4866932378161715], "policy_red_v52_reward": [-0.1529999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8229550061903371, "mean_inference_ms": 7.711267202754161, "mean_action_processing_ms": 0.2943859463660394, "mean_env_wait_ms": 0.3926175228888611, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10055792331695557, "StateBufferConnector_ms": 0.004210233688354492, "ViewRequirementAgentConnector_ms": 0.11620676517486572}}, "episode_reward_max": 4.467237227258763, "episode_reward_min": -2.637948082227053, "episode_reward_mean": 2.17628900235337, "episode_len_mean": 68.88, "episodes_this_iter": 50, "policy_reward_min": {"blue": -2.022999999999998, "red": -3.9789480822270633, "red_v62": 0.39328360500000026, "red_v75": -2.0060000000000002, "red_v38": -2.033999999999998, "red_v33": -0.026000000000000016, "red_v35": 1.9656093749999999, "red_v41": -0.005, "red_v51": 0.34076562500000007, "red_v54": 0.5001030335440549, "red_v78": -2.0479999999999947, "red_v37": -2.0299999999999994, "red_v66": -0.002, "red_v2": -2.006, "red_v71": -2.0159999999999987, "red_v32": -1.006, "red_v23": -1.8160000000000003, "red_v73": -2.0799999999999925, "red_v43": 0.5036932378161698, "red_v79": -2.0079999999999996, "red_v44": 1.1490500000000026, "red_v22": -0.5619999999999999, "red_v13": -1.0119999999999998, "red_v58": -2.007999999999999, "red_v67": -2.0819999999999923, "red_v82": -0.15799999999999992, "red_v28": -0.16599999999999993, "red_v50": -2.002, "red_v1": -2.007999999999999, "red_v80": -2.0, "red_v69": 0.4926932378161707, "red_v29": -0.5559999999999998, "red_v25": -0.003, "red_v7": -2.0059999999999993, "red_v81": -2.0059999999999993, "red_v20": 1.4866932378161715, "red_v52": -0.1529999999999999}, "policy_reward_max": {"blue": 1.3410000000000024, "red": 3.99533386281617, "red_v62": 0.39328360500000026, "red_v75": -0.15499999999999992, "red_v38": -1.005, "red_v33": 0.5046932378161699, "red_v35": 1.9656093749999999, "red_v41": -0.002, "red_v51": 0.34076562500000007, "red_v54": 0.5001030335440549, "red_v78": -2.0479999999999947, "red_v37": -2.0299999999999994, "red_v66": -0.002, "red_v2": -2.006, "red_v71": -1.0119999999999993, "red_v32": -1.006, "red_v23": 0.5041030335440548, "red_v73": -1.0089999999999992, "red_v43": 0.5036932378161698, "red_v79": -1.505, "red_v44": 1.4849346144425921, "red_v22": -0.5619999999999999, "red_v13": -1.0119999999999998, "red_v58": -2.007999999999999, "red_v67": -2.0819999999999923, "red_v82": 1.98575, "red_v28": -0.16599999999999993, "red_v50": -2.002, "red_v1": -2.007999999999999, "red_v80": -2.0, "red_v69": 0.4926932378161707, "red_v29": -0.5559999999999998, "red_v25": -0.003, "red_v7": -2.0059999999999993, "red_v81": -2.0059999999999993, "red_v20": 1.4866932378161715, "red_v52": -0.1529999999999999}, "policy_reward_mean": {"blue": -1.066434194711538, "red": 3.0730110612254156, "red_v62": 0.39328360500000026, "red_v75": -1.0805, "red_v38": -1.519499999999999, "red_v33": 0.23934661890808495, "red_v35": 1.9656093749999999, "red_v41": -0.0035, "red_v51": 0.34076562500000007, "red_v54": 0.5001030335440549, "red_v78": -2.0479999999999947, "red_v37": -2.0299999999999994, "red_v66": -0.002, "red_v2": -2.006, "red_v71": -1.5147499999999996, "red_v32": -1.006, "red_v23": -0.6559484832279727, "red_v73": -1.6979999999999975, "red_v43": 0.5036932378161698, "red_v79": -1.7564999999999997, "red_v44": 1.3169923072212972, "red_v22": -0.5619999999999999, "red_v13": -1.0119999999999998, "red_v58": -2.007999999999999, "red_v67": -2.0819999999999923, "red_v82": 0.913875, "red_v28": -0.16599999999999993, "red_v50": -2.002, "red_v1": -2.007999999999999, "red_v80": -2.0, "red_v69": 0.4926932378161707, "red_v29": -0.5559999999999998, "red_v25": -0.003, "red_v7": -2.0059999999999993, "red_v81": -2.0059999999999993, "red_v20": 1.4866932378161715, "red_v52": -0.1529999999999999}, "hist_stats": {"episode_reward": [1.40128125, 1.9888182378161698, 2.445427612816173, 3.885730388544055, 1.4903338628152039, 1.3787367300000004, 1.9903338628161702, 1.9299432378161718, 1.6692088628161785, 3.99240210063234, 1.9713026128161704, 2.3810336050000007, 2.9788963628161698, 0.47367761281617593, 0.840458862816172, 3.980593146360226, 1.312724487816175, 1.443380737816172, 2.98230261281617, 1.485743658544055, 1.6652062500000002, 1.471599487816171, 2.4631689894425923, 0.9048487927729424, 2.9825213628161706, 2.4188807378161727, 2.480708167772942, 2.46956823781617, 2.4795994878161705, 2.9404276128161726, 2.4803026128161703, 1.9695682378161707, 2.3626932378161754, -0.11919738718382922, 1.83534375, 1.4891499085440552, 3.9857771006323404, 2.455021362816171, 2.487520667772942, 3.3314119878161703, 2.492739417772942, 1.8878461050000006, -0.530578125, 4.467237227258763, 2.98000573781617, 2.9177869878161706, 0.832640625, 1.4790057378161707, 2.1573937499999998, 2.3367500000000003, 3.976749396360225, 1.4308807378161719, 2.9712783644425924, 2.447021362816172, 1.9779276128161707, 2.48441198781617, 1.2272401128161803, 0.607115112816172, 3.3068651128161712, 1.4623807378152036, 2.490739417772942, 3.2895057378161727, 2.98681823781617, 1.9488338628161714, 1.4735682378161703, 2.942427612816172, 4.100930737816174, 1.9270369878161722, 1.987853033544055, 2.8807367300000006, 2.38473673, 2.4872244878152037, 1.9719744878161705, 1.4550526128161714, -2.637948082227053, 1.9814119878161702, 2.454349487816171, 1.9807939894425923, -0.16442187499999983, 3.949198975632342, 2.937333167772942, 1.952755737816171, 2.463458862816171, 2.4577244878161704, 1.3700336050000004, 2.960056158544056, 1.8777367300000005, 0.9274744878161714, 1.4780057378161704, 1.4656463628161704, 3.4681619878161705, 1.9910362927729417, 2.48470886281617, 4.446605225632341, 3.3379276128152036, 1.9693807378161707, 2.4808182378152037, 2.485333862815204, 2.4682713628161705, 1.2264588628161814], "episode_lengths": [38, 24, 53, 18, 19, 15, 19, 48, 699, 27, 29, 16, 31, 549, 171, 33, 182, 36, 29, 19, 14, 30, 21, 78, 23, 68, 27, 40, 30, 53, 29, 40, 128, 637, 18, 17, 35, 55, 23, 26, 17, 12, 25, 29, 28, 34, 19, 28, 18, 16, 47, 68, 18, 55, 21, 26, 241, 409, 41, 36, 17, 60, 24, 51, 40, 53, 68, 82, 16, 15, 15, 22, 38, 45, 557, 26, 46, 13, 103, 60, 19, 44, 43, 54, 16, 47, 15, 70, 28, 47, 42, 18, 27, 58, 21, 36, 24, 19, 39, 235], "policy_blue_reward": [0.494, -2.002, -1.013999999999999, -2.003, -2.005, -0.3390000000000002, -1.0039999999999996, -1.6430000000000002, -2.0060000000000002, -2.0119999999999996, -1.0069999999999995, -1.0189999999999997, -1.0069999999999997, -1.0059999999999996, -2.008999999999999, -1.0299999999999978, -1.0049999999999997, -1.005, -1.003, -2.002, -0.008, -2.0069999999999997, -0.004, -0.004, -1.0119999999999998, -2.0119999999999996, -1.0049999999999997, 0.10842187500000133, -2.01, -1.0049999999999997, -0.004, -2.022999999999998, -0.018000000000000006, -0.006, -1.0029999999999997, -1.0039999999999998, -2.012999999999999, 1.3410000000000024, -2.0089999999999995, -1.0139999999999991, -0.5159999999999999, -1.010999999999999, -2.01, -1.5219999999999998, -2.0099999999999993, 0.492, -0.502, -1.004, -2.0109999999999992, -1.006, -1.0079999999999991, -1.0079999999999998], "policy_red_v62_reward": [0.39328360500000026], "policy_red_v75_reward": [-2.0060000000000002, -0.15499999999999992], "policy_red_v38_reward": [-2.033999999999998, -1.005], "policy_red_v33_reward": [0.5046932378161699, -0.026000000000000016], "policy_red_v35_reward": [1.9656093749999999], "policy_red_v41_reward": [-0.002, -0.005], "policy_red_v51_reward": [0.34076562500000007], "policy_red_v54_reward": [0.5001030335440549], "policy_red_v78_reward": [-2.0479999999999947], "policy_red_v37_reward": [-2.0299999999999994], "policy_red_v66_reward": [-0.002], "policy_red_v2_reward": [-2.006], "policy_red_v71_reward": [-1.522, -2.0159999999999987, -1.509, -1.0119999999999993], "policy_red_v32_reward": [-1.006], "policy_red_v23_reward": [-1.8160000000000003, 0.5041030335440548], "policy_red_v73_reward": [-2.005, -1.0089999999999992, -2.0799999999999925], "policy_red_v43_reward": [0.5036932378161698], "policy_red_v79_reward": [-1.505, -2.0079999999999996], "policy_red_v44_reward": [1.4849346144425921, 1.1490500000000026], "policy_red_v22_reward": [-0.5619999999999999], "policy_red_v13_reward": [-1.0119999999999998], "policy_red_v58_reward": [-2.007999999999999], "policy_red_v67_reward": [-2.0819999999999923], "policy_red_v82_reward": [-0.15799999999999992, 1.98575], "policy_red_v28_reward": [-0.16599999999999993], "policy_red_v50_reward": [-2.002], "policy_red_v1_reward": [-2.007999999999999], "policy_red_v80_reward": [-2.0], "policy_red_v69_reward": [0.4926932378161707], "policy_red_v29_reward": [-0.5559999999999998], "policy_red_v25_reward": [-0.003], "policy_red_v7_reward": [-2.0059999999999993], "policy_red_v81_reward": [-2.0059999999999993], "policy_red_v20_reward": [1.4866932378161715], "policy_red_v52_reward": [-0.1529999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8229550061903371, "mean_inference_ms": 7.711267202754161, "mean_action_processing_ms": 0.2943859463660394, "mean_env_wait_ms": 0.3926175228888611, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10055792331695557, "StateBufferConnector_ms": 0.004210233688354492, "ViewRequirementAgentConnector_ms": 0.11620676517486572}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 936000, "num_agent_steps_trained": 936000, "num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 205.16885061614371, "num_env_steps_trained_throughput_per_sec": 205.16885061614371, "timesteps_total": 468000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 936000, "timers": {"training_iteration_time_ms": 19916.188, "sample_time_ms": 1195.186, "learn_time_ms": 18635.128, "learn_throughput": 214.648, "synch_weights_time_ms": 82.477}, "counters": {"num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_agent_steps_sampled": 936000, "num_agent_steps_trained": 936000}, "done": false, "episodes_total": 2676, "training_iteration": 117, "trial_id": "a9680_00000", "date": "2023-09-24_03-20-04", "timestamp": 1695540004, "time_this_iter_s": 19.506141424179077, "time_total_s": 2333.8815820217133, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dc7ae90>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1dc66dd0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1dc66d40>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2333.8815820217133, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 5.564705882352942, "ram_util_percent": 26.785294117647055}, "win_rate": 0.84, "league_size": 86}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.496881383409103, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.05357365578674944, "policy_loss": -0.03816009831110326, "vf_loss": 0.174603393569123, "vf_explained_var": 0.8135106585919857, "kl": 0.012968982329311984, "entropy": 1.4039852348466715, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 112800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "sampler_results": {"episode_reward_max": 4.47426147563234, "episode_reward_min": -2.637948082227053, "episode_reward_mean": 2.15600702776118, "episode_len_mean": 62.53, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"blue": -2.022999999999998, "red": -3.9789480822270633, "red_v67": -2.0819999999999923, "red_v82": -0.15799999999999992, "red_v28": -0.16599999999999993, "red_v50": -2.002, "red_v44": 1.1490500000000026, "red_v71": -2.0159999999999987, "red_v1": -2.007999999999999, "red_v80": -2.0, "red_v69": -2.0029999999999997, "red_v29": -0.5559999999999998, "red_v25": -2.013999999999999, "red_v7": -2.0059999999999993, "red_v81": -2.0059999999999993, "red_v20": 1.4866932378161715, "red_v52": -2.012, "red_v73": -2.0799999999999925, "red_v2": -2.005, "red_v83": -2.0029999999999997, "red_v39": 1.98134375, "red_v55": 0.5006932378161701, "red_v40": 1.5026932378161697, "red_v13": 3.6069093750000016, "red_v66": -2.0069999999999997, "red_v18": 0.8500000000000001, "red_v68": 1.976421875, "red_v33": -0.2500000000000006, "red_v79": -2.0039999999999996, "red_v16": 1.9637968749999999, "red_v78": -1.507, "red_v37": -0.5069999999999999, "red_v19": -1.0159999999999991, "red_v53": 0.17605000000000004}, "policy_reward_max": {"blue": 1.3410000000000024, "red": 3.995556158544055, "red_v67": -2.0819999999999923, "red_v82": 1.98575, "red_v28": -0.16599999999999993, "red_v50": -2.002, "red_v44": 1.1490500000000026, "red_v71": -1.0119999999999993, "red_v1": -2.007999999999999, "red_v80": -2.0, "red_v69": 0.4926932378161707, "red_v29": -0.5559999999999998, "red_v25": -0.003, "red_v7": -2.0059999999999993, "red_v81": -2.0059999999999993, "red_v20": 1.4866932378161715, "red_v52": -0.1529999999999999, "red_v73": -2.0799999999999925, "red_v2": -2.005, "red_v83": -1.006, "red_v39": 1.98134375, "red_v55": 0.5006932378161701, "red_v40": 1.5026932378161697, "red_v13": 3.6069093750000016, "red_v66": -2.0069999999999997, "red_v18": 0.8500000000000001, "red_v68": 1.976421875, "red_v33": -0.006, "red_v79": -2.0039999999999996, "red_v16": 1.9637968749999999, "red_v78": -1.507, "red_v37": -0.5069999999999999, "red_v19": -1.0159999999999991, "red_v53": 0.17605000000000004}, "policy_reward_mean": {"blue": -1.06112844279661, "red": 3.001381860748532, "red_v67": -2.0819999999999923, "red_v82": 0.913875, "red_v28": -0.16599999999999993, "red_v50": -2.002, "red_v44": 1.1490500000000026, "red_v71": -1.5123333333333326, "red_v1": -2.007999999999999, "red_v80": -2.0, "red_v69": -1.0054355873946095, "red_v29": -0.5559999999999998, "red_v25": -1.0084999999999995, "red_v7": -2.0059999999999993, "red_v81": -2.0059999999999993, "red_v20": 1.4866932378161715, "red_v52": -1.0825, "red_v73": -2.0799999999999925, "red_v2": -2.005, "red_v83": -1.5044999999999997, "red_v39": 1.98134375, "red_v55": 0.5006932378161701, "red_v40": 1.5026932378161697, "red_v13": 3.6069093750000016, "red_v66": -2.0069999999999997, "red_v18": 0.8500000000000001, "red_v68": 1.976421875, "red_v33": -0.1280000000000003, "red_v79": -2.0039999999999996, "red_v16": 1.9637968749999999, "red_v78": -1.507, "red_v37": -0.5069999999999999, "red_v19": -1.0159999999999991, "red_v53": 0.17605000000000004}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.447021362816172, 1.9779276128161707, 2.48441198781617, 1.2272401128161803, 0.607115112816172, 3.3068651128161712, 1.4623807378152036, 2.490739417772942, 3.2895057378161727, 2.98681823781617, 1.9488338628161714, 1.4735682378161703, 2.942427612816172, 4.100930737816174, 1.9270369878161722, 1.987853033544055, 2.8807367300000006, 2.38473673, 2.4872244878152037, 1.9719744878161705, 1.4550526128161714, -2.637948082227053, 1.9814119878161702, 2.454349487816171, 1.9807939894425923, -0.16442187499999983, 3.949198975632342, 2.937333167772942, 1.952755737816171, 2.463458862816171, 2.4577244878161704, 1.3700336050000004, 2.960056158544056, 1.8777367300000005, 0.9274744878161714, 1.4780057378161704, 1.4656463628161704, 3.4681619878161705, 1.9910362927729417, 2.48470886281617, 4.446605225632341, 3.3379276128152036, 1.9693807378161707, 2.4808182378152037, 2.485333862815204, 2.4682713628161705, 1.2264588628161814, 2.4883338628161704, 1.667909375, 2.4879276128161703, 2.3650023550000006, 2.4658408644425927, 2.4841151128161703, 1.3861429800000002, 1.4775994878161702, 1.4804467835440551, 1.164503125, 1.9860369878152038, 3.9762614756323407, 4.47426147563234, 3.6096026128161727, 1.331046875, 1.462458862816171, 3.84392761281617, 2.9623807378161704, 1.9771144177729418, 2.1668000000000003, 2.456943237816171, -1.8649999999999114, 0.9479119878161703, 2.3552679800000007, 2.4906307378161703, 2.9427244878161707, 2.9768963628161704, 2.4784119878161706, 1.9729814894425926, 0.840859375, 2.98863073781617, 1.9662713628161712, 1.4851151128161701, 2.971603033544055, 2.4794119878152046, 1.9714901128161708, 2.4354276128161727, 2.480115112815204, 2.4537557378161705, 2.4686776128161707, 0.9323651128161713, -0.07065624999999986, 2.3698148550000004, 0.93370886281617, 2.4481307378161703, 2.9705682378161704, 0.7681307378161704, 1.9855213628161699, 2.4856307378161704, 2.4488651128161725, 1.992556158544055, 2.4682713628161705, 3.659243237816171], "episode_lengths": [55, 21, 26, 241, 409, 41, 36, 17, 60, 24, 51, 40, 53, 68, 82, 16, 15, 15, 22, 38, 45, 557, 26, 46, 13, 103, 60, 19, 44, 43, 54, 16, 47, 15, 70, 28, 47, 42, 18, 27, 58, 21, 36, 24, 19, 39, 235, 19, 13, 21, 26, 30, 25, 13, 30, 18, 15, 18, 40, 40, 77, 17, 43, 21, 36, 25, 16, 48, 1280, 58, 37, 20, 54, 31, 26, 17, 13, 20, 39, 25, 32, 26, 33, 53, 25, 44, 37, 73, 18, 22, 91, 52, 40, 244, 23, 20, 41, 15, 39, 32], "policy_blue_reward": [-1.0119999999999998, -2.0119999999999996, -1.0049999999999997, 0.10842187500000133, -2.01, -1.0049999999999997, -0.004, -2.022999999999998, -0.018000000000000006, -0.006, -1.0029999999999997, -1.0039999999999998, -2.012999999999999, 1.3410000000000024, -2.0089999999999995, -1.0139999999999991, -0.5159999999999999, -1.010999999999999, -2.01, -1.5219999999999998, -2.0099999999999993, 0.492, -0.502, -1.004, -2.0109999999999992, -1.006, -1.0079999999999991, -1.0079999999999998, -1.005, -1.0059999999999996, -1.007, -1.003, -1.0059999999999993, -2.003, -2.0079999999999996, -0.507, -1.0039999999999998, -1.011999999999999, -1.513, -1.01, -1.0029999999999997, -0.012, -0.008, -1.0099999999999996, -2.005, -2.0059999999999993, -2.005, -0.004, -1.0039999999999998, -1.019, -1.0059999999999998, -1.0159999999999993, -1.0099999999999993, -1.5150000000000001, -1.006, -1.0099999999999998, -1.0630000000000002, -2.0029999999999997, -1.0129999999999992], "policy_red_v67_reward": [-2.0819999999999923], "policy_red_v82_reward": [-0.15799999999999992, 1.98575], "policy_red_v28_reward": [-0.16599999999999993], "policy_red_v50_reward": [-2.002], "policy_red_v44_reward": [1.1490500000000026], "policy_red_v71_reward": [-2.0159999999999987, -1.509, -1.0119999999999993], "policy_red_v1_reward": [-2.007999999999999], "policy_red_v80_reward": [-2.0], "policy_red_v69_reward": [0.4926932378161707, -1.5059999999999998, -2.0029999999999997], "policy_red_v29_reward": [-0.5559999999999998], "policy_red_v25_reward": [-0.003, -2.013999999999999], "policy_red_v7_reward": [-2.0059999999999993], "policy_red_v81_reward": [-2.0059999999999993], "policy_red_v20_reward": [1.4866932378161715], "policy_red_v52_reward": [-0.1529999999999999, -2.012], "policy_red_v73_reward": [-2.0799999999999925], "policy_red_v2_reward": [-2.005], "policy_red_v83_reward": [-2.0029999999999997, -1.006], "policy_red_v39_reward": [1.98134375], "policy_red_v55_reward": [0.5006932378161701], "policy_red_v40_reward": [1.5026932378161697], "policy_red_v13_reward": [3.6069093750000016], "policy_red_v66_reward": [-2.0069999999999997], "policy_red_v18_reward": [0.8500000000000001], "policy_red_v68_reward": [1.976421875], "policy_red_v33_reward": [-0.2500000000000006, -0.006], "policy_red_v79_reward": [-2.0039999999999996], "policy_red_v16_reward": [1.9637968749999999], "policy_red_v78_reward": [-1.507], "policy_red_v37_reward": [-0.5069999999999999], "policy_red_v19_reward": [-1.0159999999999991], "policy_red_v53_reward": [0.17605000000000004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8239423286097401, "mean_inference_ms": 7.720459943591862, "mean_action_processing_ms": 0.29449634162463495, "mean_env_wait_ms": 0.3930295699749412, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10177266597747803, "StateBufferConnector_ms": 0.004220724105834961, "ViewRequirementAgentConnector_ms": 0.11696171760559082}}, "episode_reward_max": 4.47426147563234, "episode_reward_min": -2.637948082227053, "episode_reward_mean": 2.15600702776118, "episode_len_mean": 62.53, "episodes_this_iter": 53, "policy_reward_min": {"blue": -2.022999999999998, "red": -3.9789480822270633, "red_v67": -2.0819999999999923, "red_v82": -0.15799999999999992, "red_v28": -0.16599999999999993, "red_v50": -2.002, "red_v44": 1.1490500000000026, "red_v71": -2.0159999999999987, "red_v1": -2.007999999999999, "red_v80": -2.0, "red_v69": -2.0029999999999997, "red_v29": -0.5559999999999998, "red_v25": -2.013999999999999, "red_v7": -2.0059999999999993, "red_v81": -2.0059999999999993, "red_v20": 1.4866932378161715, "red_v52": -2.012, "red_v73": -2.0799999999999925, "red_v2": -2.005, "red_v83": -2.0029999999999997, "red_v39": 1.98134375, "red_v55": 0.5006932378161701, "red_v40": 1.5026932378161697, "red_v13": 3.6069093750000016, "red_v66": -2.0069999999999997, "red_v18": 0.8500000000000001, "red_v68": 1.976421875, "red_v33": -0.2500000000000006, "red_v79": -2.0039999999999996, "red_v16": 1.9637968749999999, "red_v78": -1.507, "red_v37": -0.5069999999999999, "red_v19": -1.0159999999999991, "red_v53": 0.17605000000000004}, "policy_reward_max": {"blue": 1.3410000000000024, "red": 3.995556158544055, "red_v67": -2.0819999999999923, "red_v82": 1.98575, "red_v28": -0.16599999999999993, "red_v50": -2.002, "red_v44": 1.1490500000000026, "red_v71": -1.0119999999999993, "red_v1": -2.007999999999999, "red_v80": -2.0, "red_v69": 0.4926932378161707, "red_v29": -0.5559999999999998, "red_v25": -0.003, "red_v7": -2.0059999999999993, "red_v81": -2.0059999999999993, "red_v20": 1.4866932378161715, "red_v52": -0.1529999999999999, "red_v73": -2.0799999999999925, "red_v2": -2.005, "red_v83": -1.006, "red_v39": 1.98134375, "red_v55": 0.5006932378161701, "red_v40": 1.5026932378161697, "red_v13": 3.6069093750000016, "red_v66": -2.0069999999999997, "red_v18": 0.8500000000000001, "red_v68": 1.976421875, "red_v33": -0.006, "red_v79": -2.0039999999999996, "red_v16": 1.9637968749999999, "red_v78": -1.507, "red_v37": -0.5069999999999999, "red_v19": -1.0159999999999991, "red_v53": 0.17605000000000004}, "policy_reward_mean": {"blue": -1.06112844279661, "red": 3.001381860748532, "red_v67": -2.0819999999999923, "red_v82": 0.913875, "red_v28": -0.16599999999999993, "red_v50": -2.002, "red_v44": 1.1490500000000026, "red_v71": -1.5123333333333326, "red_v1": -2.007999999999999, "red_v80": -2.0, "red_v69": -1.0054355873946095, "red_v29": -0.5559999999999998, "red_v25": -1.0084999999999995, "red_v7": -2.0059999999999993, "red_v81": -2.0059999999999993, "red_v20": 1.4866932378161715, "red_v52": -1.0825, "red_v73": -2.0799999999999925, "red_v2": -2.005, "red_v83": -1.5044999999999997, "red_v39": 1.98134375, "red_v55": 0.5006932378161701, "red_v40": 1.5026932378161697, "red_v13": 3.6069093750000016, "red_v66": -2.0069999999999997, "red_v18": 0.8500000000000001, "red_v68": 1.976421875, "red_v33": -0.1280000000000003, "red_v79": -2.0039999999999996, "red_v16": 1.9637968749999999, "red_v78": -1.507, "red_v37": -0.5069999999999999, "red_v19": -1.0159999999999991, "red_v53": 0.17605000000000004}, "hist_stats": {"episode_reward": [2.447021362816172, 1.9779276128161707, 2.48441198781617, 1.2272401128161803, 0.607115112816172, 3.3068651128161712, 1.4623807378152036, 2.490739417772942, 3.2895057378161727, 2.98681823781617, 1.9488338628161714, 1.4735682378161703, 2.942427612816172, 4.100930737816174, 1.9270369878161722, 1.987853033544055, 2.8807367300000006, 2.38473673, 2.4872244878152037, 1.9719744878161705, 1.4550526128161714, -2.637948082227053, 1.9814119878161702, 2.454349487816171, 1.9807939894425923, -0.16442187499999983, 3.949198975632342, 2.937333167772942, 1.952755737816171, 2.463458862816171, 2.4577244878161704, 1.3700336050000004, 2.960056158544056, 1.8777367300000005, 0.9274744878161714, 1.4780057378161704, 1.4656463628161704, 3.4681619878161705, 1.9910362927729417, 2.48470886281617, 4.446605225632341, 3.3379276128152036, 1.9693807378161707, 2.4808182378152037, 2.485333862815204, 2.4682713628161705, 1.2264588628161814, 2.4883338628161704, 1.667909375, 2.4879276128161703, 2.3650023550000006, 2.4658408644425927, 2.4841151128161703, 1.3861429800000002, 1.4775994878161702, 1.4804467835440551, 1.164503125, 1.9860369878152038, 3.9762614756323407, 4.47426147563234, 3.6096026128161727, 1.331046875, 1.462458862816171, 3.84392761281617, 2.9623807378161704, 1.9771144177729418, 2.1668000000000003, 2.456943237816171, -1.8649999999999114, 0.9479119878161703, 2.3552679800000007, 2.4906307378161703, 2.9427244878161707, 2.9768963628161704, 2.4784119878161706, 1.9729814894425926, 0.840859375, 2.98863073781617, 1.9662713628161712, 1.4851151128161701, 2.971603033544055, 2.4794119878152046, 1.9714901128161708, 2.4354276128161727, 2.480115112815204, 2.4537557378161705, 2.4686776128161707, 0.9323651128161713, -0.07065624999999986, 2.3698148550000004, 0.93370886281617, 2.4481307378161703, 2.9705682378161704, 0.7681307378161704, 1.9855213628161699, 2.4856307378161704, 2.4488651128161725, 1.992556158544055, 2.4682713628161705, 3.659243237816171], "episode_lengths": [55, 21, 26, 241, 409, 41, 36, 17, 60, 24, 51, 40, 53, 68, 82, 16, 15, 15, 22, 38, 45, 557, 26, 46, 13, 103, 60, 19, 44, 43, 54, 16, 47, 15, 70, 28, 47, 42, 18, 27, 58, 21, 36, 24, 19, 39, 235, 19, 13, 21, 26, 30, 25, 13, 30, 18, 15, 18, 40, 40, 77, 17, 43, 21, 36, 25, 16, 48, 1280, 58, 37, 20, 54, 31, 26, 17, 13, 20, 39, 25, 32, 26, 33, 53, 25, 44, 37, 73, 18, 22, 91, 52, 40, 244, 23, 20, 41, 15, 39, 32], "policy_blue_reward": [-1.0119999999999998, -2.0119999999999996, -1.0049999999999997, 0.10842187500000133, -2.01, -1.0049999999999997, -0.004, -2.022999999999998, -0.018000000000000006, -0.006, -1.0029999999999997, -1.0039999999999998, -2.012999999999999, 1.3410000000000024, -2.0089999999999995, -1.0139999999999991, -0.5159999999999999, -1.010999999999999, -2.01, -1.5219999999999998, -2.0099999999999993, 0.492, -0.502, -1.004, -2.0109999999999992, -1.006, -1.0079999999999991, -1.0079999999999998, -1.005, -1.0059999999999996, -1.007, -1.003, -1.0059999999999993, -2.003, -2.0079999999999996, -0.507, -1.0039999999999998, -1.011999999999999, -1.513, -1.01, -1.0029999999999997, -0.012, -0.008, -1.0099999999999996, -2.005, -2.0059999999999993, -2.005, -0.004, -1.0039999999999998, -1.019, -1.0059999999999998, -1.0159999999999993, -1.0099999999999993, -1.5150000000000001, -1.006, -1.0099999999999998, -1.0630000000000002, -2.0029999999999997, -1.0129999999999992], "policy_red_v67_reward": [-2.0819999999999923], "policy_red_v82_reward": [-0.15799999999999992, 1.98575], "policy_red_v28_reward": [-0.16599999999999993], "policy_red_v50_reward": [-2.002], "policy_red_v44_reward": [1.1490500000000026], "policy_red_v71_reward": [-2.0159999999999987, -1.509, -1.0119999999999993], "policy_red_v1_reward": [-2.007999999999999], "policy_red_v80_reward": [-2.0], "policy_red_v69_reward": [0.4926932378161707, -1.5059999999999998, -2.0029999999999997], "policy_red_v29_reward": [-0.5559999999999998], "policy_red_v25_reward": [-0.003, -2.013999999999999], "policy_red_v7_reward": [-2.0059999999999993], "policy_red_v81_reward": [-2.0059999999999993], "policy_red_v20_reward": [1.4866932378161715], "policy_red_v52_reward": [-0.1529999999999999, -2.012], "policy_red_v73_reward": [-2.0799999999999925], "policy_red_v2_reward": [-2.005], "policy_red_v83_reward": [-2.0029999999999997, -1.006], "policy_red_v39_reward": [1.98134375], "policy_red_v55_reward": [0.5006932378161701], "policy_red_v40_reward": [1.5026932378161697], "policy_red_v13_reward": [3.6069093750000016], "policy_red_v66_reward": [-2.0069999999999997], "policy_red_v18_reward": [0.8500000000000001], "policy_red_v68_reward": [1.976421875], "policy_red_v33_reward": [-0.2500000000000006, -0.006], "policy_red_v79_reward": [-2.0039999999999996], "policy_red_v16_reward": [1.9637968749999999], "policy_red_v78_reward": [-1.507], "policy_red_v37_reward": [-0.5069999999999999], "policy_red_v19_reward": [-1.0159999999999991], "policy_red_v53_reward": [0.17605000000000004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8239423286097401, "mean_inference_ms": 7.720459943591862, "mean_action_processing_ms": 0.29449634162463495, "mean_env_wait_ms": 0.3930295699749412, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10177266597747803, "StateBufferConnector_ms": 0.004220724105834961, "ViewRequirementAgentConnector_ms": 0.11696171760559082}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 197.43996728966607, "num_env_steps_trained_throughput_per_sec": 197.43996728966607, "timesteps_total": 472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 19932.869, "sample_time_ms": 1194.201, "learn_time_ms": 18654.454, "learn_throughput": 214.426, "synch_weights_time_ms": 80.836}, "counters": {"num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "episodes_total": 2729, "training_iteration": 118, "trial_id": "a9680_00000", "date": "2023-09-24_03-20-29", "timestamp": 1695540029, "time_this_iter_s": 20.269368410110474, "time_total_s": 2354.1509504318237, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1db62a10>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1dce0700>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1dce0790>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2354.1509504318237, "iterations_since_restore": 118, "perf": {"cpu_util_percent": 5.383333333333334, "ram_util_percent": 26.886111111111106}, "win_rate": 0.85, "league_size": 87}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3489612343410653, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.031852548057698486, "policy_loss": -0.047974915937326536, "vf_loss": 0.14849291282201496, "vf_explained_var": 0.8441741634781162, "kl": 0.015631020348018866, "entropy": 1.4529511851569017, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 113760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_agent_steps_sampled": 952000, "num_agent_steps_trained": 952000}, "sampler_results": {"episode_reward_max": 4.491620155589111, "episode_reward_min": -1.8649999999999114, "episode_reward_mean": 2.156744999300708, "episode_len_mean": 61.49, "episode_media": {}, "episodes_this_iter": 48, "policy_reward_min": {"red_v2": -2.005, "red": -1.6149999999999356, "blue": -2.015999999999999, "red_v52": -2.012, "red_v83": -2.0029999999999997, "red_v39": -1.5139999999999998, "red_v55": 0.5006932378161701, "red_v40": 1.5026932378161697, "red_v13": 3.6069093750000016, "red_v66": -2.0069999999999997, "red_v25": -2.013999999999999, "red_v18": 0.8500000000000001, "red_v68": 1.976421875, "red_v33": -0.2500000000000006, "red_v79": -2.0039999999999996, "red_v16": 0.5056932378161696, "red_v69": -2.0029999999999997, "red_v78": -2.0289999999999973, "red_v37": -2.0039999999999996, "red_v19": -1.0159999999999991, "red_v53": 0.17605000000000004, "red_v1": -2.008999999999999, "red_v61": -2.005, "red_v34": -2.008, "red_v67": -1.0169999999999983, "red_v3": -1.0259999999999996, "red_v42": -1.548, "red_v63": 0.489, "red_v47": -2.0119999999999996, "red_v32": -2.0089999999999995, "red_v71": -2.004, "red_v44": 0.39428360500000037, "red_v60": -1.0219999999999998, "red_v7": -1.511, "red_v27": 1.499692542772942, "red_v5": -1.0179999999999993, "red_v8": -0.006, "red_v51": -2.012999999999999, "red_v21": 0.446}, "policy_reward_max": {"red_v2": -2.005, "red": 3.995556158544055, "blue": 0.492, "red_v52": -1.003, "red_v83": -1.006, "red_v39": 1.98134375, "red_v55": 0.5006932378161701, "red_v40": 1.5026932378161697, "red_v13": 3.6069093750000016, "red_v66": -1.002, "red_v25": -2.013999999999999, "red_v18": 0.8500000000000001, "red_v68": 1.976421875, "red_v33": 1.6490500000000017, "red_v79": -2.0039999999999996, "red_v16": 1.9637968749999999, "red_v69": -1.5059999999999998, "red_v78": -1.507, "red_v37": -0.5069999999999999, "red_v19": -1.0159999999999991, "red_v53": 0.17605000000000004, "red_v1": -2.008999999999999, "red_v61": -2.005, "red_v34": -2.008, "red_v67": -1.0169999999999983, "red_v3": -1.0149999999999992, "red_v42": -1.548, "red_v63": 0.489, "red_v47": 0.4996925427729424, "red_v32": -2.0089999999999995, "red_v71": -2.004, "red_v44": 0.39428360500000037, "red_v60": 0.39528360500000037, "red_v7": -1.511, "red_v27": 1.499692542772942, "red_v5": -1.0179999999999993, "red_v8": -0.006, "red_v51": -2.012999999999999, "red_v21": 0.446}, "policy_reward_mean": {"red_v2": -2.005, "red": 3.074968960460763, "blue": -1.2127599999999996, "red_v52": -1.5074999999999998, "red_v83": -1.5044999999999997, "red_v39": 0.23367187500000008, "red_v55": 0.5006932378161701, "red_v40": 1.5026932378161697, "red_v13": 3.6069093750000016, "red_v66": -1.5044999999999997, "red_v25": -2.013999999999999, "red_v18": 0.8500000000000001, "red_v68": 1.976421875, "red_v33": 0.4643500000000003, "red_v79": -2.0039999999999996, "red_v16": 1.2347450564080846, "red_v69": -1.7544999999999997, "red_v78": -1.7679999999999985, "red_v37": -1.2554999999999996, "red_v19": -1.0159999999999991, "red_v53": 0.17605000000000004, "red_v1": -2.008999999999999, "red_v61": -2.005, "red_v34": -2.008, "red_v67": -1.0169999999999983, "red_v3": -1.0204999999999993, "red_v42": -1.548, "red_v63": 0.489, "red_v47": -0.7561537286135286, "red_v32": -2.0089999999999995, "red_v71": -2.004, "red_v44": 0.39428360500000037, "red_v60": -0.3133581974999997, "red_v7": -1.511, "red_v27": 1.499692542772942, "red_v5": -1.0179999999999993, "red_v8": -0.006, "red_v51": -2.012999999999999, "red_v21": 0.446}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.667909375, 2.4879276128161703, 2.3650023550000006, 2.4658408644425927, 2.4841151128161703, 1.3861429800000002, 1.4775994878161702, 1.4804467835440551, 1.164503125, 1.9860369878152038, 3.9762614756323407, 4.47426147563234, 3.6096026128161727, 1.331046875, 1.462458862816171, 3.84392761281617, 2.9623807378161704, 1.9771144177729418, 2.1668000000000003, 2.456943237816171, -1.8649999999999114, 0.9479119878161703, 2.3552679800000007, 2.4906307378161703, 2.9427244878161707, 2.9768963628161704, 2.4784119878161706, 1.9729814894425926, 0.840859375, 2.98863073781617, 1.9662713628161712, 1.4851151128161701, 2.971603033544055, 2.4794119878152046, 1.9714901128161708, 2.4354276128161727, 2.480115112815204, 2.4537557378161705, 2.4686776128161707, 0.9323651128161713, -0.07065624999999986, 2.3698148550000004, 0.93370886281617, 2.4481307378161703, 2.9705682378161704, 0.7681307378161704, 1.9855213628161699, 2.4856307378161704, 2.4488651128161725, 1.992556158544055, 2.4682713628161705, 3.659243237816171, 1.9737869878161705, 1.9832244878161702, 1.4850405335440549, 2.456943237816171, 0.6480656250000004, 1.9847436585440552, 2.339661987816172, 2.48081823781617, 1.3851429800000008, 2.4448651128161716, 0.9198651128161708, 1.3900937500000001, 1.446130737816172, 2.453349487816171, 1.3984658644425942, 0.8351562500000003, 2.469895667772943, 3.8812893428161703, 2.490446783544055, 2.4471307378161713, 3.88110184281617, -0.9042812500000001, 1.9503807378161722, 1.450943237816171, 3.9874802256323396, 1.98863073781617, 2.4319588628161717, 0.9617557378161712, 2.48622448781617, 3.980260780589112, 2.1668000000000003, 2.458755737816172, 2.4600526128161713, 4.491620155589111, 2.436911987816172, 2.9873338628161705, 1.9572401128161703, 3.5994463628161735, 1.938943237816172, 2.3800336050000004, 2.4708963628161706, 2.4725213628161704, 1.981927612815204, 3.4393338628161705, 1.3418593749999999, 1.9733877394425923, 1.8319375, 0.6972713628161703], "episode_lengths": [13, 21, 26, 30, 25, 13, 30, 18, 15, 18, 40, 40, 77, 17, 43, 21, 36, 25, 16, 48, 1280, 58, 37, 20, 54, 31, 26, 17, 13, 20, 39, 25, 32, 26, 33, 53, 25, 44, 37, 73, 18, 22, 91, 52, 40, 244, 23, 20, 41, 15, 39, 32, 34, 22, 20, 48, 27, 19, 202, 24, 13, 41, 745, 34, 52, 46, 86, 14, 31, 28, 18, 52, 24, 282, 36, 48, 34, 20, 75, 44, 22, 40, 16, 44, 45, 21, 58, 19, 49, 63, 48, 16, 31, 23, 21, 19, 13, 15, 20, 295], "policy_red_v2_reward": [-2.005], "policy_blue_reward": [-1.0059999999999996, -1.007, -1.003, -1.0059999999999993, -2.003, -2.0079999999999996, -0.507, -1.0039999999999998, -1.011999999999999, -1.513, -1.01, -1.0029999999999997, -0.012, -0.008, -1.0099999999999996, -2.005, -2.0059999999999993, -2.005, -0.004, -1.0039999999999998, -1.019, -1.0059999999999998, -1.0159999999999993, -1.0099999999999993, -1.5150000000000001, -1.006, -1.0099999999999998, -1.0630000000000002, -2.0029999999999997, -1.0129999999999992, -2.0089999999999995, -1.0159999999999987, -1.0089999999999997, -2.0039999999999996, -1.009, 0.492, -1.0049999999999997, -1.585, -2.0139999999999993, -2.015999999999999, -2.005, -1.0199999999999982, -1.0059999999999996, -1.0079999999999991, -1.0049999999999997, -1.0129999999999995, -2.0059999999999993, -2.001, -1.004, -1.5979999999999996], "policy_red_v52_reward": [-2.012, -1.003], "policy_red_v83_reward": [-2.0029999999999997, -1.006], "policy_red_v39_reward": [1.98134375, -1.5139999999999998], "policy_red_v55_reward": [0.5006932378161701], "policy_red_v40_reward": [1.5026932378161697], "policy_red_v13_reward": [3.6069093750000016], "policy_red_v66_reward": [-2.0069999999999997, -1.002], "policy_red_v25_reward": [-2.013999999999999], "policy_red_v18_reward": [0.8500000000000001], "policy_red_v68_reward": [1.976421875], "policy_red_v33_reward": [-0.2500000000000006, -0.006, 1.6490500000000017], "policy_red_v79_reward": [-2.0039999999999996], "policy_red_v16_reward": [1.9637968749999999, 0.5056932378161696], "policy_red_v69_reward": [-1.5059999999999998, -2.0029999999999997], "policy_red_v78_reward": [-1.507, -2.0289999999999973], "policy_red_v37_reward": [-0.5069999999999999, -2.0039999999999996], "policy_red_v19_reward": [-1.0159999999999991], "policy_red_v53_reward": [0.17605000000000004], "policy_red_v1_reward": [-2.008999999999999], "policy_red_v61_reward": [-2.005], "policy_red_v34_reward": [-2.008], "policy_red_v67_reward": [-1.0169999999999983], "policy_red_v3_reward": [-1.0259999999999996, -1.0149999999999992], "policy_red_v42_reward": [-1.548], "policy_red_v63_reward": [0.489], "policy_red_v47_reward": [-2.0119999999999996, 0.4996925427729424], "policy_red_v32_reward": [-2.0089999999999995], "policy_red_v71_reward": [-2.004], "policy_red_v44_reward": [0.39428360500000037], "policy_red_v60_reward": [-1.0219999999999998, 0.39528360500000037], "policy_red_v7_reward": [-1.511], "policy_red_v27_reward": [1.499692542772942], "policy_red_v5_reward": [-1.0179999999999993], "policy_red_v8_reward": [-0.006], "policy_red_v51_reward": [-2.012999999999999], "policy_red_v21_reward": [0.446]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8259783426319659, "mean_inference_ms": 7.755061556056156, "mean_action_processing_ms": 0.29534957398701395, "mean_env_wait_ms": 0.3942521016480425, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10118281841278076, "StateBufferConnector_ms": 0.004228353500366211, "ViewRequirementAgentConnector_ms": 0.11621749401092529}}, "episode_reward_max": 4.491620155589111, "episode_reward_min": -1.8649999999999114, "episode_reward_mean": 2.156744999300708, "episode_len_mean": 61.49, "episodes_this_iter": 48, "policy_reward_min": {"red_v2": -2.005, "red": -1.6149999999999356, "blue": -2.015999999999999, "red_v52": -2.012, "red_v83": -2.0029999999999997, "red_v39": -1.5139999999999998, "red_v55": 0.5006932378161701, "red_v40": 1.5026932378161697, "red_v13": 3.6069093750000016, "red_v66": -2.0069999999999997, "red_v25": -2.013999999999999, "red_v18": 0.8500000000000001, "red_v68": 1.976421875, "red_v33": -0.2500000000000006, "red_v79": -2.0039999999999996, "red_v16": 0.5056932378161696, "red_v69": -2.0029999999999997, "red_v78": -2.0289999999999973, "red_v37": -2.0039999999999996, "red_v19": -1.0159999999999991, "red_v53": 0.17605000000000004, "red_v1": -2.008999999999999, "red_v61": -2.005, "red_v34": -2.008, "red_v67": -1.0169999999999983, "red_v3": -1.0259999999999996, "red_v42": -1.548, "red_v63": 0.489, "red_v47": -2.0119999999999996, "red_v32": -2.0089999999999995, "red_v71": -2.004, "red_v44": 0.39428360500000037, "red_v60": -1.0219999999999998, "red_v7": -1.511, "red_v27": 1.499692542772942, "red_v5": -1.0179999999999993, "red_v8": -0.006, "red_v51": -2.012999999999999, "red_v21": 0.446}, "policy_reward_max": {"red_v2": -2.005, "red": 3.995556158544055, "blue": 0.492, "red_v52": -1.003, "red_v83": -1.006, "red_v39": 1.98134375, "red_v55": 0.5006932378161701, "red_v40": 1.5026932378161697, "red_v13": 3.6069093750000016, "red_v66": -1.002, "red_v25": -2.013999999999999, "red_v18": 0.8500000000000001, "red_v68": 1.976421875, "red_v33": 1.6490500000000017, "red_v79": -2.0039999999999996, "red_v16": 1.9637968749999999, "red_v69": -1.5059999999999998, "red_v78": -1.507, "red_v37": -0.5069999999999999, "red_v19": -1.0159999999999991, "red_v53": 0.17605000000000004, "red_v1": -2.008999999999999, "red_v61": -2.005, "red_v34": -2.008, "red_v67": -1.0169999999999983, "red_v3": -1.0149999999999992, "red_v42": -1.548, "red_v63": 0.489, "red_v47": 0.4996925427729424, "red_v32": -2.0089999999999995, "red_v71": -2.004, "red_v44": 0.39428360500000037, "red_v60": 0.39528360500000037, "red_v7": -1.511, "red_v27": 1.499692542772942, "red_v5": -1.0179999999999993, "red_v8": -0.006, "red_v51": -2.012999999999999, "red_v21": 0.446}, "policy_reward_mean": {"red_v2": -2.005, "red": 3.074968960460763, "blue": -1.2127599999999996, "red_v52": -1.5074999999999998, "red_v83": -1.5044999999999997, "red_v39": 0.23367187500000008, "red_v55": 0.5006932378161701, "red_v40": 1.5026932378161697, "red_v13": 3.6069093750000016, "red_v66": -1.5044999999999997, "red_v25": -2.013999999999999, "red_v18": 0.8500000000000001, "red_v68": 1.976421875, "red_v33": 0.4643500000000003, "red_v79": -2.0039999999999996, "red_v16": 1.2347450564080846, "red_v69": -1.7544999999999997, "red_v78": -1.7679999999999985, "red_v37": -1.2554999999999996, "red_v19": -1.0159999999999991, "red_v53": 0.17605000000000004, "red_v1": -2.008999999999999, "red_v61": -2.005, "red_v34": -2.008, "red_v67": -1.0169999999999983, "red_v3": -1.0204999999999993, "red_v42": -1.548, "red_v63": 0.489, "red_v47": -0.7561537286135286, "red_v32": -2.0089999999999995, "red_v71": -2.004, "red_v44": 0.39428360500000037, "red_v60": -0.3133581974999997, "red_v7": -1.511, "red_v27": 1.499692542772942, "red_v5": -1.0179999999999993, "red_v8": -0.006, "red_v51": -2.012999999999999, "red_v21": 0.446}, "hist_stats": {"episode_reward": [1.667909375, 2.4879276128161703, 2.3650023550000006, 2.4658408644425927, 2.4841151128161703, 1.3861429800000002, 1.4775994878161702, 1.4804467835440551, 1.164503125, 1.9860369878152038, 3.9762614756323407, 4.47426147563234, 3.6096026128161727, 1.331046875, 1.462458862816171, 3.84392761281617, 2.9623807378161704, 1.9771144177729418, 2.1668000000000003, 2.456943237816171, -1.8649999999999114, 0.9479119878161703, 2.3552679800000007, 2.4906307378161703, 2.9427244878161707, 2.9768963628161704, 2.4784119878161706, 1.9729814894425926, 0.840859375, 2.98863073781617, 1.9662713628161712, 1.4851151128161701, 2.971603033544055, 2.4794119878152046, 1.9714901128161708, 2.4354276128161727, 2.480115112815204, 2.4537557378161705, 2.4686776128161707, 0.9323651128161713, -0.07065624999999986, 2.3698148550000004, 0.93370886281617, 2.4481307378161703, 2.9705682378161704, 0.7681307378161704, 1.9855213628161699, 2.4856307378161704, 2.4488651128161725, 1.992556158544055, 2.4682713628161705, 3.659243237816171, 1.9737869878161705, 1.9832244878161702, 1.4850405335440549, 2.456943237816171, 0.6480656250000004, 1.9847436585440552, 2.339661987816172, 2.48081823781617, 1.3851429800000008, 2.4448651128161716, 0.9198651128161708, 1.3900937500000001, 1.446130737816172, 2.453349487816171, 1.3984658644425942, 0.8351562500000003, 2.469895667772943, 3.8812893428161703, 2.490446783544055, 2.4471307378161713, 3.88110184281617, -0.9042812500000001, 1.9503807378161722, 1.450943237816171, 3.9874802256323396, 1.98863073781617, 2.4319588628161717, 0.9617557378161712, 2.48622448781617, 3.980260780589112, 2.1668000000000003, 2.458755737816172, 2.4600526128161713, 4.491620155589111, 2.436911987816172, 2.9873338628161705, 1.9572401128161703, 3.5994463628161735, 1.938943237816172, 2.3800336050000004, 2.4708963628161706, 2.4725213628161704, 1.981927612815204, 3.4393338628161705, 1.3418593749999999, 1.9733877394425923, 1.8319375, 0.6972713628161703], "episode_lengths": [13, 21, 26, 30, 25, 13, 30, 18, 15, 18, 40, 40, 77, 17, 43, 21, 36, 25, 16, 48, 1280, 58, 37, 20, 54, 31, 26, 17, 13, 20, 39, 25, 32, 26, 33, 53, 25, 44, 37, 73, 18, 22, 91, 52, 40, 244, 23, 20, 41, 15, 39, 32, 34, 22, 20, 48, 27, 19, 202, 24, 13, 41, 745, 34, 52, 46, 86, 14, 31, 28, 18, 52, 24, 282, 36, 48, 34, 20, 75, 44, 22, 40, 16, 44, 45, 21, 58, 19, 49, 63, 48, 16, 31, 23, 21, 19, 13, 15, 20, 295], "policy_red_v2_reward": [-2.005], "policy_blue_reward": [-1.0059999999999996, -1.007, -1.003, -1.0059999999999993, -2.003, -2.0079999999999996, -0.507, -1.0039999999999998, -1.011999999999999, -1.513, -1.01, -1.0029999999999997, -0.012, -0.008, -1.0099999999999996, -2.005, -2.0059999999999993, -2.005, -0.004, -1.0039999999999998, -1.019, -1.0059999999999998, -1.0159999999999993, -1.0099999999999993, -1.5150000000000001, -1.006, -1.0099999999999998, -1.0630000000000002, -2.0029999999999997, -1.0129999999999992, -2.0089999999999995, -1.0159999999999987, -1.0089999999999997, -2.0039999999999996, -1.009, 0.492, -1.0049999999999997, -1.585, -2.0139999999999993, -2.015999999999999, -2.005, -1.0199999999999982, -1.0059999999999996, -1.0079999999999991, -1.0049999999999997, -1.0129999999999995, -2.0059999999999993, -2.001, -1.004, -1.5979999999999996], "policy_red_v52_reward": [-2.012, -1.003], "policy_red_v83_reward": [-2.0029999999999997, -1.006], "policy_red_v39_reward": [1.98134375, -1.5139999999999998], "policy_red_v55_reward": [0.5006932378161701], "policy_red_v40_reward": [1.5026932378161697], "policy_red_v13_reward": [3.6069093750000016], "policy_red_v66_reward": [-2.0069999999999997, -1.002], "policy_red_v25_reward": [-2.013999999999999], "policy_red_v18_reward": [0.8500000000000001], "policy_red_v68_reward": [1.976421875], "policy_red_v33_reward": [-0.2500000000000006, -0.006, 1.6490500000000017], "policy_red_v79_reward": [-2.0039999999999996], "policy_red_v16_reward": [1.9637968749999999, 0.5056932378161696], "policy_red_v69_reward": [-1.5059999999999998, -2.0029999999999997], "policy_red_v78_reward": [-1.507, -2.0289999999999973], "policy_red_v37_reward": [-0.5069999999999999, -2.0039999999999996], "policy_red_v19_reward": [-1.0159999999999991], "policy_red_v53_reward": [0.17605000000000004], "policy_red_v1_reward": [-2.008999999999999], "policy_red_v61_reward": [-2.005], "policy_red_v34_reward": [-2.008], "policy_red_v67_reward": [-1.0169999999999983], "policy_red_v3_reward": [-1.0259999999999996, -1.0149999999999992], "policy_red_v42_reward": [-1.548], "policy_red_v63_reward": [0.489], "policy_red_v47_reward": [-2.0119999999999996, 0.4996925427729424], "policy_red_v32_reward": [-2.0089999999999995], "policy_red_v71_reward": [-2.004], "policy_red_v44_reward": [0.39428360500000037], "policy_red_v60_reward": [-1.0219999999999998, 0.39528360500000037], "policy_red_v7_reward": [-1.511], "policy_red_v27_reward": [1.499692542772942], "policy_red_v5_reward": [-1.0179999999999993], "policy_red_v8_reward": [-0.006], "policy_red_v51_reward": [-2.012999999999999], "policy_red_v21_reward": [0.446]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8259783426319659, "mean_inference_ms": 7.755061556056156, "mean_action_processing_ms": 0.29534957398701395, "mean_env_wait_ms": 0.3942521016480425, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10118281841278076, "StateBufferConnector_ms": 0.004228353500366211, "ViewRequirementAgentConnector_ms": 0.11621749401092529}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 952000, "num_agent_steps_trained": 952000, "num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 208.1452746730423, "num_env_steps_trained_throughput_per_sec": 208.1452746730423, "timesteps_total": 476000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 952000, "timers": {"training_iteration_time_ms": 19853.189, "sample_time_ms": 1191.338, "learn_time_ms": 18576.152, "learn_throughput": 215.33, "synch_weights_time_ms": 82.386}, "counters": {"num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_agent_steps_sampled": 952000, "num_agent_steps_trained": 952000}, "done": false, "episodes_total": 2777, "training_iteration": 119, "trial_id": "a9680_00000", "date": "2023-09-24_03-20-53", "timestamp": 1695540053, "time_this_iter_s": 19.229349851608276, "time_total_s": 2373.380300283432, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1db61960>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1dce0e50>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1dce0ee0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2373.380300283432, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 5.555882352941177, "ram_util_percent": 27.008823529411764}, "win_rate": 0.83, "league_size": 88}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1744166783988477, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.03229040136745122, "policy_loss": -0.03858509337539241, "vf_loss": 0.1300941960614485, "vf_explained_var": 0.8506135029097398, "kl": 0.016104621052189336, "entropy": 1.4186824115614096, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 114720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "sampler_results": {"episode_reward_max": 4.491620155589111, "episode_reward_min": -1.8659999999999126, "episode_reward_mean": 2.188165539101043, "episode_len_mean": 70.63, "episode_media": {}, "episodes_this_iter": 41, "policy_reward_min": {"blue": -2.027999999999999, "red": -1.2119999999999818, "red_v78": -2.0289999999999973, "red_v37": -2.0039999999999996, "red_v69": -2.0029999999999997, "red_v83": -1.006, "red_v19": -1.0159999999999991, "red_v53": 0.17605000000000004, "red_v1": -2.008999999999999, "red_v61": -2.005, "red_v39": -1.5139999999999998, "red_v34": -2.008, "red_v67": -1.0169999999999983, "red_v3": -1.0259999999999996, "red_v42": -1.548, "red_v63": 0.489, "red_v47": -2.0119999999999996, "red_v32": -2.0089999999999995, "red_v71": -2.004, "red_v44": 0.39428360500000037, "red_v60": -1.0219999999999998, "red_v16": 0.5056932378161696, "red_v7": -1.511, "red_v66": -1.002, "red_v52": -1.003, "red_v27": 1.499692542772942, "red_v5": -1.0179999999999993, "red_v8": -0.006, "red_v51": -2.012999999999999, "red_v33": 1.4839346144425924, "red_v21": 0.446, "red_v82": -2.011, "red_v9": -2.024999999999998, "red_v59": -0.553, "red_v64": -1.002, "red_v65": -2.022999999999998, "red_v29": 0.1800500000000001, "red_v84": -0.513, "red_v77": -2.01, "red_v20": 1.4926932378161704, "red_v50": 1.50169323781617, "red_v48": -0.5519999999999999}, "policy_reward_max": {"blue": 0.492, "red": 3.995556158544055, "red_v78": -1.507, "red_v37": -0.5069999999999999, "red_v69": -2.0029999999999997, "red_v83": -1.006, "red_v19": -1.0159999999999991, "red_v53": 0.17605000000000004, "red_v1": -2.008999999999999, "red_v61": -1.0189999999999995, "red_v39": -1.5139999999999998, "red_v34": -2.008, "red_v67": -1.0169999999999983, "red_v3": -1.0149999999999992, "red_v42": -1.548, "red_v63": 0.489, "red_v47": 0.4996925427729424, "red_v32": -2.006, "red_v71": -2.002, "red_v44": 0.39428360500000037, "red_v60": 0.39528360500000037, "red_v16": 0.5056932378161696, "red_v7": -0.5029999999999997, "red_v66": -1.002, "red_v52": -1.003, "red_v27": 1.499692542772942, "red_v5": -1.0179999999999993, "red_v8": -0.006, "red_v51": -2.012999999999999, "red_v33": 1.6490500000000017, "red_v21": 0.446, "red_v82": -2.011, "red_v9": -2.024999999999998, "red_v59": 0.38328360500000014, "red_v64": -0.6540000000000009, "red_v65": -2.022999999999998, "red_v29": 0.1800500000000001, "red_v84": -0.513, "red_v77": -2.01, "red_v20": 1.4926932378161704, "red_v50": 1.50169323781617, "red_v48": -0.5519999999999999}, "policy_reward_mean": {"blue": -1.3708085106382975, "red": 3.268391536816671, "red_v78": -1.7679999999999985, "red_v37": -1.2554999999999996, "red_v69": -2.0029999999999997, "red_v83": -1.006, "red_v19": -1.0159999999999991, "red_v53": 0.17605000000000004, "red_v1": -2.008999999999999, "red_v61": -1.6759999999999995, "red_v39": -1.5139999999999998, "red_v34": -2.008, "red_v67": -1.0169999999999983, "red_v3": -1.0204999999999993, "red_v42": -1.548, "red_v63": 0.489, "red_v47": -0.7561537286135286, "red_v32": -2.0074999999999994, "red_v71": -2.003, "red_v44": 0.39428360500000037, "red_v60": -0.3133581974999997, "red_v16": 0.5056932378161696, "red_v7": -1.0069999999999997, "red_v66": -1.002, "red_v52": -1.003, "red_v27": 1.499692542772942, "red_v5": -1.0179999999999993, "red_v8": -0.006, "red_v51": -2.012999999999999, "red_v33": 1.566492307221297, "red_v21": 0.446, "red_v82": -2.011, "red_v9": -2.024999999999998, "red_v59": -0.08485819749999995, "red_v64": -0.8280000000000005, "red_v65": -2.022999999999998, "red_v29": 0.1800500000000001, "red_v84": -0.513, "red_v77": -2.01, "red_v20": 1.4926932378161704, "red_v50": 1.50169323781617, "red_v48": -0.5519999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.3698148550000004, 0.93370886281617, 2.4481307378161703, 2.9705682378161704, 0.7681307378161704, 1.9855213628161699, 2.4856307378161704, 2.4488651128161725, 1.992556158544055, 2.4682713628161705, 3.659243237816171, 1.9737869878161705, 1.9832244878161702, 1.4850405335440549, 2.456943237816171, 0.6480656250000004, 1.9847436585440552, 2.339661987816172, 2.48081823781617, 1.3851429800000008, 2.4448651128161716, 0.9198651128161708, 1.3900937500000001, 1.446130737816172, 2.453349487816171, 1.3984658644425942, 0.8351562500000003, 2.469895667772943, 3.8812893428161703, 2.490446783544055, 2.4471307378161713, 3.88110184281617, -0.9042812500000001, 1.9503807378161722, 1.450943237816171, 3.9874802256323396, 1.98863073781617, 2.4319588628161717, 0.9617557378161712, 2.48622448781617, 3.980260780589112, 2.1668000000000003, 2.458755737816172, 2.4600526128161713, 4.491620155589111, 2.436911987816172, 2.9873338628161705, 1.9572401128161703, 3.5994463628161735, 1.938943237816172, 2.3800336050000004, 2.4708963628161706, 2.4725213628161704, 1.981927612815204, 3.4393338628161705, 1.3418593749999999, 1.9733877394425923, 1.8319375, 0.6972713628161703, 1.8438617300000006, 1.977524908544055, 1.485853033544055, 1.9483494878161718, 3.8571799678161702, 2.4866307378161703, 2.48981823781617, 1.9634901128161715, 2.45338073781617, 0.648349487816189, 1.914849487816173, 1.9923331677729421, 1.9866307378161703, 2.462271362816171, 4.4738622272587625, -1.8659999999999126, 2.476981489442592, 2.430099487816171, 1.4780057378161704, 1.8950057378161747, 1.4753026128161708, 3.56338048, 2.3032836050000003, 2.4093338628161725, 1.9644901128161703, 2.4864467835440554, 2.940149908544055, 2.954943237816171, 1.4762237927729418, 1.9852244878161696, 2.414255737816173, 2.482634283544055, 1.834640625, 1.4832244878161704, 1.4678721144425926, 4.462777100632342, 4.49010522563234, 1.1685031250000002, 2.9433338628152037, 1.3807367300000002, 1.9859276128161703], "episode_lengths": [22, 91, 52, 40, 244, 23, 20, 41, 15, 39, 32, 34, 22, 20, 48, 27, 19, 202, 24, 13, 41, 745, 34, 52, 46, 86, 14, 31, 28, 18, 52, 24, 282, 36, 48, 34, 20, 75, 44, 22, 40, 16, 44, 45, 21, 58, 19, 49, 63, 48, 16, 31, 23, 21, 19, 13, 15, 20, 295, 39, 25, 16, 46, 31, 20, 24, 33, 36, 878, 78, 19, 20, 39, 21, 1280, 17, 62, 28, 92, 29, 17, 64, 83, 33, 18, 17, 48, 22, 22, 76, 22, 19, 22, 20, 35, 26, 15, 19, 15, 21], "policy_blue_reward": [-1.006, -1.0099999999999998, -1.0630000000000002, -2.0029999999999997, -1.0129999999999992, -2.0089999999999995, -1.0159999999999987, -1.0089999999999997, -2.0039999999999996, -1.009, 0.492, -1.0049999999999997, -1.585, -2.0139999999999993, -2.015999999999999, -2.005, -1.0199999999999982, -1.0059999999999996, -1.0079999999999991, -1.0049999999999997, -1.0129999999999995, -2.0059999999999993, -2.001, -1.004, -1.5979999999999996, -2.006, -2.01, -1.0069999999999997, -2.012999999999999, -1.2380000000000002, -2.027999999999999, -2.0059999999999993, -1.011, -1.002, -1.0189999999999988, -2.0069999999999997, -2.009999999999999, -1.0199999999999991, -1.0269999999999981, -1.0079999999999996, -0.015000000000000001, -2.0079999999999996, -1.0349999999999977, -1.0059999999999996, -1.002, -2.0069999999999997, -2.0069999999999997], "policy_red_v78_reward": [-1.507, -2.0289999999999973], "policy_red_v37_reward": [-0.5069999999999999, -2.0039999999999996], "policy_red_v69_reward": [-2.0029999999999997], "policy_red_v83_reward": [-1.006], "policy_red_v19_reward": [-1.0159999999999991], "policy_red_v53_reward": [0.17605000000000004], "policy_red_v1_reward": [-2.008999999999999], "policy_red_v61_reward": [-2.005, -1.0189999999999995, -2.004], "policy_red_v39_reward": [-1.5139999999999998], "policy_red_v34_reward": [-2.008], "policy_red_v67_reward": [-1.0169999999999983], "policy_red_v3_reward": [-1.0259999999999996, -1.0149999999999992], "policy_red_v42_reward": [-1.548], "policy_red_v63_reward": [0.489], "policy_red_v47_reward": [-2.0119999999999996, 0.4996925427729424], "policy_red_v32_reward": [-2.0089999999999995, -2.006], "policy_red_v71_reward": [-2.004, -2.002], "policy_red_v44_reward": [0.39428360500000037], "policy_red_v60_reward": [-1.0219999999999998, 0.39528360500000037], "policy_red_v16_reward": [0.5056932378161696], "policy_red_v7_reward": [-1.511, -0.5029999999999997], "policy_red_v66_reward": [-1.002], "policy_red_v52_reward": [-1.003], "policy_red_v27_reward": [1.499692542772942], "policy_red_v5_reward": [-1.0179999999999993], "policy_red_v8_reward": [-0.006], "policy_red_v51_reward": [-2.012999999999999], "policy_red_v33_reward": [1.6490500000000017, 1.4839346144425924], "policy_red_v21_reward": [0.446], "policy_red_v82_reward": [-2.011], "policy_red_v9_reward": [-2.024999999999998], "policy_red_v59_reward": [0.38328360500000014, -0.553], "policy_red_v64_reward": [-1.002, -0.6540000000000009], "policy_red_v65_reward": [-2.022999999999998], "policy_red_v29_reward": [0.1800500000000001], "policy_red_v84_reward": [-0.513], "policy_red_v77_reward": [-2.01], "policy_red_v20_reward": [1.4926932378161704], "policy_red_v50_reward": [1.50169323781617], "policy_red_v48_reward": [-0.5519999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8266537215480686, "mean_inference_ms": 7.753653638047862, "mean_action_processing_ms": 0.2959073359752852, "mean_env_wait_ms": 0.3939479940155135, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10241246223449707, "StateBufferConnector_ms": 0.004289150238037109, "ViewRequirementAgentConnector_ms": 0.11818230152130127}}, "episode_reward_max": 4.491620155589111, "episode_reward_min": -1.8659999999999126, "episode_reward_mean": 2.188165539101043, "episode_len_mean": 70.63, "episodes_this_iter": 41, "policy_reward_min": {"blue": -2.027999999999999, "red": -1.2119999999999818, "red_v78": -2.0289999999999973, "red_v37": -2.0039999999999996, "red_v69": -2.0029999999999997, "red_v83": -1.006, "red_v19": -1.0159999999999991, "red_v53": 0.17605000000000004, "red_v1": -2.008999999999999, "red_v61": -2.005, "red_v39": -1.5139999999999998, "red_v34": -2.008, "red_v67": -1.0169999999999983, "red_v3": -1.0259999999999996, "red_v42": -1.548, "red_v63": 0.489, "red_v47": -2.0119999999999996, "red_v32": -2.0089999999999995, "red_v71": -2.004, "red_v44": 0.39428360500000037, "red_v60": -1.0219999999999998, "red_v16": 0.5056932378161696, "red_v7": -1.511, "red_v66": -1.002, "red_v52": -1.003, "red_v27": 1.499692542772942, "red_v5": -1.0179999999999993, "red_v8": -0.006, "red_v51": -2.012999999999999, "red_v33": 1.4839346144425924, "red_v21": 0.446, "red_v82": -2.011, "red_v9": -2.024999999999998, "red_v59": -0.553, "red_v64": -1.002, "red_v65": -2.022999999999998, "red_v29": 0.1800500000000001, "red_v84": -0.513, "red_v77": -2.01, "red_v20": 1.4926932378161704, "red_v50": 1.50169323781617, "red_v48": -0.5519999999999999}, "policy_reward_max": {"blue": 0.492, "red": 3.995556158544055, "red_v78": -1.507, "red_v37": -0.5069999999999999, "red_v69": -2.0029999999999997, "red_v83": -1.006, "red_v19": -1.0159999999999991, "red_v53": 0.17605000000000004, "red_v1": -2.008999999999999, "red_v61": -1.0189999999999995, "red_v39": -1.5139999999999998, "red_v34": -2.008, "red_v67": -1.0169999999999983, "red_v3": -1.0149999999999992, "red_v42": -1.548, "red_v63": 0.489, "red_v47": 0.4996925427729424, "red_v32": -2.006, "red_v71": -2.002, "red_v44": 0.39428360500000037, "red_v60": 0.39528360500000037, "red_v16": 0.5056932378161696, "red_v7": -0.5029999999999997, "red_v66": -1.002, "red_v52": -1.003, "red_v27": 1.499692542772942, "red_v5": -1.0179999999999993, "red_v8": -0.006, "red_v51": -2.012999999999999, "red_v33": 1.6490500000000017, "red_v21": 0.446, "red_v82": -2.011, "red_v9": -2.024999999999998, "red_v59": 0.38328360500000014, "red_v64": -0.6540000000000009, "red_v65": -2.022999999999998, "red_v29": 0.1800500000000001, "red_v84": -0.513, "red_v77": -2.01, "red_v20": 1.4926932378161704, "red_v50": 1.50169323781617, "red_v48": -0.5519999999999999}, "policy_reward_mean": {"blue": -1.3708085106382975, "red": 3.268391536816671, "red_v78": -1.7679999999999985, "red_v37": -1.2554999999999996, "red_v69": -2.0029999999999997, "red_v83": -1.006, "red_v19": -1.0159999999999991, "red_v53": 0.17605000000000004, "red_v1": -2.008999999999999, "red_v61": -1.6759999999999995, "red_v39": -1.5139999999999998, "red_v34": -2.008, "red_v67": -1.0169999999999983, "red_v3": -1.0204999999999993, "red_v42": -1.548, "red_v63": 0.489, "red_v47": -0.7561537286135286, "red_v32": -2.0074999999999994, "red_v71": -2.003, "red_v44": 0.39428360500000037, "red_v60": -0.3133581974999997, "red_v16": 0.5056932378161696, "red_v7": -1.0069999999999997, "red_v66": -1.002, "red_v52": -1.003, "red_v27": 1.499692542772942, "red_v5": -1.0179999999999993, "red_v8": -0.006, "red_v51": -2.012999999999999, "red_v33": 1.566492307221297, "red_v21": 0.446, "red_v82": -2.011, "red_v9": -2.024999999999998, "red_v59": -0.08485819749999995, "red_v64": -0.8280000000000005, "red_v65": -2.022999999999998, "red_v29": 0.1800500000000001, "red_v84": -0.513, "red_v77": -2.01, "red_v20": 1.4926932378161704, "red_v50": 1.50169323781617, "red_v48": -0.5519999999999999}, "hist_stats": {"episode_reward": [2.3698148550000004, 0.93370886281617, 2.4481307378161703, 2.9705682378161704, 0.7681307378161704, 1.9855213628161699, 2.4856307378161704, 2.4488651128161725, 1.992556158544055, 2.4682713628161705, 3.659243237816171, 1.9737869878161705, 1.9832244878161702, 1.4850405335440549, 2.456943237816171, 0.6480656250000004, 1.9847436585440552, 2.339661987816172, 2.48081823781617, 1.3851429800000008, 2.4448651128161716, 0.9198651128161708, 1.3900937500000001, 1.446130737816172, 2.453349487816171, 1.3984658644425942, 0.8351562500000003, 2.469895667772943, 3.8812893428161703, 2.490446783544055, 2.4471307378161713, 3.88110184281617, -0.9042812500000001, 1.9503807378161722, 1.450943237816171, 3.9874802256323396, 1.98863073781617, 2.4319588628161717, 0.9617557378161712, 2.48622448781617, 3.980260780589112, 2.1668000000000003, 2.458755737816172, 2.4600526128161713, 4.491620155589111, 2.436911987816172, 2.9873338628161705, 1.9572401128161703, 3.5994463628161735, 1.938943237816172, 2.3800336050000004, 2.4708963628161706, 2.4725213628161704, 1.981927612815204, 3.4393338628161705, 1.3418593749999999, 1.9733877394425923, 1.8319375, 0.6972713628161703, 1.8438617300000006, 1.977524908544055, 1.485853033544055, 1.9483494878161718, 3.8571799678161702, 2.4866307378161703, 2.48981823781617, 1.9634901128161715, 2.45338073781617, 0.648349487816189, 1.914849487816173, 1.9923331677729421, 1.9866307378161703, 2.462271362816171, 4.4738622272587625, -1.8659999999999126, 2.476981489442592, 2.430099487816171, 1.4780057378161704, 1.8950057378161747, 1.4753026128161708, 3.56338048, 2.3032836050000003, 2.4093338628161725, 1.9644901128161703, 2.4864467835440554, 2.940149908544055, 2.954943237816171, 1.4762237927729418, 1.9852244878161696, 2.414255737816173, 2.482634283544055, 1.834640625, 1.4832244878161704, 1.4678721144425926, 4.462777100632342, 4.49010522563234, 1.1685031250000002, 2.9433338628152037, 1.3807367300000002, 1.9859276128161703], "episode_lengths": [22, 91, 52, 40, 244, 23, 20, 41, 15, 39, 32, 34, 22, 20, 48, 27, 19, 202, 24, 13, 41, 745, 34, 52, 46, 86, 14, 31, 28, 18, 52, 24, 282, 36, 48, 34, 20, 75, 44, 22, 40, 16, 44, 45, 21, 58, 19, 49, 63, 48, 16, 31, 23, 21, 19, 13, 15, 20, 295, 39, 25, 16, 46, 31, 20, 24, 33, 36, 878, 78, 19, 20, 39, 21, 1280, 17, 62, 28, 92, 29, 17, 64, 83, 33, 18, 17, 48, 22, 22, 76, 22, 19, 22, 20, 35, 26, 15, 19, 15, 21], "policy_blue_reward": [-1.006, -1.0099999999999998, -1.0630000000000002, -2.0029999999999997, -1.0129999999999992, -2.0089999999999995, -1.0159999999999987, -1.0089999999999997, -2.0039999999999996, -1.009, 0.492, -1.0049999999999997, -1.585, -2.0139999999999993, -2.015999999999999, -2.005, -1.0199999999999982, -1.0059999999999996, -1.0079999999999991, -1.0049999999999997, -1.0129999999999995, -2.0059999999999993, -2.001, -1.004, -1.5979999999999996, -2.006, -2.01, -1.0069999999999997, -2.012999999999999, -1.2380000000000002, -2.027999999999999, -2.0059999999999993, -1.011, -1.002, -1.0189999999999988, -2.0069999999999997, -2.009999999999999, -1.0199999999999991, -1.0269999999999981, -1.0079999999999996, -0.015000000000000001, -2.0079999999999996, -1.0349999999999977, -1.0059999999999996, -1.002, -2.0069999999999997, -2.0069999999999997], "policy_red_v78_reward": [-1.507, -2.0289999999999973], "policy_red_v37_reward": [-0.5069999999999999, -2.0039999999999996], "policy_red_v69_reward": [-2.0029999999999997], "policy_red_v83_reward": [-1.006], "policy_red_v19_reward": [-1.0159999999999991], "policy_red_v53_reward": [0.17605000000000004], "policy_red_v1_reward": [-2.008999999999999], "policy_red_v61_reward": [-2.005, -1.0189999999999995, -2.004], "policy_red_v39_reward": [-1.5139999999999998], "policy_red_v34_reward": [-2.008], "policy_red_v67_reward": [-1.0169999999999983], "policy_red_v3_reward": [-1.0259999999999996, -1.0149999999999992], "policy_red_v42_reward": [-1.548], "policy_red_v63_reward": [0.489], "policy_red_v47_reward": [-2.0119999999999996, 0.4996925427729424], "policy_red_v32_reward": [-2.0089999999999995, -2.006], "policy_red_v71_reward": [-2.004, -2.002], "policy_red_v44_reward": [0.39428360500000037], "policy_red_v60_reward": [-1.0219999999999998, 0.39528360500000037], "policy_red_v16_reward": [0.5056932378161696], "policy_red_v7_reward": [-1.511, -0.5029999999999997], "policy_red_v66_reward": [-1.002], "policy_red_v52_reward": [-1.003], "policy_red_v27_reward": [1.499692542772942], "policy_red_v5_reward": [-1.0179999999999993], "policy_red_v8_reward": [-0.006], "policy_red_v51_reward": [-2.012999999999999], "policy_red_v33_reward": [1.6490500000000017, 1.4839346144425924], "policy_red_v21_reward": [0.446], "policy_red_v82_reward": [-2.011], "policy_red_v9_reward": [-2.024999999999998], "policy_red_v59_reward": [0.38328360500000014, -0.553], "policy_red_v64_reward": [-1.002, -0.6540000000000009], "policy_red_v65_reward": [-2.022999999999998], "policy_red_v29_reward": [0.1800500000000001], "policy_red_v84_reward": [-0.513], "policy_red_v77_reward": [-2.01], "policy_red_v20_reward": [1.4926932378161704], "policy_red_v50_reward": [1.50169323781617], "policy_red_v48_reward": [-0.5519999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8266537215480686, "mean_inference_ms": 7.753653638047862, "mean_action_processing_ms": 0.2959073359752852, "mean_env_wait_ms": 0.3939479940155135, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10241246223449707, "StateBufferConnector_ms": 0.004289150238037109, "ViewRequirementAgentConnector_ms": 0.11818230152130127}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 197.34168400475966, "num_env_steps_trained_throughput_per_sec": 197.34168400475966, "timesteps_total": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 19926.038, "sample_time_ms": 1218.11, "learn_time_ms": 18620.537, "learn_throughput": 214.817, "synch_weights_time_ms": 83.945}, "counters": {"num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "episodes_total": 2818, "training_iteration": 120, "trial_id": "a9680_00000", "date": "2023-09-24_03-21-19", "timestamp": 1695540079, "time_this_iter_s": 20.27898406982422, "time_total_s": 2393.659284353256, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dc7b2e0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1ddc3640>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1ddc3d90>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2393.659284353256, "iterations_since_restore": 120, "perf": {"cpu_util_percent": 5.685714285714287, "ram_util_percent": 27.168571428571433}, "win_rate": 0.85, "league_size": 89}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.943664070839683, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.019007184332440374, "policy_loss": -0.03626312104946313, "vf_loss": 0.10017065103747883, "vf_explained_var": 0.8779861551399032, "kl": 0.014610259114768572, "entropy": 1.3896368170777957, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 115680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_agent_steps_sampled": 968000, "num_agent_steps_trained": 968000}, "sampler_results": {"episode_reward_max": 4.49825294208811, "episode_reward_min": -1.8659999999999126, "episode_reward_mean": 2.2826929366059687, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 40, "policy_reward_min": {"red_v47": 0.4996925427729424, "red": -1.2119999999999818, "red_v66": -1.002, "red_v52": -1.003, "blue": -2.027999999999999, "red_v27": 1.499692542772942, "red_v5": -1.0179999999999993, "red_v8": -0.006, "red_v51": -2.012999999999999, "red_v33": 1.4839346144425924, "red_v78": -2.0289999999999973, "red_v3": -1.0149999999999992, "red_v21": 0.446, "red_v37": -2.0039999999999996, "red_v82": -2.011, "red_v9": -2.024999999999998, "red_v59": -0.553, "red_v64": -1.002, "red_v61": -2.004, "red_v7": -0.5029999999999997, "red_v65": -2.022999999999998, "red_v29": 0.1800500000000001, "red_v84": -0.513, "red_v77": -2.01, "red_v20": 1.4926932378161704, "red_v50": -0.5770000000000001, "red_v71": -2.002, "red_v48": -1.5790000000000002, "red_v32": -2.006, "red_v14": -2.003, "red_v2": -1.0369999999999997, "red_v83": -1.0099999999999996, "red_v81": -2.079999999999992, "red_v60": -2.0069999999999992, "red_v58": 1.4936932378161716, "red_v80": -2.1929999999999836, "red_v23": -0.009000000000000001, "red_v57": 1.4656932378161702, "red_v26": -0.1589999999999998, "red_v67": -2.0039999999999996, "red_v75": -2.006, "red_v13": 1.8581875, "red_v45": 2.98892761281617, "red_v40": -1.017}, "policy_reward_max": {"red_v47": 0.4996925427729424, "red": 3.99322448781617, "red_v66": -1.002, "red_v52": -1.003, "blue": -0.013000000000000005, "red_v27": 1.499692542772942, "red_v5": -1.0179999999999993, "red_v8": -0.006, "red_v51": -2.012999999999999, "red_v33": 1.6490500000000017, "red_v78": -2.0289999999999973, "red_v3": -1.0149999999999992, "red_v21": 0.446, "red_v37": 1.5061030335440546, "red_v82": -2.011, "red_v9": 0.447, "red_v59": 0.38328360500000014, "red_v64": -0.6540000000000009, "red_v61": -1.0189999999999995, "red_v7": -0.5029999999999997, "red_v65": -2.022999999999998, "red_v29": 0.1800500000000001, "red_v84": -0.513, "red_v77": -2.01, "red_v20": 1.4926932378161704, "red_v50": 1.50169323781617, "red_v71": -2.002, "red_v48": -0.5519999999999999, "red_v32": -2.006, "red_v14": 1.17405, "red_v2": -1.0369999999999997, "red_v83": -1.0099999999999996, "red_v81": -2.006, "red_v60": 0.49769323781617036, "red_v58": 1.4936932378161716, "red_v80": -2.1929999999999836, "red_v23": -0.009000000000000001, "red_v57": 1.4656932378161702, "red_v26": -0.1589999999999998, "red_v67": -2.0039999999999996, "red_v75": -2.006, "red_v13": 1.8581875, "red_v45": 2.98892761281617, "red_v40": -1.017}, "policy_reward_mean": {"red_v47": 0.4996925427729424, "red": 3.1727275602016713, "red_v66": -1.002, "red_v52": -1.003, "blue": -1.2961042553191482, "red_v27": 1.499692542772942, "red_v5": -1.0179999999999993, "red_v8": -0.006, "red_v51": -2.012999999999999, "red_v33": 1.566492307221297, "red_v78": -2.0289999999999973, "red_v3": -1.0149999999999992, "red_v21": 0.446, "red_v37": -0.24894848322797247, "red_v82": -2.011, "red_v9": -0.788999999999999, "red_v59": -0.08485819749999995, "red_v64": -0.8280000000000005, "red_v61": -1.5114999999999998, "red_v7": -0.5029999999999997, "red_v65": -2.022999999999998, "red_v29": 0.1800500000000001, "red_v84": -0.513, "red_v77": -2.01, "red_v20": 1.4926932378161704, "red_v50": 0.462346618908085, "red_v71": -2.002, "red_v48": -1.0655000000000001, "red_v32": -2.006, "red_v14": -0.41447500000000004, "red_v2": -1.0369999999999997, "red_v83": -1.0099999999999996, "red_v81": -2.0429999999999957, "red_v60": -0.7546533810919145, "red_v58": 1.4936932378161716, "red_v80": -2.1929999999999836, "red_v23": -0.009000000000000001, "red_v57": 1.4656932378161702, "red_v26": -0.1589999999999998, "red_v67": -2.0039999999999996, "red_v75": -2.006, "red_v13": 1.8581875, "red_v45": 2.98892761281617, "red_v40": -1.017}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.980260780589112, 2.1668000000000003, 2.458755737816172, 2.4600526128161713, 4.491620155589111, 2.436911987816172, 2.9873338628161705, 1.9572401128161703, 3.5994463628161735, 1.938943237816172, 2.3800336050000004, 2.4708963628161706, 2.4725213628161704, 1.981927612815204, 3.4393338628161705, 1.3418593749999999, 1.9733877394425923, 1.8319375, 0.6972713628161703, 1.8438617300000006, 1.977524908544055, 1.485853033544055, 1.9483494878161718, 3.8571799678161702, 2.4866307378161703, 2.48981823781617, 1.9634901128161715, 2.45338073781617, 0.648349487816189, 1.914849487816173, 1.9923331677729421, 1.9866307378161703, 2.462271362816171, 4.4738622272587625, -1.8659999999999126, 2.476981489442592, 2.430099487816171, 1.4780057378161704, 1.8950057378161747, 1.4753026128161708, 3.56338048, 2.3032836050000003, 2.4093338628161725, 1.9644901128161703, 2.4864467835440554, 2.940149908544055, 2.954943237816171, 1.4762237927729418, 1.9852244878161696, 2.414255737816173, 2.482634283544055, 1.834640625, 1.4832244878161704, 1.4678721144425926, 4.462777100632342, 4.49010522563234, 1.1685031250000002, 2.9433338628152037, 1.3807367300000002, 1.9859276128161703, 1.48822448781617, 1.4702713628161708, 2.908599487816171, 1.3330994878161704, 2.4641619878152037, 2.4376151128161725, 1.4855213628161703, 1.9801151128161711, 2.48222448781617, 4.1680862927729425, 1.9760838628161703, 4.3691521006323475, 4.49825294208811, 1.5812088628161858, 1.0244432378161756, 2.9774119878161702, 2.491149908544055, 2.4862244878161706, 1.3622992300000005, 2.4837436585440553, 3.968667725632341, 3.440149908544055, 2.8635526128161737, 2.2433864756323696, 1.6326651128162026, 3.320677612816171, 1.1686125, 2.950646362816172, 0.4277500000000001, 1.1494711050000013, 1.968786987816171, 2.34192761281617, 2.4924425427729417, 1.199083862816185, 2.4642783644425927, 2.493149908544055, 0.4197713628161712, 2.4616776128161706, 2.4682713628161705, 2.188633862816194], "episode_lengths": [40, 16, 44, 45, 21, 58, 19, 49, 63, 48, 16, 31, 23, 21, 19, 13, 15, 20, 295, 39, 25, 16, 46, 31, 20, 24, 33, 36, 878, 78, 19, 20, 39, 21, 1280, 17, 62, 28, 92, 29, 17, 64, 83, 33, 18, 17, 48, 22, 22, 76, 22, 19, 22, 20, 35, 26, 15, 19, 15, 21, 22, 39, 94, 190, 42, 57, 23, 25, 22, 18, 35, 107, 17, 251, 464, 26, 17, 22, 27, 19, 38, 17, 77, 1280, 1017, 37, 12, 47, 16, 132, 34, 21, 16, 227, 18, 17, 711, 37, 39, 387], "policy_red_v47_reward": [0.4996925427729424], "policy_red_v66_reward": [-1.002], "policy_red_v52_reward": [-1.003], "policy_blue_reward": [-1.0079999999999991, -1.0049999999999997, -1.0129999999999995, -2.0059999999999993, -2.001, -1.004, -1.5979999999999996, -2.006, -2.01, -1.0069999999999997, -2.012999999999999, -1.2380000000000002, -2.027999999999999, -2.0059999999999993, -1.011, -1.002, -1.0189999999999988, -2.0069999999999997, -2.009999999999999, -1.0199999999999991, -1.0269999999999981, -1.0079999999999996, -0.015000000000000001, -2.0079999999999996, -1.0349999999999977, -1.0059999999999996, -1.002, -2.0069999999999997, -2.0069999999999997, -2.0089999999999995, -0.022000000000000006, -1.0179999999999982, -2.0089999999999995, -1.0059999999999996, -1.6430000000000002, -1.0039999999999998, -1.007, -2.0059999999999993, -1.0059999999999998, -0.08894999999998665, -0.013000000000000005, -2.0069999999999997, -1.005, -1.0099999999999998, -1.0019999999999998, -1.011, -0.9229499999999986], "policy_red_v27_reward": [1.499692542772942], "policy_red_v5_reward": [-1.0179999999999993], "policy_red_v8_reward": [-0.006], "policy_red_v51_reward": [-2.012999999999999], "policy_red_v33_reward": [1.6490500000000017, 1.4839346144425924], "policy_red_v78_reward": [-2.0289999999999973], "policy_red_v3_reward": [-1.0149999999999992], "policy_red_v21_reward": [0.446], "policy_red_v37_reward": [-2.0039999999999996, 1.5061030335440546], "policy_red_v82_reward": [-2.011], "policy_red_v9_reward": [-2.024999999999998, 0.447], "policy_red_v59_reward": [0.38328360500000014, -0.553], "policy_red_v64_reward": [-1.002, -0.6540000000000009], "policy_red_v61_reward": [-1.0189999999999995, -2.004], "policy_red_v7_reward": [-0.5029999999999997], "policy_red_v65_reward": [-2.022999999999998], "policy_red_v29_reward": [0.1800500000000001], "policy_red_v84_reward": [-0.513], "policy_red_v77_reward": [-2.01], "policy_red_v20_reward": [1.4926932378161704], "policy_red_v50_reward": [1.50169323781617, -0.5770000000000001], "policy_red_v71_reward": [-2.002], "policy_red_v48_reward": [-0.5519999999999999, -1.5790000000000002], "policy_red_v32_reward": [-2.006], "policy_red_v14_reward": [-2.003, 1.17405], "policy_red_v2_reward": [-1.0369999999999997], "policy_red_v83_reward": [-1.0099999999999996], "policy_red_v81_reward": [-2.006, -2.079999999999992], "policy_red_v60_reward": [-2.0069999999999992, 0.49769323781617036], "policy_red_v58_reward": [1.4936932378161716], "policy_red_v80_reward": [-2.1929999999999836], "policy_red_v23_reward": [-0.009000000000000001], "policy_red_v57_reward": [1.4656932378161702], "policy_red_v26_reward": [-0.1589999999999998], "policy_red_v67_reward": [-2.0039999999999996], "policy_red_v75_reward": [-2.006], "policy_red_v13_reward": [1.8581875], "policy_red_v45_reward": [2.98892761281617], "policy_red_v40_reward": [-1.017]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8263787277050788, "mean_inference_ms": 7.741418356059486, "mean_action_processing_ms": 0.29533699770915167, "mean_env_wait_ms": 0.3945560625278964, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09868371486663818, "StateBufferConnector_ms": 0.004138588905334473, "ViewRequirementAgentConnector_ms": 0.11535859107971191}}, "episode_reward_max": 4.49825294208811, "episode_reward_min": -1.8659999999999126, "episode_reward_mean": 2.2826929366059687, "episode_len_mean": 100.0, "episodes_this_iter": 40, "policy_reward_min": {"red_v47": 0.4996925427729424, "red": -1.2119999999999818, "red_v66": -1.002, "red_v52": -1.003, "blue": -2.027999999999999, "red_v27": 1.499692542772942, "red_v5": -1.0179999999999993, "red_v8": -0.006, "red_v51": -2.012999999999999, "red_v33": 1.4839346144425924, "red_v78": -2.0289999999999973, "red_v3": -1.0149999999999992, "red_v21": 0.446, "red_v37": -2.0039999999999996, "red_v82": -2.011, "red_v9": -2.024999999999998, "red_v59": -0.553, "red_v64": -1.002, "red_v61": -2.004, "red_v7": -0.5029999999999997, "red_v65": -2.022999999999998, "red_v29": 0.1800500000000001, "red_v84": -0.513, "red_v77": -2.01, "red_v20": 1.4926932378161704, "red_v50": -0.5770000000000001, "red_v71": -2.002, "red_v48": -1.5790000000000002, "red_v32": -2.006, "red_v14": -2.003, "red_v2": -1.0369999999999997, "red_v83": -1.0099999999999996, "red_v81": -2.079999999999992, "red_v60": -2.0069999999999992, "red_v58": 1.4936932378161716, "red_v80": -2.1929999999999836, "red_v23": -0.009000000000000001, "red_v57": 1.4656932378161702, "red_v26": -0.1589999999999998, "red_v67": -2.0039999999999996, "red_v75": -2.006, "red_v13": 1.8581875, "red_v45": 2.98892761281617, "red_v40": -1.017}, "policy_reward_max": {"red_v47": 0.4996925427729424, "red": 3.99322448781617, "red_v66": -1.002, "red_v52": -1.003, "blue": -0.013000000000000005, "red_v27": 1.499692542772942, "red_v5": -1.0179999999999993, "red_v8": -0.006, "red_v51": -2.012999999999999, "red_v33": 1.6490500000000017, "red_v78": -2.0289999999999973, "red_v3": -1.0149999999999992, "red_v21": 0.446, "red_v37": 1.5061030335440546, "red_v82": -2.011, "red_v9": 0.447, "red_v59": 0.38328360500000014, "red_v64": -0.6540000000000009, "red_v61": -1.0189999999999995, "red_v7": -0.5029999999999997, "red_v65": -2.022999999999998, "red_v29": 0.1800500000000001, "red_v84": -0.513, "red_v77": -2.01, "red_v20": 1.4926932378161704, "red_v50": 1.50169323781617, "red_v71": -2.002, "red_v48": -0.5519999999999999, "red_v32": -2.006, "red_v14": 1.17405, "red_v2": -1.0369999999999997, "red_v83": -1.0099999999999996, "red_v81": -2.006, "red_v60": 0.49769323781617036, "red_v58": 1.4936932378161716, "red_v80": -2.1929999999999836, "red_v23": -0.009000000000000001, "red_v57": 1.4656932378161702, "red_v26": -0.1589999999999998, "red_v67": -2.0039999999999996, "red_v75": -2.006, "red_v13": 1.8581875, "red_v45": 2.98892761281617, "red_v40": -1.017}, "policy_reward_mean": {"red_v47": 0.4996925427729424, "red": 3.1727275602016713, "red_v66": -1.002, "red_v52": -1.003, "blue": -1.2961042553191482, "red_v27": 1.499692542772942, "red_v5": -1.0179999999999993, "red_v8": -0.006, "red_v51": -2.012999999999999, "red_v33": 1.566492307221297, "red_v78": -2.0289999999999973, "red_v3": -1.0149999999999992, "red_v21": 0.446, "red_v37": -0.24894848322797247, "red_v82": -2.011, "red_v9": -0.788999999999999, "red_v59": -0.08485819749999995, "red_v64": -0.8280000000000005, "red_v61": -1.5114999999999998, "red_v7": -0.5029999999999997, "red_v65": -2.022999999999998, "red_v29": 0.1800500000000001, "red_v84": -0.513, "red_v77": -2.01, "red_v20": 1.4926932378161704, "red_v50": 0.462346618908085, "red_v71": -2.002, "red_v48": -1.0655000000000001, "red_v32": -2.006, "red_v14": -0.41447500000000004, "red_v2": -1.0369999999999997, "red_v83": -1.0099999999999996, "red_v81": -2.0429999999999957, "red_v60": -0.7546533810919145, "red_v58": 1.4936932378161716, "red_v80": -2.1929999999999836, "red_v23": -0.009000000000000001, "red_v57": 1.4656932378161702, "red_v26": -0.1589999999999998, "red_v67": -2.0039999999999996, "red_v75": -2.006, "red_v13": 1.8581875, "red_v45": 2.98892761281617, "red_v40": -1.017}, "hist_stats": {"episode_reward": [3.980260780589112, 2.1668000000000003, 2.458755737816172, 2.4600526128161713, 4.491620155589111, 2.436911987816172, 2.9873338628161705, 1.9572401128161703, 3.5994463628161735, 1.938943237816172, 2.3800336050000004, 2.4708963628161706, 2.4725213628161704, 1.981927612815204, 3.4393338628161705, 1.3418593749999999, 1.9733877394425923, 1.8319375, 0.6972713628161703, 1.8438617300000006, 1.977524908544055, 1.485853033544055, 1.9483494878161718, 3.8571799678161702, 2.4866307378161703, 2.48981823781617, 1.9634901128161715, 2.45338073781617, 0.648349487816189, 1.914849487816173, 1.9923331677729421, 1.9866307378161703, 2.462271362816171, 4.4738622272587625, -1.8659999999999126, 2.476981489442592, 2.430099487816171, 1.4780057378161704, 1.8950057378161747, 1.4753026128161708, 3.56338048, 2.3032836050000003, 2.4093338628161725, 1.9644901128161703, 2.4864467835440554, 2.940149908544055, 2.954943237816171, 1.4762237927729418, 1.9852244878161696, 2.414255737816173, 2.482634283544055, 1.834640625, 1.4832244878161704, 1.4678721144425926, 4.462777100632342, 4.49010522563234, 1.1685031250000002, 2.9433338628152037, 1.3807367300000002, 1.9859276128161703, 1.48822448781617, 1.4702713628161708, 2.908599487816171, 1.3330994878161704, 2.4641619878152037, 2.4376151128161725, 1.4855213628161703, 1.9801151128161711, 2.48222448781617, 4.1680862927729425, 1.9760838628161703, 4.3691521006323475, 4.49825294208811, 1.5812088628161858, 1.0244432378161756, 2.9774119878161702, 2.491149908544055, 2.4862244878161706, 1.3622992300000005, 2.4837436585440553, 3.968667725632341, 3.440149908544055, 2.8635526128161737, 2.2433864756323696, 1.6326651128162026, 3.320677612816171, 1.1686125, 2.950646362816172, 0.4277500000000001, 1.1494711050000013, 1.968786987816171, 2.34192761281617, 2.4924425427729417, 1.199083862816185, 2.4642783644425927, 2.493149908544055, 0.4197713628161712, 2.4616776128161706, 2.4682713628161705, 2.188633862816194], "episode_lengths": [40, 16, 44, 45, 21, 58, 19, 49, 63, 48, 16, 31, 23, 21, 19, 13, 15, 20, 295, 39, 25, 16, 46, 31, 20, 24, 33, 36, 878, 78, 19, 20, 39, 21, 1280, 17, 62, 28, 92, 29, 17, 64, 83, 33, 18, 17, 48, 22, 22, 76, 22, 19, 22, 20, 35, 26, 15, 19, 15, 21, 22, 39, 94, 190, 42, 57, 23, 25, 22, 18, 35, 107, 17, 251, 464, 26, 17, 22, 27, 19, 38, 17, 77, 1280, 1017, 37, 12, 47, 16, 132, 34, 21, 16, 227, 18, 17, 711, 37, 39, 387], "policy_red_v47_reward": [0.4996925427729424], "policy_red_v66_reward": [-1.002], "policy_red_v52_reward": [-1.003], "policy_blue_reward": [-1.0079999999999991, -1.0049999999999997, -1.0129999999999995, -2.0059999999999993, -2.001, -1.004, -1.5979999999999996, -2.006, -2.01, -1.0069999999999997, -2.012999999999999, -1.2380000000000002, -2.027999999999999, -2.0059999999999993, -1.011, -1.002, -1.0189999999999988, -2.0069999999999997, -2.009999999999999, -1.0199999999999991, -1.0269999999999981, -1.0079999999999996, -0.015000000000000001, -2.0079999999999996, -1.0349999999999977, -1.0059999999999996, -1.002, -2.0069999999999997, -2.0069999999999997, -2.0089999999999995, -0.022000000000000006, -1.0179999999999982, -2.0089999999999995, -1.0059999999999996, -1.6430000000000002, -1.0039999999999998, -1.007, -2.0059999999999993, -1.0059999999999998, -0.08894999999998665, -0.013000000000000005, -2.0069999999999997, -1.005, -1.0099999999999998, -1.0019999999999998, -1.011, -0.9229499999999986], "policy_red_v27_reward": [1.499692542772942], "policy_red_v5_reward": [-1.0179999999999993], "policy_red_v8_reward": [-0.006], "policy_red_v51_reward": [-2.012999999999999], "policy_red_v33_reward": [1.6490500000000017, 1.4839346144425924], "policy_red_v78_reward": [-2.0289999999999973], "policy_red_v3_reward": [-1.0149999999999992], "policy_red_v21_reward": [0.446], "policy_red_v37_reward": [-2.0039999999999996, 1.5061030335440546], "policy_red_v82_reward": [-2.011], "policy_red_v9_reward": [-2.024999999999998, 0.447], "policy_red_v59_reward": [0.38328360500000014, -0.553], "policy_red_v64_reward": [-1.002, -0.6540000000000009], "policy_red_v61_reward": [-1.0189999999999995, -2.004], "policy_red_v7_reward": [-0.5029999999999997], "policy_red_v65_reward": [-2.022999999999998], "policy_red_v29_reward": [0.1800500000000001], "policy_red_v84_reward": [-0.513], "policy_red_v77_reward": [-2.01], "policy_red_v20_reward": [1.4926932378161704], "policy_red_v50_reward": [1.50169323781617, -0.5770000000000001], "policy_red_v71_reward": [-2.002], "policy_red_v48_reward": [-0.5519999999999999, -1.5790000000000002], "policy_red_v32_reward": [-2.006], "policy_red_v14_reward": [-2.003, 1.17405], "policy_red_v2_reward": [-1.0369999999999997], "policy_red_v83_reward": [-1.0099999999999996], "policy_red_v81_reward": [-2.006, -2.079999999999992], "policy_red_v60_reward": [-2.0069999999999992, 0.49769323781617036], "policy_red_v58_reward": [1.4936932378161716], "policy_red_v80_reward": [-2.1929999999999836], "policy_red_v23_reward": [-0.009000000000000001], "policy_red_v57_reward": [1.4656932378161702], "policy_red_v26_reward": [-0.1589999999999998], "policy_red_v67_reward": [-2.0039999999999996], "policy_red_v75_reward": [-2.006], "policy_red_v13_reward": [1.8581875], "policy_red_v45_reward": [2.98892761281617], "policy_red_v40_reward": [-1.017]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8263787277050788, "mean_inference_ms": 7.741418356059486, "mean_action_processing_ms": 0.29533699770915167, "mean_env_wait_ms": 0.3945560625278964, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09868371486663818, "StateBufferConnector_ms": 0.004138588905334473, "ViewRequirementAgentConnector_ms": 0.11535859107971191}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 968000, "num_agent_steps_trained": 968000, "num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 203.19579745584502, "num_env_steps_trained_throughput_per_sec": 203.19579745584502, "timesteps_total": 484000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 968000, "timers": {"training_iteration_time_ms": 19881.093, "sample_time_ms": 1217.087, "learn_time_ms": 18576.319, "learn_throughput": 215.328, "synch_weights_time_ms": 84.337}, "counters": {"num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_agent_steps_sampled": 968000, "num_agent_steps_trained": 968000}, "done": false, "episodes_total": 2858, "training_iteration": 121, "trial_id": "a9680_00000", "date": "2023-09-24_03-21-48", "timestamp": 1695540108, "time_this_iter_s": 19.695773363113403, "time_total_s": 2413.3550577163696, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1db615a0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1dc665f0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1dc66a70>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2413.3550577163696, "iterations_since_restore": 121, "perf": {"cpu_util_percent": 4.7975609756097555, "ram_util_percent": 27.27560975609756}, "win_rate": 0.83, "league_size": 90}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0283390158166488, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.020145691473832508, "policy_loss": -0.04512019489581386, "vf_loss": 0.1200454669771716, "vf_explained_var": 0.8619699492429693, "kl": 0.014688170056657176, "entropy": 1.3665232236186664, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 116640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "sampler_results": {"episode_reward_max": 4.49825294208811, "episode_reward_min": 0.4197713628161712, "episode_reward_mean": 2.363240173119225, "episode_len_mean": 91.62, "episode_media": {}, "episodes_this_iter": 47, "policy_reward_min": {"red_v77": -2.01, "red": -0.7087163949999993, "blue": -2.013999999999999, "red_v20": 1.4926932378161704, "red_v50": -0.5770000000000001, "red_v71": -2.002, "red_v48": -1.5790000000000002, "red_v61": -2.004, "red_v32": -2.006, "red_v14": -2.003, "red_v2": -1.0369999999999997, "red_v83": -1.0099999999999996, "red_v81": -2.079999999999992, "red_v60": -2.0069999999999992, "red_v58": 1.4936932378161716, "red_v37": 1.5061030335440546, "red_v80": -2.1929999999999836, "red_v23": -0.009000000000000001, "red_v9": 0.447, "red_v57": -0.1499999999999999, "red_v26": -0.1589999999999998, "red_v67": -2.0039999999999996, "red_v75": -2.006, "red_v13": 1.8581875, "red_v45": 2.98892761281617, "red_v40": -1.017, "red_v52": 0.5056932378161696, "red_v17": 0.17705000000000037, "red_v79": -2.002, "red_v65": 1.9787401128161721, "red_v35": 1.49969323781617, "red_v59": -1.002, "red_v34": 0.5016932378152037, "red_v38": 1.4826932378152058, "red_v36": 1.5031030335440547, "red_v46": 2.441255737816171, "red_v82": -1.0629999999999942}, "policy_reward_max": {"red_v77": -2.01, "red": 3.99322448781617, "blue": 1.8307656250000002, "red_v20": 1.4926932378161704, "red_v50": 1.50169323781617, "red_v71": -2.002, "red_v48": 1.5006932378161697, "red_v61": -2.004, "red_v32": -2.006, "red_v14": 1.17405, "red_v2": -1.003, "red_v83": -1.0099999999999996, "red_v81": -2.006, "red_v60": 0.49769323781617036, "red_v58": 1.4936932378161716, "red_v37": 1.5061030335440546, "red_v80": -2.1929999999999836, "red_v23": -0.009000000000000001, "red_v9": 0.447, "red_v57": 1.4656932378161702, "red_v26": -0.1589999999999998, "red_v67": -2.0039999999999996, "red_v75": -2.006, "red_v13": 1.8581875, "red_v45": 2.98892761281617, "red_v40": -1.017, "red_v52": 0.5056932378161696, "red_v17": 0.17705000000000037, "red_v79": -2.002, "red_v65": 1.9787401128161721, "red_v35": 1.49969323781617, "red_v59": -1.002, "red_v34": 0.5016932378152037, "red_v38": 1.4826932378152058, "red_v36": 1.5031030335440547, "red_v46": 2.441255737816171, "red_v82": -1.0629999999999942}, "policy_reward_mean": {"red_v77": -2.01, "red": 3.0883186766378334, "blue": -1.1613964242956671, "red_v20": 1.4926932378161704, "red_v50": 0.462346618908085, "red_v71": -2.002, "red_v48": -0.21010225406127683, "red_v61": -2.004, "red_v32": -2.006, "red_v14": -0.27798333333333336, "red_v2": -1.0199999999999998, "red_v83": -1.0099999999999996, "red_v81": -2.0429999999999957, "red_v60": -0.7546533810919145, "red_v58": 1.4936932378161716, "red_v37": 1.5061030335440546, "red_v80": -2.1929999999999836, "red_v23": -0.009000000000000001, "red_v9": 0.447, "red_v57": 0.6578466189080852, "red_v26": -0.1589999999999998, "red_v67": -2.0039999999999996, "red_v75": -2.006, "red_v13": 1.8581875, "red_v45": 2.98892761281617, "red_v40": -1.017, "red_v52": 0.5056932378161696, "red_v17": 0.17705000000000037, "red_v79": -2.002, "red_v65": 1.9787401128161721, "red_v35": 1.49969323781617, "red_v59": -1.002, "red_v34": 0.5016932378152037, "red_v38": 1.4826932378152058, "red_v36": 1.5031030335440547, "red_v46": 2.441255737816171, "red_v82": -1.0629999999999942}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.4762237927729418, 1.9852244878161696, 2.414255737816173, 2.482634283544055, 1.834640625, 1.4832244878161704, 1.4678721144425926, 4.462777100632342, 4.49010522563234, 1.1685031250000002, 2.9433338628152037, 1.3807367300000002, 1.9859276128161703, 1.48822448781617, 1.4702713628161708, 2.908599487816171, 1.3330994878161704, 2.4641619878152037, 2.4376151128161725, 1.4855213628161703, 1.9801151128161711, 2.48222448781617, 4.1680862927729425, 1.9760838628161703, 4.3691521006323475, 4.49825294208811, 1.5812088628161858, 1.0244432378161756, 2.9774119878161702, 2.491149908544055, 2.4862244878161706, 1.3622992300000005, 2.4837436585440553, 3.968667725632341, 3.440149908544055, 2.8635526128161737, 2.2433864756323696, 1.6326651128162026, 3.320677612816171, 1.1686125, 2.950646362816172, 0.4277500000000001, 1.1494711050000013, 1.968786987816171, 2.34192761281617, 2.4924425427729417, 1.199083862816185, 2.4642783644425927, 2.493149908544055, 0.4197713628161712, 2.4616776128161706, 2.4682713628161705, 2.188633862816194, 4.46404272563234, 1.48563073781617, 2.47638073781617, 3.977042725632341, 2.4287557378161737, 3.6656807378152036, 1.3823304800000003, 2.48330261281617, 2.415365112816174, 2.4737869878161702, 2.1814333506323855, 4.471292725632341, 2.465168989442592, 3.982777100631374, 1.9725213628161706, 2.163096875, 1.821458862816176, 1.9733877394425923, 1.9827088628161704, 1.1699093750000003, 2.480630042772942, 2.484521362816171, 1.3604086050000004, 2.48241198781617, 1.4861151128161703, 2.491446783544055, 4.433605225631377, 2.469712408544055, 2.480224487815204, 2.429474487816172, 1.3661776128161707, 4.4814056463602245, 3.3405213628161707, 1.4803026128152041, 2.975793989442592, 1.9378807378161733, 2.948948975632341, 1.4622713628161712, 1.9350682378161714, 2.9291776128161726, 2.4559432378161716, 2.690737227258767, 2.350052612816177, 0.959974487816171, 1.381033605, 2.4681932378152043, 2.4189588628161736], "episode_lengths": [22, 22, 76, 22, 19, 22, 20, 35, 26, 15, 19, 15, 21, 22, 39, 94, 190, 42, 57, 23, 25, 22, 18, 35, 107, 17, 251, 464, 26, 17, 22, 27, 19, 38, 17, 77, 1280, 1017, 37, 12, 47, 16, 132, 34, 21, 16, 227, 18, 17, 711, 37, 39, 387, 46, 20, 36, 46, 44, 20, 17, 29, 73, 34, 593, 30, 21, 35, 23, 17, 171, 15, 27, 13, 20, 23, 24, 26, 25, 18, 58, 29, 22, 70, 133, 29, 23, 29, 13, 388, 76, 39, 72, 69, 48, 317, 109, 38, 16, 32, 75], "policy_red_v77_reward": [-2.01], "policy_blue_reward": [-2.0079999999999996, -1.0349999999999977, -1.0059999999999996, -1.002, -2.0069999999999997, -2.0069999999999997, -2.0089999999999995, -0.022000000000000006, -1.0179999999999982, -2.0089999999999995, -1.0059999999999996, -1.6430000000000002, -1.0039999999999998, -1.007, -2.0059999999999993, -1.0059999999999998, -0.08894999999998665, -0.013000000000000005, -2.0069999999999997, -1.005, -1.0099999999999998, -1.0019999999999998, -1.011, -0.9229499999999986, -2.008, 0.484, -1.005, -1.019999999999998, -1.0089999999999997, -2.0109999999999992, -1.005, 1.8307656250000002, -2.002, -2.0069999999999992, -2.0029999999999997, -1.009, -1.0049999999999997, -2.005, -1.0059999999999998, -2.005, -1.003, -1.009, -1.0069999999999995, -1.014999999999999, -1.5469999999999997, -2.0069999999999997, -1.1099999999999905, -2.013999999999999, -0.518, -0.019000000000000006, -1.013999999999999, 0.4099346144425928, -1.511999999999999, -2.003, -1.0099999999999996, -1.0199999999999978], "policy_red_v20_reward": [1.4926932378161704], "policy_red_v50_reward": [1.50169323781617, -0.5770000000000001], "policy_red_v71_reward": [-2.002], "policy_red_v48_reward": [-0.5519999999999999, -1.5790000000000002, 1.5006932378161697], "policy_red_v61_reward": [-2.004], "policy_red_v32_reward": [-2.006], "policy_red_v14_reward": [-2.003, 1.17405, -0.005], "policy_red_v2_reward": [-1.0369999999999997, -1.003], "policy_red_v83_reward": [-1.0099999999999996], "policy_red_v81_reward": [-2.006, -2.079999999999992], "policy_red_v60_reward": [-2.0069999999999992, 0.49769323781617036], "policy_red_v58_reward": [1.4936932378161716], "policy_red_v37_reward": [1.5061030335440546], "policy_red_v80_reward": [-2.1929999999999836], "policy_red_v23_reward": [-0.009000000000000001], "policy_red_v9_reward": [0.447], "policy_red_v57_reward": [1.4656932378161702, -0.1499999999999999], "policy_red_v26_reward": [-0.1589999999999998], "policy_red_v67_reward": [-2.0039999999999996], "policy_red_v75_reward": [-2.006], "policy_red_v13_reward": [1.8581875], "policy_red_v45_reward": [2.98892761281617], "policy_red_v40_reward": [-1.017], "policy_red_v52_reward": [0.5056932378161696], "policy_red_v17_reward": [0.17705000000000037], "policy_red_v79_reward": [-2.002], "policy_red_v65_reward": [1.9787401128161721], "policy_red_v35_reward": [1.49969323781617], "policy_red_v59_reward": [-1.002], "policy_red_v34_reward": [0.5016932378152037], "policy_red_v38_reward": [1.4826932378152058], "policy_red_v36_reward": [1.5031030335440547], "policy_red_v46_reward": [2.441255737816171], "policy_red_v82_reward": [-1.0629999999999942]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.827844562700273, "mean_inference_ms": 7.75342115346508, "mean_action_processing_ms": 0.29555264142951343, "mean_env_wait_ms": 0.3958925757017716, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09954345226287842, "StateBufferConnector_ms": 0.004138469696044922, "ViewRequirementAgentConnector_ms": 0.11478066444396973}}, "episode_reward_max": 4.49825294208811, "episode_reward_min": 0.4197713628161712, "episode_reward_mean": 2.363240173119225, "episode_len_mean": 91.62, "episodes_this_iter": 47, "policy_reward_min": {"red_v77": -2.01, "red": -0.7087163949999993, "blue": -2.013999999999999, "red_v20": 1.4926932378161704, "red_v50": -0.5770000000000001, "red_v71": -2.002, "red_v48": -1.5790000000000002, "red_v61": -2.004, "red_v32": -2.006, "red_v14": -2.003, "red_v2": -1.0369999999999997, "red_v83": -1.0099999999999996, "red_v81": -2.079999999999992, "red_v60": -2.0069999999999992, "red_v58": 1.4936932378161716, "red_v37": 1.5061030335440546, "red_v80": -2.1929999999999836, "red_v23": -0.009000000000000001, "red_v9": 0.447, "red_v57": -0.1499999999999999, "red_v26": -0.1589999999999998, "red_v67": -2.0039999999999996, "red_v75": -2.006, "red_v13": 1.8581875, "red_v45": 2.98892761281617, "red_v40": -1.017, "red_v52": 0.5056932378161696, "red_v17": 0.17705000000000037, "red_v79": -2.002, "red_v65": 1.9787401128161721, "red_v35": 1.49969323781617, "red_v59": -1.002, "red_v34": 0.5016932378152037, "red_v38": 1.4826932378152058, "red_v36": 1.5031030335440547, "red_v46": 2.441255737816171, "red_v82": -1.0629999999999942}, "policy_reward_max": {"red_v77": -2.01, "red": 3.99322448781617, "blue": 1.8307656250000002, "red_v20": 1.4926932378161704, "red_v50": 1.50169323781617, "red_v71": -2.002, "red_v48": 1.5006932378161697, "red_v61": -2.004, "red_v32": -2.006, "red_v14": 1.17405, "red_v2": -1.003, "red_v83": -1.0099999999999996, "red_v81": -2.006, "red_v60": 0.49769323781617036, "red_v58": 1.4936932378161716, "red_v37": 1.5061030335440546, "red_v80": -2.1929999999999836, "red_v23": -0.009000000000000001, "red_v9": 0.447, "red_v57": 1.4656932378161702, "red_v26": -0.1589999999999998, "red_v67": -2.0039999999999996, "red_v75": -2.006, "red_v13": 1.8581875, "red_v45": 2.98892761281617, "red_v40": -1.017, "red_v52": 0.5056932378161696, "red_v17": 0.17705000000000037, "red_v79": -2.002, "red_v65": 1.9787401128161721, "red_v35": 1.49969323781617, "red_v59": -1.002, "red_v34": 0.5016932378152037, "red_v38": 1.4826932378152058, "red_v36": 1.5031030335440547, "red_v46": 2.441255737816171, "red_v82": -1.0629999999999942}, "policy_reward_mean": {"red_v77": -2.01, "red": 3.0883186766378334, "blue": -1.1613964242956671, "red_v20": 1.4926932378161704, "red_v50": 0.462346618908085, "red_v71": -2.002, "red_v48": -0.21010225406127683, "red_v61": -2.004, "red_v32": -2.006, "red_v14": -0.27798333333333336, "red_v2": -1.0199999999999998, "red_v83": -1.0099999999999996, "red_v81": -2.0429999999999957, "red_v60": -0.7546533810919145, "red_v58": 1.4936932378161716, "red_v37": 1.5061030335440546, "red_v80": -2.1929999999999836, "red_v23": -0.009000000000000001, "red_v9": 0.447, "red_v57": 0.6578466189080852, "red_v26": -0.1589999999999998, "red_v67": -2.0039999999999996, "red_v75": -2.006, "red_v13": 1.8581875, "red_v45": 2.98892761281617, "red_v40": -1.017, "red_v52": 0.5056932378161696, "red_v17": 0.17705000000000037, "red_v79": -2.002, "red_v65": 1.9787401128161721, "red_v35": 1.49969323781617, "red_v59": -1.002, "red_v34": 0.5016932378152037, "red_v38": 1.4826932378152058, "red_v36": 1.5031030335440547, "red_v46": 2.441255737816171, "red_v82": -1.0629999999999942}, "hist_stats": {"episode_reward": [1.4762237927729418, 1.9852244878161696, 2.414255737816173, 2.482634283544055, 1.834640625, 1.4832244878161704, 1.4678721144425926, 4.462777100632342, 4.49010522563234, 1.1685031250000002, 2.9433338628152037, 1.3807367300000002, 1.9859276128161703, 1.48822448781617, 1.4702713628161708, 2.908599487816171, 1.3330994878161704, 2.4641619878152037, 2.4376151128161725, 1.4855213628161703, 1.9801151128161711, 2.48222448781617, 4.1680862927729425, 1.9760838628161703, 4.3691521006323475, 4.49825294208811, 1.5812088628161858, 1.0244432378161756, 2.9774119878161702, 2.491149908544055, 2.4862244878161706, 1.3622992300000005, 2.4837436585440553, 3.968667725632341, 3.440149908544055, 2.8635526128161737, 2.2433864756323696, 1.6326651128162026, 3.320677612816171, 1.1686125, 2.950646362816172, 0.4277500000000001, 1.1494711050000013, 1.968786987816171, 2.34192761281617, 2.4924425427729417, 1.199083862816185, 2.4642783644425927, 2.493149908544055, 0.4197713628161712, 2.4616776128161706, 2.4682713628161705, 2.188633862816194, 4.46404272563234, 1.48563073781617, 2.47638073781617, 3.977042725632341, 2.4287557378161737, 3.6656807378152036, 1.3823304800000003, 2.48330261281617, 2.415365112816174, 2.4737869878161702, 2.1814333506323855, 4.471292725632341, 2.465168989442592, 3.982777100631374, 1.9725213628161706, 2.163096875, 1.821458862816176, 1.9733877394425923, 1.9827088628161704, 1.1699093750000003, 2.480630042772942, 2.484521362816171, 1.3604086050000004, 2.48241198781617, 1.4861151128161703, 2.491446783544055, 4.433605225631377, 2.469712408544055, 2.480224487815204, 2.429474487816172, 1.3661776128161707, 4.4814056463602245, 3.3405213628161707, 1.4803026128152041, 2.975793989442592, 1.9378807378161733, 2.948948975632341, 1.4622713628161712, 1.9350682378161714, 2.9291776128161726, 2.4559432378161716, 2.690737227258767, 2.350052612816177, 0.959974487816171, 1.381033605, 2.4681932378152043, 2.4189588628161736], "episode_lengths": [22, 22, 76, 22, 19, 22, 20, 35, 26, 15, 19, 15, 21, 22, 39, 94, 190, 42, 57, 23, 25, 22, 18, 35, 107, 17, 251, 464, 26, 17, 22, 27, 19, 38, 17, 77, 1280, 1017, 37, 12, 47, 16, 132, 34, 21, 16, 227, 18, 17, 711, 37, 39, 387, 46, 20, 36, 46, 44, 20, 17, 29, 73, 34, 593, 30, 21, 35, 23, 17, 171, 15, 27, 13, 20, 23, 24, 26, 25, 18, 58, 29, 22, 70, 133, 29, 23, 29, 13, 388, 76, 39, 72, 69, 48, 317, 109, 38, 16, 32, 75], "policy_red_v77_reward": [-2.01], "policy_blue_reward": [-2.0079999999999996, -1.0349999999999977, -1.0059999999999996, -1.002, -2.0069999999999997, -2.0069999999999997, -2.0089999999999995, -0.022000000000000006, -1.0179999999999982, -2.0089999999999995, -1.0059999999999996, -1.6430000000000002, -1.0039999999999998, -1.007, -2.0059999999999993, -1.0059999999999998, -0.08894999999998665, -0.013000000000000005, -2.0069999999999997, -1.005, -1.0099999999999998, -1.0019999999999998, -1.011, -0.9229499999999986, -2.008, 0.484, -1.005, -1.019999999999998, -1.0089999999999997, -2.0109999999999992, -1.005, 1.8307656250000002, -2.002, -2.0069999999999992, -2.0029999999999997, -1.009, -1.0049999999999997, -2.005, -1.0059999999999998, -2.005, -1.003, -1.009, -1.0069999999999995, -1.014999999999999, -1.5469999999999997, -2.0069999999999997, -1.1099999999999905, -2.013999999999999, -0.518, -0.019000000000000006, -1.013999999999999, 0.4099346144425928, -1.511999999999999, -2.003, -1.0099999999999996, -1.0199999999999978], "policy_red_v20_reward": [1.4926932378161704], "policy_red_v50_reward": [1.50169323781617, -0.5770000000000001], "policy_red_v71_reward": [-2.002], "policy_red_v48_reward": [-0.5519999999999999, -1.5790000000000002, 1.5006932378161697], "policy_red_v61_reward": [-2.004], "policy_red_v32_reward": [-2.006], "policy_red_v14_reward": [-2.003, 1.17405, -0.005], "policy_red_v2_reward": [-1.0369999999999997, -1.003], "policy_red_v83_reward": [-1.0099999999999996], "policy_red_v81_reward": [-2.006, -2.079999999999992], "policy_red_v60_reward": [-2.0069999999999992, 0.49769323781617036], "policy_red_v58_reward": [1.4936932378161716], "policy_red_v37_reward": [1.5061030335440546], "policy_red_v80_reward": [-2.1929999999999836], "policy_red_v23_reward": [-0.009000000000000001], "policy_red_v9_reward": [0.447], "policy_red_v57_reward": [1.4656932378161702, -0.1499999999999999], "policy_red_v26_reward": [-0.1589999999999998], "policy_red_v67_reward": [-2.0039999999999996], "policy_red_v75_reward": [-2.006], "policy_red_v13_reward": [1.8581875], "policy_red_v45_reward": [2.98892761281617], "policy_red_v40_reward": [-1.017], "policy_red_v52_reward": [0.5056932378161696], "policy_red_v17_reward": [0.17705000000000037], "policy_red_v79_reward": [-2.002], "policy_red_v65_reward": [1.9787401128161721], "policy_red_v35_reward": [1.49969323781617], "policy_red_v59_reward": [-1.002], "policy_red_v34_reward": [0.5016932378152037], "policy_red_v38_reward": [1.4826932378152058], "policy_red_v36_reward": [1.5031030335440547], "policy_red_v46_reward": [2.441255737816171], "policy_red_v82_reward": [-1.0629999999999942]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.827844562700273, "mean_inference_ms": 7.75342115346508, "mean_action_processing_ms": 0.29555264142951343, "mean_env_wait_ms": 0.3958925757017716, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09954345226287842, "StateBufferConnector_ms": 0.004138469696044922, "ViewRequirementAgentConnector_ms": 0.11478066444396973}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.94803323431907, "num_env_steps_trained_throughput_per_sec": 200.94803323431907, "timesteps_total": 488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 19878.098, "sample_time_ms": 1210.305, "learn_time_ms": 18580.344, "learn_throughput": 215.281, "synch_weights_time_ms": 84.073}, "counters": {"num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "episodes_total": 2905, "training_iteration": 122, "trial_id": "a9680_00000", "date": "2023-09-24_03-22-13", "timestamp": 1695540133, "time_this_iter_s": 19.915691614151, "time_total_s": 2433.2707493305206, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dc7a530>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1dce2dd0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1dce2d40>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2433.2707493305206, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 5.779411764705883, "ram_util_percent": 27.39411764705882}, "win_rate": 0.78, "league_size": 91}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1957775324583055, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.04930751024221536, "policy_loss": -0.04038092355379679, "vf_loss": 0.166328109044116, "vf_explained_var": 0.8408201416954398, "kl": 0.01755656563802578, "entropy": 1.3760750306149323, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 117600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_agent_steps_sampled": 984000, "num_agent_steps_trained": 984000}, "sampler_results": {"episode_reward_max": 4.4814056463602245, "episode_reward_min": -0.07635937499999967, "episode_reward_mean": 2.2647909050402864, "episode_len_mean": 67.48, "episode_media": {}, "episodes_this_iter": 48, "policy_reward_min": {"blue": -2.0169999999999986, "red": -0.009306762183829087, "red_v48": -1.5790000000000002, "red_v40": -1.017, "red_v2": -1.003, "red_v52": 0.5056932378161696, "red_v17": 0.17705000000000037, "red_v79": -2.002, "red_v65": 1.9787401128161721, "red_v35": 1.49969323781617, "red_v59": -1.002, "red_v34": 0.5016932378152037, "red_v38": 1.4826932378152058, "red_v36": 1.5031030335440547, "red_v57": -2.0029999999999997, "red_v14": -0.005, "red_v46": 2.441255737816171, "red_v82": -1.0629999999999942, "red_v70": -2.002, "red_v30": -1.0059999999999993, "red_v25": -1.0109999999999992, "red_v26": 0.17705000000000015, "red_v64": 0.45, "red_v80": -2.0039999999999996, "red_v49": -2.01, "red_v61": -1.003, "red_v23": -1.0049999999999994, "red_v37": 1.3932836050000004, "red_v12": -1.0099999999999996, "red_v27": 0.5036932378161698, "red_v69": -2.007999999999999, "red_v16": 1.7234936585440548, "red_v1": -1.0209999999999992}, "policy_reward_max": {"blue": 1.8307656250000002, "red": 3.994333862815204, "red_v48": 1.5006932378161697, "red_v40": -1.017, "red_v2": -1.003, "red_v52": 0.5056932378161696, "red_v17": 0.17705000000000037, "red_v79": -2.002, "red_v65": 1.9787401128161721, "red_v35": 1.49969323781617, "red_v59": -1.002, "red_v34": 0.5016932378152037, "red_v38": 1.4826932378152058, "red_v36": 1.5031030335440547, "red_v57": -0.1499999999999999, "red_v14": -0.005, "red_v46": 2.441255737816171, "red_v82": -1.0629999999999942, "red_v70": -2.002, "red_v30": -1.0059999999999993, "red_v25": -1.0109999999999992, "red_v26": 0.17705000000000015, "red_v64": 0.45, "red_v80": -2.0039999999999996, "red_v49": -2.01, "red_v61": -1.003, "red_v23": -1.0049999999999994, "red_v37": 1.3932836050000004, "red_v12": -1.0099999999999996, "red_v27": 0.5036932378161698, "red_v69": -2.007999999999999, "red_v16": 1.7234936585440548, "red_v1": -1.0209999999999992}, "policy_reward_mean": {"blue": -1.2514280266751117, "red": 3.1864320468997045, "red_v48": -0.03915338109191524, "red_v40": -1.017, "red_v2": -1.003, "red_v52": 0.5056932378161696, "red_v17": 0.17705000000000037, "red_v79": -2.002, "red_v65": 1.9787401128161721, "red_v35": 1.49969323781617, "red_v59": -1.002, "red_v34": 0.5016932378152037, "red_v38": 1.4826932378152058, "red_v36": 1.5031030335440547, "red_v57": -1.2189999999999999, "red_v14": -0.005, "red_v46": 2.441255737816171, "red_v82": -1.0629999999999942, "red_v70": -2.002, "red_v30": -1.0059999999999993, "red_v25": -1.0109999999999992, "red_v26": 0.17705000000000015, "red_v64": 0.45, "red_v80": -2.0039999999999996, "red_v49": -2.01, "red_v61": -1.003, "red_v23": -1.0049999999999994, "red_v37": 1.3932836050000004, "red_v12": -1.0099999999999996, "red_v27": 0.5036932378161698, "red_v69": -2.007999999999999, "red_v16": 1.7234936585440548, "red_v1": -1.0209999999999992}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.493149908544055, 0.4197713628161712, 2.4616776128161706, 2.4682713628161705, 2.188633862816194, 4.46404272563234, 1.48563073781617, 2.47638073781617, 3.977042725632341, 2.4287557378161737, 3.6656807378152036, 1.3823304800000003, 2.48330261281617, 2.415365112816174, 2.4737869878161702, 2.1814333506323855, 4.471292725632341, 2.465168989442592, 3.982777100631374, 1.9725213628161706, 2.163096875, 1.821458862816176, 1.9733877394425923, 1.9827088628161704, 1.1699093750000003, 2.480630042772942, 2.484521362816171, 1.3604086050000004, 2.48241198781617, 1.4861151128161703, 2.491446783544055, 4.433605225631377, 2.469712408544055, 2.480224487815204, 2.429474487816172, 1.3661776128161707, 4.4814056463602245, 3.3405213628161707, 1.4803026128152041, 2.975793989442592, 1.9378807378161733, 2.948948975632341, 1.4622713628161712, 1.9350682378161714, 2.9291776128161726, 2.4559432378161716, 2.690737227258767, 2.350052612816177, 0.959974487816171, 1.381033605, 2.4681932378152043, 2.4189588628161736, 1.1679093749999998, 2.447099487816172, 2.470005737815205, 2.488333167772942, 2.459755737816171, 1.486630737815204, 2.4654588628161704, 2.47641198781617, 2.46319323781617, 0.9855213628161703, 0.8371562499999999, 1.9617869878161711, 2.485446783544055, 1.990333862815204, 1.98963073781617, 3.66586823781617, 1.3401562500000002, 1.991036292772942, 0.6678807378161695, 3.444333862815204, 1.3398593749999999, 0.6558781250000001, 1.4688963628161709, 1.9771932378161705, 2.469193237816171, 2.490036292772942, 2.4844467835440547, 1.4699744878161707, 2.4714901128161704, 1.3229375, 2.4688721144425925, 2.457974487816171, 1.4832244878161704, 2.4817869878161702, 2.48622448781617, 2.4307244878161733, 2.433505737816172, 4.38521121781617, 1.9046932378161763, -0.07635937499999967, 2.4799276128161707, 2.48322448781617, 3.993027100631373, 1.3681117300000007, 2.2251868963602313, 2.456677612816171, 1.466974487816171, 2.467677612816171], "episode_lengths": [17, 711, 37, 39, 387, 46, 20, 36, 46, 44, 20, 17, 29, 73, 34, 593, 30, 21, 35, 23, 17, 171, 15, 27, 13, 20, 23, 24, 26, 25, 18, 58, 29, 22, 70, 133, 29, 23, 29, 13, 388, 76, 39, 72, 69, 48, 317, 109, 38, 16, 32, 75, 13, 62, 28, 19, 44, 20, 43, 26, 32, 23, 14, 34, 18, 19, 20, 24, 14, 18, 836, 19, 13, 23, 31, 32, 32, 18, 18, 38, 33, 20, 20, 38, 22, 34, 22, 54, 60, 21, 64, 19, 21, 22, 19, 23, 291, 37, 38, 37], "policy_blue_reward": [-1.0019999999999998, -1.011, -0.9229499999999986, -2.008, 0.484, -1.005, -1.019999999999998, -1.0089999999999997, -2.0109999999999992, -1.005, 1.8307656250000002, -2.002, -2.0069999999999992, -2.0029999999999997, -1.009, -1.0049999999999997, -2.005, -1.0059999999999998, -2.005, -1.003, -1.009, -1.0069999999999995, -1.014999999999999, -1.5469999999999997, -2.0069999999999997, -1.1099999999999905, -2.013999999999999, -0.518, -0.019000000000000006, -1.013999999999999, 0.4099346144425928, -1.511999999999999, -2.003, -1.0099999999999996, -1.0199999999999978, -1.0069999999999997, -1.0109999999999992, -2.0069999999999997, -1.0089999999999995, -1.011, -1.0079999999999998, -1.506, -2.0060000000000002, -2.012999999999999, -1.0059999999999996, -2.0039999999999996, -2.003, -2.002, -1.7190000000000003, -2.011999999999999, -2.0049999999999994, -1.0089999999999992, -1.0039999999999998, -1.009, -2.0089999999999995, -1.0099999999999996, -1.002, 0.49, -2.0059999999999993, -1.0229999999999981, -1.013999999999999, -2.0169999999999986, -1.5069999999999997, -1.0069999999999997, -2.0119999999999996, -1.0069999999999992], "policy_red_v48_reward": [-1.5790000000000002, 1.5006932378161697], "policy_red_v40_reward": [-1.017], "policy_red_v2_reward": [-1.003], "policy_red_v52_reward": [0.5056932378161696], "policy_red_v17_reward": [0.17705000000000037], "policy_red_v79_reward": [-2.002], "policy_red_v65_reward": [1.9787401128161721], "policy_red_v35_reward": [1.49969323781617], "policy_red_v59_reward": [-1.002], "policy_red_v34_reward": [0.5016932378152037], "policy_red_v38_reward": [1.4826932378152058], "policy_red_v36_reward": [1.5031030335440547], "policy_red_v57_reward": [-0.1499999999999999, -2.0029999999999997, -1.504], "policy_red_v14_reward": [-0.005], "policy_red_v46_reward": [2.441255737816171], "policy_red_v82_reward": [-1.0629999999999942], "policy_red_v70_reward": [-2.002], "policy_red_v30_reward": [-1.0059999999999993], "policy_red_v25_reward": [-1.0109999999999992], "policy_red_v26_reward": [0.17705000000000015], "policy_red_v64_reward": [0.45], "policy_red_v80_reward": [-2.0039999999999996], "policy_red_v49_reward": [-2.01], "policy_red_v61_reward": [-1.003], "policy_red_v23_reward": [-1.0049999999999994], "policy_red_v37_reward": [1.3932836050000004], "policy_red_v12_reward": [-1.0099999999999996], "policy_red_v27_reward": [0.5036932378161698], "policy_red_v69_reward": [-2.007999999999999], "policy_red_v16_reward": [1.7234936585440548], "policy_red_v1_reward": [-1.0209999999999992]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8287821960033892, "mean_inference_ms": 7.7512160442235665, "mean_action_processing_ms": 0.29554512916246395, "mean_env_wait_ms": 0.39686267654104684, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10302126407623291, "StateBufferConnector_ms": 0.004308581352233887, "ViewRequirementAgentConnector_ms": 0.11903679370880127}}, "episode_reward_max": 4.4814056463602245, "episode_reward_min": -0.07635937499999967, "episode_reward_mean": 2.2647909050402864, "episode_len_mean": 67.48, "episodes_this_iter": 48, "policy_reward_min": {"blue": -2.0169999999999986, "red": -0.009306762183829087, "red_v48": -1.5790000000000002, "red_v40": -1.017, "red_v2": -1.003, "red_v52": 0.5056932378161696, "red_v17": 0.17705000000000037, "red_v79": -2.002, "red_v65": 1.9787401128161721, "red_v35": 1.49969323781617, "red_v59": -1.002, "red_v34": 0.5016932378152037, "red_v38": 1.4826932378152058, "red_v36": 1.5031030335440547, "red_v57": -2.0029999999999997, "red_v14": -0.005, "red_v46": 2.441255737816171, "red_v82": -1.0629999999999942, "red_v70": -2.002, "red_v30": -1.0059999999999993, "red_v25": -1.0109999999999992, "red_v26": 0.17705000000000015, "red_v64": 0.45, "red_v80": -2.0039999999999996, "red_v49": -2.01, "red_v61": -1.003, "red_v23": -1.0049999999999994, "red_v37": 1.3932836050000004, "red_v12": -1.0099999999999996, "red_v27": 0.5036932378161698, "red_v69": -2.007999999999999, "red_v16": 1.7234936585440548, "red_v1": -1.0209999999999992}, "policy_reward_max": {"blue": 1.8307656250000002, "red": 3.994333862815204, "red_v48": 1.5006932378161697, "red_v40": -1.017, "red_v2": -1.003, "red_v52": 0.5056932378161696, "red_v17": 0.17705000000000037, "red_v79": -2.002, "red_v65": 1.9787401128161721, "red_v35": 1.49969323781617, "red_v59": -1.002, "red_v34": 0.5016932378152037, "red_v38": 1.4826932378152058, "red_v36": 1.5031030335440547, "red_v57": -0.1499999999999999, "red_v14": -0.005, "red_v46": 2.441255737816171, "red_v82": -1.0629999999999942, "red_v70": -2.002, "red_v30": -1.0059999999999993, "red_v25": -1.0109999999999992, "red_v26": 0.17705000000000015, "red_v64": 0.45, "red_v80": -2.0039999999999996, "red_v49": -2.01, "red_v61": -1.003, "red_v23": -1.0049999999999994, "red_v37": 1.3932836050000004, "red_v12": -1.0099999999999996, "red_v27": 0.5036932378161698, "red_v69": -2.007999999999999, "red_v16": 1.7234936585440548, "red_v1": -1.0209999999999992}, "policy_reward_mean": {"blue": -1.2514280266751117, "red": 3.1864320468997045, "red_v48": -0.03915338109191524, "red_v40": -1.017, "red_v2": -1.003, "red_v52": 0.5056932378161696, "red_v17": 0.17705000000000037, "red_v79": -2.002, "red_v65": 1.9787401128161721, "red_v35": 1.49969323781617, "red_v59": -1.002, "red_v34": 0.5016932378152037, "red_v38": 1.4826932378152058, "red_v36": 1.5031030335440547, "red_v57": -1.2189999999999999, "red_v14": -0.005, "red_v46": 2.441255737816171, "red_v82": -1.0629999999999942, "red_v70": -2.002, "red_v30": -1.0059999999999993, "red_v25": -1.0109999999999992, "red_v26": 0.17705000000000015, "red_v64": 0.45, "red_v80": -2.0039999999999996, "red_v49": -2.01, "red_v61": -1.003, "red_v23": -1.0049999999999994, "red_v37": 1.3932836050000004, "red_v12": -1.0099999999999996, "red_v27": 0.5036932378161698, "red_v69": -2.007999999999999, "red_v16": 1.7234936585440548, "red_v1": -1.0209999999999992}, "hist_stats": {"episode_reward": [2.493149908544055, 0.4197713628161712, 2.4616776128161706, 2.4682713628161705, 2.188633862816194, 4.46404272563234, 1.48563073781617, 2.47638073781617, 3.977042725632341, 2.4287557378161737, 3.6656807378152036, 1.3823304800000003, 2.48330261281617, 2.415365112816174, 2.4737869878161702, 2.1814333506323855, 4.471292725632341, 2.465168989442592, 3.982777100631374, 1.9725213628161706, 2.163096875, 1.821458862816176, 1.9733877394425923, 1.9827088628161704, 1.1699093750000003, 2.480630042772942, 2.484521362816171, 1.3604086050000004, 2.48241198781617, 1.4861151128161703, 2.491446783544055, 4.433605225631377, 2.469712408544055, 2.480224487815204, 2.429474487816172, 1.3661776128161707, 4.4814056463602245, 3.3405213628161707, 1.4803026128152041, 2.975793989442592, 1.9378807378161733, 2.948948975632341, 1.4622713628161712, 1.9350682378161714, 2.9291776128161726, 2.4559432378161716, 2.690737227258767, 2.350052612816177, 0.959974487816171, 1.381033605, 2.4681932378152043, 2.4189588628161736, 1.1679093749999998, 2.447099487816172, 2.470005737815205, 2.488333167772942, 2.459755737816171, 1.486630737815204, 2.4654588628161704, 2.47641198781617, 2.46319323781617, 0.9855213628161703, 0.8371562499999999, 1.9617869878161711, 2.485446783544055, 1.990333862815204, 1.98963073781617, 3.66586823781617, 1.3401562500000002, 1.991036292772942, 0.6678807378161695, 3.444333862815204, 1.3398593749999999, 0.6558781250000001, 1.4688963628161709, 1.9771932378161705, 2.469193237816171, 2.490036292772942, 2.4844467835440547, 1.4699744878161707, 2.4714901128161704, 1.3229375, 2.4688721144425925, 2.457974487816171, 1.4832244878161704, 2.4817869878161702, 2.48622448781617, 2.4307244878161733, 2.433505737816172, 4.38521121781617, 1.9046932378161763, -0.07635937499999967, 2.4799276128161707, 2.48322448781617, 3.993027100631373, 1.3681117300000007, 2.2251868963602313, 2.456677612816171, 1.466974487816171, 2.467677612816171], "episode_lengths": [17, 711, 37, 39, 387, 46, 20, 36, 46, 44, 20, 17, 29, 73, 34, 593, 30, 21, 35, 23, 17, 171, 15, 27, 13, 20, 23, 24, 26, 25, 18, 58, 29, 22, 70, 133, 29, 23, 29, 13, 388, 76, 39, 72, 69, 48, 317, 109, 38, 16, 32, 75, 13, 62, 28, 19, 44, 20, 43, 26, 32, 23, 14, 34, 18, 19, 20, 24, 14, 18, 836, 19, 13, 23, 31, 32, 32, 18, 18, 38, 33, 20, 20, 38, 22, 34, 22, 54, 60, 21, 64, 19, 21, 22, 19, 23, 291, 37, 38, 37], "policy_blue_reward": [-1.0019999999999998, -1.011, -0.9229499999999986, -2.008, 0.484, -1.005, -1.019999999999998, -1.0089999999999997, -2.0109999999999992, -1.005, 1.8307656250000002, -2.002, -2.0069999999999992, -2.0029999999999997, -1.009, -1.0049999999999997, -2.005, -1.0059999999999998, -2.005, -1.003, -1.009, -1.0069999999999995, -1.014999999999999, -1.5469999999999997, -2.0069999999999997, -1.1099999999999905, -2.013999999999999, -0.518, -0.019000000000000006, -1.013999999999999, 0.4099346144425928, -1.511999999999999, -2.003, -1.0099999999999996, -1.0199999999999978, -1.0069999999999997, -1.0109999999999992, -2.0069999999999997, -1.0089999999999995, -1.011, -1.0079999999999998, -1.506, -2.0060000000000002, -2.012999999999999, -1.0059999999999996, -2.0039999999999996, -2.003, -2.002, -1.7190000000000003, -2.011999999999999, -2.0049999999999994, -1.0089999999999992, -1.0039999999999998, -1.009, -2.0089999999999995, -1.0099999999999996, -1.002, 0.49, -2.0059999999999993, -1.0229999999999981, -1.013999999999999, -2.0169999999999986, -1.5069999999999997, -1.0069999999999997, -2.0119999999999996, -1.0069999999999992], "policy_red_v48_reward": [-1.5790000000000002, 1.5006932378161697], "policy_red_v40_reward": [-1.017], "policy_red_v2_reward": [-1.003], "policy_red_v52_reward": [0.5056932378161696], "policy_red_v17_reward": [0.17705000000000037], "policy_red_v79_reward": [-2.002], "policy_red_v65_reward": [1.9787401128161721], "policy_red_v35_reward": [1.49969323781617], "policy_red_v59_reward": [-1.002], "policy_red_v34_reward": [0.5016932378152037], "policy_red_v38_reward": [1.4826932378152058], "policy_red_v36_reward": [1.5031030335440547], "policy_red_v57_reward": [-0.1499999999999999, -2.0029999999999997, -1.504], "policy_red_v14_reward": [-0.005], "policy_red_v46_reward": [2.441255737816171], "policy_red_v82_reward": [-1.0629999999999942], "policy_red_v70_reward": [-2.002], "policy_red_v30_reward": [-1.0059999999999993], "policy_red_v25_reward": [-1.0109999999999992], "policy_red_v26_reward": [0.17705000000000015], "policy_red_v64_reward": [0.45], "policy_red_v80_reward": [-2.0039999999999996], "policy_red_v49_reward": [-2.01], "policy_red_v61_reward": [-1.003], "policy_red_v23_reward": [-1.0049999999999994], "policy_red_v37_reward": [1.3932836050000004], "policy_red_v12_reward": [-1.0099999999999996], "policy_red_v27_reward": [0.5036932378161698], "policy_red_v69_reward": [-2.007999999999999], "policy_red_v16_reward": [1.7234936585440548], "policy_red_v1_reward": [-1.0209999999999992]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8287821960033892, "mean_inference_ms": 7.7512160442235665, "mean_action_processing_ms": 0.29554512916246395, "mean_env_wait_ms": 0.39686267654104684, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10302126407623291, "StateBufferConnector_ms": 0.004308581352233887, "ViewRequirementAgentConnector_ms": 0.11903679370880127}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 984000, "num_agent_steps_trained": 984000, "num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 195.61934441813912, "num_env_steps_trained_throughput_per_sec": 195.61934441813912, "timesteps_total": 492000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 984000, "timers": {"training_iteration_time_ms": 19947.28, "sample_time_ms": 1222.635, "learn_time_ms": 18638.494, "learn_throughput": 214.61, "synch_weights_time_ms": 82.776}, "counters": {"num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_agent_steps_sampled": 984000, "num_agent_steps_trained": 984000}, "done": false, "episodes_total": 2953, "training_iteration": 123, "trial_id": "a9680_00000", "date": "2023-09-24_03-22-39", "timestamp": 1695540159, "time_this_iter_s": 20.4593665599823, "time_total_s": 2453.730115890503, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dc7d6f0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1dce3400>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1dce3490>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2453.730115890503, "iterations_since_restore": 123, "perf": {"cpu_util_percent": 5.427777777777779, "ram_util_percent": 27.491666666666667}, "win_rate": 0.82, "league_size": 92}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.627830298865835, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.05740163019145257, "policy_loss": -0.03896963562971602, "vf_loss": 0.18127352986484765, "vf_explained_var": 0.8220941804349422, "kl": 0.015688082460861796, "entropy": 1.3251360847304265, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 118560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "sampler_results": {"episode_reward_max": 4.495213905589113, "episode_reward_min": -5.275447387183827, "episode_reward_mean": 2.1015521181061922, "episode_len_mean": 75.18, "episode_media": {}, "episodes_this_iter": 51, "policy_reward_min": {"blue": -2.0169999999999986, "red": -9.552447387183827, "red_v70": -2.002, "red_v30": -1.0059999999999993, "red_v25": -1.0109999999999992, "red_v26": 0.17705000000000015, "red_v57": -2.0029999999999997, "red_v64": 0.45, "red_v80": -2.0039999999999996, "red_v49": -2.01, "red_v61": -1.003, "red_v23": -1.0049999999999994, "red_v37": 1.3932836050000004, "red_v12": -1.0099999999999996, "red_v27": 0.5036932378161698, "red_v69": -2.007999999999999, "red_v16": 1.7234936585440548, "red_v1": -1.0209999999999992, "red_v63": -2.006, "red_v8": -1.005, "red_v44": 1.5066925427729416, "red_v6": 0.4120937500000005, "red_v74": -2.1069999999999887, "red_v78": 0.5026932378161701, "red_v55": -2.0069999999999997, "red_v5": -2.013, "red_v46": 1.948515625, "red_v72": -0.3330000000000007, "red_v48": 0.45654687500000013, "red_v54": -0.564, "red_v77": 0.5016932378161703, "red_v33": -0.1559999999999997, "red_v85": -1.509, "red_v67": -2.003, "red_v2": -2.0069999999999997, "red_v66": 0.494693237816171, "red_v7": -2.008, "red_v56": 0.50269323781617, "red_v9": -1.0139999999999993, "red_v73": -2.0079999999999996}, "policy_reward_max": {"blue": 4.277000000000003, "red": 3.994333862815204, "red_v70": -2.002, "red_v30": -1.0059999999999993, "red_v25": -1.0109999999999992, "red_v26": 0.17705000000000015, "red_v57": 1.460693237816173, "red_v64": 0.45, "red_v80": 0.4856932378161707, "red_v49": -2.01, "red_v61": -1.003, "red_v23": -1.0049999999999994, "red_v37": 1.3932836050000004, "red_v12": -1.0099999999999996, "red_v27": 0.5036932378161698, "red_v69": -2.0039999999999996, "red_v16": 1.7234936585440548, "red_v1": -1.0209999999999992, "red_v63": -2.006, "red_v8": -1.005, "red_v44": 1.5066925427729416, "red_v6": 0.4120937500000005, "red_v74": -2.1069999999999887, "red_v78": 0.5026932378161701, "red_v55": -2.0069999999999997, "red_v5": -2.013, "red_v46": 1.948515625, "red_v72": -0.3330000000000007, "red_v48": 0.45654687500000013, "red_v54": -0.564, "red_v77": 0.5016932378161703, "red_v33": -0.1559999999999997, "red_v85": -1.509, "red_v67": -2.003, "red_v2": -2.0069999999999997, "red_v66": 0.494693237816171, "red_v7": -2.008, "red_v56": 0.50269323781617, "red_v9": -1.0139999999999993, "red_v73": -2.0079999999999996}, "policy_reward_mean": {"blue": -1.2001034482758615, "red": 3.07572683089589, "red_v70": -2.002, "red_v30": -1.0059999999999993, "red_v25": -1.0109999999999992, "red_v26": 0.17705000000000015, "red_v57": -0.6821022540612756, "red_v64": 0.45, "red_v80": -0.7591533810919144, "red_v49": -2.01, "red_v61": -1.003, "red_v23": -1.0049999999999994, "red_v37": 1.3932836050000004, "red_v12": -1.0099999999999996, "red_v27": 0.5036932378161698, "red_v69": -2.0059999999999993, "red_v16": 1.7234936585440548, "red_v1": -1.0209999999999992, "red_v63": -2.006, "red_v8": -1.005, "red_v44": 1.5066925427729416, "red_v6": 0.4120937500000005, "red_v74": -2.1069999999999887, "red_v78": 0.5026932378161701, "red_v55": -2.0069999999999997, "red_v5": -2.013, "red_v46": 1.948515625, "red_v72": -0.3330000000000007, "red_v48": 0.45654687500000013, "red_v54": -0.564, "red_v77": 0.5016932378161703, "red_v33": -0.1559999999999997, "red_v85": -1.509, "red_v67": -2.003, "red_v2": -2.0069999999999997, "red_v66": 0.494693237816171, "red_v7": -2.008, "red_v56": 0.50269323781617, "red_v9": -1.0139999999999993, "red_v73": -2.0079999999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.4189588628161736, 1.1679093749999998, 2.447099487816172, 2.470005737815205, 2.488333167772942, 2.459755737816171, 1.486630737815204, 2.4654588628161704, 2.47641198781617, 2.46319323781617, 0.9855213628161703, 0.8371562499999999, 1.9617869878161711, 2.485446783544055, 1.990333862815204, 1.98963073781617, 3.66586823781617, 1.3401562500000002, 1.991036292772942, 0.6678807378161695, 3.444333862815204, 1.3398593749999999, 0.6558781250000001, 1.4688963628161709, 1.9771932378161705, 2.469193237816171, 2.490036292772942, 2.4844467835440547, 1.4699744878161707, 2.4714901128161704, 1.3229375, 2.4688721144425925, 2.457974487816171, 1.4832244878161704, 2.4817869878161702, 2.48622448781617, 2.4307244878161733, 2.433505737816172, 4.38521121781617, 1.9046932378161763, -0.07635937499999967, 2.4799276128161707, 2.48322448781617, 3.993027100631373, 1.3681117300000007, 2.2251868963602313, 2.456677612816171, 1.466974487816171, 2.467677612816171, 1.9545994878161717, 1.9874467835440552, 2.484337408544055, 4.495213905589113, 0.9027869878161723, 4.334761475632348, 2.4841151128161703, 1.9581619878161707, 1.6292401128161873, 3.978667725632341, 0.4199375000000001, 1.9714901128161715, 1.4750838628161707, 1.165503125, 1.4750908644425926, 1.48963073781617, 2.4069276128161743, 1.9372088628161714, -1.6209999999999338, 2.489036292772942, -5.275447387183827, 0.9422401128161715, 2.4764119878161703, 2.9880362927729416, 2.490146362815204, 2.4861499085440553, 2.8862088628161726, 2.4822244878161706, 3.9147614756323446, 2.4552401128161714, 3.9715271006323407, 3.3203807378161714, 0.8286463628161709, 1.9833026128161697, 2.4745994878161706, 1.33315625, 1.6660968750000003, 2.8718148550000007, 2.449536987816172, 3.9101833506323445, 2.4837088628161705, 1.462490112816171, 2.4198807378161726, 2.443130737816171, 2.48441198781617, 3.9861833506323405, 0.6931151128161999, 2.490446783544055, 2.48452136281617, 2.4301463628161715, 1.4542401128161717], "episode_lengths": [75, 13, 62, 28, 19, 44, 20, 43, 26, 32, 23, 14, 34, 18, 19, 20, 24, 14, 18, 836, 19, 13, 23, 31, 32, 32, 18, 18, 38, 33, 20, 20, 38, 22, 34, 22, 54, 60, 21, 64, 19, 21, 22, 19, 23, 291, 37, 38, 37, 30, 18, 21, 23, 98, 136, 25, 42, 305, 38, 20, 33, 35, 15, 14, 20, 85, 59, 1280, 18, 781, 49, 26, 18, 15, 17, 59, 22, 72, 49, 51, 36, 239, 29, 30, 14, 17, 22, 50, 97, 27, 33, 68, 52, 26, 33, 601, 18, 23, 79, 49], "policy_blue_reward": [-1.0199999999999978, -1.0069999999999997, -1.0109999999999992, -2.0069999999999997, -1.0089999999999995, -1.011, -1.0079999999999998, -1.506, -2.0060000000000002, -2.012999999999999, -1.0059999999999996, -2.0039999999999996, -2.003, -2.002, -1.7190000000000003, -2.011999999999999, -2.0049999999999994, -1.0089999999999992, -1.0039999999999998, -1.009, -2.0089999999999995, -1.0099999999999996, -1.002, 0.49, -2.0059999999999993, -1.0229999999999981, -1.013999999999999, -2.0169999999999986, -1.5069999999999997, -1.0069999999999997, -2.0119999999999996, -1.0069999999999992, -2.012999999999999, -1.006, -2.0109999999999992, -2.0039999999999996, -2.0039999999999996, -2.0039999999999996, -1.027999999999998, -1.0049999999999997, 4.277000000000003, -1.0139999999999991, -0.005, -1.0079999999999998, -1.0079999999999998, -1.0099999999999998, -1.0159999999999998, -1.0089999999999992, -2.001, -0.007, -1.0109999999999988, -1.005, -1.0159999999999991, -1.021999999999999, -1.0049999999999997, -1.166, -1.0039999999999998, -1.0059999999999996], "policy_red_v70_reward": [-2.002], "policy_red_v30_reward": [-1.0059999999999993], "policy_red_v25_reward": [-1.0109999999999992], "policy_red_v26_reward": [0.17705000000000015], "policy_red_v57_reward": [-2.0029999999999997, -1.504, 1.460693237816173], "policy_red_v64_reward": [0.45], "policy_red_v80_reward": [-2.0039999999999996, 0.4856932378161707], "policy_red_v49_reward": [-2.01], "policy_red_v61_reward": [-1.003], "policy_red_v23_reward": [-1.0049999999999994], "policy_red_v37_reward": [1.3932836050000004], "policy_red_v12_reward": [-1.0099999999999996], "policy_red_v27_reward": [0.5036932378161698], "policy_red_v69_reward": [-2.007999999999999, -2.0039999999999996], "policy_red_v16_reward": [1.7234936585440548], "policy_red_v1_reward": [-1.0209999999999992], "policy_red_v63_reward": [-2.006], "policy_red_v8_reward": [-1.005], "policy_red_v44_reward": [1.5066925427729416], "policy_red_v6_reward": [0.4120937500000005], "policy_red_v74_reward": [-2.1069999999999887], "policy_red_v78_reward": [0.5026932378161701], "policy_red_v55_reward": [-2.0069999999999997], "policy_red_v5_reward": [-2.013], "policy_red_v46_reward": [1.948515625], "policy_red_v72_reward": [-0.3330000000000007], "policy_red_v48_reward": [0.45654687500000013], "policy_red_v54_reward": [-0.564], "policy_red_v77_reward": [0.5016932378161703], "policy_red_v33_reward": [-0.1559999999999997], "policy_red_v85_reward": [-1.509], "policy_red_v67_reward": [-2.003], "policy_red_v2_reward": [-2.0069999999999997], "policy_red_v66_reward": [0.494693237816171], "policy_red_v7_reward": [-2.008], "policy_red_v56_reward": [0.50269323781617], "policy_red_v9_reward": [-1.0139999999999993], "policy_red_v73_reward": [-2.0079999999999996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.827304906398011, "mean_inference_ms": 7.712633505956046, "mean_action_processing_ms": 0.2945493247357414, "mean_env_wait_ms": 0.3963607067085111, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10069155693054199, "StateBufferConnector_ms": 0.004257678985595703, "ViewRequirementAgentConnector_ms": 0.11767983436584473}}, "episode_reward_max": 4.495213905589113, "episode_reward_min": -5.275447387183827, "episode_reward_mean": 2.1015521181061922, "episode_len_mean": 75.18, "episodes_this_iter": 51, "policy_reward_min": {"blue": -2.0169999999999986, "red": -9.552447387183827, "red_v70": -2.002, "red_v30": -1.0059999999999993, "red_v25": -1.0109999999999992, "red_v26": 0.17705000000000015, "red_v57": -2.0029999999999997, "red_v64": 0.45, "red_v80": -2.0039999999999996, "red_v49": -2.01, "red_v61": -1.003, "red_v23": -1.0049999999999994, "red_v37": 1.3932836050000004, "red_v12": -1.0099999999999996, "red_v27": 0.5036932378161698, "red_v69": -2.007999999999999, "red_v16": 1.7234936585440548, "red_v1": -1.0209999999999992, "red_v63": -2.006, "red_v8": -1.005, "red_v44": 1.5066925427729416, "red_v6": 0.4120937500000005, "red_v74": -2.1069999999999887, "red_v78": 0.5026932378161701, "red_v55": -2.0069999999999997, "red_v5": -2.013, "red_v46": 1.948515625, "red_v72": -0.3330000000000007, "red_v48": 0.45654687500000013, "red_v54": -0.564, "red_v77": 0.5016932378161703, "red_v33": -0.1559999999999997, "red_v85": -1.509, "red_v67": -2.003, "red_v2": -2.0069999999999997, "red_v66": 0.494693237816171, "red_v7": -2.008, "red_v56": 0.50269323781617, "red_v9": -1.0139999999999993, "red_v73": -2.0079999999999996}, "policy_reward_max": {"blue": 4.277000000000003, "red": 3.994333862815204, "red_v70": -2.002, "red_v30": -1.0059999999999993, "red_v25": -1.0109999999999992, "red_v26": 0.17705000000000015, "red_v57": 1.460693237816173, "red_v64": 0.45, "red_v80": 0.4856932378161707, "red_v49": -2.01, "red_v61": -1.003, "red_v23": -1.0049999999999994, "red_v37": 1.3932836050000004, "red_v12": -1.0099999999999996, "red_v27": 0.5036932378161698, "red_v69": -2.0039999999999996, "red_v16": 1.7234936585440548, "red_v1": -1.0209999999999992, "red_v63": -2.006, "red_v8": -1.005, "red_v44": 1.5066925427729416, "red_v6": 0.4120937500000005, "red_v74": -2.1069999999999887, "red_v78": 0.5026932378161701, "red_v55": -2.0069999999999997, "red_v5": -2.013, "red_v46": 1.948515625, "red_v72": -0.3330000000000007, "red_v48": 0.45654687500000013, "red_v54": -0.564, "red_v77": 0.5016932378161703, "red_v33": -0.1559999999999997, "red_v85": -1.509, "red_v67": -2.003, "red_v2": -2.0069999999999997, "red_v66": 0.494693237816171, "red_v7": -2.008, "red_v56": 0.50269323781617, "red_v9": -1.0139999999999993, "red_v73": -2.0079999999999996}, "policy_reward_mean": {"blue": -1.2001034482758615, "red": 3.07572683089589, "red_v70": -2.002, "red_v30": -1.0059999999999993, "red_v25": -1.0109999999999992, "red_v26": 0.17705000000000015, "red_v57": -0.6821022540612756, "red_v64": 0.45, "red_v80": -0.7591533810919144, "red_v49": -2.01, "red_v61": -1.003, "red_v23": -1.0049999999999994, "red_v37": 1.3932836050000004, "red_v12": -1.0099999999999996, "red_v27": 0.5036932378161698, "red_v69": -2.0059999999999993, "red_v16": 1.7234936585440548, "red_v1": -1.0209999999999992, "red_v63": -2.006, "red_v8": -1.005, "red_v44": 1.5066925427729416, "red_v6": 0.4120937500000005, "red_v74": -2.1069999999999887, "red_v78": 0.5026932378161701, "red_v55": -2.0069999999999997, "red_v5": -2.013, "red_v46": 1.948515625, "red_v72": -0.3330000000000007, "red_v48": 0.45654687500000013, "red_v54": -0.564, "red_v77": 0.5016932378161703, "red_v33": -0.1559999999999997, "red_v85": -1.509, "red_v67": -2.003, "red_v2": -2.0069999999999997, "red_v66": 0.494693237816171, "red_v7": -2.008, "red_v56": 0.50269323781617, "red_v9": -1.0139999999999993, "red_v73": -2.0079999999999996}, "hist_stats": {"episode_reward": [2.4189588628161736, 1.1679093749999998, 2.447099487816172, 2.470005737815205, 2.488333167772942, 2.459755737816171, 1.486630737815204, 2.4654588628161704, 2.47641198781617, 2.46319323781617, 0.9855213628161703, 0.8371562499999999, 1.9617869878161711, 2.485446783544055, 1.990333862815204, 1.98963073781617, 3.66586823781617, 1.3401562500000002, 1.991036292772942, 0.6678807378161695, 3.444333862815204, 1.3398593749999999, 0.6558781250000001, 1.4688963628161709, 1.9771932378161705, 2.469193237816171, 2.490036292772942, 2.4844467835440547, 1.4699744878161707, 2.4714901128161704, 1.3229375, 2.4688721144425925, 2.457974487816171, 1.4832244878161704, 2.4817869878161702, 2.48622448781617, 2.4307244878161733, 2.433505737816172, 4.38521121781617, 1.9046932378161763, -0.07635937499999967, 2.4799276128161707, 2.48322448781617, 3.993027100631373, 1.3681117300000007, 2.2251868963602313, 2.456677612816171, 1.466974487816171, 2.467677612816171, 1.9545994878161717, 1.9874467835440552, 2.484337408544055, 4.495213905589113, 0.9027869878161723, 4.334761475632348, 2.4841151128161703, 1.9581619878161707, 1.6292401128161873, 3.978667725632341, 0.4199375000000001, 1.9714901128161715, 1.4750838628161707, 1.165503125, 1.4750908644425926, 1.48963073781617, 2.4069276128161743, 1.9372088628161714, -1.6209999999999338, 2.489036292772942, -5.275447387183827, 0.9422401128161715, 2.4764119878161703, 2.9880362927729416, 2.490146362815204, 2.4861499085440553, 2.8862088628161726, 2.4822244878161706, 3.9147614756323446, 2.4552401128161714, 3.9715271006323407, 3.3203807378161714, 0.8286463628161709, 1.9833026128161697, 2.4745994878161706, 1.33315625, 1.6660968750000003, 2.8718148550000007, 2.449536987816172, 3.9101833506323445, 2.4837088628161705, 1.462490112816171, 2.4198807378161726, 2.443130737816171, 2.48441198781617, 3.9861833506323405, 0.6931151128161999, 2.490446783544055, 2.48452136281617, 2.4301463628161715, 1.4542401128161717], "episode_lengths": [75, 13, 62, 28, 19, 44, 20, 43, 26, 32, 23, 14, 34, 18, 19, 20, 24, 14, 18, 836, 19, 13, 23, 31, 32, 32, 18, 18, 38, 33, 20, 20, 38, 22, 34, 22, 54, 60, 21, 64, 19, 21, 22, 19, 23, 291, 37, 38, 37, 30, 18, 21, 23, 98, 136, 25, 42, 305, 38, 20, 33, 35, 15, 14, 20, 85, 59, 1280, 18, 781, 49, 26, 18, 15, 17, 59, 22, 72, 49, 51, 36, 239, 29, 30, 14, 17, 22, 50, 97, 27, 33, 68, 52, 26, 33, 601, 18, 23, 79, 49], "policy_blue_reward": [-1.0199999999999978, -1.0069999999999997, -1.0109999999999992, -2.0069999999999997, -1.0089999999999995, -1.011, -1.0079999999999998, -1.506, -2.0060000000000002, -2.012999999999999, -1.0059999999999996, -2.0039999999999996, -2.003, -2.002, -1.7190000000000003, -2.011999999999999, -2.0049999999999994, -1.0089999999999992, -1.0039999999999998, -1.009, -2.0089999999999995, -1.0099999999999996, -1.002, 0.49, -2.0059999999999993, -1.0229999999999981, -1.013999999999999, -2.0169999999999986, -1.5069999999999997, -1.0069999999999997, -2.0119999999999996, -1.0069999999999992, -2.012999999999999, -1.006, -2.0109999999999992, -2.0039999999999996, -2.0039999999999996, -2.0039999999999996, -1.027999999999998, -1.0049999999999997, 4.277000000000003, -1.0139999999999991, -0.005, -1.0079999999999998, -1.0079999999999998, -1.0099999999999998, -1.0159999999999998, -1.0089999999999992, -2.001, -0.007, -1.0109999999999988, -1.005, -1.0159999999999991, -1.021999999999999, -1.0049999999999997, -1.166, -1.0039999999999998, -1.0059999999999996], "policy_red_v70_reward": [-2.002], "policy_red_v30_reward": [-1.0059999999999993], "policy_red_v25_reward": [-1.0109999999999992], "policy_red_v26_reward": [0.17705000000000015], "policy_red_v57_reward": [-2.0029999999999997, -1.504, 1.460693237816173], "policy_red_v64_reward": [0.45], "policy_red_v80_reward": [-2.0039999999999996, 0.4856932378161707], "policy_red_v49_reward": [-2.01], "policy_red_v61_reward": [-1.003], "policy_red_v23_reward": [-1.0049999999999994], "policy_red_v37_reward": [1.3932836050000004], "policy_red_v12_reward": [-1.0099999999999996], "policy_red_v27_reward": [0.5036932378161698], "policy_red_v69_reward": [-2.007999999999999, -2.0039999999999996], "policy_red_v16_reward": [1.7234936585440548], "policy_red_v1_reward": [-1.0209999999999992], "policy_red_v63_reward": [-2.006], "policy_red_v8_reward": [-1.005], "policy_red_v44_reward": [1.5066925427729416], "policy_red_v6_reward": [0.4120937500000005], "policy_red_v74_reward": [-2.1069999999999887], "policy_red_v78_reward": [0.5026932378161701], "policy_red_v55_reward": [-2.0069999999999997], "policy_red_v5_reward": [-2.013], "policy_red_v46_reward": [1.948515625], "policy_red_v72_reward": [-0.3330000000000007], "policy_red_v48_reward": [0.45654687500000013], "policy_red_v54_reward": [-0.564], "policy_red_v77_reward": [0.5016932378161703], "policy_red_v33_reward": [-0.1559999999999997], "policy_red_v85_reward": [-1.509], "policy_red_v67_reward": [-2.003], "policy_red_v2_reward": [-2.0069999999999997], "policy_red_v66_reward": [0.494693237816171], "policy_red_v7_reward": [-2.008], "policy_red_v56_reward": [0.50269323781617], "policy_red_v9_reward": [-1.0139999999999993], "policy_red_v73_reward": [-2.0079999999999996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.827304906398011, "mean_inference_ms": 7.712633505956046, "mean_action_processing_ms": 0.2945493247357414, "mean_env_wait_ms": 0.3963607067085111, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10069155693054199, "StateBufferConnector_ms": 0.004257678985595703, "ViewRequirementAgentConnector_ms": 0.11767983436584473}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 195.31181087829592, "num_env_steps_trained_throughput_per_sec": 195.31181087829592, "timesteps_total": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 19990.39, "sample_time_ms": 1251.999, "learn_time_ms": 18652.274, "learn_throughput": 214.451, "synch_weights_time_ms": 82.697}, "counters": {"num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "episodes_total": 3004, "training_iteration": 124, "trial_id": "a9680_00000", "date": "2023-09-24_03-23-05", "timestamp": 1695540185, "time_this_iter_s": 20.49236536026001, "time_total_s": 2474.222481250763, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dc7f850>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1dce2a70>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1dce2b00>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2474.222481250763, "iterations_since_restore": 124, "perf": {"cpu_util_percent": 5.752777777777778, "ram_util_percent": 27.677777777777784}, "win_rate": 0.83, "league_size": 93}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3353852183868486, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.04539077504571954, "policy_loss": -0.04172074686114987, "vf_loss": 0.16268292679063354, "vf_explained_var": 0.8378928050398826, "kl": 0.015842412889825633, "entropy": 1.3590268834183614, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 119520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_agent_steps_sampled": 1000000, "num_agent_steps_trained": 1000000}, "sampler_results": {"episode_reward_max": 4.495213905589113, "episode_reward_min": -5.275447387183827, "episode_reward_mean": 2.148710142756766, "episode_len_mean": 93.1, "episode_media": {}, "episodes_this_iter": 45, "policy_reward_min": {"red_v16": 1.7234936585440548, "red": -9.552447387183827, "red_v1": -1.0209999999999992, "blue": -2.038999999999997, "red_v63": -2.006, "red_v8": -1.005, "red_v44": 1.5066925427729416, "red_v6": 0.4120937500000005, "red_v57": 1.460693237816173, "red_v74": -2.1069999999999887, "red_v78": 0.5026932378161701, "red_v55": -2.0069999999999997, "red_v5": -2.013, "red_v69": -2.0039999999999996, "red_v46": 1.948515625, "red_v72": -2.002, "red_v48": 0.45654687500000013, "red_v54": -0.564, "red_v80": 0.4856932378161707, "red_v77": 0.5016932378161703, "red_v33": -1.6709999999999527, "red_v85": -1.509, "red_v67": -2.003, "red_v2": -2.0069999999999997, "red_v66": 0.494693237816171, "red_v7": -2.008, "red_v56": 0.50269323781617, "red_v9": -1.0139999999999993, "red_v73": -2.0079999999999996, "red_v59": -1.002, "red_v64": 1.9095369878161705, "red_v11": -0.5079999999999999, "red_v29": 0.8989346144425968, "red_v20": 0.48169323781617, "red_v71": -2.002, "red_v39": 1.4616932378152068, "red_v32": 0.4879346144425921, "red_v53": 0.5056932378161697, "red_v68": -1.0059999999999998, "red_v23": -1.001, "red_v41": -1.0049999999999994, "red_v14": -1.0049999999999997}, "policy_reward_max": {"red_v16": 1.7234936585440548, "red": 3.993446783544055, "red_v1": -1.0209999999999992, "blue": 4.277000000000003, "red_v63": -2.006, "red_v8": -1.005, "red_v44": 1.5066925427729416, "red_v6": 0.4866932378161702, "red_v57": 1.460693237816173, "red_v74": -2.1069999999999887, "red_v78": 0.5026932378161701, "red_v55": -2.0069999999999997, "red_v5": -2.013, "red_v69": -2.0039999999999996, "red_v46": 1.948515625, "red_v72": -0.3330000000000007, "red_v48": 0.45654687500000013, "red_v54": -0.564, "red_v80": 0.4856932378161707, "red_v77": 0.5016932378161703, "red_v33": -0.1559999999999997, "red_v85": -1.0089999999999997, "red_v67": -2.003, "red_v2": -2.0069999999999997, "red_v66": 1.491693237816171, "red_v7": -2.008, "red_v56": 0.50269323781617, "red_v9": -1.0139999999999993, "red_v73": 0.23315625000000018, "red_v59": -1.002, "red_v64": 1.9095369878161705, "red_v11": -0.5079999999999999, "red_v29": 0.8989346144425968, "red_v20": 0.48169323781617, "red_v71": -2.002, "red_v39": 1.4616932378152068, "red_v32": 0.4879346144425921, "red_v53": 0.5056932378161697, "red_v68": -1.0059999999999998, "red_v23": -1.001, "red_v41": -1.0049999999999994, "red_v14": -1.0049999999999997}, "policy_reward_mean": {"red_v16": 1.7234936585440548, "red": 2.9644528061668116, "red_v1": -1.0209999999999992, "blue": -1.1768666087962958, "red_v63": -2.006, "red_v8": -1.005, "red_v44": 1.5066925427729416, "red_v6": 0.44939349390808536, "red_v57": 1.460693237816173, "red_v74": -2.1069999999999887, "red_v78": 0.5026932378161701, "red_v55": -2.0069999999999997, "red_v5": -2.013, "red_v69": -2.0039999999999996, "red_v46": 1.948515625, "red_v72": -1.1675000000000002, "red_v48": 0.45654687500000013, "red_v54": -0.564, "red_v80": 0.4856932378161707, "red_v77": 0.5016932378161703, "red_v33": -0.9134999999999762, "red_v85": -1.259, "red_v67": -2.003, "red_v2": -2.0069999999999997, "red_v66": 0.993193237816171, "red_v7": -2.008, "red_v56": 0.50269323781617, "red_v9": -1.0139999999999993, "red_v73": -0.8874218749999997, "red_v59": -1.002, "red_v64": 1.9095369878161705, "red_v11": -0.5079999999999999, "red_v29": 0.8989346144425968, "red_v20": 0.48169323781617, "red_v71": -2.002, "red_v39": 1.4616932378152068, "red_v32": 0.4879346144425921, "red_v53": 0.5056932378161697, "red_v68": -1.0059999999999998, "red_v23": -1.001, "red_v41": -1.0049999999999994, "red_v14": -1.0049999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.2251868963602313, 2.456677612816171, 1.466974487816171, 2.467677612816171, 1.9545994878161717, 1.9874467835440552, 2.484337408544055, 4.495213905589113, 0.9027869878161723, 4.334761475632348, 2.4841151128161703, 1.9581619878161707, 1.6292401128161873, 3.978667725632341, 0.4199375000000001, 1.9714901128161715, 1.4750838628161707, 1.165503125, 1.4750908644425926, 1.48963073781617, 2.4069276128161743, 1.9372088628161714, -1.6209999999999338, 2.489036292772942, -5.275447387183827, 0.9422401128161715, 2.4764119878161703, 2.9880362927729416, 2.490146362815204, 2.4861499085440553, 2.8862088628161726, 2.4822244878161706, 3.9147614756323446, 2.4552401128161714, 3.9715271006323407, 3.3203807378161714, 0.8286463628161709, 1.9833026128161697, 2.4745994878161706, 1.33315625, 1.6660968750000003, 2.8718148550000007, 2.449536987816172, 3.9101833506323445, 2.4837088628161705, 1.462490112816171, 2.4198807378161726, 2.443130737816171, 2.48441198781617, 3.9861833506323405, 0.6931151128161999, 2.490446783544055, 2.48452136281617, 2.4301463628161715, 1.4542401128161717, 0.73284948781617, -2.1849999999999064, 1.4613807378161705, 1.9751932378161707, 2.4696463628161696, 2.4723026128161707, 1.4358807378161722, 1.8666463628161718, 2.476981489442592, 2.4921456677729417, 0.641161987816171, 2.464677612816171, 2.485853033544055, 1.9614588628161707, 1.316203125, 0.43615625, 1.492036292772942, 2.4457244878161717, 2.3882302256323444, 2.987036292772942, 1.48833386281617, 3.167299727258783, 2.47330261281617, 2.1549875000000003, 3.946339600632342, 1.3823304800000003, 1.9476151128161718, 3.953855225632342, 4.3491833506313835, 1.97389636281617, 3.979565352257796, 1.9674901128161706, 1.4566776128161707, 3.9898864756323404, 2.456865112816171, 1.3821619878161744, 2.3759242300000003, 4.427995850632341, 2.48833386281617, 2.49092761281617, 2.458021362816171, 2.456865112816171, 2.3421586050000003, 2.4813026128161697, 1.940880737816171], "episode_lengths": [291, 37, 38, 37, 30, 18, 21, 23, 98, 136, 25, 42, 305, 38, 20, 33, 35, 15, 14, 20, 85, 59, 1280, 18, 781, 49, 26, 18, 15, 17, 59, 22, 72, 49, 51, 36, 239, 29, 30, 14, 17, 22, 50, 97, 27, 33, 68, 52, 26, 33, 601, 18, 23, 79, 49, 334, 1280, 36, 32, 47, 29, 68, 111, 17, 15, 362, 37, 16, 43, 31, 14, 18, 54, 114, 18, 19, 201, 29, 20, 47, 17, 57, 42, 97, 31, 20, 33, 37, 32, 41, 106, 19, 93, 19, 21, 55, 41, 40, 29, 68], "policy_red_v16_reward": [1.7234936585440548], "policy_red_v1_reward": [-1.0209999999999992], "policy_blue_reward": [-2.0119999999999996, -1.0069999999999992, -2.012999999999999, -1.006, -2.0109999999999992, -2.0039999999999996, -2.0039999999999996, -2.0039999999999996, -1.027999999999998, -1.0049999999999997, 4.277000000000003, -1.0139999999999991, -0.005, -1.0079999999999998, -1.0079999999999998, -1.0099999999999998, -1.0159999999999998, -1.0089999999999992, -2.001, -0.007, -1.0109999999999988, -1.005, -1.0159999999999991, -1.021999999999999, -1.0049999999999997, -1.166, -1.0039999999999998, -1.0059999999999996, -2.0149999999999997, -2.01, -1.0059999999999998, -2.0199999999999982, -0.5289999999999985, -1.002, -1.005, -1.6059999999999999, -1.0099999999999991, -1.007, -2.0119999999999996, 1.9702031249999998, -2.004, -1.0149999999999983, -2.005, -1.0089999999999997, -2.0159999999999982, -2.01, -2.0109999999999992, -2.0109999999999992, -1.0119999999999996, -2.038999999999997, -1.0039999999999996, -1.0129999999999997, -1.0099999999999996, -2.01], "policy_red_v63_reward": [-2.006], "policy_red_v8_reward": [-1.005], "policy_red_v44_reward": [1.5066925427729416], "policy_red_v6_reward": [0.4120937500000005, 0.4866932378161702], "policy_red_v57_reward": [1.460693237816173], "policy_red_v74_reward": [-2.1069999999999887], "policy_red_v78_reward": [0.5026932378161701], "policy_red_v55_reward": [-2.0069999999999997], "policy_red_v5_reward": [-2.013], "policy_red_v69_reward": [-2.0039999999999996], "policy_red_v46_reward": [1.948515625], "policy_red_v72_reward": [-0.3330000000000007, -2.002], "policy_red_v48_reward": [0.45654687500000013], "policy_red_v54_reward": [-0.564], "policy_red_v80_reward": [0.4856932378161707], "policy_red_v77_reward": [0.5016932378161703], "policy_red_v33_reward": [-0.1559999999999997, -1.6709999999999527], "policy_red_v85_reward": [-1.509, -1.0089999999999997], "policy_red_v67_reward": [-2.003], "policy_red_v2_reward": [-2.0069999999999997], "policy_red_v66_reward": [0.494693237816171, 1.491693237816171], "policy_red_v7_reward": [-2.008], "policy_red_v56_reward": [0.50269323781617], "policy_red_v9_reward": [-1.0139999999999993], "policy_red_v73_reward": [-2.0079999999999996, 0.23315625000000018], "policy_red_v59_reward": [-1.002], "policy_red_v64_reward": [1.9095369878161705], "policy_red_v11_reward": [-0.5079999999999999], "policy_red_v29_reward": [0.8989346144425968], "policy_red_v20_reward": [0.48169323781617], "policy_red_v71_reward": [-2.002], "policy_red_v39_reward": [1.4616932378152068], "policy_red_v32_reward": [0.4879346144425921], "policy_red_v53_reward": [0.5056932378161697], "policy_red_v68_reward": [-1.0059999999999998], "policy_red_v23_reward": [-1.001], "policy_red_v41_reward": [-1.0049999999999994], "policy_red_v14_reward": [-1.0049999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8258312611143132, "mean_inference_ms": 7.683239041844821, "mean_action_processing_ms": 0.2937683831491483, "mean_env_wait_ms": 0.39621941198237715, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0977931022644043, "StateBufferConnector_ms": 0.004097580909729004, "ViewRequirementAgentConnector_ms": 0.11307501792907715}}, "episode_reward_max": 4.495213905589113, "episode_reward_min": -5.275447387183827, "episode_reward_mean": 2.148710142756766, "episode_len_mean": 93.1, "episodes_this_iter": 45, "policy_reward_min": {"red_v16": 1.7234936585440548, "red": -9.552447387183827, "red_v1": -1.0209999999999992, "blue": -2.038999999999997, "red_v63": -2.006, "red_v8": -1.005, "red_v44": 1.5066925427729416, "red_v6": 0.4120937500000005, "red_v57": 1.460693237816173, "red_v74": -2.1069999999999887, "red_v78": 0.5026932378161701, "red_v55": -2.0069999999999997, "red_v5": -2.013, "red_v69": -2.0039999999999996, "red_v46": 1.948515625, "red_v72": -2.002, "red_v48": 0.45654687500000013, "red_v54": -0.564, "red_v80": 0.4856932378161707, "red_v77": 0.5016932378161703, "red_v33": -1.6709999999999527, "red_v85": -1.509, "red_v67": -2.003, "red_v2": -2.0069999999999997, "red_v66": 0.494693237816171, "red_v7": -2.008, "red_v56": 0.50269323781617, "red_v9": -1.0139999999999993, "red_v73": -2.0079999999999996, "red_v59": -1.002, "red_v64": 1.9095369878161705, "red_v11": -0.5079999999999999, "red_v29": 0.8989346144425968, "red_v20": 0.48169323781617, "red_v71": -2.002, "red_v39": 1.4616932378152068, "red_v32": 0.4879346144425921, "red_v53": 0.5056932378161697, "red_v68": -1.0059999999999998, "red_v23": -1.001, "red_v41": -1.0049999999999994, "red_v14": -1.0049999999999997}, "policy_reward_max": {"red_v16": 1.7234936585440548, "red": 3.993446783544055, "red_v1": -1.0209999999999992, "blue": 4.277000000000003, "red_v63": -2.006, "red_v8": -1.005, "red_v44": 1.5066925427729416, "red_v6": 0.4866932378161702, "red_v57": 1.460693237816173, "red_v74": -2.1069999999999887, "red_v78": 0.5026932378161701, "red_v55": -2.0069999999999997, "red_v5": -2.013, "red_v69": -2.0039999999999996, "red_v46": 1.948515625, "red_v72": -0.3330000000000007, "red_v48": 0.45654687500000013, "red_v54": -0.564, "red_v80": 0.4856932378161707, "red_v77": 0.5016932378161703, "red_v33": -0.1559999999999997, "red_v85": -1.0089999999999997, "red_v67": -2.003, "red_v2": -2.0069999999999997, "red_v66": 1.491693237816171, "red_v7": -2.008, "red_v56": 0.50269323781617, "red_v9": -1.0139999999999993, "red_v73": 0.23315625000000018, "red_v59": -1.002, "red_v64": 1.9095369878161705, "red_v11": -0.5079999999999999, "red_v29": 0.8989346144425968, "red_v20": 0.48169323781617, "red_v71": -2.002, "red_v39": 1.4616932378152068, "red_v32": 0.4879346144425921, "red_v53": 0.5056932378161697, "red_v68": -1.0059999999999998, "red_v23": -1.001, "red_v41": -1.0049999999999994, "red_v14": -1.0049999999999997}, "policy_reward_mean": {"red_v16": 1.7234936585440548, "red": 2.9644528061668116, "red_v1": -1.0209999999999992, "blue": -1.1768666087962958, "red_v63": -2.006, "red_v8": -1.005, "red_v44": 1.5066925427729416, "red_v6": 0.44939349390808536, "red_v57": 1.460693237816173, "red_v74": -2.1069999999999887, "red_v78": 0.5026932378161701, "red_v55": -2.0069999999999997, "red_v5": -2.013, "red_v69": -2.0039999999999996, "red_v46": 1.948515625, "red_v72": -1.1675000000000002, "red_v48": 0.45654687500000013, "red_v54": -0.564, "red_v80": 0.4856932378161707, "red_v77": 0.5016932378161703, "red_v33": -0.9134999999999762, "red_v85": -1.259, "red_v67": -2.003, "red_v2": -2.0069999999999997, "red_v66": 0.993193237816171, "red_v7": -2.008, "red_v56": 0.50269323781617, "red_v9": -1.0139999999999993, "red_v73": -0.8874218749999997, "red_v59": -1.002, "red_v64": 1.9095369878161705, "red_v11": -0.5079999999999999, "red_v29": 0.8989346144425968, "red_v20": 0.48169323781617, "red_v71": -2.002, "red_v39": 1.4616932378152068, "red_v32": 0.4879346144425921, "red_v53": 0.5056932378161697, "red_v68": -1.0059999999999998, "red_v23": -1.001, "red_v41": -1.0049999999999994, "red_v14": -1.0049999999999997}, "hist_stats": {"episode_reward": [2.2251868963602313, 2.456677612816171, 1.466974487816171, 2.467677612816171, 1.9545994878161717, 1.9874467835440552, 2.484337408544055, 4.495213905589113, 0.9027869878161723, 4.334761475632348, 2.4841151128161703, 1.9581619878161707, 1.6292401128161873, 3.978667725632341, 0.4199375000000001, 1.9714901128161715, 1.4750838628161707, 1.165503125, 1.4750908644425926, 1.48963073781617, 2.4069276128161743, 1.9372088628161714, -1.6209999999999338, 2.489036292772942, -5.275447387183827, 0.9422401128161715, 2.4764119878161703, 2.9880362927729416, 2.490146362815204, 2.4861499085440553, 2.8862088628161726, 2.4822244878161706, 3.9147614756323446, 2.4552401128161714, 3.9715271006323407, 3.3203807378161714, 0.8286463628161709, 1.9833026128161697, 2.4745994878161706, 1.33315625, 1.6660968750000003, 2.8718148550000007, 2.449536987816172, 3.9101833506323445, 2.4837088628161705, 1.462490112816171, 2.4198807378161726, 2.443130737816171, 2.48441198781617, 3.9861833506323405, 0.6931151128161999, 2.490446783544055, 2.48452136281617, 2.4301463628161715, 1.4542401128161717, 0.73284948781617, -2.1849999999999064, 1.4613807378161705, 1.9751932378161707, 2.4696463628161696, 2.4723026128161707, 1.4358807378161722, 1.8666463628161718, 2.476981489442592, 2.4921456677729417, 0.641161987816171, 2.464677612816171, 2.485853033544055, 1.9614588628161707, 1.316203125, 0.43615625, 1.492036292772942, 2.4457244878161717, 2.3882302256323444, 2.987036292772942, 1.48833386281617, 3.167299727258783, 2.47330261281617, 2.1549875000000003, 3.946339600632342, 1.3823304800000003, 1.9476151128161718, 3.953855225632342, 4.3491833506313835, 1.97389636281617, 3.979565352257796, 1.9674901128161706, 1.4566776128161707, 3.9898864756323404, 2.456865112816171, 1.3821619878161744, 2.3759242300000003, 4.427995850632341, 2.48833386281617, 2.49092761281617, 2.458021362816171, 2.456865112816171, 2.3421586050000003, 2.4813026128161697, 1.940880737816171], "episode_lengths": [291, 37, 38, 37, 30, 18, 21, 23, 98, 136, 25, 42, 305, 38, 20, 33, 35, 15, 14, 20, 85, 59, 1280, 18, 781, 49, 26, 18, 15, 17, 59, 22, 72, 49, 51, 36, 239, 29, 30, 14, 17, 22, 50, 97, 27, 33, 68, 52, 26, 33, 601, 18, 23, 79, 49, 334, 1280, 36, 32, 47, 29, 68, 111, 17, 15, 362, 37, 16, 43, 31, 14, 18, 54, 114, 18, 19, 201, 29, 20, 47, 17, 57, 42, 97, 31, 20, 33, 37, 32, 41, 106, 19, 93, 19, 21, 55, 41, 40, 29, 68], "policy_red_v16_reward": [1.7234936585440548], "policy_red_v1_reward": [-1.0209999999999992], "policy_blue_reward": [-2.0119999999999996, -1.0069999999999992, -2.012999999999999, -1.006, -2.0109999999999992, -2.0039999999999996, -2.0039999999999996, -2.0039999999999996, -1.027999999999998, -1.0049999999999997, 4.277000000000003, -1.0139999999999991, -0.005, -1.0079999999999998, -1.0079999999999998, -1.0099999999999998, -1.0159999999999998, -1.0089999999999992, -2.001, -0.007, -1.0109999999999988, -1.005, -1.0159999999999991, -1.021999999999999, -1.0049999999999997, -1.166, -1.0039999999999998, -1.0059999999999996, -2.0149999999999997, -2.01, -1.0059999999999998, -2.0199999999999982, -0.5289999999999985, -1.002, -1.005, -1.6059999999999999, -1.0099999999999991, -1.007, -2.0119999999999996, 1.9702031249999998, -2.004, -1.0149999999999983, -2.005, -1.0089999999999997, -2.0159999999999982, -2.01, -2.0109999999999992, -2.0109999999999992, -1.0119999999999996, -2.038999999999997, -1.0039999999999996, -1.0129999999999997, -1.0099999999999996, -2.01], "policy_red_v63_reward": [-2.006], "policy_red_v8_reward": [-1.005], "policy_red_v44_reward": [1.5066925427729416], "policy_red_v6_reward": [0.4120937500000005, 0.4866932378161702], "policy_red_v57_reward": [1.460693237816173], "policy_red_v74_reward": [-2.1069999999999887], "policy_red_v78_reward": [0.5026932378161701], "policy_red_v55_reward": [-2.0069999999999997], "policy_red_v5_reward": [-2.013], "policy_red_v69_reward": [-2.0039999999999996], "policy_red_v46_reward": [1.948515625], "policy_red_v72_reward": [-0.3330000000000007, -2.002], "policy_red_v48_reward": [0.45654687500000013], "policy_red_v54_reward": [-0.564], "policy_red_v80_reward": [0.4856932378161707], "policy_red_v77_reward": [0.5016932378161703], "policy_red_v33_reward": [-0.1559999999999997, -1.6709999999999527], "policy_red_v85_reward": [-1.509, -1.0089999999999997], "policy_red_v67_reward": [-2.003], "policy_red_v2_reward": [-2.0069999999999997], "policy_red_v66_reward": [0.494693237816171, 1.491693237816171], "policy_red_v7_reward": [-2.008], "policy_red_v56_reward": [0.50269323781617], "policy_red_v9_reward": [-1.0139999999999993], "policy_red_v73_reward": [-2.0079999999999996, 0.23315625000000018], "policy_red_v59_reward": [-1.002], "policy_red_v64_reward": [1.9095369878161705], "policy_red_v11_reward": [-0.5079999999999999], "policy_red_v29_reward": [0.8989346144425968], "policy_red_v20_reward": [0.48169323781617], "policy_red_v71_reward": [-2.002], "policy_red_v39_reward": [1.4616932378152068], "policy_red_v32_reward": [0.4879346144425921], "policy_red_v53_reward": [0.5056932378161697], "policy_red_v68_reward": [-1.0059999999999998], "policy_red_v23_reward": [-1.001], "policy_red_v41_reward": [-1.0049999999999994], "policy_red_v14_reward": [-1.0049999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8258312611143132, "mean_inference_ms": 7.683239041844821, "mean_action_processing_ms": 0.2937683831491483, "mean_env_wait_ms": 0.39621941198237715, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0977931022644043, "StateBufferConnector_ms": 0.004097580909729004, "ViewRequirementAgentConnector_ms": 0.11307501792907715}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1000000, "num_agent_steps_trained": 1000000, "num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.91587602486845, "num_env_steps_trained_throughput_per_sec": 199.91587602486845, "timesteps_total": 500000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1000000, "timers": {"training_iteration_time_ms": 20026.722, "sample_time_ms": 1248.878, "learn_time_ms": 18691.618, "learn_throughput": 214.0, "synch_weights_time_ms": 82.824}, "counters": {"num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_agent_steps_sampled": 1000000, "num_agent_steps_trained": 1000000}, "done": false, "episodes_total": 3049, "training_iteration": 125, "trial_id": "a9680_00000", "date": "2023-09-24_03-23-30", "timestamp": 1695540210, "time_this_iter_s": 20.019502878189087, "time_total_s": 2494.241984128952, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dc7da50>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1db51b40>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1db51bd0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2494.241984128952, "iterations_since_restore": 125, "perf": {"cpu_util_percent": 5.425000000000001, "ram_util_percent": 27.76944444444444}, "win_rate": 0.78, "league_size": 94}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5075384327520926, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.05182468290440738, "policy_loss": -0.04442732340539805, "vf_loss": 0.18226877062309843, "vf_explained_var": 0.8480510538443923, "kl": 0.01425151474228382, "entropy": 1.2955597242961328, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 120480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "sampler_results": {"episode_reward_max": 4.466558350632342, "episode_reward_min": -2.626999999999988, "episode_reward_mean": 2.2559492670007812, "episode_len_mean": 63.97, "episode_media": {}, "episodes_this_iter": 66, "policy_reward_min": {"blue": -2.038999999999997, "red": -3.0130000000000083, "red_v72": -2.002, "red_v64": 1.9095369878161705, "red_v11": -0.5079999999999999, "red_v29": 0.17405000000000015, "red_v85": -1.0089999999999997, "red_v20": 0.48169323781617, "red_v71": -2.002, "red_v6": 0.4866932378161702, "red_v39": 1.4616932378152068, "red_v32": 0.4879346144425921, "red_v53": 0.5056932378161697, "red_v68": -1.0059999999999998, "red_v66": -1.0119999999999991, "red_v23": -1.001, "red_v41": -1.0049999999999994, "red_v14": -1.0049999999999997, "red_v31": 0.7769999999999999, "red_v34": -1.0339999999999971, "red_v4": -2.005, "red_v1": -2.013, "red_v81": -1.512, "red_v74": -2.0039999999999996, "red_v79": -2.0029999999999997, "red_v8": -2.0069999999999997, "red_v28": -0.1459999999999999, "red_v15": -2.0079999999999996, "red_v22": -2.008, "red_v13": 0.49969323781520375, "red_v21": -0.5619999999999994, "red_v82": 1.985453125, "red_v26": -0.16799999999999993, "red_v36": 0.485, "red_v62": -1.0169999999999997, "red_v80": -2.021999999999998, "red_v88": -0.5229999999999999, "red_v44": 0.5486932378161696}, "policy_reward_max": {"blue": 1.988453125, "red": 3.998146362815204, "red_v72": -2.002, "red_v64": 1.9095369878161705, "red_v11": -0.5079999999999999, "red_v29": 0.8989346144425968, "red_v85": -1.0089999999999997, "red_v20": 0.48169323781617, "red_v71": -2.002, "red_v6": 0.4866932378161702, "red_v39": 1.5006932378161701, "red_v32": 2.9532843750000057, "red_v53": 0.5056932378161697, "red_v68": -1.0059999999999998, "red_v66": 1.491693237816171, "red_v23": -1.001, "red_v41": -1.0049999999999994, "red_v14": -1.0049999999999997, "red_v31": 0.7769999999999999, "red_v34": -1.0339999999999971, "red_v4": -2.005, "red_v1": -1.0079999999999998, "red_v81": -1.512, "red_v74": -2.0039999999999996, "red_v79": -1.0169999999999997, "red_v8": -0.8389499999999999, "red_v28": -0.1459999999999999, "red_v15": -2.0079999999999996, "red_v22": -2.008, "red_v13": 0.49969323781520375, "red_v21": -0.5619999999999994, "red_v82": 1.985453125, "red_v26": -0.16799999999999993, "red_v36": 0.485, "red_v62": -1.0169999999999997, "red_v80": -2.021999999999998, "red_v88": -0.5229999999999999, "red_v44": 0.5486932378161696}, "policy_reward_mean": {"blue": -1.2563989955357135, "red": 3.13251787593033, "red_v72": -2.002, "red_v64": 1.9095369878161705, "red_v11": -0.5079999999999999, "red_v29": 0.5242259507529224, "red_v85": -1.0089999999999997, "red_v20": 0.48169323781617, "red_v71": -2.002, "red_v6": 0.4866932378161702, "red_v39": 1.4811932378156885, "red_v32": 1.7206094947212989, "red_v53": 0.5056932378161697, "red_v68": -1.0059999999999998, "red_v66": 0.2398466189080859, "red_v23": -1.001, "red_v41": -1.0049999999999994, "red_v14": -1.0049999999999997, "red_v31": 0.7769999999999999, "red_v34": -1.0339999999999971, "red_v4": -2.005, "red_v1": -1.5105, "red_v81": -1.512, "red_v74": -2.0039999999999996, "red_v79": -1.5099999999999998, "red_v8": -1.4229749999999997, "red_v28": -0.1459999999999999, "red_v15": -2.0079999999999996, "red_v22": -2.008, "red_v13": 0.49969323781520375, "red_v21": -0.5619999999999994, "red_v82": 1.985453125, "red_v26": -0.16799999999999993, "red_v36": 0.485, "red_v62": -1.0169999999999997, "red_v80": -2.021999999999998, "red_v88": -0.5229999999999999, "red_v44": 0.5486932378161696}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.464677612816171, 2.485853033544055, 1.9614588628161707, 1.316203125, 0.43615625, 1.492036292772942, 2.4457244878161717, 2.3882302256323444, 2.987036292772942, 1.48833386281617, 3.167299727258783, 2.47330261281617, 2.1549875000000003, 3.946339600632342, 1.3823304800000003, 1.9476151128161718, 3.953855225632342, 4.3491833506313835, 1.97389636281617, 3.979565352257796, 1.9674901128161706, 1.4566776128161707, 3.9898864756323404, 2.456865112816171, 1.3821619878161744, 2.3759242300000003, 4.427995850632341, 2.48833386281617, 2.49092761281617, 2.458021362816171, 2.456865112816171, 2.3421586050000003, 2.4813026128161697, 1.940880737816171, 3.6605994878161843, 1.488036987815204, 2.3126619878161745, 2.379033605, 3.975152100632341, 1.48270886281617, 1.4719814894425927, 2.4873338628152037, 0.928333862816171, 2.871627355, 1.16720625, 1.48781823781617, 4.466558350632342, 2.592790112816173, 2.4765994878161703, 1.3587836050000004, 1.3851429800000004, 3.351442542772942, 3.380849487816172, -2.626999999999988, 0.9364531250000001, 2.47711511281617, 2.4718721144425926, 2.4757088628161705, 1.9859276128161698, 1.1600968750000002, 2.4777088628161703, 1.491036987815204, 2.4872237927729417, 1.9520213628161713, 2.48452136281617, 2.4839276128161702, 2.4777088628161703, 1.3848461050000003, 2.4659780335440553, 1.9649814894425928, 1.4701619878161705, 1.9599744878161716, 2.4675994878161713, 1.47941198781617, 1.3159375, 1.9822244878161699, 2.4773026128161706, 3.55538048, 1.994146362815204, 1.964349487816171, 3.986698975631374, 1.48230261281617, 2.92130261281617, 2.4711186585440545, 1.334453125, 2.4890362927729415, 2.472193237816171, 2.968193237816171, 3.3160838628161713, 2.368974487816171, 0.42620023944262175, 1.9836307378152038, 2.907977612816184, 2.9871499085440547, 2.459384283544056, 1.8523651128161762, 2.4660838628161708, 1.9114432378161732, 1.29109375, 2.0483864756323906], "episode_lengths": [37, 16, 43, 31, 14, 18, 54, 114, 18, 19, 201, 29, 20, 47, 17, 57, 42, 97, 31, 20, 33, 37, 32, 41, 106, 19, 93, 19, 21, 55, 41, 40, 29, 68, 94, 18, 202, 16, 43, 27, 17, 19, 83, 18, 14, 24, 41, 81, 30, 32, 13, 16, 78, 448, 15, 25, 20, 27, 21, 17, 27, 18, 22, 55, 23, 21, 27, 12, 40, 17, 42, 38, 30, 26, 20, 22, 29, 17, 15, 46, 28, 29, 29, 27, 15, 18, 32, 32, 35, 166, 587, 20, 213, 17, 38, 137, 35, 80, 34, 1280], "policy_blue_reward": [-1.0099999999999991, -1.007, -2.0119999999999996, 1.9702031249999998, -2.004, -1.0149999999999983, -2.005, -1.0089999999999997, -2.0159999999999982, -2.01, -2.0109999999999992, -2.0109999999999992, -1.0119999999999996, -2.038999999999997, -1.0039999999999996, -1.0129999999999997, -1.0099999999999996, -2.01, -2.0069999999999997, -1.0069999999999997, -2.0059999999999993, -0.008, -1.0059999999999998, -2.0059999999999993, -2.003, 0.431, 0.386000000000003, 1.988453125, -1.0079999999999996, -1.0039999999999998, -2.006, -1.0079999999999993, -2.005, -1.0049999999999997, -2.009999999999999, -1.0059999999999996, -1.0069999999999995, -1.0089999999999997, -2.005, -1.0109999999999992, -2.0069999999999997, -2.0109999999999992, -2.005, -1.0109999999999992, -2.0039999999999996, -2.007999999999999, -2.0060000000000002, -1.0059999999999993, -1.0029999999999997, -1.0099999999999998, -0.513, -1.183, -2.005, -0.006, -1.012999999999999, -2.0179999999999985], "policy_red_v72_reward": [-2.002], "policy_red_v64_reward": [1.9095369878161705], "policy_red_v11_reward": [-0.5079999999999999], "policy_red_v29_reward": [0.8989346144425968, 0.49969323781617014, 0.17405000000000015], "policy_red_v85_reward": [-1.0089999999999997], "policy_red_v20_reward": [0.48169323781617], "policy_red_v71_reward": [-2.002], "policy_red_v6_reward": [0.4866932378161702], "policy_red_v39_reward": [1.4616932378152068, 1.5006932378161701], "policy_red_v32_reward": [0.4879346144425921, 2.9532843750000057], "policy_red_v53_reward": [0.5056932378161697], "policy_red_v68_reward": [-1.0059999999999998], "policy_red_v66_reward": [1.491693237816171, -1.0119999999999991], "policy_red_v23_reward": [-1.001], "policy_red_v41_reward": [-1.0049999999999994], "policy_red_v14_reward": [-1.0049999999999997], "policy_red_v31_reward": [0.7769999999999999], "policy_red_v34_reward": [-1.0339999999999971], "policy_red_v4_reward": [-2.005], "policy_red_v1_reward": [-1.0079999999999998, -2.013], "policy_red_v81_reward": [-1.512], "policy_red_v74_reward": [-2.0039999999999996], "policy_red_v79_reward": [-2.0029999999999997, -1.0169999999999997], "policy_red_v8_reward": [-0.8389499999999999, -2.0069999999999997], "policy_red_v28_reward": [-0.1459999999999999], "policy_red_v15_reward": [-2.0079999999999996], "policy_red_v22_reward": [-2.008], "policy_red_v13_reward": [0.49969323781520375], "policy_red_v21_reward": [-0.5619999999999994], "policy_red_v82_reward": [1.985453125], "policy_red_v26_reward": [-0.16799999999999993], "policy_red_v36_reward": [0.485], "policy_red_v62_reward": [-1.0169999999999997], "policy_red_v80_reward": [-2.021999999999998], "policy_red_v88_reward": [-0.5229999999999999], "policy_red_v44_reward": [0.5486932378161696]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8275699061824087, "mean_inference_ms": 7.696142381130533, "mean_action_processing_ms": 0.29373950080417666, "mean_env_wait_ms": 0.39715426307169194, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09990966320037842, "StateBufferConnector_ms": 0.004212856292724609, "ViewRequirementAgentConnector_ms": 0.11494779586791992}}, "episode_reward_max": 4.466558350632342, "episode_reward_min": -2.626999999999988, "episode_reward_mean": 2.2559492670007812, "episode_len_mean": 63.97, "episodes_this_iter": 66, "policy_reward_min": {"blue": -2.038999999999997, "red": -3.0130000000000083, "red_v72": -2.002, "red_v64": 1.9095369878161705, "red_v11": -0.5079999999999999, "red_v29": 0.17405000000000015, "red_v85": -1.0089999999999997, "red_v20": 0.48169323781617, "red_v71": -2.002, "red_v6": 0.4866932378161702, "red_v39": 1.4616932378152068, "red_v32": 0.4879346144425921, "red_v53": 0.5056932378161697, "red_v68": -1.0059999999999998, "red_v66": -1.0119999999999991, "red_v23": -1.001, "red_v41": -1.0049999999999994, "red_v14": -1.0049999999999997, "red_v31": 0.7769999999999999, "red_v34": -1.0339999999999971, "red_v4": -2.005, "red_v1": -2.013, "red_v81": -1.512, "red_v74": -2.0039999999999996, "red_v79": -2.0029999999999997, "red_v8": -2.0069999999999997, "red_v28": -0.1459999999999999, "red_v15": -2.0079999999999996, "red_v22": -2.008, "red_v13": 0.49969323781520375, "red_v21": -0.5619999999999994, "red_v82": 1.985453125, "red_v26": -0.16799999999999993, "red_v36": 0.485, "red_v62": -1.0169999999999997, "red_v80": -2.021999999999998, "red_v88": -0.5229999999999999, "red_v44": 0.5486932378161696}, "policy_reward_max": {"blue": 1.988453125, "red": 3.998146362815204, "red_v72": -2.002, "red_v64": 1.9095369878161705, "red_v11": -0.5079999999999999, "red_v29": 0.8989346144425968, "red_v85": -1.0089999999999997, "red_v20": 0.48169323781617, "red_v71": -2.002, "red_v6": 0.4866932378161702, "red_v39": 1.5006932378161701, "red_v32": 2.9532843750000057, "red_v53": 0.5056932378161697, "red_v68": -1.0059999999999998, "red_v66": 1.491693237816171, "red_v23": -1.001, "red_v41": -1.0049999999999994, "red_v14": -1.0049999999999997, "red_v31": 0.7769999999999999, "red_v34": -1.0339999999999971, "red_v4": -2.005, "red_v1": -1.0079999999999998, "red_v81": -1.512, "red_v74": -2.0039999999999996, "red_v79": -1.0169999999999997, "red_v8": -0.8389499999999999, "red_v28": -0.1459999999999999, "red_v15": -2.0079999999999996, "red_v22": -2.008, "red_v13": 0.49969323781520375, "red_v21": -0.5619999999999994, "red_v82": 1.985453125, "red_v26": -0.16799999999999993, "red_v36": 0.485, "red_v62": -1.0169999999999997, "red_v80": -2.021999999999998, "red_v88": -0.5229999999999999, "red_v44": 0.5486932378161696}, "policy_reward_mean": {"blue": -1.2563989955357135, "red": 3.13251787593033, "red_v72": -2.002, "red_v64": 1.9095369878161705, "red_v11": -0.5079999999999999, "red_v29": 0.5242259507529224, "red_v85": -1.0089999999999997, "red_v20": 0.48169323781617, "red_v71": -2.002, "red_v6": 0.4866932378161702, "red_v39": 1.4811932378156885, "red_v32": 1.7206094947212989, "red_v53": 0.5056932378161697, "red_v68": -1.0059999999999998, "red_v66": 0.2398466189080859, "red_v23": -1.001, "red_v41": -1.0049999999999994, "red_v14": -1.0049999999999997, "red_v31": 0.7769999999999999, "red_v34": -1.0339999999999971, "red_v4": -2.005, "red_v1": -1.5105, "red_v81": -1.512, "red_v74": -2.0039999999999996, "red_v79": -1.5099999999999998, "red_v8": -1.4229749999999997, "red_v28": -0.1459999999999999, "red_v15": -2.0079999999999996, "red_v22": -2.008, "red_v13": 0.49969323781520375, "red_v21": -0.5619999999999994, "red_v82": 1.985453125, "red_v26": -0.16799999999999993, "red_v36": 0.485, "red_v62": -1.0169999999999997, "red_v80": -2.021999999999998, "red_v88": -0.5229999999999999, "red_v44": 0.5486932378161696}, "hist_stats": {"episode_reward": [2.464677612816171, 2.485853033544055, 1.9614588628161707, 1.316203125, 0.43615625, 1.492036292772942, 2.4457244878161717, 2.3882302256323444, 2.987036292772942, 1.48833386281617, 3.167299727258783, 2.47330261281617, 2.1549875000000003, 3.946339600632342, 1.3823304800000003, 1.9476151128161718, 3.953855225632342, 4.3491833506313835, 1.97389636281617, 3.979565352257796, 1.9674901128161706, 1.4566776128161707, 3.9898864756323404, 2.456865112816171, 1.3821619878161744, 2.3759242300000003, 4.427995850632341, 2.48833386281617, 2.49092761281617, 2.458021362816171, 2.456865112816171, 2.3421586050000003, 2.4813026128161697, 1.940880737816171, 3.6605994878161843, 1.488036987815204, 2.3126619878161745, 2.379033605, 3.975152100632341, 1.48270886281617, 1.4719814894425927, 2.4873338628152037, 0.928333862816171, 2.871627355, 1.16720625, 1.48781823781617, 4.466558350632342, 2.592790112816173, 2.4765994878161703, 1.3587836050000004, 1.3851429800000004, 3.351442542772942, 3.380849487816172, -2.626999999999988, 0.9364531250000001, 2.47711511281617, 2.4718721144425926, 2.4757088628161705, 1.9859276128161698, 1.1600968750000002, 2.4777088628161703, 1.491036987815204, 2.4872237927729417, 1.9520213628161713, 2.48452136281617, 2.4839276128161702, 2.4777088628161703, 1.3848461050000003, 2.4659780335440553, 1.9649814894425928, 1.4701619878161705, 1.9599744878161716, 2.4675994878161713, 1.47941198781617, 1.3159375, 1.9822244878161699, 2.4773026128161706, 3.55538048, 1.994146362815204, 1.964349487816171, 3.986698975631374, 1.48230261281617, 2.92130261281617, 2.4711186585440545, 1.334453125, 2.4890362927729415, 2.472193237816171, 2.968193237816171, 3.3160838628161713, 2.368974487816171, 0.42620023944262175, 1.9836307378152038, 2.907977612816184, 2.9871499085440547, 2.459384283544056, 1.8523651128161762, 2.4660838628161708, 1.9114432378161732, 1.29109375, 2.0483864756323906], "episode_lengths": [37, 16, 43, 31, 14, 18, 54, 114, 18, 19, 201, 29, 20, 47, 17, 57, 42, 97, 31, 20, 33, 37, 32, 41, 106, 19, 93, 19, 21, 55, 41, 40, 29, 68, 94, 18, 202, 16, 43, 27, 17, 19, 83, 18, 14, 24, 41, 81, 30, 32, 13, 16, 78, 448, 15, 25, 20, 27, 21, 17, 27, 18, 22, 55, 23, 21, 27, 12, 40, 17, 42, 38, 30, 26, 20, 22, 29, 17, 15, 46, 28, 29, 29, 27, 15, 18, 32, 32, 35, 166, 587, 20, 213, 17, 38, 137, 35, 80, 34, 1280], "policy_blue_reward": [-1.0099999999999991, -1.007, -2.0119999999999996, 1.9702031249999998, -2.004, -1.0149999999999983, -2.005, -1.0089999999999997, -2.0159999999999982, -2.01, -2.0109999999999992, -2.0109999999999992, -1.0119999999999996, -2.038999999999997, -1.0039999999999996, -1.0129999999999997, -1.0099999999999996, -2.01, -2.0069999999999997, -1.0069999999999997, -2.0059999999999993, -0.008, -1.0059999999999998, -2.0059999999999993, -2.003, 0.431, 0.386000000000003, 1.988453125, -1.0079999999999996, -1.0039999999999998, -2.006, -1.0079999999999993, -2.005, -1.0049999999999997, -2.009999999999999, -1.0059999999999996, -1.0069999999999995, -1.0089999999999997, -2.005, -1.0109999999999992, -2.0069999999999997, -2.0109999999999992, -2.005, -1.0109999999999992, -2.0039999999999996, -2.007999999999999, -2.0060000000000002, -1.0059999999999993, -1.0029999999999997, -1.0099999999999998, -0.513, -1.183, -2.005, -0.006, -1.012999999999999, -2.0179999999999985], "policy_red_v72_reward": [-2.002], "policy_red_v64_reward": [1.9095369878161705], "policy_red_v11_reward": [-0.5079999999999999], "policy_red_v29_reward": [0.8989346144425968, 0.49969323781617014, 0.17405000000000015], "policy_red_v85_reward": [-1.0089999999999997], "policy_red_v20_reward": [0.48169323781617], "policy_red_v71_reward": [-2.002], "policy_red_v6_reward": [0.4866932378161702], "policy_red_v39_reward": [1.4616932378152068, 1.5006932378161701], "policy_red_v32_reward": [0.4879346144425921, 2.9532843750000057], "policy_red_v53_reward": [0.5056932378161697], "policy_red_v68_reward": [-1.0059999999999998], "policy_red_v66_reward": [1.491693237816171, -1.0119999999999991], "policy_red_v23_reward": [-1.001], "policy_red_v41_reward": [-1.0049999999999994], "policy_red_v14_reward": [-1.0049999999999997], "policy_red_v31_reward": [0.7769999999999999], "policy_red_v34_reward": [-1.0339999999999971], "policy_red_v4_reward": [-2.005], "policy_red_v1_reward": [-1.0079999999999998, -2.013], "policy_red_v81_reward": [-1.512], "policy_red_v74_reward": [-2.0039999999999996], "policy_red_v79_reward": [-2.0029999999999997, -1.0169999999999997], "policy_red_v8_reward": [-0.8389499999999999, -2.0069999999999997], "policy_red_v28_reward": [-0.1459999999999999], "policy_red_v15_reward": [-2.0079999999999996], "policy_red_v22_reward": [-2.008], "policy_red_v13_reward": [0.49969323781520375], "policy_red_v21_reward": [-0.5619999999999994], "policy_red_v82_reward": [1.985453125], "policy_red_v26_reward": [-0.16799999999999993], "policy_red_v36_reward": [0.485], "policy_red_v62_reward": [-1.0169999999999997], "policy_red_v80_reward": [-2.021999999999998], "policy_red_v88_reward": [-0.5229999999999999], "policy_red_v44_reward": [0.5486932378161696]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8275699061824087, "mean_inference_ms": 7.696142381130533, "mean_action_processing_ms": 0.29373950080417666, "mean_env_wait_ms": 0.39715426307169194, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09990966320037842, "StateBufferConnector_ms": 0.004212856292724609, "ViewRequirementAgentConnector_ms": 0.11494779586791992}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.1392693654452, "num_env_steps_trained_throughput_per_sec": 199.1392693654452, "timesteps_total": 504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 19985.572, "sample_time_ms": 1236.561, "learn_time_ms": 18662.868, "learn_throughput": 214.329, "synch_weights_time_ms": 82.502}, "counters": {"num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "episodes_total": 3115, "training_iteration": 126, "trial_id": "a9680_00000", "date": "2023-09-24_03-23-55", "timestamp": 1695540235, "time_this_iter_s": 20.09666347503662, "time_total_s": 2514.3386476039886, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dc7dab0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1db50310>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1db50040>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2514.3386476039886, "iterations_since_restore": 126, "perf": {"cpu_util_percent": 5.497142857142857, "ram_util_percent": 27.88285714285714}, "win_rate": 0.79, "league_size": 95}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5082056641578676, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.047716446891233014, "policy_loss": -0.04240713733209608, "vf_loss": 0.16891136397219572, "vf_explained_var": 0.8474078809842467, "kl": 0.01524202250333805, "entropy": 1.1910074230283498, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 121440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_agent_steps_sampled": 1016000, "num_agent_steps_trained": 1016000}, "sampler_results": {"episode_reward_max": 4.47644897563234, "episode_reward_min": 0.4181250000000001, "episode_reward_mean": 2.2819011009559715, "episode_len_mean": 75.8, "episode_media": {}, "episodes_this_iter": 71, "policy_reward_min": {"blue": -2.0179999999999985, "red": -1.0670000000000002, "red_v79": -1.0169999999999997, "red_v1": -2.013, "red_v22": -2.008, "red_v29": 0.17405000000000015, "red_v13": 0.49969323781520375, "red_v21": -0.5619999999999994, "red_v82": 1.985453125, "red_v26": -0.16799999999999993, "red_v36": -2.008, "red_v32": 2.9532843750000057, "red_v62": -1.0169999999999997, "red_v80": -2.021999999999998, "red_v88": -0.5229999999999999, "red_v44": 0.5486932378161696, "red_v72": 0.4736932378161701, "red_v5": -1.0099999999999993, "red_v10": -1.0069999999999997, "red_v43": 0.5036932378161697, "red_v20": -2.0109999999999997, "red_v7": -1.528, "red_v8": -1.0099999999999996, "red_v2": -1.004, "red_v81": -1.0039999999999998, "red_v33": 0.48593461444259234, "red_v48": 0.18105000000000038, "red_v11": -1.0269999999999972, "red_v61": -0.5079999999999999, "red_v40": -1.0139999999999993, "red_v60": -1.0149999999999997, "red_v19": -2.0839999999999943, "red_v37": 0.50169323781617, "red_v74": -2.009}, "policy_reward_max": {"blue": -0.006, "red": 3.998146362815204, "red_v79": -1.0169999999999997, "red_v1": -2.013, "red_v22": -2.008, "red_v29": 0.17405000000000015, "red_v13": 0.49969323781520375, "red_v21": -0.5619999999999994, "red_v82": 1.985453125, "red_v26": -0.16799999999999993, "red_v36": 0.485, "red_v32": 2.9532843750000057, "red_v62": -1.0169999999999997, "red_v80": 1.5016932378161698, "red_v88": -0.5229999999999999, "red_v44": 0.5486932378161696, "red_v72": 0.4736932378161701, "red_v5": 1.957390625, "red_v10": 1.4699346144425933, "red_v43": 0.5036932378161697, "red_v20": -2.0109999999999997, "red_v7": -1.0139999999999998, "red_v8": -1.0099999999999996, "red_v2": -1.004, "red_v81": -1.0039999999999998, "red_v33": 0.48593461444259234, "red_v48": 1.2676463628161718, "red_v11": -1.0189999999999995, "red_v61": -0.5079999999999999, "red_v40": -1.0139999999999993, "red_v60": -1.0149999999999997, "red_v19": -2.0839999999999943, "red_v37": 0.50169323781617, "red_v74": -2.009}, "policy_reward_mean": {"blue": -1.2185344827586204, "red": 3.1848920695199956, "red_v79": -1.0169999999999997, "red_v1": -2.013, "red_v22": -2.008, "red_v29": 0.17405000000000015, "red_v13": 0.49969323781520375, "red_v21": -0.5619999999999994, "red_v82": 1.985453125, "red_v26": -0.16799999999999993, "red_v36": -0.7615000000000001, "red_v32": 2.9532843750000057, "red_v62": -1.0169999999999997, "red_v80": -1.1062613524367655, "red_v88": -0.5229999999999999, "red_v44": 0.5486932378161696, "red_v72": 0.4736932378161701, "red_v5": 0.4736953125000003, "red_v10": 0.23146730722129683, "red_v43": 0.5036932378161697, "red_v20": -2.0109999999999997, "red_v7": -1.271, "red_v8": -1.0099999999999996, "red_v2": -1.004, "red_v81": -1.0039999999999998, "red_v33": 0.48593461444259234, "red_v48": 0.7243481814080861, "red_v11": -1.0229999999999984, "red_v61": -0.5079999999999999, "red_v40": -1.0139999999999993, "red_v60": -1.0149999999999997, "red_v19": -2.0839999999999943, "red_v37": 0.50169323781617, "red_v74": -2.009}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.9599744878161716, 2.4675994878161713, 1.47941198781617, 1.3159375, 1.9822244878161699, 2.4773026128161706, 3.55538048, 1.994146362815204, 1.964349487816171, 3.986698975631374, 1.48230261281617, 2.92130261281617, 2.4711186585440545, 1.334453125, 2.4890362927729415, 2.472193237816171, 2.968193237816171, 3.3160838628161713, 2.368974487816171, 0.42620023944262175, 1.9836307378152038, 2.907977612816184, 2.9871499085440547, 2.459384283544056, 1.8523651128161762, 2.4660838628161708, 1.9114432378161732, 1.29109375, 2.0483864756323906, 3.8776521006323432, 2.47141198781617, 1.98792761281617, 4.47644897563234, 2.48941198781617, 2.4800057378161706, 2.4695994878161702, 2.9598651128161713, 1.9719744878161705, 2.3705179800000002, 2.47030261281617, 1.9738175427729419, 4.441205977258764, 2.4856307378161704, 3.9837771006323397, 1.4749814894425923, 1.1575031250000005, 1.9948487927729417, 2.4763026128161707, 2.4828182378161703, 0.4181250000000001, 2.4807088628161704, 2.4737869878161707, 2.962458862816171, 0.8146117300000029, 1.1642062499999999, 0.890390625, 1.65839375, 2.467599487816171, 2.4479119878161715, 2.4659744878161707, 2.4696776128161706, 1.8258281250000001, 2.4788182378161703, 2.4624588628161703, 2.4608963628161704, 3.975455977258763, 1.7703396006324041, 0.4726932378161699, 1.9492471144425925, 3.67438386281617, 2.4102244878161714, 2.427802612816173, 1.9678963628161703, 2.46530261281617, 2.474005737816171, 2.4625994878161706, 0.9881151128161698, 2.3857367300000005, 2.4738963628161703, 2.4793026128161704, 1.9770057378161705, 1.5967843750000004, 0.916234375, 2.461271362816171, 2.978223792772942, 2.4498651128161706, 2.47500573781617, 1.6843026128161813, 2.4673026128161704, 2.489446783544055, 3.98048022563234, 2.973083167772942, 2.470895667772942, 0.821234375, 1.9879276128161703, 2.48130261281617, 1.4753374085440554, 2.4857088628161703, 2.4831151128161704, 1.38033048], "episode_lengths": [38, 30, 26, 20, 22, 29, 17, 15, 46, 28, 29, 29, 27, 15, 18, 32, 32, 35, 166, 587, 20, 213, 17, 38, 137, 35, 80, 34, 1280, 139, 26, 21, 44, 26, 28, 30, 41, 38, 21, 29, 24, 39, 20, 35, 17, 15, 14, 29, 24, 24, 27, 34, 43, 55, 14, 35, 18, 30, 58, 38, 37, 23, 24, 43, 31, 23, 751, 1280, 28, 19, 86, 61, 31, 29, 28, 30, 25, 15, 31, 29, 28, 53, 21, 39, 22, 41, 28, 285, 29, 18, 34, 35, 31, 21, 21, 29, 21, 27, 25, 17], "policy_blue_reward": [-2.0109999999999992, -2.005, -1.0109999999999992, -2.0039999999999996, -2.007999999999999, -2.0060000000000002, -1.0059999999999993, -1.0029999999999997, -1.0099999999999998, -0.513, -1.183, -2.005, -0.006, -1.012999999999999, -2.0179999999999985, -1.0099999999999996, -2.005, -1.0079999999999996, -1.0119999999999996, -0.5169999999999999, -2.0069999999999997, -1.007, -2.0079999999999996, -2.002, -2.003, -1.508, -1.0079999999999996, -1.0079999999999993, -1.0099999999999991, -0.013000000000000005, -2.006, -1.0149999999999986, -1.0109999999999992, -1.0079999999999996, -1.011, -1.016, -2.0159999999999996, -1.007, -1.0119999999999996, -1.503, -1.0019999999999998, -1.0059999999999998, -1.0079999999999996, -2.0079999999999996, -0.521, -0.51, -0.008, -1.0169999999999992, -1.005, -1.0089999999999995, -1.0039999999999996, -0.008, -1.0089999999999995, -2.006, -1.0049999999999997, -1.0039999999999996, -1.0059999999999996, -2.006], "policy_red_v79_reward": [-1.0169999999999997], "policy_red_v1_reward": [-2.013], "policy_red_v22_reward": [-2.008], "policy_red_v29_reward": [0.17405000000000015], "policy_red_v13_reward": [0.49969323781520375], "policy_red_v21_reward": [-0.5619999999999994], "policy_red_v82_reward": [1.985453125], "policy_red_v26_reward": [-0.16799999999999993], "policy_red_v36_reward": [0.485, -2.008], "policy_red_v32_reward": [2.9532843750000057], "policy_red_v62_reward": [-1.0169999999999997], "policy_red_v80_reward": [-2.021999999999998, 1.5016932378161698, -1.001, -2.006, -2.0039999999999996], "policy_red_v88_reward": [-0.5229999999999999], "policy_red_v44_reward": [0.5486932378161696], "policy_red_v72_reward": [0.4736932378161701], "policy_red_v5_reward": [-1.0099999999999993, 1.957390625], "policy_red_v10_reward": [1.4699346144425933, -1.0069999999999997], "policy_red_v43_reward": [0.5036932378161697], "policy_red_v20_reward": [-2.0109999999999997], "policy_red_v7_reward": [-1.528, -1.0139999999999998], "policy_red_v8_reward": [-1.0099999999999996], "policy_red_v2_reward": [-1.004], "policy_red_v81_reward": [-1.0039999999999998], "policy_red_v33_reward": [0.48593461444259234], "policy_red_v48_reward": [1.2676463628161718, 0.18105000000000038], "policy_red_v11_reward": [-1.0269999999999972, -1.0189999999999995], "policy_red_v61_reward": [-0.5079999999999999], "policy_red_v40_reward": [-1.0139999999999993], "policy_red_v60_reward": [-1.0149999999999997], "policy_red_v19_reward": [-2.0839999999999943], "policy_red_v37_reward": [0.50169323781617], "policy_red_v74_reward": [-2.009]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8244609446833473, "mean_inference_ms": 7.669060973665519, "mean_action_processing_ms": 0.2924628332919088, "mean_env_wait_ms": 0.395249993470334, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09925973415374756, "StateBufferConnector_ms": 0.0041391849517822266, "ViewRequirementAgentConnector_ms": 0.11487078666687012}}, "episode_reward_max": 4.47644897563234, "episode_reward_min": 0.4181250000000001, "episode_reward_mean": 2.2819011009559715, "episode_len_mean": 75.8, "episodes_this_iter": 71, "policy_reward_min": {"blue": -2.0179999999999985, "red": -1.0670000000000002, "red_v79": -1.0169999999999997, "red_v1": -2.013, "red_v22": -2.008, "red_v29": 0.17405000000000015, "red_v13": 0.49969323781520375, "red_v21": -0.5619999999999994, "red_v82": 1.985453125, "red_v26": -0.16799999999999993, "red_v36": -2.008, "red_v32": 2.9532843750000057, "red_v62": -1.0169999999999997, "red_v80": -2.021999999999998, "red_v88": -0.5229999999999999, "red_v44": 0.5486932378161696, "red_v72": 0.4736932378161701, "red_v5": -1.0099999999999993, "red_v10": -1.0069999999999997, "red_v43": 0.5036932378161697, "red_v20": -2.0109999999999997, "red_v7": -1.528, "red_v8": -1.0099999999999996, "red_v2": -1.004, "red_v81": -1.0039999999999998, "red_v33": 0.48593461444259234, "red_v48": 0.18105000000000038, "red_v11": -1.0269999999999972, "red_v61": -0.5079999999999999, "red_v40": -1.0139999999999993, "red_v60": -1.0149999999999997, "red_v19": -2.0839999999999943, "red_v37": 0.50169323781617, "red_v74": -2.009}, "policy_reward_max": {"blue": -0.006, "red": 3.998146362815204, "red_v79": -1.0169999999999997, "red_v1": -2.013, "red_v22": -2.008, "red_v29": 0.17405000000000015, "red_v13": 0.49969323781520375, "red_v21": -0.5619999999999994, "red_v82": 1.985453125, "red_v26": -0.16799999999999993, "red_v36": 0.485, "red_v32": 2.9532843750000057, "red_v62": -1.0169999999999997, "red_v80": 1.5016932378161698, "red_v88": -0.5229999999999999, "red_v44": 0.5486932378161696, "red_v72": 0.4736932378161701, "red_v5": 1.957390625, "red_v10": 1.4699346144425933, "red_v43": 0.5036932378161697, "red_v20": -2.0109999999999997, "red_v7": -1.0139999999999998, "red_v8": -1.0099999999999996, "red_v2": -1.004, "red_v81": -1.0039999999999998, "red_v33": 0.48593461444259234, "red_v48": 1.2676463628161718, "red_v11": -1.0189999999999995, "red_v61": -0.5079999999999999, "red_v40": -1.0139999999999993, "red_v60": -1.0149999999999997, "red_v19": -2.0839999999999943, "red_v37": 0.50169323781617, "red_v74": -2.009}, "policy_reward_mean": {"blue": -1.2185344827586204, "red": 3.1848920695199956, "red_v79": -1.0169999999999997, "red_v1": -2.013, "red_v22": -2.008, "red_v29": 0.17405000000000015, "red_v13": 0.49969323781520375, "red_v21": -0.5619999999999994, "red_v82": 1.985453125, "red_v26": -0.16799999999999993, "red_v36": -0.7615000000000001, "red_v32": 2.9532843750000057, "red_v62": -1.0169999999999997, "red_v80": -1.1062613524367655, "red_v88": -0.5229999999999999, "red_v44": 0.5486932378161696, "red_v72": 0.4736932378161701, "red_v5": 0.4736953125000003, "red_v10": 0.23146730722129683, "red_v43": 0.5036932378161697, "red_v20": -2.0109999999999997, "red_v7": -1.271, "red_v8": -1.0099999999999996, "red_v2": -1.004, "red_v81": -1.0039999999999998, "red_v33": 0.48593461444259234, "red_v48": 0.7243481814080861, "red_v11": -1.0229999999999984, "red_v61": -0.5079999999999999, "red_v40": -1.0139999999999993, "red_v60": -1.0149999999999997, "red_v19": -2.0839999999999943, "red_v37": 0.50169323781617, "red_v74": -2.009}, "hist_stats": {"episode_reward": [1.9599744878161716, 2.4675994878161713, 1.47941198781617, 1.3159375, 1.9822244878161699, 2.4773026128161706, 3.55538048, 1.994146362815204, 1.964349487816171, 3.986698975631374, 1.48230261281617, 2.92130261281617, 2.4711186585440545, 1.334453125, 2.4890362927729415, 2.472193237816171, 2.968193237816171, 3.3160838628161713, 2.368974487816171, 0.42620023944262175, 1.9836307378152038, 2.907977612816184, 2.9871499085440547, 2.459384283544056, 1.8523651128161762, 2.4660838628161708, 1.9114432378161732, 1.29109375, 2.0483864756323906, 3.8776521006323432, 2.47141198781617, 1.98792761281617, 4.47644897563234, 2.48941198781617, 2.4800057378161706, 2.4695994878161702, 2.9598651128161713, 1.9719744878161705, 2.3705179800000002, 2.47030261281617, 1.9738175427729419, 4.441205977258764, 2.4856307378161704, 3.9837771006323397, 1.4749814894425923, 1.1575031250000005, 1.9948487927729417, 2.4763026128161707, 2.4828182378161703, 0.4181250000000001, 2.4807088628161704, 2.4737869878161707, 2.962458862816171, 0.8146117300000029, 1.1642062499999999, 0.890390625, 1.65839375, 2.467599487816171, 2.4479119878161715, 2.4659744878161707, 2.4696776128161706, 1.8258281250000001, 2.4788182378161703, 2.4624588628161703, 2.4608963628161704, 3.975455977258763, 1.7703396006324041, 0.4726932378161699, 1.9492471144425925, 3.67438386281617, 2.4102244878161714, 2.427802612816173, 1.9678963628161703, 2.46530261281617, 2.474005737816171, 2.4625994878161706, 0.9881151128161698, 2.3857367300000005, 2.4738963628161703, 2.4793026128161704, 1.9770057378161705, 1.5967843750000004, 0.916234375, 2.461271362816171, 2.978223792772942, 2.4498651128161706, 2.47500573781617, 1.6843026128161813, 2.4673026128161704, 2.489446783544055, 3.98048022563234, 2.973083167772942, 2.470895667772942, 0.821234375, 1.9879276128161703, 2.48130261281617, 1.4753374085440554, 2.4857088628161703, 2.4831151128161704, 1.38033048], "episode_lengths": [38, 30, 26, 20, 22, 29, 17, 15, 46, 28, 29, 29, 27, 15, 18, 32, 32, 35, 166, 587, 20, 213, 17, 38, 137, 35, 80, 34, 1280, 139, 26, 21, 44, 26, 28, 30, 41, 38, 21, 29, 24, 39, 20, 35, 17, 15, 14, 29, 24, 24, 27, 34, 43, 55, 14, 35, 18, 30, 58, 38, 37, 23, 24, 43, 31, 23, 751, 1280, 28, 19, 86, 61, 31, 29, 28, 30, 25, 15, 31, 29, 28, 53, 21, 39, 22, 41, 28, 285, 29, 18, 34, 35, 31, 21, 21, 29, 21, 27, 25, 17], "policy_blue_reward": [-2.0109999999999992, -2.005, -1.0109999999999992, -2.0039999999999996, -2.007999999999999, -2.0060000000000002, -1.0059999999999993, -1.0029999999999997, -1.0099999999999998, -0.513, -1.183, -2.005, -0.006, -1.012999999999999, -2.0179999999999985, -1.0099999999999996, -2.005, -1.0079999999999996, -1.0119999999999996, -0.5169999999999999, -2.0069999999999997, -1.007, -2.0079999999999996, -2.002, -2.003, -1.508, -1.0079999999999996, -1.0079999999999993, -1.0099999999999991, -0.013000000000000005, -2.006, -1.0149999999999986, -1.0109999999999992, -1.0079999999999996, -1.011, -1.016, -2.0159999999999996, -1.007, -1.0119999999999996, -1.503, -1.0019999999999998, -1.0059999999999998, -1.0079999999999996, -2.0079999999999996, -0.521, -0.51, -0.008, -1.0169999999999992, -1.005, -1.0089999999999995, -1.0039999999999996, -0.008, -1.0089999999999995, -2.006, -1.0049999999999997, -1.0039999999999996, -1.0059999999999996, -2.006], "policy_red_v79_reward": [-1.0169999999999997], "policy_red_v1_reward": [-2.013], "policy_red_v22_reward": [-2.008], "policy_red_v29_reward": [0.17405000000000015], "policy_red_v13_reward": [0.49969323781520375], "policy_red_v21_reward": [-0.5619999999999994], "policy_red_v82_reward": [1.985453125], "policy_red_v26_reward": [-0.16799999999999993], "policy_red_v36_reward": [0.485, -2.008], "policy_red_v32_reward": [2.9532843750000057], "policy_red_v62_reward": [-1.0169999999999997], "policy_red_v80_reward": [-2.021999999999998, 1.5016932378161698, -1.001, -2.006, -2.0039999999999996], "policy_red_v88_reward": [-0.5229999999999999], "policy_red_v44_reward": [0.5486932378161696], "policy_red_v72_reward": [0.4736932378161701], "policy_red_v5_reward": [-1.0099999999999993, 1.957390625], "policy_red_v10_reward": [1.4699346144425933, -1.0069999999999997], "policy_red_v43_reward": [0.5036932378161697], "policy_red_v20_reward": [-2.0109999999999997], "policy_red_v7_reward": [-1.528, -1.0139999999999998], "policy_red_v8_reward": [-1.0099999999999996], "policy_red_v2_reward": [-1.004], "policy_red_v81_reward": [-1.0039999999999998], "policy_red_v33_reward": [0.48593461444259234], "policy_red_v48_reward": [1.2676463628161718, 0.18105000000000038], "policy_red_v11_reward": [-1.0269999999999972, -1.0189999999999995], "policy_red_v61_reward": [-0.5079999999999999], "policy_red_v40_reward": [-1.0139999999999993], "policy_red_v60_reward": [-1.0149999999999997], "policy_red_v19_reward": [-2.0839999999999943], "policy_red_v37_reward": [0.50169323781617], "policy_red_v74_reward": [-2.009]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8244609446833473, "mean_inference_ms": 7.669060973665519, "mean_action_processing_ms": 0.2924628332919088, "mean_env_wait_ms": 0.395249993470334, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09925973415374756, "StateBufferConnector_ms": 0.0041391849517822266, "ViewRequirementAgentConnector_ms": 0.11487078666687012}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1016000, "num_agent_steps_trained": 1016000, "num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 197.7321823787831, "num_env_steps_trained_throughput_per_sec": 197.7321823787831, "timesteps_total": 508000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1016000, "timers": {"training_iteration_time_ms": 20058.895, "sample_time_ms": 1236.325, "learn_time_ms": 18736.563, "learn_throughput": 213.486, "synch_weights_time_ms": 82.346}, "counters": {"num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_agent_steps_sampled": 1016000, "num_agent_steps_trained": 1016000}, "done": false, "episodes_total": 3186, "training_iteration": 127, "trial_id": "a9680_00000", "date": "2023-09-24_03-24-21", "timestamp": 1695540261, "time_this_iter_s": 20.238876581192017, "time_total_s": 2534.5775241851807, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1db842e0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1db525f0>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1db52680>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2534.5775241851807, "iterations_since_restore": 127, "perf": {"cpu_util_percent": 5.447222222222223, "ram_util_percent": 27.980555555555558}, "win_rate": 0.85, "league_size": 96}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3771914208928746, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.035678338844930595, "policy_loss": -0.04601470459601842, "vf_loss": 0.1466911727290911, "vf_explained_var": 0.8361969656621416, "kl": 0.021349889634486734, "entropy": 1.2599921992669503, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 122400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "sampler_results": {"episode_reward_max": 4.484995850632339, "episode_reward_min": 0.4726932378161699, "episode_reward_mean": 2.4393666915021672, "episode_len_mean": 70.96, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"blue": -2.0159999999999996, "red": -1.0670000000000002, "red_v7": -2.0219999999999985, "red_v80": -2.0039999999999996, "red_v5": -1.0059999999999998, "red_v8": -1.0099999999999996, "red_v2": -1.004, "red_v81": -2.0069999999999997, "red_v33": -1.011999999999999, "red_v48": 0.18105000000000038, "red_v11": -1.0269999999999972, "red_v61": -0.5079999999999999, "red_v40": -1.0139999999999993, "red_v60": -1.0149999999999997, "red_v19": -2.0839999999999943, "red_v37": 0.50169323781617, "red_v74": -2.009, "red_v36": -2.008, "red_v49": 0.4996925427729416, "red_v88": -2.080999999999992, "red_v24": 0.4926932378161707, "red_v87": 0.458693237816171, "red_v46": -1.0349999999999966, "red_v67": -1.009999999999999, "red_v58": -0.5079999999999999, "red_v93": -2.004, "red_v29": -1.0139999999999996, "red_v27": 1.3862836050000005, "red_v21": 0.49969323781520386, "red_v73": -2.002, "red_v57": 1.4926932378161706, "red_v32": 1.4966932378161713}, "policy_reward_max": {"blue": -0.006, "red": 3.9975561585440547, "red_v7": -1.0139999999999998, "red_v80": -2.0039999999999996, "red_v5": 1.957390625, "red_v8": -1.0099999999999996, "red_v2": -1.004, "red_v81": -1.0039999999999998, "red_v33": 0.48593461444259234, "red_v48": 1.2676463628161718, "red_v11": 0.4846925427729426, "red_v61": -0.5079999999999999, "red_v40": -1.0139999999999993, "red_v60": 1.5056932378161703, "red_v19": -2.0169999999999995, "red_v37": 0.50169323781617, "red_v74": -2.009, "red_v36": 0.4856925427729428, "red_v49": 0.4996925427729416, "red_v88": -2.080999999999992, "red_v24": 1.491693237816171, "red_v87": 0.458693237816171, "red_v46": -1.0349999999999966, "red_v67": -1.009999999999999, "red_v58": -0.5079999999999999, "red_v93": -2.004, "red_v29": -1.0139999999999996, "red_v27": 1.49969323781617, "red_v21": 0.49969323781520386, "red_v73": -2.002, "red_v57": 1.4926932378161706, "red_v32": 1.4966932378161713}, "policy_reward_mean": {"blue": -1.0778928571428565, "red": 3.236053539364782, "red_v7": -1.5213333333333328, "red_v80": -2.0039999999999996, "red_v5": 0.4756953125000001, "red_v8": -1.0099999999999996, "red_v2": -1.004, "red_v81": -1.5054999999999996, "red_v33": -0.2630326927787033, "red_v48": 0.7243481814080861, "red_v11": -0.5204358190756847, "red_v61": -0.5079999999999999, "red_v40": -1.0139999999999993, "red_v60": 0.32079549187744694, "red_v19": -2.050499999999997, "red_v37": 0.50169323781617, "red_v74": -2.009, "red_v36": -0.7611537286135286, "red_v49": 0.4996925427729416, "red_v88": -2.080999999999992, "red_v24": 0.9921932378161709, "red_v87": 0.458693237816171, "red_v46": -1.0349999999999966, "red_v67": -1.009999999999999, "red_v58": -0.5079999999999999, "red_v93": -2.004, "red_v29": -1.0139999999999996, "red_v27": 1.4429884214080853, "red_v21": 0.49969323781520386, "red_v73": -2.002, "red_v57": 1.4926932378161706, "red_v32": 1.4966932378161713}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.4807088628161704, 2.4737869878161707, 2.962458862816171, 0.8146117300000029, 1.1642062499999999, 0.890390625, 1.65839375, 2.467599487816171, 2.4479119878161715, 2.4659744878161707, 2.4696776128161706, 1.8258281250000001, 2.4788182378161703, 2.4624588628161703, 2.4608963628161704, 3.975455977258763, 1.7703396006324041, 0.4726932378161699, 1.9492471144425925, 3.67438386281617, 2.4102244878161714, 2.427802612816173, 1.9678963628161703, 2.46530261281617, 2.474005737816171, 2.4625994878161706, 0.9881151128161698, 2.3857367300000005, 2.4738963628161703, 2.4793026128161704, 1.9770057378161705, 1.5967843750000004, 0.916234375, 2.461271362816171, 2.978223792772942, 2.4498651128161706, 2.47500573781617, 1.6843026128161813, 2.4673026128161704, 2.489446783544055, 3.98048022563234, 2.973083167772942, 2.470895667772942, 0.821234375, 1.9879276128161703, 2.48130261281617, 1.4753374085440554, 2.4857088628161703, 2.4831151128161704, 1.38033048, 1.34396875, 0.6248026128161928, 3.9773701555891128, 2.4489744878161717, 1.9556776128161713, 2.454240112816171, 2.470490112816171, 1.8138963628161824, 2.4106619878161712, 4.482589600632339, 1.8863338628161703, 0.8316898550000005, 3.966339600632341, 2.4834119878161696, 2.4446151128161713, 2.4605752394425924, 3.8717927256323437, 2.4674901128161704, 2.177536987816187, 2.46708386281617, 2.4792244878161704, 2.4680838628161714, 3.910401405589116, 1.9760908644425925, 3.947823280589114, 2.431318237816173, 2.466568237816171, 2.4520213628161707, 2.9608651128161707, 2.9617869878161702, 1.4646463628161706, 2.9831151128161704, 1.491149908544055, 2.3786273550000003, 1.3307523550000016, 1.9591619878161715, 2.443943237816172, 4.484995850632339, 4.366773717816171, 2.9530596144425925, 2.4854119878161702, 1.9450526128161711, 3.9869177256313733, 1.9955561585440547, 4.431027100632342, 3.9090739756323427, 0.9679744878161705, 4.450277100632341, 4.475667725632341, 2.4041776128161745], "episode_lengths": [27, 34, 43, 55, 14, 35, 18, 30, 58, 38, 37, 23, 24, 43, 31, 23, 751, 1280, 28, 19, 86, 61, 31, 29, 28, 30, 25, 15, 31, 29, 28, 53, 21, 39, 22, 41, 28, 285, 29, 18, 34, 35, 31, 21, 21, 29, 21, 27, 25, 17, 10, 829, 37, 38, 37, 49, 33, 95, 74, 31, 147, 62, 47, 26, 57, 19, 126, 33, 242, 35, 22, 35, 91, 14, 52, 56, 40, 55, 41, 34, 47, 25, 17, 18, 42, 42, 48, 29, 33, 24, 26, 45, 22, 15, 83, 100, 38, 67, 38, 69], "policy_blue_reward": [-1.0079999999999993, -1.0099999999999991, -0.013000000000000005, -2.006, -1.0149999999999986, -1.0109999999999992, -1.0079999999999996, -1.011, -1.016, -2.0159999999999996, -1.007, -1.0119999999999996, -1.503, -1.0019999999999998, -1.0059999999999998, -1.0079999999999996, -2.0079999999999996, -0.521, -0.51, -0.008, -1.0169999999999992, -1.005, -1.0089999999999995, -1.0039999999999996, -0.008, -1.0089999999999995, -2.006, -1.0049999999999997, -1.0039999999999996, -1.0059999999999996, -2.006, -2.003, -0.29199999999999104, -1.0129999999999988, -2.0149999999999997, -1.0099999999999993, -1.0239999999999985, -1.523, -1.0069999999999997, -1.0189999999999984, -1.007, -1.0109999999999995, -1.0129999999999992, -1.0079999999999996, -2.005, -1.0189999999999986, -1.0119999999999993, -0.016000000000000004, -0.007, -1.003, -2.0159999999999996, -2.0109999999999992, -0.006, -1.0049999999999997, -1.512, -1.0269999999999977], "policy_red_v7_reward": [-1.528, -1.0139999999999998, -2.0219999999999985], "policy_red_v80_reward": [-2.0039999999999996], "policy_red_v5_reward": [1.957390625, -1.0059999999999998], "policy_red_v8_reward": [-1.0099999999999996], "policy_red_v2_reward": [-1.004], "policy_red_v81_reward": [-1.0039999999999998, -2.0069999999999997], "policy_red_v33_reward": [0.48593461444259234, -1.011999999999999], "policy_red_v48_reward": [1.2676463628161718, 0.18105000000000038], "policy_red_v11_reward": [-1.0269999999999972, -1.0189999999999995, 0.4846925427729426], "policy_red_v61_reward": [-0.5079999999999999], "policy_red_v40_reward": [-1.0139999999999993], "policy_red_v60_reward": [-1.0149999999999997, 1.5056932378161703, 0.47169323781617023], "policy_red_v19_reward": [-2.0839999999999943, -2.0169999999999995], "policy_red_v37_reward": [0.50169323781617], "policy_red_v74_reward": [-2.009], "policy_red_v36_reward": [-2.008, 0.4856925427729428], "policy_red_v49_reward": [0.4996925427729416], "policy_red_v88_reward": [-2.080999999999992], "policy_red_v24_reward": [0.4926932378161707, 1.491693237816171], "policy_red_v87_reward": [0.458693237816171], "policy_red_v46_reward": [-1.0349999999999966], "policy_red_v67_reward": [-1.009999999999999], "policy_red_v58_reward": [-0.5079999999999999], "policy_red_v93_reward": [-2.004], "policy_red_v29_reward": [-1.0139999999999996], "policy_red_v27_reward": [1.49969323781617, 1.3862836050000005], "policy_red_v21_reward": [0.49969323781520386], "policy_red_v73_reward": [-2.002], "policy_red_v57_reward": [1.4926932378161706], "policy_red_v32_reward": [1.4966932378161713]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8247670005030754, "mean_inference_ms": 7.66933779512116, "mean_action_processing_ms": 0.29289067398844437, "mean_env_wait_ms": 0.3955167629662718, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09858155250549316, "StateBufferConnector_ms": 0.004090666770935059, "ViewRequirementAgentConnector_ms": 0.11378121376037598}}, "episode_reward_max": 4.484995850632339, "episode_reward_min": 0.4726932378161699, "episode_reward_mean": 2.4393666915021672, "episode_len_mean": 70.96, "episodes_this_iter": 50, "policy_reward_min": {"blue": -2.0159999999999996, "red": -1.0670000000000002, "red_v7": -2.0219999999999985, "red_v80": -2.0039999999999996, "red_v5": -1.0059999999999998, "red_v8": -1.0099999999999996, "red_v2": -1.004, "red_v81": -2.0069999999999997, "red_v33": -1.011999999999999, "red_v48": 0.18105000000000038, "red_v11": -1.0269999999999972, "red_v61": -0.5079999999999999, "red_v40": -1.0139999999999993, "red_v60": -1.0149999999999997, "red_v19": -2.0839999999999943, "red_v37": 0.50169323781617, "red_v74": -2.009, "red_v36": -2.008, "red_v49": 0.4996925427729416, "red_v88": -2.080999999999992, "red_v24": 0.4926932378161707, "red_v87": 0.458693237816171, "red_v46": -1.0349999999999966, "red_v67": -1.009999999999999, "red_v58": -0.5079999999999999, "red_v93": -2.004, "red_v29": -1.0139999999999996, "red_v27": 1.3862836050000005, "red_v21": 0.49969323781520386, "red_v73": -2.002, "red_v57": 1.4926932378161706, "red_v32": 1.4966932378161713}, "policy_reward_max": {"blue": -0.006, "red": 3.9975561585440547, "red_v7": -1.0139999999999998, "red_v80": -2.0039999999999996, "red_v5": 1.957390625, "red_v8": -1.0099999999999996, "red_v2": -1.004, "red_v81": -1.0039999999999998, "red_v33": 0.48593461444259234, "red_v48": 1.2676463628161718, "red_v11": 0.4846925427729426, "red_v61": -0.5079999999999999, "red_v40": -1.0139999999999993, "red_v60": 1.5056932378161703, "red_v19": -2.0169999999999995, "red_v37": 0.50169323781617, "red_v74": -2.009, "red_v36": 0.4856925427729428, "red_v49": 0.4996925427729416, "red_v88": -2.080999999999992, "red_v24": 1.491693237816171, "red_v87": 0.458693237816171, "red_v46": -1.0349999999999966, "red_v67": -1.009999999999999, "red_v58": -0.5079999999999999, "red_v93": -2.004, "red_v29": -1.0139999999999996, "red_v27": 1.49969323781617, "red_v21": 0.49969323781520386, "red_v73": -2.002, "red_v57": 1.4926932378161706, "red_v32": 1.4966932378161713}, "policy_reward_mean": {"blue": -1.0778928571428565, "red": 3.236053539364782, "red_v7": -1.5213333333333328, "red_v80": -2.0039999999999996, "red_v5": 0.4756953125000001, "red_v8": -1.0099999999999996, "red_v2": -1.004, "red_v81": -1.5054999999999996, "red_v33": -0.2630326927787033, "red_v48": 0.7243481814080861, "red_v11": -0.5204358190756847, "red_v61": -0.5079999999999999, "red_v40": -1.0139999999999993, "red_v60": 0.32079549187744694, "red_v19": -2.050499999999997, "red_v37": 0.50169323781617, "red_v74": -2.009, "red_v36": -0.7611537286135286, "red_v49": 0.4996925427729416, "red_v88": -2.080999999999992, "red_v24": 0.9921932378161709, "red_v87": 0.458693237816171, "red_v46": -1.0349999999999966, "red_v67": -1.009999999999999, "red_v58": -0.5079999999999999, "red_v93": -2.004, "red_v29": -1.0139999999999996, "red_v27": 1.4429884214080853, "red_v21": 0.49969323781520386, "red_v73": -2.002, "red_v57": 1.4926932378161706, "red_v32": 1.4966932378161713}, "hist_stats": {"episode_reward": [2.4807088628161704, 2.4737869878161707, 2.962458862816171, 0.8146117300000029, 1.1642062499999999, 0.890390625, 1.65839375, 2.467599487816171, 2.4479119878161715, 2.4659744878161707, 2.4696776128161706, 1.8258281250000001, 2.4788182378161703, 2.4624588628161703, 2.4608963628161704, 3.975455977258763, 1.7703396006324041, 0.4726932378161699, 1.9492471144425925, 3.67438386281617, 2.4102244878161714, 2.427802612816173, 1.9678963628161703, 2.46530261281617, 2.474005737816171, 2.4625994878161706, 0.9881151128161698, 2.3857367300000005, 2.4738963628161703, 2.4793026128161704, 1.9770057378161705, 1.5967843750000004, 0.916234375, 2.461271362816171, 2.978223792772942, 2.4498651128161706, 2.47500573781617, 1.6843026128161813, 2.4673026128161704, 2.489446783544055, 3.98048022563234, 2.973083167772942, 2.470895667772942, 0.821234375, 1.9879276128161703, 2.48130261281617, 1.4753374085440554, 2.4857088628161703, 2.4831151128161704, 1.38033048, 1.34396875, 0.6248026128161928, 3.9773701555891128, 2.4489744878161717, 1.9556776128161713, 2.454240112816171, 2.470490112816171, 1.8138963628161824, 2.4106619878161712, 4.482589600632339, 1.8863338628161703, 0.8316898550000005, 3.966339600632341, 2.4834119878161696, 2.4446151128161713, 2.4605752394425924, 3.8717927256323437, 2.4674901128161704, 2.177536987816187, 2.46708386281617, 2.4792244878161704, 2.4680838628161714, 3.910401405589116, 1.9760908644425925, 3.947823280589114, 2.431318237816173, 2.466568237816171, 2.4520213628161707, 2.9608651128161707, 2.9617869878161702, 1.4646463628161706, 2.9831151128161704, 1.491149908544055, 2.3786273550000003, 1.3307523550000016, 1.9591619878161715, 2.443943237816172, 4.484995850632339, 4.366773717816171, 2.9530596144425925, 2.4854119878161702, 1.9450526128161711, 3.9869177256313733, 1.9955561585440547, 4.431027100632342, 3.9090739756323427, 0.9679744878161705, 4.450277100632341, 4.475667725632341, 2.4041776128161745], "episode_lengths": [27, 34, 43, 55, 14, 35, 18, 30, 58, 38, 37, 23, 24, 43, 31, 23, 751, 1280, 28, 19, 86, 61, 31, 29, 28, 30, 25, 15, 31, 29, 28, 53, 21, 39, 22, 41, 28, 285, 29, 18, 34, 35, 31, 21, 21, 29, 21, 27, 25, 17, 10, 829, 37, 38, 37, 49, 33, 95, 74, 31, 147, 62, 47, 26, 57, 19, 126, 33, 242, 35, 22, 35, 91, 14, 52, 56, 40, 55, 41, 34, 47, 25, 17, 18, 42, 42, 48, 29, 33, 24, 26, 45, 22, 15, 83, 100, 38, 67, 38, 69], "policy_blue_reward": [-1.0079999999999993, -1.0099999999999991, -0.013000000000000005, -2.006, -1.0149999999999986, -1.0109999999999992, -1.0079999999999996, -1.011, -1.016, -2.0159999999999996, -1.007, -1.0119999999999996, -1.503, -1.0019999999999998, -1.0059999999999998, -1.0079999999999996, -2.0079999999999996, -0.521, -0.51, -0.008, -1.0169999999999992, -1.005, -1.0089999999999995, -1.0039999999999996, -0.008, -1.0089999999999995, -2.006, -1.0049999999999997, -1.0039999999999996, -1.0059999999999996, -2.006, -2.003, -0.29199999999999104, -1.0129999999999988, -2.0149999999999997, -1.0099999999999993, -1.0239999999999985, -1.523, -1.0069999999999997, -1.0189999999999984, -1.007, -1.0109999999999995, -1.0129999999999992, -1.0079999999999996, -2.005, -1.0189999999999986, -1.0119999999999993, -0.016000000000000004, -0.007, -1.003, -2.0159999999999996, -2.0109999999999992, -0.006, -1.0049999999999997, -1.512, -1.0269999999999977], "policy_red_v7_reward": [-1.528, -1.0139999999999998, -2.0219999999999985], "policy_red_v80_reward": [-2.0039999999999996], "policy_red_v5_reward": [1.957390625, -1.0059999999999998], "policy_red_v8_reward": [-1.0099999999999996], "policy_red_v2_reward": [-1.004], "policy_red_v81_reward": [-1.0039999999999998, -2.0069999999999997], "policy_red_v33_reward": [0.48593461444259234, -1.011999999999999], "policy_red_v48_reward": [1.2676463628161718, 0.18105000000000038], "policy_red_v11_reward": [-1.0269999999999972, -1.0189999999999995, 0.4846925427729426], "policy_red_v61_reward": [-0.5079999999999999], "policy_red_v40_reward": [-1.0139999999999993], "policy_red_v60_reward": [-1.0149999999999997, 1.5056932378161703, 0.47169323781617023], "policy_red_v19_reward": [-2.0839999999999943, -2.0169999999999995], "policy_red_v37_reward": [0.50169323781617], "policy_red_v74_reward": [-2.009], "policy_red_v36_reward": [-2.008, 0.4856925427729428], "policy_red_v49_reward": [0.4996925427729416], "policy_red_v88_reward": [-2.080999999999992], "policy_red_v24_reward": [0.4926932378161707, 1.491693237816171], "policy_red_v87_reward": [0.458693237816171], "policy_red_v46_reward": [-1.0349999999999966], "policy_red_v67_reward": [-1.009999999999999], "policy_red_v58_reward": [-0.5079999999999999], "policy_red_v93_reward": [-2.004], "policy_red_v29_reward": [-1.0139999999999996], "policy_red_v27_reward": [1.49969323781617, 1.3862836050000005], "policy_red_v21_reward": [0.49969323781520386], "policy_red_v73_reward": [-2.002], "policy_red_v57_reward": [1.4926932378161706], "policy_red_v32_reward": [1.4966932378161713]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8247670005030754, "mean_inference_ms": 7.66933779512116, "mean_action_processing_ms": 0.29289067398844437, "mean_env_wait_ms": 0.3955167629662718, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09858155250549316, "StateBufferConnector_ms": 0.004090666770935059, "ViewRequirementAgentConnector_ms": 0.11378121376037598}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 197.46231763188564, "num_env_steps_trained_throughput_per_sec": 197.46231763188564, "timesteps_total": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 20058.666, "sample_time_ms": 1250.674, "learn_time_ms": 18721.398, "learn_throughput": 213.659, "synch_weights_time_ms": 82.89}, "counters": {"num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "episodes_total": 3236, "training_iteration": 128, "trial_id": "a9680_00000", "date": "2023-09-24_03-24-47", "timestamp": 1695540287, "time_this_iter_s": 20.267399787902832, "time_total_s": 2554.8449239730835, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1db86620>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1db53520>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1db53490>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2554.8449239730835, "iterations_since_restore": 128, "perf": {"cpu_util_percent": 5.68918918918919, "ram_util_percent": 28.081081081081088}, "win_rate": 0.82, "league_size": 97}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6964245239893594, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.04299483276505877, "policy_loss": -0.033613920325296934, "vf_loss": 0.14062272899318487, "vf_explained_var": 0.8573655761157473, "kl": 0.011118390017354863, "entropy": 1.2075249900420506, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 123360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_agent_steps_sampled": 1032000, "num_agent_steps_trained": 1032000}, "sampler_results": {"episode_reward_max": 4.484995850632339, "episode_reward_min": -1.5279999999999547, "episode_reward_mean": 2.5122083721648565, "episode_len_mean": 67.55, "episode_media": {}, "episodes_this_iter": 57, "policy_reward_min": {"red_v88": -2.080999999999992, "red": -1.2950000000000002, "blue": -2.027999999999998, "red_v60": 0.47169323781617023, "red_v19": -2.0169999999999995, "red_v24": 0.4926932378161707, "red_v87": 0.458693237816171, "red_v46": -1.0349999999999966, "red_v67": -1.009999999999999, "red_v11": -0.005, "red_v36": 0.4856925427729428, "red_v33": -1.011999999999999, "red_v58": -1.0169999999999986, "red_v81": -2.0069999999999997, "red_v93": -2.004, "red_v29": -1.0139999999999996, "red_v27": 1.3862836050000005, "red_v7": -2.0219999999999985, "red_v21": 0.49969323781520386, "red_v73": -2.002, "red_v57": 1.4926932378161706, "red_v32": -1.008, "red_v4": -1.0459999999999958, "red_v71": -2.0029999999999997, "red_v51": 0.5041030335440548, "red_v18": 0.49369323781520386, "red_v68": 1.4966932378161708, "red_v49": 0.49169254277294183, "red_v94": -2.0479999999999956, "red_v28": -1.025, "red_v39": 0.49210303354405527, "red_v84": -2.007999999999999, "red_v31": 0.459693237816174, "red_v95": -2.005, "red_v92": -2.006, "red_v15": 0.28700000000000025, "red_v2": -1.030999999999998, "red_v59": -1.0099999999999998, "red_v25": 0.8450000000000001, "red_v38": 1.8980831677729433, "red_v66": 0.508103033544055, "red_v83": 0.46799999999999997}, "policy_reward_max": {"red_v88": -2.080999999999992, "red": 3.998259283544055, "blue": 1.985046875, "red_v60": 1.5056932378161703, "red_v19": -2.0169999999999995, "red_v24": 1.491693237816171, "red_v87": 0.458693237816171, "red_v46": -1.0349999999999966, "red_v67": -1.009999999999999, "red_v11": 0.4846925427729426, "red_v36": 0.4856925427729428, "red_v33": -0.002, "red_v58": -0.4750000000000008, "red_v81": -2.0069999999999997, "red_v93": -2.004, "red_v29": -1.0139999999999996, "red_v27": 1.49969323781617, "red_v7": 1.8265561585440553, "red_v21": 0.49969323781520386, "red_v73": -1.5030000000000001, "red_v57": 1.4926932378161706, "red_v32": 1.4966932378161713, "red_v4": -1.0459999999999958, "red_v71": -2.0029999999999997, "red_v51": 0.5041030335440548, "red_v18": 0.49369323781520386, "red_v68": 1.4966932378161708, "red_v49": 0.49169254277294183, "red_v94": -2.0479999999999956, "red_v28": 0.47493461444259333, "red_v39": 0.49210303354405527, "red_v84": -2.007999999999999, "red_v31": 0.459693237816174, "red_v95": -2.005, "red_v92": -2.006, "red_v15": 0.50269323781617, "red_v2": -1.030999999999998, "red_v59": -1.0099999999999998, "red_v25": 0.8450000000000001, "red_v38": 1.8980831677729433, "red_v66": 0.508103033544055, "red_v83": 0.46799999999999997}, "policy_reward_mean": {"red_v88": -2.080999999999992, "red": 3.12703739985724, "blue": -1.0227741486574453, "red_v60": 0.9886932378161702, "red_v19": -2.0169999999999995, "red_v24": 0.9921932378161709, "red_v87": 0.458693237816171, "red_v46": -1.0349999999999966, "red_v67": -1.009999999999999, "red_v11": 0.2398462713864713, "red_v36": 0.4856925427729428, "red_v33": -0.5069999999999995, "red_v58": -0.6666666666666664, "red_v81": -2.0069999999999997, "red_v93": -2.004, "red_v29": -1.0139999999999996, "red_v27": 1.4429884214080853, "red_v7": -0.09772192072797159, "red_v21": 0.49969323781520386, "red_v73": -1.7525, "red_v57": 1.4926932378161706, "red_v32": 0.24434661890808562, "red_v4": -1.0459999999999958, "red_v71": -2.0029999999999997, "red_v51": 0.5041030335440548, "red_v18": 0.49369323781520386, "red_v68": 1.4966932378161708, "red_v49": 0.49169254277294183, "red_v94": -2.0479999999999956, "red_v28": -0.2750326927787033, "red_v39": 0.49210303354405527, "red_v84": -2.007999999999999, "red_v31": 0.459693237816174, "red_v95": -2.005, "red_v92": -2.006, "red_v15": 0.39484661890808515, "red_v2": -1.030999999999998, "red_v59": -1.0099999999999998, "red_v25": 0.8450000000000001, "red_v38": 1.8980831677729433, "red_v66": 0.508103033544055, "red_v83": 0.46799999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.8138963628161824, 2.4106619878161712, 4.482589600632339, 1.8863338628161703, 0.8316898550000005, 3.966339600632341, 2.4834119878161696, 2.4446151128161713, 2.4605752394425924, 3.8717927256323437, 2.4674901128161704, 2.177536987816187, 2.46708386281617, 2.4792244878161704, 2.4680838628161714, 3.910401405589116, 1.9760908644425925, 3.947823280589114, 2.431318237816173, 2.466568237816171, 2.4520213628161707, 2.9608651128161707, 2.9617869878161702, 1.4646463628161706, 2.9831151128161704, 1.491149908544055, 2.3786273550000003, 1.3307523550000016, 1.9591619878161715, 2.443943237816172, 4.484995850632339, 4.366773717816171, 2.9530596144425925, 2.4854119878161702, 1.9450526128161711, 3.9869177256313733, 1.9955561585440547, 4.431027100632342, 3.9090739756323427, 0.9679744878161705, 4.450277100632341, 4.475667725632341, 2.4041776128161745, 2.351974487816178, 1.6685031250000002, -0.7062031250000003, 2.3850369878161763, 3.9961435670881102, 3.9404958506313763, 2.4739814894425924, 1.9912592835440548, 1.8928494878161752, 4.439495850632342, 0.6663937500000001, 3.9504170305891133, 1.3697244878161743, 1.9917394177729415, 2.472684614442592, 1.9313182378161726, 2.4382088628161713, 2.4375838628161706, 3.959265021360226, 1.364892980000001, 2.988036987815204, 2.8486052256323484, 0.6707939894426096, 2.434021362816172, 1.9750838628161704, 1.9533494878161717, -1.5279999999999547, 0.8354531250000002, 2.99033386281617, 2.4399119878161715, 2.9680057378161697, 2.471981489442592, 0.8320468750000001, 2.6509875000000003, 3.987589600632341, 2.4679744878161705, 2.3378338628161774, 2.162690625, 2.47489636281617, 2.3212493963602343, 2.486743658544055, 0.8852187500000002, 1.9811151128161701, 3.831302612816171, 2.4741186585440547, 2.4027764055891163, 2.4813374085440554, 2.4628651128161705, 2.483817542772942, 2.566674230000008, 3.999327521360225, 3.830330977258771, 2.4743807378161704, 2.48122448781617, 1.9770908644425924, 1.9879276128161703, 2.3904112927729466], "episode_lengths": [95, 74, 31, 147, 62, 47, 26, 57, 19, 126, 33, 242, 35, 22, 35, 91, 14, 52, 56, 40, 55, 41, 34, 47, 25, 17, 18, 42, 42, 48, 29, 33, 24, 26, 45, 22, 15, 83, 100, 38, 67, 38, 69, 102, 15, 161, 82, 20, 61, 17, 14, 78, 61, 18, 54, 118, 17, 16, 56, 59, 67, 42, 29, 18, 122, 525, 55, 35, 46, 1280, 15, 19, 58, 28, 17, 17, 20, 31, 38, 115, 19, 31, 143, 19, 58, 25, 29, 27, 99, 21, 41, 24, 99, 22, 127, 36, 22, 14, 21, 90], "policy_red_v88_reward": [-2.080999999999992], "policy_blue_reward": [-1.0239999999999985, -1.523, -1.0069999999999997, -1.0189999999999984, -1.007, -1.0109999999999995, -1.0129999999999992, -1.0079999999999996, -2.005, -1.0189999999999986, -1.0119999999999993, -0.016000000000000004, -0.007, -1.003, -2.0159999999999996, -2.0109999999999992, -0.006, -1.0049999999999997, -1.512, -1.0269999999999977, -1.045, -1.003, -2.0069999999999997, -2.027999999999998, 1.985046875, -1.0059999999999998, -2.0219999999999985, -1.0189999999999988, 1.9657939894425986, -1.0199999999999985, -2.0069999999999992, -2.0119999999999987, -1.0159999999999987, -0.008, -1.004, -0.011000000000000003, -1.0039999999999996, -1.003, -0.5119999999999999, -2.0089999999999995, -1.0079999999999993, -1.0079999999999998, -1.013, -1.0019999999999998, -1.0079999999999993, -1.0079999999999993, -2.0039999999999996, -2.006], "policy_red_v60_reward": [1.5056932378161703, 0.47169323781617023], "policy_red_v19_reward": [-2.0169999999999995], "policy_red_v24_reward": [0.4926932378161707, 1.491693237816171], "policy_red_v87_reward": [0.458693237816171], "policy_red_v46_reward": [-1.0349999999999966], "policy_red_v67_reward": [-1.009999999999999], "policy_red_v11_reward": [0.4846925427729426, -0.005], "policy_red_v36_reward": [0.4856925427729428], "policy_red_v33_reward": [-1.011999999999999, -0.002], "policy_red_v58_reward": [-0.5079999999999999, -1.0169999999999986, -0.4750000000000008], "policy_red_v81_reward": [-2.0069999999999997], "policy_red_v93_reward": [-2.004], "policy_red_v29_reward": [-1.0139999999999996], "policy_red_v27_reward": [1.49969323781617, 1.3862836050000005], "policy_red_v7_reward": [-2.0219999999999985, 1.8265561585440553], "policy_red_v21_reward": [0.49969323781520386], "policy_red_v73_reward": [-2.002, -1.5030000000000001], "policy_red_v57_reward": [1.4926932378161706], "policy_red_v32_reward": [1.4966932378161713, -1.008], "policy_red_v4_reward": [-1.0459999999999958], "policy_red_v71_reward": [-2.0029999999999997], "policy_red_v51_reward": [0.5041030335440548], "policy_red_v18_reward": [0.49369323781520386], "policy_red_v68_reward": [1.4966932378161708], "policy_red_v49_reward": [0.49169254277294183], "policy_red_v94_reward": [-2.0479999999999956], "policy_red_v28_reward": [-1.025, 0.47493461444259333], "policy_red_v39_reward": [0.49210303354405527], "policy_red_v84_reward": [-2.007999999999999], "policy_red_v31_reward": [0.459693237816174], "policy_red_v95_reward": [-2.005], "policy_red_v92_reward": [-2.006], "policy_red_v15_reward": [0.50269323781617, 0.28700000000000025], "policy_red_v2_reward": [-1.030999999999998], "policy_red_v59_reward": [-1.0099999999999998], "policy_red_v25_reward": [0.8450000000000001], "policy_red_v38_reward": [1.8980831677729433], "policy_red_v66_reward": [0.508103033544055], "policy_red_v83_reward": [0.46799999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8253247255729937, "mean_inference_ms": 7.678272638457933, "mean_action_processing_ms": 0.29340920608132653, "mean_env_wait_ms": 0.3954661189751895, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09837961196899414, "StateBufferConnector_ms": 0.0040847063064575195, "ViewRequirementAgentConnector_ms": 0.11342966556549072}}, "episode_reward_max": 4.484995850632339, "episode_reward_min": -1.5279999999999547, "episode_reward_mean": 2.5122083721648565, "episode_len_mean": 67.55, "episodes_this_iter": 57, "policy_reward_min": {"red_v88": -2.080999999999992, "red": -1.2950000000000002, "blue": -2.027999999999998, "red_v60": 0.47169323781617023, "red_v19": -2.0169999999999995, "red_v24": 0.4926932378161707, "red_v87": 0.458693237816171, "red_v46": -1.0349999999999966, "red_v67": -1.009999999999999, "red_v11": -0.005, "red_v36": 0.4856925427729428, "red_v33": -1.011999999999999, "red_v58": -1.0169999999999986, "red_v81": -2.0069999999999997, "red_v93": -2.004, "red_v29": -1.0139999999999996, "red_v27": 1.3862836050000005, "red_v7": -2.0219999999999985, "red_v21": 0.49969323781520386, "red_v73": -2.002, "red_v57": 1.4926932378161706, "red_v32": -1.008, "red_v4": -1.0459999999999958, "red_v71": -2.0029999999999997, "red_v51": 0.5041030335440548, "red_v18": 0.49369323781520386, "red_v68": 1.4966932378161708, "red_v49": 0.49169254277294183, "red_v94": -2.0479999999999956, "red_v28": -1.025, "red_v39": 0.49210303354405527, "red_v84": -2.007999999999999, "red_v31": 0.459693237816174, "red_v95": -2.005, "red_v92": -2.006, "red_v15": 0.28700000000000025, "red_v2": -1.030999999999998, "red_v59": -1.0099999999999998, "red_v25": 0.8450000000000001, "red_v38": 1.8980831677729433, "red_v66": 0.508103033544055, "red_v83": 0.46799999999999997}, "policy_reward_max": {"red_v88": -2.080999999999992, "red": 3.998259283544055, "blue": 1.985046875, "red_v60": 1.5056932378161703, "red_v19": -2.0169999999999995, "red_v24": 1.491693237816171, "red_v87": 0.458693237816171, "red_v46": -1.0349999999999966, "red_v67": -1.009999999999999, "red_v11": 0.4846925427729426, "red_v36": 0.4856925427729428, "red_v33": -0.002, "red_v58": -0.4750000000000008, "red_v81": -2.0069999999999997, "red_v93": -2.004, "red_v29": -1.0139999999999996, "red_v27": 1.49969323781617, "red_v7": 1.8265561585440553, "red_v21": 0.49969323781520386, "red_v73": -1.5030000000000001, "red_v57": 1.4926932378161706, "red_v32": 1.4966932378161713, "red_v4": -1.0459999999999958, "red_v71": -2.0029999999999997, "red_v51": 0.5041030335440548, "red_v18": 0.49369323781520386, "red_v68": 1.4966932378161708, "red_v49": 0.49169254277294183, "red_v94": -2.0479999999999956, "red_v28": 0.47493461444259333, "red_v39": 0.49210303354405527, "red_v84": -2.007999999999999, "red_v31": 0.459693237816174, "red_v95": -2.005, "red_v92": -2.006, "red_v15": 0.50269323781617, "red_v2": -1.030999999999998, "red_v59": -1.0099999999999998, "red_v25": 0.8450000000000001, "red_v38": 1.8980831677729433, "red_v66": 0.508103033544055, "red_v83": 0.46799999999999997}, "policy_reward_mean": {"red_v88": -2.080999999999992, "red": 3.12703739985724, "blue": -1.0227741486574453, "red_v60": 0.9886932378161702, "red_v19": -2.0169999999999995, "red_v24": 0.9921932378161709, "red_v87": 0.458693237816171, "red_v46": -1.0349999999999966, "red_v67": -1.009999999999999, "red_v11": 0.2398462713864713, "red_v36": 0.4856925427729428, "red_v33": -0.5069999999999995, "red_v58": -0.6666666666666664, "red_v81": -2.0069999999999997, "red_v93": -2.004, "red_v29": -1.0139999999999996, "red_v27": 1.4429884214080853, "red_v7": -0.09772192072797159, "red_v21": 0.49969323781520386, "red_v73": -1.7525, "red_v57": 1.4926932378161706, "red_v32": 0.24434661890808562, "red_v4": -1.0459999999999958, "red_v71": -2.0029999999999997, "red_v51": 0.5041030335440548, "red_v18": 0.49369323781520386, "red_v68": 1.4966932378161708, "red_v49": 0.49169254277294183, "red_v94": -2.0479999999999956, "red_v28": -0.2750326927787033, "red_v39": 0.49210303354405527, "red_v84": -2.007999999999999, "red_v31": 0.459693237816174, "red_v95": -2.005, "red_v92": -2.006, "red_v15": 0.39484661890808515, "red_v2": -1.030999999999998, "red_v59": -1.0099999999999998, "red_v25": 0.8450000000000001, "red_v38": 1.8980831677729433, "red_v66": 0.508103033544055, "red_v83": 0.46799999999999997}, "hist_stats": {"episode_reward": [1.8138963628161824, 2.4106619878161712, 4.482589600632339, 1.8863338628161703, 0.8316898550000005, 3.966339600632341, 2.4834119878161696, 2.4446151128161713, 2.4605752394425924, 3.8717927256323437, 2.4674901128161704, 2.177536987816187, 2.46708386281617, 2.4792244878161704, 2.4680838628161714, 3.910401405589116, 1.9760908644425925, 3.947823280589114, 2.431318237816173, 2.466568237816171, 2.4520213628161707, 2.9608651128161707, 2.9617869878161702, 1.4646463628161706, 2.9831151128161704, 1.491149908544055, 2.3786273550000003, 1.3307523550000016, 1.9591619878161715, 2.443943237816172, 4.484995850632339, 4.366773717816171, 2.9530596144425925, 2.4854119878161702, 1.9450526128161711, 3.9869177256313733, 1.9955561585440547, 4.431027100632342, 3.9090739756323427, 0.9679744878161705, 4.450277100632341, 4.475667725632341, 2.4041776128161745, 2.351974487816178, 1.6685031250000002, -0.7062031250000003, 2.3850369878161763, 3.9961435670881102, 3.9404958506313763, 2.4739814894425924, 1.9912592835440548, 1.8928494878161752, 4.439495850632342, 0.6663937500000001, 3.9504170305891133, 1.3697244878161743, 1.9917394177729415, 2.472684614442592, 1.9313182378161726, 2.4382088628161713, 2.4375838628161706, 3.959265021360226, 1.364892980000001, 2.988036987815204, 2.8486052256323484, 0.6707939894426096, 2.434021362816172, 1.9750838628161704, 1.9533494878161717, -1.5279999999999547, 0.8354531250000002, 2.99033386281617, 2.4399119878161715, 2.9680057378161697, 2.471981489442592, 0.8320468750000001, 2.6509875000000003, 3.987589600632341, 2.4679744878161705, 2.3378338628161774, 2.162690625, 2.47489636281617, 2.3212493963602343, 2.486743658544055, 0.8852187500000002, 1.9811151128161701, 3.831302612816171, 2.4741186585440547, 2.4027764055891163, 2.4813374085440554, 2.4628651128161705, 2.483817542772942, 2.566674230000008, 3.999327521360225, 3.830330977258771, 2.4743807378161704, 2.48122448781617, 1.9770908644425924, 1.9879276128161703, 2.3904112927729466], "episode_lengths": [95, 74, 31, 147, 62, 47, 26, 57, 19, 126, 33, 242, 35, 22, 35, 91, 14, 52, 56, 40, 55, 41, 34, 47, 25, 17, 18, 42, 42, 48, 29, 33, 24, 26, 45, 22, 15, 83, 100, 38, 67, 38, 69, 102, 15, 161, 82, 20, 61, 17, 14, 78, 61, 18, 54, 118, 17, 16, 56, 59, 67, 42, 29, 18, 122, 525, 55, 35, 46, 1280, 15, 19, 58, 28, 17, 17, 20, 31, 38, 115, 19, 31, 143, 19, 58, 25, 29, 27, 99, 21, 41, 24, 99, 22, 127, 36, 22, 14, 21, 90], "policy_red_v88_reward": [-2.080999999999992], "policy_blue_reward": [-1.0239999999999985, -1.523, -1.0069999999999997, -1.0189999999999984, -1.007, -1.0109999999999995, -1.0129999999999992, -1.0079999999999996, -2.005, -1.0189999999999986, -1.0119999999999993, -0.016000000000000004, -0.007, -1.003, -2.0159999999999996, -2.0109999999999992, -0.006, -1.0049999999999997, -1.512, -1.0269999999999977, -1.045, -1.003, -2.0069999999999997, -2.027999999999998, 1.985046875, -1.0059999999999998, -2.0219999999999985, -1.0189999999999988, 1.9657939894425986, -1.0199999999999985, -2.0069999999999992, -2.0119999999999987, -1.0159999999999987, -0.008, -1.004, -0.011000000000000003, -1.0039999999999996, -1.003, -0.5119999999999999, -2.0089999999999995, -1.0079999999999993, -1.0079999999999998, -1.013, -1.0019999999999998, -1.0079999999999993, -1.0079999999999993, -2.0039999999999996, -2.006], "policy_red_v60_reward": [1.5056932378161703, 0.47169323781617023], "policy_red_v19_reward": [-2.0169999999999995], "policy_red_v24_reward": [0.4926932378161707, 1.491693237816171], "policy_red_v87_reward": [0.458693237816171], "policy_red_v46_reward": [-1.0349999999999966], "policy_red_v67_reward": [-1.009999999999999], "policy_red_v11_reward": [0.4846925427729426, -0.005], "policy_red_v36_reward": [0.4856925427729428], "policy_red_v33_reward": [-1.011999999999999, -0.002], "policy_red_v58_reward": [-0.5079999999999999, -1.0169999999999986, -0.4750000000000008], "policy_red_v81_reward": [-2.0069999999999997], "policy_red_v93_reward": [-2.004], "policy_red_v29_reward": [-1.0139999999999996], "policy_red_v27_reward": [1.49969323781617, 1.3862836050000005], "policy_red_v7_reward": [-2.0219999999999985, 1.8265561585440553], "policy_red_v21_reward": [0.49969323781520386], "policy_red_v73_reward": [-2.002, -1.5030000000000001], "policy_red_v57_reward": [1.4926932378161706], "policy_red_v32_reward": [1.4966932378161713, -1.008], "policy_red_v4_reward": [-1.0459999999999958], "policy_red_v71_reward": [-2.0029999999999997], "policy_red_v51_reward": [0.5041030335440548], "policy_red_v18_reward": [0.49369323781520386], "policy_red_v68_reward": [1.4966932378161708], "policy_red_v49_reward": [0.49169254277294183], "policy_red_v94_reward": [-2.0479999999999956], "policy_red_v28_reward": [-1.025, 0.47493461444259333], "policy_red_v39_reward": [0.49210303354405527], "policy_red_v84_reward": [-2.007999999999999], "policy_red_v31_reward": [0.459693237816174], "policy_red_v95_reward": [-2.005], "policy_red_v92_reward": [-2.006], "policy_red_v15_reward": [0.50269323781617, 0.28700000000000025], "policy_red_v2_reward": [-1.030999999999998], "policy_red_v59_reward": [-1.0099999999999998], "policy_red_v25_reward": [0.8450000000000001], "policy_red_v38_reward": [1.8980831677729433], "policy_red_v66_reward": [0.508103033544055], "policy_red_v83_reward": [0.46799999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8253247255729937, "mean_inference_ms": 7.678272638457933, "mean_action_processing_ms": 0.29340920608132653, "mean_env_wait_ms": 0.3954661189751895, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09837961196899414, "StateBufferConnector_ms": 0.0040847063064575195, "ViewRequirementAgentConnector_ms": 0.11342966556549072}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1032000, "num_agent_steps_trained": 1032000, "num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 196.05590198495017, "num_env_steps_trained_throughput_per_sec": 196.05590198495017, "timesteps_total": 516000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1032000, "timers": {"training_iteration_time_ms": 20177.165, "sample_time_ms": 1271.375, "learn_time_ms": 18819.634, "learn_throughput": 212.544, "synch_weights_time_ms": 82.455}, "counters": {"num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_agent_steps_sampled": 1032000, "num_agent_steps_trained": 1032000}, "done": false, "episodes_total": 3293, "training_iteration": 129, "trial_id": "a9680_00000", "date": "2023-09-24_03-25-13", "timestamp": 1695540313, "time_this_iter_s": 20.412832260131836, "time_total_s": 2575.2577562332153, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1db87b50>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1dbe0670>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1dbe0700>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2575.2577562332153, "iterations_since_restore": 129, "perf": {"cpu_util_percent": 5.391891891891893, "ram_util_percent": 28.189189189189197}, "win_rate": 0.72, "league_size": 98}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8415670091907184, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.09129641041896927, "policy_loss": -0.04073942945396993, "vf_loss": 0.24949420171324163, "vf_explained_var": 0.7670270389566819, "kl": 0.012551943314762563, "entropy": 1.1838225855802496, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 124320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "sampler_results": {"episode_reward_max": 4.4760739756323416, "episode_reward_min": -5.372306762183822, "episode_reward_mean": 2.139593778108856, "episode_len_mean": 105.68, "episode_media": {}, "episodes_this_iter": 62, "policy_reward_min": {"red_v84": -2.007999999999999, "red": -10.502306762183832, "red_v11": -2.0169999999999995, "red_v31": 0.459693237816174, "blue": -2.0119999999999996, "red_v58": -0.4750000000000008, "red_v95": -2.005, "red_v33": -0.002, "red_v92": -2.006, "red_v15": 0.28700000000000025, "red_v32": -1.008, "red_v2": -1.030999999999998, "red_v59": -2.005, "red_v7": 1.8265561585440553, "red_v25": 0.49669323781520364, "red_v38": 0.8645312500000002, "red_v66": -1.559, "red_v28": 0.47493461444259333, "red_v83": 0.46799999999999997, "red_v22": -1.0299999999999976, "red_v21": 0.845, "red_v82": -1.0189999999999995, "red_v67": -0.4713067621838243, "red_v10": -1.577, "red_v71": -2.005, "red_v90": -2.013, "red_v45": -1.0149999999999986, "red_v61": -0.5239999999999998, "red_v36": -2.009, "red_v34": 1.484103033544056, "red_v79": 0.45129687500000015, "red_v87": -1.508, "red_v4": -1.641, "red_v85": -1.003, "red_v60": 0.45062500000000005, "red_v55": -1.0109999999999997, "red_v70": -2.002, "red_v52": -2.064999999999997, "red_v8": -0.024000000000000014, "red_v75": 0.4816932378161727, "red_v29": 0.5026932378161701, "red_v46": -0.5119999999999999}, "policy_reward_max": {"red_v84": -1.515, "red": 3.99392761281617, "red_v11": -0.005, "red_v31": 0.459693237816174, "blue": 5.130000000000006, "red_v58": -0.4750000000000008, "red_v95": -2.005, "red_v33": 0.29769323781617074, "red_v92": -1.005, "red_v15": 0.50269323781617, "red_v32": -1.008, "red_v2": -1.0129999999999992, "red_v59": -1.0099999999999998, "red_v7": 1.8265561585440553, "red_v25": 0.8450000000000001, "red_v38": 1.8980831677729433, "red_v66": 0.508103033544055, "red_v28": 0.47493461444259333, "red_v83": 0.46799999999999997, "red_v22": -1.0299999999999976, "red_v21": 0.845, "red_v82": -1.0189999999999995, "red_v67": 0.5046932378152038, "red_v10": -1.577, "red_v71": -2.005, "red_v90": -2.013, "red_v45": -1.0149999999999986, "red_v61": -0.5239999999999998, "red_v36": -2.009, "red_v34": 1.484103033544056, "red_v79": 0.45129687500000015, "red_v87": -1.508, "red_v4": -1.641, "red_v85": -1.003, "red_v60": 0.45062500000000005, "red_v55": -1.0109999999999997, "red_v70": -2.002, "red_v52": 1.5036932378161705, "red_v8": -0.024000000000000014, "red_v75": 0.4816932378161727, "red_v29": 0.5026932378161701, "red_v46": -0.5119999999999999}, "policy_reward_mean": {"red_v84": -1.7614999999999994, "red": 2.8384358029825147, "red_v11": -1.0109999999999997, "red_v31": 0.459693237816174, "blue": -0.9363265575116119, "red_v58": -0.4750000000000008, "red_v95": -2.005, "red_v33": 0.14784661890808537, "red_v92": -1.5054999999999998, "red_v15": 0.39484661890808515, "red_v32": -1.008, "red_v2": -1.0219999999999985, "red_v59": -1.5074999999999998, "red_v7": 1.8265561585440553, "red_v25": 0.6708466189076019, "red_v38": 1.3813072088864717, "red_v66": -0.5254484832279724, "red_v28": 0.47493461444259333, "red_v83": 0.46799999999999997, "red_v22": -1.0299999999999976, "red_v21": 0.845, "red_v82": -1.0189999999999995, "red_v67": 0.016693237815689765, "red_v10": -1.577, "red_v71": -2.005, "red_v90": -2.013, "red_v45": -1.0149999999999986, "red_v61": -0.5239999999999998, "red_v36": -2.009, "red_v34": 1.484103033544056, "red_v79": 0.45129687500000015, "red_v87": -1.508, "red_v4": -1.641, "red_v85": -1.003, "red_v60": 0.45062500000000005, "red_v55": -1.0109999999999997, "red_v70": -2.002, "red_v52": -0.2806533810919132, "red_v8": -0.024000000000000014, "red_v75": 0.4816932378161727, "red_v29": 0.5026932378161701, "red_v46": -0.5119999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.364892980000001, 2.988036987815204, 2.8486052256323484, 0.6707939894426096, 2.434021362816172, 1.9750838628161704, 1.9533494878161717, -1.5279999999999547, 0.8354531250000002, 2.99033386281617, 2.4399119878161715, 2.9680057378161697, 2.471981489442592, 0.8320468750000001, 2.6509875000000003, 3.987589600632341, 2.4679744878161705, 2.3378338628161774, 2.162690625, 2.47489636281617, 2.3212493963602343, 2.486743658544055, 0.8852187500000002, 1.9811151128161701, 3.831302612816171, 2.4741186585440547, 2.4027764055891163, 2.4813374085440554, 2.4628651128161705, 2.483817542772942, 2.566674230000008, 3.999327521360225, 3.830330977258771, 2.4743807378161704, 2.48122448781617, 1.9770908644425924, 1.9879276128161703, 2.3904112927729466, 2.385599487816175, 0.8535994878161703, 2.464677612816171, 1.339224487816176, 3.82970886281617, 1.4785994878161706, 2.9710838628161707, 2.4278408644425924, 2.4032244878161713, 1.5427771006323945, 3.971339600631374, 0.882286987816172, 2.358958862816174, 1.4633182378161704, 0.8172343750000002, 2.408818237816173, 3.972777100631374, 2.4630526128161705, 2.4296619878161714, 2.4507244878161707, 0.9766932378161701, 0.9402869878161713, 1.6648, 1.479630042772942, 2.4688963628161704, 1.3354531250000001, 1.3531117300000006, 2.4494588628161713, 2.967083862816171, 4.440233771360228, 1.9650838628161709, 0.9559901128161703, 2.47859948781617, -0.08568750000000003, 2.1648, 0.6259276128161697, 0.8416030335440555, 2.4714119878161704, 2.463865112816171, 1.9715994878161704, 2.48922448781617, 0.9413182378161724, 2.438958862816171, 2.15239375, 2.4644658644425927, 1.3787367300000004, 0.8374531250000001, 4.4760739756323416, 1.3243651128161766, -5.372306762183822, 2.483228033544055, 1.9710838628161704, 2.465411292772942, 2.484337408544055, 1.9760908644425925, 3.5341052256323735, 2.9268026128161733, 3.9076989756323446, 3.98829272563234, 1.971271362816171, 2.4677557378161707, 2.9648651128161716], "episode_lengths": [29, 18, 122, 525, 55, 35, 46, 1280, 15, 19, 58, 28, 17, 17, 20, 31, 38, 115, 19, 31, 143, 19, 58, 25, 29, 27, 99, 21, 41, 24, 99, 22, 127, 36, 22, 14, 21, 90, 94, 158, 37, 86, 27, 30, 35, 30, 86, 675, 47, 130, 75, 56, 21, 88, 35, 45, 74, 54, 1280, 66, 16, 20, 31, 15, 23, 43, 35, 52, 35, 65, 30, 28, 16, 1045, 96, 26, 41, 30, 22, 56, 75, 18, 22, 15, 15, 36, 73, 1280, 24, 35, 26, 21, 14, 218, 61, 92, 30, 39, 44, 41], "policy_red_v84_reward": [-2.007999999999999, -1.515], "policy_red_v11_reward": [-0.005, -2.0169999999999995], "policy_red_v31_reward": [0.459693237816174], "policy_blue_reward": [1.9657939894425986, -1.0199999999999985, -2.0069999999999992, -2.0119999999999987, -1.0159999999999987, -0.008, -1.004, -0.011000000000000003, -1.0039999999999996, -1.003, -0.5119999999999999, -2.0089999999999995, -1.0079999999999993, -1.0079999999999998, -1.013, -1.0019999999999998, -1.0079999999999993, -1.0079999999999993, -2.0039999999999996, -2.006, -1.0430000000000001, -1.0119999999999998, -2.008, -0.010000000000000002, 2.41453125, -1.012999999999999, -1.015999999999999, -1.0109999999999992, -1.52, -2.003, -1.0119999999999993, -2.0060000000000002, -1.0119999999999991, -0.014000000000000005, -2.0119999999999996, -1.0069999999999995, -1.0109999999999992, -2.006, -1.016, -1.005, -2.0060000000000002, 5.130000000000006, -1.0059999999999996, -2.0109999999999992, -1.006, -1.0069999999999997, -2.0079999999999996, -1.0099999999999991], "policy_red_v58_reward": [-0.4750000000000008], "policy_red_v95_reward": [-2.005], "policy_red_v33_reward": [-0.002, 0.29769323781617074], "policy_red_v92_reward": [-2.006, -1.005], "policy_red_v15_reward": [0.50269323781617, 0.28700000000000025], "policy_red_v32_reward": [-1.008], "policy_red_v2_reward": [-1.030999999999998, -1.0129999999999992], "policy_red_v59_reward": [-1.0099999999999998, -2.005], "policy_red_v7_reward": [1.8265561585440553], "policy_red_v25_reward": [0.8450000000000001, 0.49669323781520364], "policy_red_v38_reward": [1.8980831677729433, 0.8645312500000002], "policy_red_v66_reward": [0.508103033544055, -1.559], "policy_red_v28_reward": [0.47493461444259333], "policy_red_v83_reward": [0.46799999999999997], "policy_red_v22_reward": [-1.0299999999999976], "policy_red_v21_reward": [0.845], "policy_red_v82_reward": [-1.0189999999999995], "policy_red_v67_reward": [-0.4713067621838243, 0.5046932378152038], "policy_red_v10_reward": [-1.577], "policy_red_v71_reward": [-2.005], "policy_red_v90_reward": [-2.013], "policy_red_v45_reward": [-1.0149999999999986], "policy_red_v61_reward": [-0.5239999999999998], "policy_red_v36_reward": [-2.009], "policy_red_v34_reward": [1.484103033544056], "policy_red_v79_reward": [0.45129687500000015], "policy_red_v87_reward": [-1.508], "policy_red_v4_reward": [-1.641], "policy_red_v85_reward": [-1.003], "policy_red_v60_reward": [0.45062500000000005], "policy_red_v55_reward": [-1.0109999999999997], "policy_red_v70_reward": [-2.002], "policy_red_v52_reward": [1.5036932378161705, -2.064999999999997], "policy_red_v8_reward": [-0.024000000000000014], "policy_red_v75_reward": [0.4816932378161727], "policy_red_v29_reward": [0.5026932378161701], "policy_red_v46_reward": [-0.5119999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8247018622641336, "mean_inference_ms": 7.65547144870758, "mean_action_processing_ms": 0.2925820770455051, "mean_env_wait_ms": 0.39401726370132856, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10013878345489502, "StateBufferConnector_ms": 0.004225969314575195, "ViewRequirementAgentConnector_ms": 0.11640894412994385}}, "episode_reward_max": 4.4760739756323416, "episode_reward_min": -5.372306762183822, "episode_reward_mean": 2.139593778108856, "episode_len_mean": 105.68, "episodes_this_iter": 62, "policy_reward_min": {"red_v84": -2.007999999999999, "red": -10.502306762183832, "red_v11": -2.0169999999999995, "red_v31": 0.459693237816174, "blue": -2.0119999999999996, "red_v58": -0.4750000000000008, "red_v95": -2.005, "red_v33": -0.002, "red_v92": -2.006, "red_v15": 0.28700000000000025, "red_v32": -1.008, "red_v2": -1.030999999999998, "red_v59": -2.005, "red_v7": 1.8265561585440553, "red_v25": 0.49669323781520364, "red_v38": 0.8645312500000002, "red_v66": -1.559, "red_v28": 0.47493461444259333, "red_v83": 0.46799999999999997, "red_v22": -1.0299999999999976, "red_v21": 0.845, "red_v82": -1.0189999999999995, "red_v67": -0.4713067621838243, "red_v10": -1.577, "red_v71": -2.005, "red_v90": -2.013, "red_v45": -1.0149999999999986, "red_v61": -0.5239999999999998, "red_v36": -2.009, "red_v34": 1.484103033544056, "red_v79": 0.45129687500000015, "red_v87": -1.508, "red_v4": -1.641, "red_v85": -1.003, "red_v60": 0.45062500000000005, "red_v55": -1.0109999999999997, "red_v70": -2.002, "red_v52": -2.064999999999997, "red_v8": -0.024000000000000014, "red_v75": 0.4816932378161727, "red_v29": 0.5026932378161701, "red_v46": -0.5119999999999999}, "policy_reward_max": {"red_v84": -1.515, "red": 3.99392761281617, "red_v11": -0.005, "red_v31": 0.459693237816174, "blue": 5.130000000000006, "red_v58": -0.4750000000000008, "red_v95": -2.005, "red_v33": 0.29769323781617074, "red_v92": -1.005, "red_v15": 0.50269323781617, "red_v32": -1.008, "red_v2": -1.0129999999999992, "red_v59": -1.0099999999999998, "red_v7": 1.8265561585440553, "red_v25": 0.8450000000000001, "red_v38": 1.8980831677729433, "red_v66": 0.508103033544055, "red_v28": 0.47493461444259333, "red_v83": 0.46799999999999997, "red_v22": -1.0299999999999976, "red_v21": 0.845, "red_v82": -1.0189999999999995, "red_v67": 0.5046932378152038, "red_v10": -1.577, "red_v71": -2.005, "red_v90": -2.013, "red_v45": -1.0149999999999986, "red_v61": -0.5239999999999998, "red_v36": -2.009, "red_v34": 1.484103033544056, "red_v79": 0.45129687500000015, "red_v87": -1.508, "red_v4": -1.641, "red_v85": -1.003, "red_v60": 0.45062500000000005, "red_v55": -1.0109999999999997, "red_v70": -2.002, "red_v52": 1.5036932378161705, "red_v8": -0.024000000000000014, "red_v75": 0.4816932378161727, "red_v29": 0.5026932378161701, "red_v46": -0.5119999999999999}, "policy_reward_mean": {"red_v84": -1.7614999999999994, "red": 2.8384358029825147, "red_v11": -1.0109999999999997, "red_v31": 0.459693237816174, "blue": -0.9363265575116119, "red_v58": -0.4750000000000008, "red_v95": -2.005, "red_v33": 0.14784661890808537, "red_v92": -1.5054999999999998, "red_v15": 0.39484661890808515, "red_v32": -1.008, "red_v2": -1.0219999999999985, "red_v59": -1.5074999999999998, "red_v7": 1.8265561585440553, "red_v25": 0.6708466189076019, "red_v38": 1.3813072088864717, "red_v66": -0.5254484832279724, "red_v28": 0.47493461444259333, "red_v83": 0.46799999999999997, "red_v22": -1.0299999999999976, "red_v21": 0.845, "red_v82": -1.0189999999999995, "red_v67": 0.016693237815689765, "red_v10": -1.577, "red_v71": -2.005, "red_v90": -2.013, "red_v45": -1.0149999999999986, "red_v61": -0.5239999999999998, "red_v36": -2.009, "red_v34": 1.484103033544056, "red_v79": 0.45129687500000015, "red_v87": -1.508, "red_v4": -1.641, "red_v85": -1.003, "red_v60": 0.45062500000000005, "red_v55": -1.0109999999999997, "red_v70": -2.002, "red_v52": -0.2806533810919132, "red_v8": -0.024000000000000014, "red_v75": 0.4816932378161727, "red_v29": 0.5026932378161701, "red_v46": -0.5119999999999999}, "hist_stats": {"episode_reward": [1.364892980000001, 2.988036987815204, 2.8486052256323484, 0.6707939894426096, 2.434021362816172, 1.9750838628161704, 1.9533494878161717, -1.5279999999999547, 0.8354531250000002, 2.99033386281617, 2.4399119878161715, 2.9680057378161697, 2.471981489442592, 0.8320468750000001, 2.6509875000000003, 3.987589600632341, 2.4679744878161705, 2.3378338628161774, 2.162690625, 2.47489636281617, 2.3212493963602343, 2.486743658544055, 0.8852187500000002, 1.9811151128161701, 3.831302612816171, 2.4741186585440547, 2.4027764055891163, 2.4813374085440554, 2.4628651128161705, 2.483817542772942, 2.566674230000008, 3.999327521360225, 3.830330977258771, 2.4743807378161704, 2.48122448781617, 1.9770908644425924, 1.9879276128161703, 2.3904112927729466, 2.385599487816175, 0.8535994878161703, 2.464677612816171, 1.339224487816176, 3.82970886281617, 1.4785994878161706, 2.9710838628161707, 2.4278408644425924, 2.4032244878161713, 1.5427771006323945, 3.971339600631374, 0.882286987816172, 2.358958862816174, 1.4633182378161704, 0.8172343750000002, 2.408818237816173, 3.972777100631374, 2.4630526128161705, 2.4296619878161714, 2.4507244878161707, 0.9766932378161701, 0.9402869878161713, 1.6648, 1.479630042772942, 2.4688963628161704, 1.3354531250000001, 1.3531117300000006, 2.4494588628161713, 2.967083862816171, 4.440233771360228, 1.9650838628161709, 0.9559901128161703, 2.47859948781617, -0.08568750000000003, 2.1648, 0.6259276128161697, 0.8416030335440555, 2.4714119878161704, 2.463865112816171, 1.9715994878161704, 2.48922448781617, 0.9413182378161724, 2.438958862816171, 2.15239375, 2.4644658644425927, 1.3787367300000004, 0.8374531250000001, 4.4760739756323416, 1.3243651128161766, -5.372306762183822, 2.483228033544055, 1.9710838628161704, 2.465411292772942, 2.484337408544055, 1.9760908644425925, 3.5341052256323735, 2.9268026128161733, 3.9076989756323446, 3.98829272563234, 1.971271362816171, 2.4677557378161707, 2.9648651128161716], "episode_lengths": [29, 18, 122, 525, 55, 35, 46, 1280, 15, 19, 58, 28, 17, 17, 20, 31, 38, 115, 19, 31, 143, 19, 58, 25, 29, 27, 99, 21, 41, 24, 99, 22, 127, 36, 22, 14, 21, 90, 94, 158, 37, 86, 27, 30, 35, 30, 86, 675, 47, 130, 75, 56, 21, 88, 35, 45, 74, 54, 1280, 66, 16, 20, 31, 15, 23, 43, 35, 52, 35, 65, 30, 28, 16, 1045, 96, 26, 41, 30, 22, 56, 75, 18, 22, 15, 15, 36, 73, 1280, 24, 35, 26, 21, 14, 218, 61, 92, 30, 39, 44, 41], "policy_red_v84_reward": [-2.007999999999999, -1.515], "policy_red_v11_reward": [-0.005, -2.0169999999999995], "policy_red_v31_reward": [0.459693237816174], "policy_blue_reward": [1.9657939894425986, -1.0199999999999985, -2.0069999999999992, -2.0119999999999987, -1.0159999999999987, -0.008, -1.004, -0.011000000000000003, -1.0039999999999996, -1.003, -0.5119999999999999, -2.0089999999999995, -1.0079999999999993, -1.0079999999999998, -1.013, -1.0019999999999998, -1.0079999999999993, -1.0079999999999993, -2.0039999999999996, -2.006, -1.0430000000000001, -1.0119999999999998, -2.008, -0.010000000000000002, 2.41453125, -1.012999999999999, -1.015999999999999, -1.0109999999999992, -1.52, -2.003, -1.0119999999999993, -2.0060000000000002, -1.0119999999999991, -0.014000000000000005, -2.0119999999999996, -1.0069999999999995, -1.0109999999999992, -2.006, -1.016, -1.005, -2.0060000000000002, 5.130000000000006, -1.0059999999999996, -2.0109999999999992, -1.006, -1.0069999999999997, -2.0079999999999996, -1.0099999999999991], "policy_red_v58_reward": [-0.4750000000000008], "policy_red_v95_reward": [-2.005], "policy_red_v33_reward": [-0.002, 0.29769323781617074], "policy_red_v92_reward": [-2.006, -1.005], "policy_red_v15_reward": [0.50269323781617, 0.28700000000000025], "policy_red_v32_reward": [-1.008], "policy_red_v2_reward": [-1.030999999999998, -1.0129999999999992], "policy_red_v59_reward": [-1.0099999999999998, -2.005], "policy_red_v7_reward": [1.8265561585440553], "policy_red_v25_reward": [0.8450000000000001, 0.49669323781520364], "policy_red_v38_reward": [1.8980831677729433, 0.8645312500000002], "policy_red_v66_reward": [0.508103033544055, -1.559], "policy_red_v28_reward": [0.47493461444259333], "policy_red_v83_reward": [0.46799999999999997], "policy_red_v22_reward": [-1.0299999999999976], "policy_red_v21_reward": [0.845], "policy_red_v82_reward": [-1.0189999999999995], "policy_red_v67_reward": [-0.4713067621838243, 0.5046932378152038], "policy_red_v10_reward": [-1.577], "policy_red_v71_reward": [-2.005], "policy_red_v90_reward": [-2.013], "policy_red_v45_reward": [-1.0149999999999986], "policy_red_v61_reward": [-0.5239999999999998], "policy_red_v36_reward": [-2.009], "policy_red_v34_reward": [1.484103033544056], "policy_red_v79_reward": [0.45129687500000015], "policy_red_v87_reward": [-1.508], "policy_red_v4_reward": [-1.641], "policy_red_v85_reward": [-1.003], "policy_red_v60_reward": [0.45062500000000005], "policy_red_v55_reward": [-1.0109999999999997], "policy_red_v70_reward": [-2.002], "policy_red_v52_reward": [1.5036932378161705, -2.064999999999997], "policy_red_v8_reward": [-0.024000000000000014], "policy_red_v75_reward": [0.4816932378161727], "policy_red_v29_reward": [0.5026932378161701], "policy_red_v46_reward": [-0.5119999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8247018622641336, "mean_inference_ms": 7.65547144870758, "mean_action_processing_ms": 0.2925820770455051, "mean_env_wait_ms": 0.39401726370132856, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10013878345489502, "StateBufferConnector_ms": 0.004225969314575195, "ViewRequirementAgentConnector_ms": 0.11640894412994385}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 195.36264858642033, "num_env_steps_trained_throughput_per_sec": 195.36264858642033, "timesteps_total": 520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 20197.698, "sample_time_ms": 1253.406, "learn_time_ms": 18858.806, "learn_throughput": 212.103, "synch_weights_time_ms": 81.815}, "counters": {"num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "episodes_total": 3355, "training_iteration": 130, "trial_id": "a9680_00000", "date": "2023-09-24_03-25-39", "timestamp": 1695540339, "time_this_iter_s": 20.485584259033203, "time_total_s": 2595.7433404922485, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1da10970>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1dbe0c10>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1dbe0ca0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2595.7433404922485, "iterations_since_restore": 130, "perf": {"cpu_util_percent": 5.4942857142857155, "ram_util_percent": 28.36857142857143}, "win_rate": 0.77, "league_size": 99}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9537236648301284, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.06452124013497572, "policy_loss": -0.0394953567670503, "vf_loss": 0.19281856892630458, "vf_explained_var": 0.8208149838571747, "kl": 0.012982281670086119, "entropy": 1.15572728831321, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 125280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_agent_steps_sampled": 1048000, "num_agent_steps_trained": 1048000}, "sampler_results": {"episode_reward_max": 4.4760739756323416, "episode_reward_min": -5.372306762183822, "episode_reward_mean": 2.1481143751176823, "episode_len_mean": 88.22, "episode_media": {}, "episodes_this_iter": 73, "policy_reward_min": {"red_v4": -1.641, "red": -10.502306762183832, "red_v66": -1.559, "blue": -2.0189999999999984, "red_v2": -2.007999999999999, "red_v85": -1.003, "red_v60": 0.45062500000000005, "red_v55": -1.0109999999999997, "red_v70": -2.002, "red_v52": -2.064999999999997, "red_v59": -2.005, "red_v33": 0.29769323781617074, "red_v8": -0.024000000000000014, "red_v75": -2.0039999999999996, "red_v29": 0.5026932378161701, "red_v46": -0.5119999999999999, "red_v50": -2.023999999999999, "red_v58": -1.003, "red_v95": -2.0069999999999997, "red_v90": 1.471693237816172, "red_v37": 1.0026932378152038, "red_v64": 0.5006932378161704, "red_v20": 0.435, "red_v49": 0.5066932378161697, "red_v38": -0.033306762183827776, "red_v23": 0.46969323781617256, "red_v62": -1.0129999999999997, "red_v43": -1.0039999999999998, "red_v97": -0.5189999999999999, "red_v18": -2.019999999999999, "red_v9": -1.002, "red_v83": 1.49369323781617, "red_v21": 0.39528360500000026, "red_v69": -2.001, "red_v7": -2.0039999999999996, "red_v13": -1.5229999999999992, "red_v84": 0.5056932378161698, "red_v81": -2.003, "red_v71": -2.008, "red_v91": -2.0089999999999995, "red_v77": -0.563, "red_v45": -1.001, "red_v27": -1.0249999999999992, "red_v63": -0.5810000000000008, "red_v31": 0.488}, "policy_reward_max": {"red_v4": -1.641, "red": 3.99011511281617, "red_v66": -1.559, "blue": 5.130000000000006, "red_v2": -1.0129999999999992, "red_v85": -1.003, "red_v60": 0.45062500000000005, "red_v55": -1.0109999999999997, "red_v70": -2.002, "red_v52": 1.5036932378161705, "red_v59": -2.005, "red_v33": 0.29769323781617074, "red_v8": -0.024000000000000014, "red_v75": 0.4816932378161727, "red_v29": 0.5026932378161701, "red_v46": -0.5119999999999999, "red_v50": 3.035784375000004, "red_v58": -1.003, "red_v95": -2.0069999999999997, "red_v90": 1.471693237816172, "red_v37": 1.0026932378152038, "red_v64": 0.5006932378161704, "red_v20": 0.435, "red_v49": 0.5066932378161697, "red_v38": -0.033306762183827776, "red_v23": 0.46969323781617256, "red_v62": -1.0129999999999997, "red_v43": 0.5026932378152035, "red_v97": -0.5189999999999999, "red_v18": -2.019999999999999, "red_v9": -1.002, "red_v83": 1.49369323781617, "red_v21": 0.39528360500000026, "red_v69": -2.001, "red_v7": -2.0039999999999996, "red_v13": -1.5229999999999992, "red_v84": 0.5056932378161698, "red_v81": -2.003, "red_v71": -2.008, "red_v91": -2.0039999999999996, "red_v77": -0.563, "red_v45": -1.001, "red_v27": -1.0249999999999992, "red_v63": 0.5421030335440605, "red_v31": 1.49969323781617}, "policy_reward_mean": {"red_v4": -1.641, "red": 3.0234793616879956, "red_v66": -1.559, "blue": -1.1999148936170205, "red_v2": -1.510499999999999, "red_v85": -1.003, "red_v60": 0.45062500000000005, "red_v55": -1.0109999999999997, "red_v70": -2.002, "red_v52": -0.530768920727942, "red_v59": -2.005, "red_v33": 0.29769323781617074, "red_v8": -0.024000000000000014, "red_v75": -0.7611533810919134, "red_v29": 0.5026932378161701, "red_v46": -0.5119999999999999, "red_v50": -0.329738541666665, "red_v58": -1.003, "red_v95": -2.0069999999999997, "red_v90": 1.471693237816172, "red_v37": 1.0026932378152038, "red_v64": 0.5006932378161704, "red_v20": 0.435, "red_v49": 0.5066932378161697, "red_v38": -0.033306762183827776, "red_v23": 0.46969323781617256, "red_v62": -1.0129999999999997, "red_v43": -0.25065338109239815, "red_v97": -0.5189999999999999, "red_v18": -2.019999999999999, "red_v9": -1.002, "red_v83": 1.49369323781617, "red_v21": 0.39528360500000026, "red_v69": -2.001, "red_v7": -2.0039999999999996, "red_v13": -1.5229999999999992, "red_v84": 0.5056932378161698, "red_v81": -2.003, "red_v71": -2.008, "red_v91": -2.0064999999999995, "red_v77": -0.563, "red_v45": -1.001, "red_v27": -1.0249999999999992, "red_v63": -0.01944848322797016, "red_v31": 0.993846618908085}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.6259276128161697, 0.8416030335440555, 2.4714119878161704, 2.463865112816171, 1.9715994878161704, 2.48922448781617, 0.9413182378161724, 2.438958862816171, 2.15239375, 2.4644658644425927, 1.3787367300000004, 0.8374531250000001, 4.4760739756323416, 1.3243651128161766, -5.372306762183822, 2.483228033544055, 1.9710838628161704, 2.465411292772942, 2.484337408544055, 1.9760908644425925, 3.5341052256323735, 2.9268026128161733, 3.9076989756323446, 3.98829272563234, 1.971271362816171, 2.4677557378161707, 2.9648651128161716, 2.5084776128161783, 2.4891499085440545, 2.3773304800000004, 1.1605031250000002, 1.343859375, 2.48622448781617, 2.475490112816171, 4.433902100632343, 1.4780057378161702, 2.48222448781617, 3.4844802256313745, 3.9665271006323417, 3.403943237816171, 2.473634283544055, 2.4662713628161708, 3.9914021006323397, 1.9731932378161705, 0.8215369878161711, 1.9556776128161704, 1.408443237816173, 2.3442302256323493, 3.9032146006323454, 2.47581823781617, 2.1830838628161864, 2.4855213628161703, 1.49303698781617, 0.4551250000000002, 1.4641151128161711, 2.47941198781617, 2.4089901128161735, 4.448714600632341, 1.4938530335440552, 3.8894335135440556, 0.8435625000000001, 1.4524581677729431, 1.6652062500000002, 2.4659814894425924, 2.47470886281617, 1.4579744878161707, 0.9264744878161725, 0.9514936585440571, 3.97715210063234, 1.1648, 1.9821151128161705, 1.940615112816172, 1.950490112816171, 0.9825249085440553, 2.4587627394425926, 2.4915561585440553, 1.1618000000000004, 2.9187869878161714, 2.4538338628161718, 2.963677612816171, 0.8279375, 2.48378698781617, 1.4713026128152038, 1.1689093750000004, 0.8257500000000001, 1.9714901128161706, 2.443240112816172, 1.9561619878161702, 1.3647962713602904, 2.4577869878161707, 2.48452136281617, 2.4841151128161707, 3.9861052256313734, -1.9979999999998959, 2.990853033544055, 1.9724901128161703, 4.463667725632342, 2.4563494878161714, 2.4743026128161705, 2.49103698781617], "episode_lengths": [1045, 96, 26, 41, 30, 22, 56, 75, 18, 22, 15, 15, 36, 73, 1280, 24, 35, 26, 21, 14, 218, 61, 92, 30, 39, 44, 41, 117, 17, 17, 15, 13, 22, 33, 59, 28, 22, 34, 51, 48, 22, 39, 27, 32, 178, 37, 80, 114, 87, 24, 227, 23, 18, 24, 25, 26, 65, 55, 16, 17, 12, 43, 14, 17, 27, 38, 70, 35, 43, 16, 25, 57, 33, 25, 23, 15, 16, 34, 51, 37, 20, 34, 29, 13, 16, 33, 49, 42, 1280, 34, 23, 25, 26, 1280, 16, 33, 38, 46, 29, 18], "policy_red_v4_reward": [-1.641], "policy_red_v66_reward": [-1.559], "policy_blue_reward": [-1.0109999999999992, -2.006, -1.016, -1.005, -2.0060000000000002, 5.130000000000006, -1.0059999999999996, -2.0109999999999992, -1.006, -1.0069999999999997, -2.0079999999999996, -1.0099999999999991, -1.002, -1.0049999999999994, -1.009999999999999, -2.008, -1.0049999999999997, -1.0099999999999996, -1.0079999999999993, -1.553, -2.01, -2.0189999999999984, -1.0699999999999936, -2.0029999999999997, -2.0029999999999997, -2.012999999999999, -1.0109999999999995, -1.011, -2.0139999999999993, -1.5199999999999998, -2.0169999999999986, -1.504, -1.0079999999999998, -1.0039999999999998, -1.015999999999999, -0.014000000000000002, -2.0069999999999997, -2.005, -2.011999999999999, -0.517, -1.003, -1.0069999999999992, -0.006, -2.0079999999999996, -1.0169999999999986, -1.0099999999999998, -1.0039999999999998], "policy_red_v2_reward": [-1.0129999999999992, -2.007999999999999], "policy_red_v85_reward": [-1.003], "policy_red_v60_reward": [0.45062500000000005], "policy_red_v55_reward": [-1.0109999999999997], "policy_red_v70_reward": [-2.002], "policy_red_v52_reward": [1.5036932378161705, -2.064999999999997, -1.0309999999999997], "policy_red_v59_reward": [-2.005], "policy_red_v33_reward": [0.29769323781617074], "policy_red_v8_reward": [-0.024000000000000014], "policy_red_v75_reward": [0.4816932378161727, -2.0039999999999996], "policy_red_v29_reward": [0.5026932378161701], "policy_red_v46_reward": [-0.5119999999999999], "policy_red_v50_reward": [3.035784375000004, -2.001, -2.023999999999999], "policy_red_v58_reward": [-1.003], "policy_red_v95_reward": [-2.0069999999999997], "policy_red_v90_reward": [1.471693237816172], "policy_red_v37_reward": [1.0026932378152038], "policy_red_v64_reward": [0.5006932378161704], "policy_red_v20_reward": [0.435], "policy_red_v49_reward": [0.5066932378161697], "policy_red_v38_reward": [-0.033306762183827776], "policy_red_v23_reward": [0.46969323781617256], "policy_red_v62_reward": [-1.0129999999999997], "policy_red_v43_reward": [-1.0039999999999998, 0.5026932378152035], "policy_red_v97_reward": [-0.5189999999999999], "policy_red_v18_reward": [-2.019999999999999], "policy_red_v9_reward": [-1.002], "policy_red_v83_reward": [1.49369323781617], "policy_red_v21_reward": [0.39528360500000026], "policy_red_v69_reward": [-2.001], "policy_red_v7_reward": [-2.0039999999999996], "policy_red_v13_reward": [-1.5229999999999992], "policy_red_v84_reward": [0.5056932378161698], "policy_red_v81_reward": [-2.003], "policy_red_v71_reward": [-2.008], "policy_red_v91_reward": [-2.0039999999999996, -2.0089999999999995], "policy_red_v77_reward": [-0.563], "policy_red_v45_reward": [-1.001], "policy_red_v27_reward": [-1.0249999999999992], "policy_red_v63_reward": [0.5421030335440605, -0.5810000000000008], "policy_red_v31_reward": [0.488, 1.49969323781617]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8273080850882928, "mean_inference_ms": 7.682217823527258, "mean_action_processing_ms": 0.2935829420247968, "mean_env_wait_ms": 0.3952206358207775, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09799778461456299, "StateBufferConnector_ms": 0.0041419267654418945, "ViewRequirementAgentConnector_ms": 0.11484670639038086}}, "episode_reward_max": 4.4760739756323416, "episode_reward_min": -5.372306762183822, "episode_reward_mean": 2.1481143751176823, "episode_len_mean": 88.22, "episodes_this_iter": 73, "policy_reward_min": {"red_v4": -1.641, "red": -10.502306762183832, "red_v66": -1.559, "blue": -2.0189999999999984, "red_v2": -2.007999999999999, "red_v85": -1.003, "red_v60": 0.45062500000000005, "red_v55": -1.0109999999999997, "red_v70": -2.002, "red_v52": -2.064999999999997, "red_v59": -2.005, "red_v33": 0.29769323781617074, "red_v8": -0.024000000000000014, "red_v75": -2.0039999999999996, "red_v29": 0.5026932378161701, "red_v46": -0.5119999999999999, "red_v50": -2.023999999999999, "red_v58": -1.003, "red_v95": -2.0069999999999997, "red_v90": 1.471693237816172, "red_v37": 1.0026932378152038, "red_v64": 0.5006932378161704, "red_v20": 0.435, "red_v49": 0.5066932378161697, "red_v38": -0.033306762183827776, "red_v23": 0.46969323781617256, "red_v62": -1.0129999999999997, "red_v43": -1.0039999999999998, "red_v97": -0.5189999999999999, "red_v18": -2.019999999999999, "red_v9": -1.002, "red_v83": 1.49369323781617, "red_v21": 0.39528360500000026, "red_v69": -2.001, "red_v7": -2.0039999999999996, "red_v13": -1.5229999999999992, "red_v84": 0.5056932378161698, "red_v81": -2.003, "red_v71": -2.008, "red_v91": -2.0089999999999995, "red_v77": -0.563, "red_v45": -1.001, "red_v27": -1.0249999999999992, "red_v63": -0.5810000000000008, "red_v31": 0.488}, "policy_reward_max": {"red_v4": -1.641, "red": 3.99011511281617, "red_v66": -1.559, "blue": 5.130000000000006, "red_v2": -1.0129999999999992, "red_v85": -1.003, "red_v60": 0.45062500000000005, "red_v55": -1.0109999999999997, "red_v70": -2.002, "red_v52": 1.5036932378161705, "red_v59": -2.005, "red_v33": 0.29769323781617074, "red_v8": -0.024000000000000014, "red_v75": 0.4816932378161727, "red_v29": 0.5026932378161701, "red_v46": -0.5119999999999999, "red_v50": 3.035784375000004, "red_v58": -1.003, "red_v95": -2.0069999999999997, "red_v90": 1.471693237816172, "red_v37": 1.0026932378152038, "red_v64": 0.5006932378161704, "red_v20": 0.435, "red_v49": 0.5066932378161697, "red_v38": -0.033306762183827776, "red_v23": 0.46969323781617256, "red_v62": -1.0129999999999997, "red_v43": 0.5026932378152035, "red_v97": -0.5189999999999999, "red_v18": -2.019999999999999, "red_v9": -1.002, "red_v83": 1.49369323781617, "red_v21": 0.39528360500000026, "red_v69": -2.001, "red_v7": -2.0039999999999996, "red_v13": -1.5229999999999992, "red_v84": 0.5056932378161698, "red_v81": -2.003, "red_v71": -2.008, "red_v91": -2.0039999999999996, "red_v77": -0.563, "red_v45": -1.001, "red_v27": -1.0249999999999992, "red_v63": 0.5421030335440605, "red_v31": 1.49969323781617}, "policy_reward_mean": {"red_v4": -1.641, "red": 3.0234793616879956, "red_v66": -1.559, "blue": -1.1999148936170205, "red_v2": -1.510499999999999, "red_v85": -1.003, "red_v60": 0.45062500000000005, "red_v55": -1.0109999999999997, "red_v70": -2.002, "red_v52": -0.530768920727942, "red_v59": -2.005, "red_v33": 0.29769323781617074, "red_v8": -0.024000000000000014, "red_v75": -0.7611533810919134, "red_v29": 0.5026932378161701, "red_v46": -0.5119999999999999, "red_v50": -0.329738541666665, "red_v58": -1.003, "red_v95": -2.0069999999999997, "red_v90": 1.471693237816172, "red_v37": 1.0026932378152038, "red_v64": 0.5006932378161704, "red_v20": 0.435, "red_v49": 0.5066932378161697, "red_v38": -0.033306762183827776, "red_v23": 0.46969323781617256, "red_v62": -1.0129999999999997, "red_v43": -0.25065338109239815, "red_v97": -0.5189999999999999, "red_v18": -2.019999999999999, "red_v9": -1.002, "red_v83": 1.49369323781617, "red_v21": 0.39528360500000026, "red_v69": -2.001, "red_v7": -2.0039999999999996, "red_v13": -1.5229999999999992, "red_v84": 0.5056932378161698, "red_v81": -2.003, "red_v71": -2.008, "red_v91": -2.0064999999999995, "red_v77": -0.563, "red_v45": -1.001, "red_v27": -1.0249999999999992, "red_v63": -0.01944848322797016, "red_v31": 0.993846618908085}, "hist_stats": {"episode_reward": [0.6259276128161697, 0.8416030335440555, 2.4714119878161704, 2.463865112816171, 1.9715994878161704, 2.48922448781617, 0.9413182378161724, 2.438958862816171, 2.15239375, 2.4644658644425927, 1.3787367300000004, 0.8374531250000001, 4.4760739756323416, 1.3243651128161766, -5.372306762183822, 2.483228033544055, 1.9710838628161704, 2.465411292772942, 2.484337408544055, 1.9760908644425925, 3.5341052256323735, 2.9268026128161733, 3.9076989756323446, 3.98829272563234, 1.971271362816171, 2.4677557378161707, 2.9648651128161716, 2.5084776128161783, 2.4891499085440545, 2.3773304800000004, 1.1605031250000002, 1.343859375, 2.48622448781617, 2.475490112816171, 4.433902100632343, 1.4780057378161702, 2.48222448781617, 3.4844802256313745, 3.9665271006323417, 3.403943237816171, 2.473634283544055, 2.4662713628161708, 3.9914021006323397, 1.9731932378161705, 0.8215369878161711, 1.9556776128161704, 1.408443237816173, 2.3442302256323493, 3.9032146006323454, 2.47581823781617, 2.1830838628161864, 2.4855213628161703, 1.49303698781617, 0.4551250000000002, 1.4641151128161711, 2.47941198781617, 2.4089901128161735, 4.448714600632341, 1.4938530335440552, 3.8894335135440556, 0.8435625000000001, 1.4524581677729431, 1.6652062500000002, 2.4659814894425924, 2.47470886281617, 1.4579744878161707, 0.9264744878161725, 0.9514936585440571, 3.97715210063234, 1.1648, 1.9821151128161705, 1.940615112816172, 1.950490112816171, 0.9825249085440553, 2.4587627394425926, 2.4915561585440553, 1.1618000000000004, 2.9187869878161714, 2.4538338628161718, 2.963677612816171, 0.8279375, 2.48378698781617, 1.4713026128152038, 1.1689093750000004, 0.8257500000000001, 1.9714901128161706, 2.443240112816172, 1.9561619878161702, 1.3647962713602904, 2.4577869878161707, 2.48452136281617, 2.4841151128161707, 3.9861052256313734, -1.9979999999998959, 2.990853033544055, 1.9724901128161703, 4.463667725632342, 2.4563494878161714, 2.4743026128161705, 2.49103698781617], "episode_lengths": [1045, 96, 26, 41, 30, 22, 56, 75, 18, 22, 15, 15, 36, 73, 1280, 24, 35, 26, 21, 14, 218, 61, 92, 30, 39, 44, 41, 117, 17, 17, 15, 13, 22, 33, 59, 28, 22, 34, 51, 48, 22, 39, 27, 32, 178, 37, 80, 114, 87, 24, 227, 23, 18, 24, 25, 26, 65, 55, 16, 17, 12, 43, 14, 17, 27, 38, 70, 35, 43, 16, 25, 57, 33, 25, 23, 15, 16, 34, 51, 37, 20, 34, 29, 13, 16, 33, 49, 42, 1280, 34, 23, 25, 26, 1280, 16, 33, 38, 46, 29, 18], "policy_red_v4_reward": [-1.641], "policy_red_v66_reward": [-1.559], "policy_blue_reward": [-1.0109999999999992, -2.006, -1.016, -1.005, -2.0060000000000002, 5.130000000000006, -1.0059999999999996, -2.0109999999999992, -1.006, -1.0069999999999997, -2.0079999999999996, -1.0099999999999991, -1.002, -1.0049999999999994, -1.009999999999999, -2.008, -1.0049999999999997, -1.0099999999999996, -1.0079999999999993, -1.553, -2.01, -2.0189999999999984, -1.0699999999999936, -2.0029999999999997, -2.0029999999999997, -2.012999999999999, -1.0109999999999995, -1.011, -2.0139999999999993, -1.5199999999999998, -2.0169999999999986, -1.504, -1.0079999999999998, -1.0039999999999998, -1.015999999999999, -0.014000000000000002, -2.0069999999999997, -2.005, -2.011999999999999, -0.517, -1.003, -1.0069999999999992, -0.006, -2.0079999999999996, -1.0169999999999986, -1.0099999999999998, -1.0039999999999998], "policy_red_v2_reward": [-1.0129999999999992, -2.007999999999999], "policy_red_v85_reward": [-1.003], "policy_red_v60_reward": [0.45062500000000005], "policy_red_v55_reward": [-1.0109999999999997], "policy_red_v70_reward": [-2.002], "policy_red_v52_reward": [1.5036932378161705, -2.064999999999997, -1.0309999999999997], "policy_red_v59_reward": [-2.005], "policy_red_v33_reward": [0.29769323781617074], "policy_red_v8_reward": [-0.024000000000000014], "policy_red_v75_reward": [0.4816932378161727, -2.0039999999999996], "policy_red_v29_reward": [0.5026932378161701], "policy_red_v46_reward": [-0.5119999999999999], "policy_red_v50_reward": [3.035784375000004, -2.001, -2.023999999999999], "policy_red_v58_reward": [-1.003], "policy_red_v95_reward": [-2.0069999999999997], "policy_red_v90_reward": [1.471693237816172], "policy_red_v37_reward": [1.0026932378152038], "policy_red_v64_reward": [0.5006932378161704], "policy_red_v20_reward": [0.435], "policy_red_v49_reward": [0.5066932378161697], "policy_red_v38_reward": [-0.033306762183827776], "policy_red_v23_reward": [0.46969323781617256], "policy_red_v62_reward": [-1.0129999999999997], "policy_red_v43_reward": [-1.0039999999999998, 0.5026932378152035], "policy_red_v97_reward": [-0.5189999999999999], "policy_red_v18_reward": [-2.019999999999999], "policy_red_v9_reward": [-1.002], "policy_red_v83_reward": [1.49369323781617], "policy_red_v21_reward": [0.39528360500000026], "policy_red_v69_reward": [-2.001], "policy_red_v7_reward": [-2.0039999999999996], "policy_red_v13_reward": [-1.5229999999999992], "policy_red_v84_reward": [0.5056932378161698], "policy_red_v81_reward": [-2.003], "policy_red_v71_reward": [-2.008], "policy_red_v91_reward": [-2.0039999999999996, -2.0089999999999995], "policy_red_v77_reward": [-0.563], "policy_red_v45_reward": [-1.001], "policy_red_v27_reward": [-1.0249999999999992], "policy_red_v63_reward": [0.5421030335440605, -0.5810000000000008], "policy_red_v31_reward": [0.488, 1.49969323781617]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8273080850882928, "mean_inference_ms": 7.682217823527258, "mean_action_processing_ms": 0.2935829420247968, "mean_env_wait_ms": 0.3952206358207775, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.09799778461456299, "StateBufferConnector_ms": 0.0041419267654418945, "ViewRequirementAgentConnector_ms": 0.11484670639038086}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1048000, "num_agent_steps_trained": 1048000, "num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.53059542692142, "num_env_steps_trained_throughput_per_sec": 200.53059542692142, "timesteps_total": 524000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1048000, "timers": {"training_iteration_time_ms": 20223.861, "sample_time_ms": 1253.776, "learn_time_ms": 18884.588, "learn_throughput": 211.813, "synch_weights_time_ms": 81.846}, "counters": {"num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_agent_steps_sampled": 1048000, "num_agent_steps_trained": 1048000}, "done": false, "episodes_total": 3428, "training_iteration": 131, "trial_id": "a9680_00000", "date": "2023-09-24_03-26-09", "timestamp": 1695540369, "time_this_iter_s": 19.957374811172485, "time_total_s": 2615.700715303421, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1dc7ba30>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1db52680>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1db525f0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2615.700715303421, "iterations_since_restore": 131, "perf": {"cpu_util_percent": 5.109302325581396, "ram_util_percent": 28.479069767441857}, "win_rate": 0.8, "league_size": 100}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5607719036440053, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.01758064084909468, "policy_loss": -0.03859159879987904, "vf_loss": 0.09955210378199505, "vf_explained_var": 0.8966802712529898, "kl": 0.011193315031133959, "entropy": 1.1592997992411256, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 126240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "sampler_results": {"episode_reward_max": 4.965557655589113, "episode_reward_min": -1.9979999999998959, "episode_reward_mean": 2.244216419721363, "episode_len_mean": 61.65, "episode_media": {}, "episodes_this_iter": 60, "policy_reward_min": {"red_v69": -2.001, "red": -1.4169999999999585, "blue": -2.0169999999999986, "red_v7": -2.0039999999999996, "red_v13": -1.5229999999999992, "red_v84": 0.5056932378161698, "red_v81": -2.003, "red_v71": -2.008, "red_v50": -2.023999999999999, "red_v91": -2.0089999999999995, "red_v77": -0.563, "red_v75": -2.0039999999999996, "red_v45": -1.001, "red_v27": -1.0249999999999992, "red_v63": -1.0259999999999991, "red_v31": 0.488, "red_v43": 0.5026932378152035, "red_v22": -0.543, "red_v74": 1.9237968749999999, "red_v52": 1.5026932378161701, "red_v28": -1.007, "red_v86": -2.0039999999999996, "red_v29": 0.8530000000000001, "red_v44": -1.0159999999999987, "red_v58": -2.005, "red_v65": -2.0069999999999997, "red_v11": -1.0069999999999997, "red_v41": -1.52, "red_v53": 0.5026932378152034, "red_v15": 0.17305000000000026, "red_v73": -2.013, "red_v76": -0.55, "red_v19": 1.4976932378161705, "red_v83": -2.002, "red_v16": 0.5066925427729421, "red_v18": -1.0159999999999996, "red_v30": -1.0019999999999998, "red_v79": -2.002, "red_v17": -2.029, "red_v85": -2.0069999999999997, "red_v26": 3.397399908544055, "red_v20": -0.15499999999999958}, "policy_reward_max": {"red_v69": -2.001, "red": 3.99011511281617, "blue": 0.488, "red_v7": -2.0039999999999996, "red_v13": -1.5229999999999992, "red_v84": 0.5056932378161698, "red_v81": -0.51, "red_v71": -2.008, "red_v50": -2.023999999999999, "red_v91": -2.0039999999999996, "red_v77": -0.563, "red_v75": 2.0006925427729416, "red_v45": -1.001, "red_v27": -1.0249999999999992, "red_v63": 2.3513281249999998, "red_v31": 1.49969323781617, "red_v43": 0.5026932378152035, "red_v22": -0.543, "red_v74": 1.9237968749999999, "red_v52": 1.5026932378161701, "red_v28": -1.007, "red_v86": -2.0039999999999996, "red_v29": 0.8530000000000001, "red_v44": -1.0159999999999987, "red_v58": -2.005, "red_v65": 0.841, "red_v11": -1.0069999999999997, "red_v41": -0.5313067621838278, "red_v53": 0.5026932378152034, "red_v15": 0.4981030335440551, "red_v73": -2.013, "red_v76": -0.55, "red_v19": 1.4976932378161705, "red_v83": -2.002, "red_v16": 0.5066925427729421, "red_v18": -1.0159999999999996, "red_v30": -1.0019999999999998, "red_v79": -2.002, "red_v17": -2.029, "red_v85": -2.0069999999999997, "red_v26": 3.397399908544055, "red_v20": -0.15499999999999958}, "policy_reward_mean": {"red_v69": -2.001, "red": 3.1450462324624677, "blue": -1.249020833333333, "red_v7": -2.0039999999999996, "red_v13": -1.5229999999999992, "red_v84": 0.5056932378161698, "red_v81": -1.3817499999999998, "red_v71": -2.008, "red_v50": -2.023999999999999, "red_v91": -2.0064999999999995, "red_v77": -0.563, "red_v75": -0.0016537286135289708, "red_v45": -1.001, "red_v27": -1.0249999999999992, "red_v63": 0.32160778963601505, "red_v31": 0.993846618908085, "red_v43": 0.5026932378152035, "red_v22": -0.543, "red_v74": 1.9237968749999999, "red_v52": 1.5026932378161701, "red_v28": -1.007, "red_v86": -2.0039999999999996, "red_v29": 0.8530000000000001, "red_v44": -1.0159999999999987, "red_v58": -2.005, "red_v65": -0.5829999999999999, "red_v11": -1.0069999999999997, "red_v41": -1.025653381091914, "red_v53": 0.5026932378152034, "red_v15": 0.3355765167720277, "red_v73": -2.013, "red_v76": -0.55, "red_v19": 1.4976932378161705, "red_v83": -2.002, "red_v16": 0.5066925427729421, "red_v18": -1.0159999999999996, "red_v30": -1.0019999999999998, "red_v79": -2.002, "red_v17": -2.029, "red_v85": -2.0069999999999997, "red_v26": 3.397399908544055, "red_v20": -0.15499999999999958}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.8435625000000001, 1.4524581677729431, 1.6652062500000002, 2.4659814894425924, 2.47470886281617, 1.4579744878161707, 0.9264744878161725, 0.9514936585440571, 3.97715210063234, 1.1648, 1.9821151128161705, 1.940615112816172, 1.950490112816171, 0.9825249085440553, 2.4587627394425926, 2.4915561585440553, 1.1618000000000004, 2.9187869878161714, 2.4538338628161718, 2.963677612816171, 0.8279375, 2.48378698781617, 1.4713026128152038, 1.1689093750000004, 0.8257500000000001, 1.9714901128161706, 2.443240112816172, 1.9561619878161702, 1.3647962713602904, 2.4577869878161707, 2.48452136281617, 2.4841151128161707, 3.9861052256313734, -1.9979999999998959, 2.990853033544055, 1.9724901128161703, 4.463667725632342, 2.4563494878161714, 2.4743026128161705, 2.49103698781617, 3.4627557378161704, 1.6652062500000007, 2.8973651128161757, 2.47670886281617, 1.9234901128161717, 2.483743658544055, 2.48292761281617, 2.4491307378161706, 2.47711511281617, 4.48788647563234, 2.37873673, 0.8387500000000001, 3.84352136281617, 2.4534276128161716, 1.161503125, 3.8306307378161697, 1.9829276128152038, 2.8749242300000004, 1.4699814894425922, 1.4744901128161707, 1.9685249085440557, 2.4828182378161703, 1.171315625, 2.9243651128161723, 1.97116198781617, 2.347021362816175, 0.901224487816174, 2.484630737815204, 3.985886475631373, 3.9781087713602243, 1.16139375, 3.651649487816171, 1.97652136281617, 2.379033605, 2.8864744878161717, 4.471152100632341, 1.4787869878161701, 2.481926917772942, 3.981042030589112, 2.423693237816173, 2.429840864442592, 2.419481489442594, 1.4842244878161703, 2.4660838628161708, 4.965557655589113, 2.454505737816171, 1.4907436585440554, 1.4802244878161703, 2.4656776128161706, 1.15939375, 3.3607614756323456, 2.471490112816171, 1.951786987815204, 0.8618929800000004, 2.3767869878161716, 1.4346463628161719, 0.8314531250000002, 2.8360931463602324, 2.4647557378161706, 3.3337088628161706], "episode_lengths": [12, 43, 14, 17, 27, 38, 70, 35, 43, 16, 25, 57, 33, 25, 23, 15, 16, 34, 51, 37, 20, 34, 29, 13, 16, 33, 49, 42, 1280, 34, 23, 25, 26, 1280, 16, 33, 38, 46, 29, 18, 44, 14, 73, 27, 97, 19, 21, 52, 25, 32, 15, 16, 23, 53, 15, 20, 21, 19, 17, 33, 25, 24, 11, 73, 42, 119, 86, 20, 32, 28, 18, 30, 23, 16, 70, 43, 34, 21, 46, 64, 30, 49, 22, 35, 41, 60, 19, 22, 37, 18, 136, 33, 34, 29, 162, 47, 15, 129, 44, 27], "policy_red_v69_reward": [-2.001], "policy_blue_reward": [-2.012999999999999, -1.0109999999999995, -1.011, -2.0139999999999993, -1.5199999999999998, -2.0169999999999986, -1.504, -1.0079999999999998, -1.0039999999999998, -1.015999999999999, -0.014000000000000002, -2.0069999999999997, -2.005, -2.011999999999999, -0.517, -1.003, -1.0069999999999992, -0.006, -2.0079999999999996, -1.0169999999999986, -1.0099999999999998, -1.0039999999999998, 0.488, -2.006, -1.009, -1.005, -1.0099999999999998, -1.0179999999999998, -1.0079999999999996, -2.005, -0.005, -2.005, -2.0109999999999992, -2.011, -2.004, -0.01900000000000001, -2.002, -1.0069999999999997, -1.0059999999999996, -1.0059999999999993, -1.0159999999999987, -1.008, -2.0089999999999995, -2.0039999999999996, -1.0079999999999993, -1.013999999999999, -1.5070000000000001, -1.0099999999999993], "policy_red_v7_reward": [-2.0039999999999996], "policy_red_v13_reward": [-1.5229999999999992], "policy_red_v84_reward": [0.5056932378161698], "policy_red_v81_reward": [-2.003, -2.003, -0.51, -1.0109999999999988], "policy_red_v71_reward": [-2.008], "policy_red_v50_reward": [-2.023999999999999], "policy_red_v91_reward": [-2.0039999999999996, -2.0089999999999995], "policy_red_v77_reward": [-0.563], "policy_red_v75_reward": [-2.0039999999999996, 2.0006925427729416], "policy_red_v45_reward": [-1.001], "policy_red_v27_reward": [-1.0249999999999992], "policy_red_v63_reward": [0.5421030335440605, -0.5810000000000008, 2.3513281249999998, -1.0259999999999991], "policy_red_v31_reward": [0.488, 1.49969323781617], "policy_red_v43_reward": [0.5026932378152035], "policy_red_v22_reward": [-0.543], "policy_red_v74_reward": [1.9237968749999999], "policy_red_v52_reward": [1.5026932378161701], "policy_red_v28_reward": [-1.007], "policy_red_v86_reward": [-2.0039999999999996], "policy_red_v29_reward": [0.8530000000000001], "policy_red_v44_reward": [-1.0159999999999987], "policy_red_v58_reward": [-2.005], "policy_red_v65_reward": [0.841, -2.0069999999999997], "policy_red_v11_reward": [-1.0069999999999997], "policy_red_v41_reward": [-1.52, -0.5313067621838278], "policy_red_v53_reward": [0.5026932378152034], "policy_red_v15_reward": [0.4981030335440551, 0.17305000000000026], "policy_red_v73_reward": [-2.013], "policy_red_v76_reward": [-0.55], "policy_red_v19_reward": [1.4976932378161705], "policy_red_v83_reward": [-2.002], "policy_red_v16_reward": [0.5066925427729421], "policy_red_v18_reward": [-1.0159999999999996], "policy_red_v30_reward": [-1.0019999999999998], "policy_red_v79_reward": [-2.002], "policy_red_v17_reward": [-2.029], "policy_red_v85_reward": [-2.0069999999999997], "policy_red_v26_reward": [3.397399908544055], "policy_red_v20_reward": [-0.15499999999999958]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8282427167331738, "mean_inference_ms": 7.697368802185139, "mean_action_processing_ms": 0.2940427248093732, "mean_env_wait_ms": 0.3946085137146016, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10089540481567383, "StateBufferConnector_ms": 0.004213809967041016, "ViewRequirementAgentConnector_ms": 0.11605024337768555}}, "episode_reward_max": 4.965557655589113, "episode_reward_min": -1.9979999999998959, "episode_reward_mean": 2.244216419721363, "episode_len_mean": 61.65, "episodes_this_iter": 60, "policy_reward_min": {"red_v69": -2.001, "red": -1.4169999999999585, "blue": -2.0169999999999986, "red_v7": -2.0039999999999996, "red_v13": -1.5229999999999992, "red_v84": 0.5056932378161698, "red_v81": -2.003, "red_v71": -2.008, "red_v50": -2.023999999999999, "red_v91": -2.0089999999999995, "red_v77": -0.563, "red_v75": -2.0039999999999996, "red_v45": -1.001, "red_v27": -1.0249999999999992, "red_v63": -1.0259999999999991, "red_v31": 0.488, "red_v43": 0.5026932378152035, "red_v22": -0.543, "red_v74": 1.9237968749999999, "red_v52": 1.5026932378161701, "red_v28": -1.007, "red_v86": -2.0039999999999996, "red_v29": 0.8530000000000001, "red_v44": -1.0159999999999987, "red_v58": -2.005, "red_v65": -2.0069999999999997, "red_v11": -1.0069999999999997, "red_v41": -1.52, "red_v53": 0.5026932378152034, "red_v15": 0.17305000000000026, "red_v73": -2.013, "red_v76": -0.55, "red_v19": 1.4976932378161705, "red_v83": -2.002, "red_v16": 0.5066925427729421, "red_v18": -1.0159999999999996, "red_v30": -1.0019999999999998, "red_v79": -2.002, "red_v17": -2.029, "red_v85": -2.0069999999999997, "red_v26": 3.397399908544055, "red_v20": -0.15499999999999958}, "policy_reward_max": {"red_v69": -2.001, "red": 3.99011511281617, "blue": 0.488, "red_v7": -2.0039999999999996, "red_v13": -1.5229999999999992, "red_v84": 0.5056932378161698, "red_v81": -0.51, "red_v71": -2.008, "red_v50": -2.023999999999999, "red_v91": -2.0039999999999996, "red_v77": -0.563, "red_v75": 2.0006925427729416, "red_v45": -1.001, "red_v27": -1.0249999999999992, "red_v63": 2.3513281249999998, "red_v31": 1.49969323781617, "red_v43": 0.5026932378152035, "red_v22": -0.543, "red_v74": 1.9237968749999999, "red_v52": 1.5026932378161701, "red_v28": -1.007, "red_v86": -2.0039999999999996, "red_v29": 0.8530000000000001, "red_v44": -1.0159999999999987, "red_v58": -2.005, "red_v65": 0.841, "red_v11": -1.0069999999999997, "red_v41": -0.5313067621838278, "red_v53": 0.5026932378152034, "red_v15": 0.4981030335440551, "red_v73": -2.013, "red_v76": -0.55, "red_v19": 1.4976932378161705, "red_v83": -2.002, "red_v16": 0.5066925427729421, "red_v18": -1.0159999999999996, "red_v30": -1.0019999999999998, "red_v79": -2.002, "red_v17": -2.029, "red_v85": -2.0069999999999997, "red_v26": 3.397399908544055, "red_v20": -0.15499999999999958}, "policy_reward_mean": {"red_v69": -2.001, "red": 3.1450462324624677, "blue": -1.249020833333333, "red_v7": -2.0039999999999996, "red_v13": -1.5229999999999992, "red_v84": 0.5056932378161698, "red_v81": -1.3817499999999998, "red_v71": -2.008, "red_v50": -2.023999999999999, "red_v91": -2.0064999999999995, "red_v77": -0.563, "red_v75": -0.0016537286135289708, "red_v45": -1.001, "red_v27": -1.0249999999999992, "red_v63": 0.32160778963601505, "red_v31": 0.993846618908085, "red_v43": 0.5026932378152035, "red_v22": -0.543, "red_v74": 1.9237968749999999, "red_v52": 1.5026932378161701, "red_v28": -1.007, "red_v86": -2.0039999999999996, "red_v29": 0.8530000000000001, "red_v44": -1.0159999999999987, "red_v58": -2.005, "red_v65": -0.5829999999999999, "red_v11": -1.0069999999999997, "red_v41": -1.025653381091914, "red_v53": 0.5026932378152034, "red_v15": 0.3355765167720277, "red_v73": -2.013, "red_v76": -0.55, "red_v19": 1.4976932378161705, "red_v83": -2.002, "red_v16": 0.5066925427729421, "red_v18": -1.0159999999999996, "red_v30": -1.0019999999999998, "red_v79": -2.002, "red_v17": -2.029, "red_v85": -2.0069999999999997, "red_v26": 3.397399908544055, "red_v20": -0.15499999999999958}, "hist_stats": {"episode_reward": [0.8435625000000001, 1.4524581677729431, 1.6652062500000002, 2.4659814894425924, 2.47470886281617, 1.4579744878161707, 0.9264744878161725, 0.9514936585440571, 3.97715210063234, 1.1648, 1.9821151128161705, 1.940615112816172, 1.950490112816171, 0.9825249085440553, 2.4587627394425926, 2.4915561585440553, 1.1618000000000004, 2.9187869878161714, 2.4538338628161718, 2.963677612816171, 0.8279375, 2.48378698781617, 1.4713026128152038, 1.1689093750000004, 0.8257500000000001, 1.9714901128161706, 2.443240112816172, 1.9561619878161702, 1.3647962713602904, 2.4577869878161707, 2.48452136281617, 2.4841151128161707, 3.9861052256313734, -1.9979999999998959, 2.990853033544055, 1.9724901128161703, 4.463667725632342, 2.4563494878161714, 2.4743026128161705, 2.49103698781617, 3.4627557378161704, 1.6652062500000007, 2.8973651128161757, 2.47670886281617, 1.9234901128161717, 2.483743658544055, 2.48292761281617, 2.4491307378161706, 2.47711511281617, 4.48788647563234, 2.37873673, 0.8387500000000001, 3.84352136281617, 2.4534276128161716, 1.161503125, 3.8306307378161697, 1.9829276128152038, 2.8749242300000004, 1.4699814894425922, 1.4744901128161707, 1.9685249085440557, 2.4828182378161703, 1.171315625, 2.9243651128161723, 1.97116198781617, 2.347021362816175, 0.901224487816174, 2.484630737815204, 3.985886475631373, 3.9781087713602243, 1.16139375, 3.651649487816171, 1.97652136281617, 2.379033605, 2.8864744878161717, 4.471152100632341, 1.4787869878161701, 2.481926917772942, 3.981042030589112, 2.423693237816173, 2.429840864442592, 2.419481489442594, 1.4842244878161703, 2.4660838628161708, 4.965557655589113, 2.454505737816171, 1.4907436585440554, 1.4802244878161703, 2.4656776128161706, 1.15939375, 3.3607614756323456, 2.471490112816171, 1.951786987815204, 0.8618929800000004, 2.3767869878161716, 1.4346463628161719, 0.8314531250000002, 2.8360931463602324, 2.4647557378161706, 3.3337088628161706], "episode_lengths": [12, 43, 14, 17, 27, 38, 70, 35, 43, 16, 25, 57, 33, 25, 23, 15, 16, 34, 51, 37, 20, 34, 29, 13, 16, 33, 49, 42, 1280, 34, 23, 25, 26, 1280, 16, 33, 38, 46, 29, 18, 44, 14, 73, 27, 97, 19, 21, 52, 25, 32, 15, 16, 23, 53, 15, 20, 21, 19, 17, 33, 25, 24, 11, 73, 42, 119, 86, 20, 32, 28, 18, 30, 23, 16, 70, 43, 34, 21, 46, 64, 30, 49, 22, 35, 41, 60, 19, 22, 37, 18, 136, 33, 34, 29, 162, 47, 15, 129, 44, 27], "policy_red_v69_reward": [-2.001], "policy_blue_reward": [-2.012999999999999, -1.0109999999999995, -1.011, -2.0139999999999993, -1.5199999999999998, -2.0169999999999986, -1.504, -1.0079999999999998, -1.0039999999999998, -1.015999999999999, -0.014000000000000002, -2.0069999999999997, -2.005, -2.011999999999999, -0.517, -1.003, -1.0069999999999992, -0.006, -2.0079999999999996, -1.0169999999999986, -1.0099999999999998, -1.0039999999999998, 0.488, -2.006, -1.009, -1.005, -1.0099999999999998, -1.0179999999999998, -1.0079999999999996, -2.005, -0.005, -2.005, -2.0109999999999992, -2.011, -2.004, -0.01900000000000001, -2.002, -1.0069999999999997, -1.0059999999999996, -1.0059999999999993, -1.0159999999999987, -1.008, -2.0089999999999995, -2.0039999999999996, -1.0079999999999993, -1.013999999999999, -1.5070000000000001, -1.0099999999999993], "policy_red_v7_reward": [-2.0039999999999996], "policy_red_v13_reward": [-1.5229999999999992], "policy_red_v84_reward": [0.5056932378161698], "policy_red_v81_reward": [-2.003, -2.003, -0.51, -1.0109999999999988], "policy_red_v71_reward": [-2.008], "policy_red_v50_reward": [-2.023999999999999], "policy_red_v91_reward": [-2.0039999999999996, -2.0089999999999995], "policy_red_v77_reward": [-0.563], "policy_red_v75_reward": [-2.0039999999999996, 2.0006925427729416], "policy_red_v45_reward": [-1.001], "policy_red_v27_reward": [-1.0249999999999992], "policy_red_v63_reward": [0.5421030335440605, -0.5810000000000008, 2.3513281249999998, -1.0259999999999991], "policy_red_v31_reward": [0.488, 1.49969323781617], "policy_red_v43_reward": [0.5026932378152035], "policy_red_v22_reward": [-0.543], "policy_red_v74_reward": [1.9237968749999999], "policy_red_v52_reward": [1.5026932378161701], "policy_red_v28_reward": [-1.007], "policy_red_v86_reward": [-2.0039999999999996], "policy_red_v29_reward": [0.8530000000000001], "policy_red_v44_reward": [-1.0159999999999987], "policy_red_v58_reward": [-2.005], "policy_red_v65_reward": [0.841, -2.0069999999999997], "policy_red_v11_reward": [-1.0069999999999997], "policy_red_v41_reward": [-1.52, -0.5313067621838278], "policy_red_v53_reward": [0.5026932378152034], "policy_red_v15_reward": [0.4981030335440551, 0.17305000000000026], "policy_red_v73_reward": [-2.013], "policy_red_v76_reward": [-0.55], "policy_red_v19_reward": [1.4976932378161705], "policy_red_v83_reward": [-2.002], "policy_red_v16_reward": [0.5066925427729421], "policy_red_v18_reward": [-1.0159999999999996], "policy_red_v30_reward": [-1.0019999999999998], "policy_red_v79_reward": [-2.002], "policy_red_v17_reward": [-2.029], "policy_red_v85_reward": [-2.0069999999999997], "policy_red_v26_reward": [3.397399908544055], "policy_red_v20_reward": [-0.15499999999999958]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8282427167331738, "mean_inference_ms": 7.697368802185139, "mean_action_processing_ms": 0.2940427248093732, "mean_env_wait_ms": 0.3946085137146016, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.10089540481567383, "StateBufferConnector_ms": 0.004213809967041016, "ViewRequirementAgentConnector_ms": 0.11605024337768555}, "num_healthy_workers": 40, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.5080584901531, "num_env_steps_trained_throughput_per_sec": 199.5080584901531, "timesteps_total": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 20238.231, "sample_time_ms": 1254.268, "learn_time_ms": 18899.631, "learn_throughput": 211.644, "synch_weights_time_ms": 80.682}, "counters": {"num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "episodes_total": 3488, "training_iteration": 132, "trial_id": "a9680_00000", "date": "2023-09-24_03-26-35", "timestamp": 1695540395, "time_this_iter_s": 20.061598300933838, "time_total_s": 2635.762313604355, "pid": 730621, "hostname": "str-lin-3397", "node_ip": "10.1.60.66", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTCE-2v2", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "death_match": true, "teams": {"blue": 2, "red": 2}, "agents": 4, "training_scheme": "CTCE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_1": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "policies_map": {"red": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x7f1b1da6a3e0>"}, "team_policies_mapping": {"red": "your_policy_name"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 2, "red": 2}, "training_scheme": "CTCE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue": [null, null, null, null], "red": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7f1b1dbe0160>", "policies_to_train": ["red"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x7f1b1dbe00d0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 40}, "time_since_restore": 2635.762313604355, "iterations_since_restore": 132, "perf": {"cpu_util_percent": 6.197297297297299, "ram_util_percent": 28.589189189189188}, "win_rate": 0.82, "league_size": 101}
